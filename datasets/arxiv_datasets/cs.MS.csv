Title,ID,Published,Updated,Summary,Author,Comments,Journal_Ref,Link,Primary_Category,Categories,DOI,License,Affiliation
"Scalable Automated Verification for Cyber-Physical Systems in
  Isabelle/HOL",http://arxiv.org/abs/2401.12061v1,2024-01-22T15:54:47Z,2024-01-22T15:54:47Z,"  We formally introduce IsaVODEs (Isabelle verification with Ordinary
Differential Equations), a framework for the verification of cyber-physical
systems. We describe the semantic foundations of the framework's formalisation
in the Isabelle/HOL proof assistant. A user-friendly language specification
based on a robust state model makes our framework flexible and adaptable to
various engineering workflows. New additions to the framework increase both its
expressivity and proof automation. Specifically, formalisations related to
forward diamond correctness specifications, certification of unique solutions
to ordinary differential equations (ODEs) as flows, and invariant reasoning for
systems of ODEs contribute to the framework's scalability and usability.
Various examples and an evaluation validate the effectiveness of our framework.
","['\nJonathan Julián Huerta y Munive\n', '\nSimon Foster\n', '\nMario Gleirscher\n', '\nGeorg Struth\n', '\nChristian Pardillo Laursen\n', '\nThomas Hickman\n']",Submitted to the Journal of Automated Reasoning,,http://arxiv.org/abs/2401.12061v1,cs.LO,"['cs.LO', 'cs.MS']",,,[]
"LongMemory.jl: Generating, Estimating, and Forecasting Long Memory
  Models in Julia",http://arxiv.org/abs/2401.14077v1,2024-01-25T10:55:38Z,2024-01-25T10:55:38Z,"  LongMemory.jl is a package for time series long memory modelling in Julia.
The package provides functions to generate long memory, estimate model
parameters, and forecast. Generating methods include fractional differencing,
stochastic error duration, and cross-sectional aggregation. Estimators include
the classic ones used to estimate the Hurst effect, those inspired by
log-periodogram regression, and parametric ones. Forecasting is provided for
all parametric estimators. Moreover, the package adds plotting capabilities to
illustrate long memory dynamics and forecasting. This article presents the
theoretical developments for long memory modelling, show examples using the
data included with the package, and compares the properties of LongMemory.jl
with current alternatives, including benchmarks. For some of the theoretical
developments, LongMemory.jl provides the first publicly available
implementation in any programming language. A notable feature of this package
is that all functions are implemented in the same programming language, taking
advantage of the ease of use and speed provided by Julia. Therefore, all code
is accessible to the user. Multiple dispatch, a novel feature of the language,
is used to speed computations and provide consistent calls to related methods.
The package is related to the R packages LongMemoryTS and fracdiff.
",['\nJ. Eduardo Vera-Valdés\n'],,,http://arxiv.org/abs/2401.14077v1,cs.MS,"['cs.MS', 'stat.CO']",,,[]
"Reproducibility, energy efficiency and performance of pseudorandom
  number generators in machine learning: a comparative study of python, numpy,
  tensorflow, and pytorch implementations",http://arxiv.org/abs/2401.17345v2,2024-01-30T15:44:14Z,2024-02-10T12:09:18Z,"  Pseudo-Random Number Generators (PRNGs) have become ubiquitous in machine
learning technologies because they are interesting for numerous methods. The
field of machine learning holds the potential for substantial advancements
across various domains, as exemplified by recent breakthroughs in Large
Language Models (LLMs). However, despite the growing interest, persistent
concerns include issues related to reproducibility and energy consumption.
Reproducibility is crucial for robust scientific inquiry and explainability,
while energy efficiency underscores the imperative to conserve finite global
resources. This study delves into the investigation of whether the leading
Pseudo-Random Number Generators (PRNGs) employed in machine learning languages,
libraries, and frameworks uphold statistical quality and numerical
reproducibility when compared to the original C implementation of the
respective PRNG algorithms. Additionally, we aim to evaluate the time
efficiency and energy consumption of various implementations. Our experiments
encompass Python, NumPy, TensorFlow, and PyTorch, utilizing the Mersenne
Twister, PCG, and Philox algorithms. Remarkably, we verified that the temporal
performance of machine learning technologies closely aligns with that of
C-based implementations, with instances of achieving even superior
performances. On the other hand, it is noteworthy that ML technologies consumed
only 10% more energy than their C-implementation counterparts. However, while
statistical quality was found to be comparable, achieving numerical
reproducibility across different platforms for identical seeds and algorithms
was not achieved.
","['\nBenjamin Antunes\n', '\nDavid R. C Hill\n']","20 pages, 10 tables, 1 figure",,http://arxiv.org/abs/2401.17345v2,cs.MS,"['cs.MS', 'cs.LG']",,,[]
"Sphractal: Estimating the Fractal Dimension of Surfaces Computed from
  Precise Atomic Coordinates via Box-Counting Algorithm",http://arxiv.org/abs/2401.11737v1,2024-01-22T07:29:22Z,2024-01-22T07:29:22Z,"  The fractal dimension of a surface allows its degree of roughness to be
characterised quantitatively. However, limited effort has been attempted to
compute the fractal dimension of surfaces computed from precisely known atomic
coordinates from computational biomolecular and nanomaterial studies. This work
proposes methods to estimate the fractal dimension of the surface of any
three-dimensional object composed of spheres, by representing it as either a
voxelised point cloud or a mathematically exact surface, and computing its
box-counting dimension. Sphractal is published as a Python package that
provides these functionalities, and its utility is demonstrated on a set of
simulated palladium nanoparticle data.
","['\nJonathan Yik Chang Ting\n', '\nAndrew Thomas Agars Wood\n', '\nAmanda Susan Barnard\n']","46 pages, 26 figures, submitted to Advanced Theory and Simulations",,http://arxiv.org/abs/2401.11737v1,cs.MS,"['cs.MS', 'physics.atom-ph', 'physics.comp-ph']",,,[]
Open Source Prover in the Attic,http://arxiv.org/abs/2401.13702v1,2024-01-22T12:50:29Z,2024-01-22T12:50:29Z,"  The well known JGEX program became open source a few years ago, but
seemingly, further development of the program can only be done without the
original authors. In our project, we are looking at whether it is possible to
continue such a large project as a newcomer without the involvement of the
original authors. Is there a way to internationalize, fix bugs, improve the
code base, add new features? In other words, to save a relic found in the attic
and polish it into a useful everyday tool.
","['\nZoltán Kovács\nThe Private University College of Education of the Diocese of Linz, Austria\n', '\nAlexander Vujic\nThe Private University College of Education of the Diocese of Linz, Austria\n']","In Proceedings ADG 2023, arXiv:2401.10725","EPTCS 398, 2024, pp. 53-61",http://dx.doi.org/10.4204/EPTCS.398.9,cs.PL,"['cs.PL', 'cs.MS', 'cs.SC', 'cs.SE']",10.4204/EPTCS.398.9,,"['The Private University College of Education of the Diocese of Linz, Austria', 'The Private University College of Education of the Diocese of Linz, Austria']"
Evaluation of POSIT Arithmetic with Accelerators,http://arxiv.org/abs/2401.14117v1,2024-01-25T11:54:44Z,2024-01-25T11:54:44Z,"  We present an evaluation of 32-bit POSIT arithmetic through its
implementation as accelerators on FPGAs and GPUs. POSIT, a floating-point
number format, adaptively changes the size of its fractional part. We developed
hardware designs for FPGAs and software for GPUs to accelerate linear algebra
operations using Posit(32,2) arithmetic. Our FPGA- and GPU-based accelerators
in Posit(32,2) arithmetic significantly accelerated the Cholesky and LU
decomposition algorithms for dense matrices. In terms of numerical accuracy,
Posit(32,2) arithmetic is approximately 0.5 - 1.0 digits more accurate than the
standard 32-bit format, especially when the norm of the elements of the input
matrix is close to 1. Evaluating power consumption, we observed that the power
efficiency of the accelerators ranged between 0.043 - 0.076 Gflops/watts for
the LU decomposition in Posit(32,2) arithmetic. The power efficiency of the
latest GPUs as accelerators of Posit(32,2) arithmetic is better than that of
the evaluated FPGA chip.
","['\nNaohito Nakasato\n', '\nYuki Murakami\n', '\nFumiya Kono\n', '\nMaho Nakata\n']","11 pages, 8 figures; Published in HPCAsia '24: Proceedings of the
  International Conference on High Performance Computing in Asia-Pacific Region","HPCAsia '24: Proceedings of the International Conference on High
  Performance Computing in Asia-Pacific Region, January 2024, Pages 62-72",http://dx.doi.org/10.1145/3635035.3635046,cs.DC,"['cs.DC', 'cs.AR', 'cs.MS']",10.1145/3635035.3635046,,[]
"Mixed-Order Meshes through rp-adaptivity for Surface Fitting to Implicit
  Geometries",http://arxiv.org/abs/2401.16369v1,2024-01-29T18:10:01Z,2024-01-29T18:10:01Z,"  Computational analysis with the finite element method requires geometrically
accurate meshes. It is well known that high-order meshes can accurately capture
curved surfaces with fewer degrees of freedom in comparison to low-order
meshes. Existing techniques for high-order mesh generation typically output
meshes with same polynomial order for all elements. However, high order
elements away from curvilinear boundaries or interfaces increase the
computational cost of the simulation without increasing geometric accuracy. In
prior work, we have presented one such approach for generating body-fitted
uniform-order meshes that takes a given mesh and morphs it to align with the
surface of interest prescribed as the zero isocontour of a level-set function.
We extend this method to generate mixed-order meshes such that curved surfaces
of the domain are discretized with high-order elements, while low-order
elements are used elsewhere. Numerical experiments demonstrate the robustness
of the approach and show that it can be used to generate mixed-order meshes
that are much more efficient than high uniform-order meshes. The proposed
approach is purely algebraic, and extends to different types of elements
(quadrilaterals/triangles/tetrahedron/hexahedra) in two- and three-dimensions.
","['\nKetan Mittal\n', '\nVeselin A. Dobrev\n', '\nPatrick Knupp\n', '\nTzanio Kolev\n', '\nFranck Ledoux\n', '\nClaire Roche\n', '\nVladimir Z. Tomov\n']","14 pages, 11 figures",,http://arxiv.org/abs/2401.16369v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Rigorous Error Analysis for Logarithmic Number Systems,http://arxiv.org/abs/2401.17184v1,2024-01-30T17:12:56Z,2024-01-30T17:12:56Z,"  Logarithmic Number Systems (LNS) hold considerable promise in helping reduce
the number of bits needed to represent a high dynamic range of real-numbers
with finite precision, and also efficiently support multiplication and
division. However, under LNS, addition and subtraction turn into non-linear
functions that must be approximated - typically using precomputed table-based
functions. Additionally, multiple layers of error correction are typically
needed to improve result accuracy. Unfortunately, previous efforts have not
characterized the resulting error bound. We provide the first rigorous analysis
of LNS, covering detailed techniques such as co-transformation that are crucial
to implementing subtraction with reasonable accuracy. We provide theorems
capturing the error due to table interpolations, the finite precision of
pre-computed values in the tables, and the error introduced by fix-point
multiplications involved in LNS implementations. We empirically validate our
analysis using a Python implementation, showing that our analytical bounds are
tight, and that our testing campaign generates inputs diverse-enough to almost
match (but not exceed) the analytical bounds. We close with discussions on how
to adapt our analysis to LNS systems with different bases and also discuss many
pragmatic ramifications of our work in the broader arena of scientific
computing and machine learning.
","['\nThanh Son Nguyen\n', '\nAlexey Solovyev\n', '\nGanesh Gopalakrishnan\n']","42 pages, 14 figures, 6 tables",,http://arxiv.org/abs/2401.17184v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65G50', 'G.1']",,,[]
Efficient N-to-M Checkpointing Algorithm for Finite Element Simulations,http://arxiv.org/abs/2401.05868v1,2024-01-11T12:20:50Z,2024-01-11T12:20:50Z,"  In this work, we introduce a new algorithm for N-to-M checkpointing in finite
element simulations. This new algorithm allows efficient saving/loading of
functions representing physical quantities associated with the mesh
representing the physical domain. Specifically, the algorithm allows for using
different numbers of parallel processes for saving and loading, allowing for
restarting and post-processing on the process count appropriate to the given
phase of the simulation and other conditions. For demonstration, we implemented
this algorithm in PETSc, the Portable, Extensible Toolkit for Scientific
Computation, and added a convenient high-level interface into Firedrake, a
system for solving partial differential equations using finite element methods.
We evaluated our new implementation by saving and loading data involving 8.2
billion finite element degrees of freedom using 8,192 parallel processes on
ARCHER2, the UK National Supercomputing Service.
","['\nDavid A. Ham\n', '\nVaclav Hapla\n', '\nMatthew G. Knepley\n', '\nLawrence Mitchell\n', '\nKoki Sagiyama\n']",,,http://arxiv.org/abs/2401.05868v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Approximations of the integral of a class of sinusoidal composite
  functions",http://arxiv.org/abs/2401.08080v1,2024-01-16T03:13:02Z,2024-01-16T03:13:02Z,"  Two approximations of the integral of a class of sinusoidal composite
functions, for which an explicit form does not exist, are derived. Numerical
experiments show that the proposed approximations yield an error that does not
depend on the width of the integration interval. Using such approximations,
definite integrals can be computed in almost real-time.
",['\nAlberto Costa\n'],,,http://arxiv.org/abs/2401.08080v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Proceedings 14th International Conference on Automated Deduction in
  Geometry",http://arxiv.org/abs/2401.10725v1,2024-01-19T14:42:08Z,2024-01-19T14:42:08Z,"  ADG is a forum to exchange ideas and views, to present research results and
progress, and to demonstrate software tools at the intersection between
geometry and automated deduction. The conference is held every two years. The
previous editions of ADG were held in Hagenberg in 2021 (online, postponed from
2020 due to COVID-19), Nanning in 2018, Strasbourg in 2016, Coimbra in 2014,
Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,
Gainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and
Toulouse in 1996.
  The 14th edition, ADG 2023, was held in Belgrade, Serbia, in September 20-22,
2023. This edition of ADG had an additional special focus topic, Deduction in
Education.
  Invited Speakers: Julien Narboux, University of Strasbourg, France
""Formalisation, arithmetization and automatisation of geometry""; Filip Mari\'c,
University of Belgrade, Serbia, ""Automatization, formalization and
visualization of hyperbolic geometry""; Zlatan Magajna, University of Ljubljana,
Slovenia, ""Workshop OK Geometry""
","['\nPedro Quaresma\nUniversity of Coimbra, Portugal\n', '\nZoltán Kovács\nThe Private University College of Education of the Diocese of Linz, Austria\n']",,"EPTCS 398, 2024",http://dx.doi.org/10.4204/EPTCS.398,cs.LO,"['cs.LO', 'cs.AI', 'cs.CG', 'cs.MS']",10.4204/EPTCS.398,,"['University of Coimbra, Portugal', 'The Private University College of Education of the Diocese of Linz, Austria']"
"Toward a comprehensive simulation framework for hypergraphs: a
  Python-base approach",http://arxiv.org/abs/2401.03917v1,2024-01-08T14:24:54Z,2024-01-08T14:24:54Z,"  Hypergraphs, or generalization of graphs such that edges can contain more
than two nodes, have become increasingly prominent in understanding complex
network analysis. Unlike graphs, hypergraphs have relatively few supporting
platforms, and such dearth presents a barrier to more widespread adaptation of
hypergraph computational toolboxes that could enable further research in
several areas. Here, we introduce HyperRD, a Python package for hypergraph
computation, simulation, and interoperability with other powerful Python
packages in graph and hypergraph research. Then, we will introduce two models
on hypergraph, the general Schelling's model and the SIR model, and simulate
them with HyperRD.
","['\nQuoc Chuong Nguyen\n', '\nTrung Kien Le\n']","13 pages, 3 figures",,http://arxiv.org/abs/2401.03917v1,cs.MS,['cs.MS'],,,[]
The Cytnx Library for Tensor Networks,http://arxiv.org/abs/2401.01921v1,2024-01-03T14:59:50Z,2024-01-03T14:59:50Z,"  We introduce a tensor network library designed for classical and quantum
physics simulations called Cytnx (pronounced as sci-tens). This library
provides almost an identical interface and syntax for both C++ and Python,
allowing users to effortlessly switch between two languages. Aiming at a quick
learning process for new users of tensor network algorithms, the interfaces
resemble the popular Python scientific libraries like NumPy, Scipy, and
PyTorch. Not only multiple global Abelian symmetries can be easily defined and
implemented, Cytnx also provides a new tool called Network that allows users to
store large tensor networks and perform tensor network contractions in an
optimal order automatically. With the integration of cuQuantum, tensor
calculations can also be executed efficiently on GPUs. We present benchmark
results for tensor operations on both devices, CPU and GPU. We also discuss
features and higher-level interfaces to be added in the future.
","['\nKai-Hsin Wu\n', '\nChang-Teng Lin\n', '\nKe Hsu\n', '\nHao-Ti Hung\n', '\nManuel Schneider\n', '\nChia-Min Chung\n', '\nYing-Jer Kao\n', '\nPochung Chen\n']",,,http://arxiv.org/abs/2401.01921v1,cs.MS,"['cs.MS', 'cond-mat.str-el']",,,[]
Using monodromy to recover symmetries of polynomial systems,http://arxiv.org/abs/2312.12685v1,2023-12-20T01:05:00Z,2023-12-20T01:05:00Z,"  Galois/monodromy groups attached to parametric systems of polynomial
equations provide a method for detecting the existence of symmetries in
solution sets. Beyond the question of existence, one would like to compute
formulas for these symmetries, towards the eventual goal of solving the systems
more efficiently. We describe and implement one possible approach to this task
using numerical homotopy continuation and multivariate rational function
interpolation. We describe additional methods that detect and exploit a priori
unknown quasi-homogeneous structure in symmetries. These methods extend the
range of interpolation to larger examples, including applications with
nonlinear symmetries drawn from vision and robotics.
","['\nTimothy Duff\n', '\nViktor Korotynskiy\n', '\nTomas Pajdla\n', '\nMargaret Regan\n']",Extended journal version of conference paper published at ISSAC 2023,,http://arxiv.org/abs/2312.12685v1,math.AG,"['math.AG', 'cs.MS']",,,[]
Strassen's Matrix Multiplication Algorithm Is Still Faster,http://arxiv.org/abs/2312.12732v1,2023-12-20T03:09:50Z,2023-12-20T03:09:50Z,"  Recently, reinforcement algorithms discovered new algorithms that really
jump-started a wave of excitements and a flourishing of publications. However,
there is little on implementations, applications, and, especially, no absolute
performance and, we show here they are not here to replace Strassen's original
fast matrix multiplication yet. We present Matrix Flow, this is a simple Python
project for the automatic formulation, design, implementation, code generation,
and execution of fast matrix multiplication algorithms for CPUs, using BLAS
interface GPUs, and in the future other accelerators. We shall not play with
module-2 (Z2) algorithms and, for simplicity, we present only square
double-precision matrices. By means of factorizing the operand matrices we can
express many algorithms and prove them correct. These algorithms are
represented by Data Flows and matrix data partitions: a Directed Acyclic Graph.
We show that Strassen's original algorithm is still the top choice even for
modern GPUs. We also address error analysis in double precision, because
integer computations are correct, always
","[""\nPaolo D'Alberto\n""]","8 pages, 2 images, mathematical software",,http://arxiv.org/abs/2312.12732v1,cs.MS,"['cs.MS', 'cs.PF', '97N80', 'G.4']",,,[]
MindOpt Adapter for CPLEX Benchmarking Performance Analysis,http://arxiv.org/abs/2312.13527v4,2023-12-21T01:59:33Z,2024-02-01T03:09:51Z,"  This report provides a comprehensive analysis of the performance of MindOpt
Adapter for CPLEX 12.9 in benchmark testing. CPLEX, recognized as a robust
Mixed Integer Programming (MIP) solver, has faced some scrutiny regarding its
performance on MIPLIB 2017 when configured to default settings. MindOpt Adapter
aims to enhance CPLEX's performance by automatically applying improved
configurations for solving optimization problems. Our testing demonstrates that
MindOpt Adapter for CPLEX yields successfully solved 232 of the 240 problems in
the MIPLIB 2017 benchmark set. This performance surpasses all the other solvers
in terms of the number of problems solved and the geometric mean of running
times. The report provides a comparison of the benchmark results against the
outcomes achieved by CPLEX under its default configuration.
","['\nMou Sun\n', '\nTao Li\n', '\nWotao Yin\n']",,,http://arxiv.org/abs/2312.13527v4,cs.MS,"['cs.MS', 'math.OC']",,,[]
Implementation of the Emulator-based Component Analysis,http://arxiv.org/abs/2312.12967v1,2023-12-20T12:14:25Z,2023-12-20T12:14:25Z,"  We present a PyTorch-powered implementation of the emulator-based component
analysis used for ill-posed numerical non-linear inverse problems, where an
approximate emulator for the forward problem is known. This emulator may be a
numerical model, an interpolating function, or a fitting function such as a
neural network. With the help of the emulator and a data set, the method seeks
dimensionality reduction by projection in the variable space so that maximal
variance of the target (response) values of the data is covered. The obtained
basis set for projection in the variable space defines a subspace of the
greatest response for the outcome of the forward problem. The method allows for
the reconstruction of the coordinates in this subspace for an approximate
solution to the inverse problem. We present an example of using the code
provided as a Python class.
","['\nAnton Vladyka\n', '\nEemeli A. Eronen\n', '\nJohannes Niskanen\n']",,,http://arxiv.org/abs/2312.12967v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Automated MPI code generation for scalable finite-difference solvers,http://arxiv.org/abs/2312.13094v1,2023-12-20T15:15:56Z,2023-12-20T15:15:56Z,"  Partial differential equations (PDEs) are crucial in modelling diverse
phenomena across scientific disciplines, including seismic and medical imaging,
computational fluid dynamics, image processing, and neural networks. Solving
these PDEs on a large scale is an intricate and time-intensive process that
demands careful tuning. This paper introduces automated code-generation
techniques specifically tailored for distributed memory parallelism (DMP) to
solve explicit finite-difference (FD) stencils at scale, a fundamental
challenge in numerous scientific applications. These techniques are implemented
and integrated into the Devito DSL and compiler framework, a well-established
solution for automating the generation of FD solvers based on a high-level
symbolic math input. Users benefit from modelling simulations at a high-level
symbolic abstraction and effortlessly harnessing HPC-ready distributed-memory
parallelism without altering their source code. This results in drastic
reductions both in execution time and developer effort. While the contributions
of this work are implemented and integrated within the Devito framework, the
DMP concepts and the techniques applied are generally applicable to any FD
solvers. A comprehensive performance evaluation of Devito's DMP via MPI
demonstrates highly competitive weak and strong scaling on the Archer2
supercomputer, demonstrating the effectiveness of the proposed approach in
meeting the demands of large-scale scientific simulations.
","['\nGeorge Bisbas\n', '\nRhodri Nelson\n', '\nMathias Louboutin\n', '\nPaul H. J. Kelly\n', '\nFabio Luporini\n', '\nGerard Gorman\n']","10 pages, 12 figures (18 pages with References and Appendix)",,http://arxiv.org/abs/2312.13094v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
"Efficient Implementation of Interior-Point Methods for Quantum Relative
  Entropy",http://arxiv.org/abs/2312.07438v1,2023-12-12T17:05:38Z,2023-12-12T17:05:38Z,"  Quantum Relative Entropy (QRE) programming is a recently popular and
challenging class of convex optimization problems with significant applications
in quantum computing and quantum information theory. We are interested in
modern interior point (IP) methods based on optimal self-concordant barriers
for the QRE cone. A range of theoretical and numerical challenges associated
with such barrier functions and the QRE cones have hindered the scalability of
IP methods. To address these challenges, we propose a series of numerical and
linear algebraic techniques and heuristics aimed at enhancing the efficiency of
gradient and Hessian computations for the self-concordant barrier function,
solving linear systems, and performing matrix-vector products. We also
introduce and deliberate about some interesting concepts related to QRE such as
symmetric quantum relative entropy (SQRE). We also introduce a two-phase method
for performing facial reduction that can significantly improve the performance
of QRE programming. Our new techniques have been implemented in the latest
version (DDS 2.2) of the software package DDS. In addition to handling QRE
constraints, DDS accepts any combination of several other conic and non-conic
convex constraints. Our comprehensive numerical experiments encompass several
parts including 1) a comparison of DDS 2.2 with Hypatia for the nearest
correlation matrix problem, 2) using DDS for combining QRE constraints with
various other constraint types, and 3) calculating the key rate for quantum key
distribution (QKD) channels and presenting results for several QKD protocols.
","['\nMehdi Karimi\n', '\nLevent Tuncel\n']",24 pages,,http://arxiv.org/abs/2312.07438v1,quant-ph,"['quant-ph', 'cs.MS', 'math.OC']",,,[]
"Performance of linear solvers in tensor-train format on current
  multicore architectures",http://arxiv.org/abs/2312.08006v1,2023-12-13T09:28:09Z,2023-12-13T09:28:09Z,"  In this paper we discuss the performance of solvers for low-rank linear
systems in the tensor-train format, also known as matrix-product states (MPS)
in physics. We focus on today's many-core CPU systems and the interplay of the
performance and the required linear algebra operations in this setting.
Specifically, we consider the tensor-train GMRES method, the modified
alternating linear scheme (MALS) and the alternating minimal energy (AMEn).
Based on the example of a simple non-symmetric system from discretizing a
multidimensional convection-diffusion equation in, e.g., $50^{10}$ grid points,
we illustrate the computational complexity of the three methods. This shows
that the projection to smaller sub-problems reduces the required number of
floating point operations by orders of magnitude: between GMRES and MALS, and
again between MALS and AMEn. All three methods require similar underlying
linear algebra operations (building blocks). We suggest several building block
improvements regarding orthogonalization steps, singular value decompositions,
and tensor contractions. In addition, we propose a simple generic
preconditioner in the tensor-train format based on a rank-1 approximation of
the operator. Combining all optimizations, we obtain roughly a 5x speedup over
the reference implementation for the fastest method (AMEn) on a current
multi-core CPU.
","['\nMelven Röhrig-Zöllner\n', '\nManuel Joey Becklas\n', '\nJonas Thies\n', '\nAchim Basermann\n']","22 pages, 8 figures, submitted to SISC",,http://arxiv.org/abs/2312.08006v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Lineax: unified linear solves and linear least-squares in JAX and
  Equinox",http://arxiv.org/abs/2311.17283v1,2023-11-28T23:50:08Z,2023-11-28T23:50:08Z,"  We introduce Lineax, a library bringing linear solves and linear
least-squares to the JAX+Equinox scientific computing ecosystem. Lineax uses
general linear operators, and unifies linear solves and least-squares into a
single, autodifferentiable API. Solvers and operators are user-extensible,
without requiring the user to implement any custom derivative rules to get
differentiability. Lineax is available at https://github.com/google/lineax.
","['\nJason Rader\n', '\nTerry Lyons\n', '\nPatrick Kidger\n']","7 pages, 1 figure, NeurIPS 2023 AI for Science workshop",,http://arxiv.org/abs/2311.17283v1,cs.MS,['cs.MS'],,,[]
Impact of parallel code optimization on computer power consumption,http://arxiv.org/abs/2312.03315v1,2023-12-06T06:48:16Z,2023-12-06T06:48:16Z,"  The increase in performance and power of computing systems requires the wider
use of program optimizations. The goal of performing optimizations is not only
to reduce program runtime, but also to reduce other computer resources
including power consumption. The goal of the study was to evaluate the impact
of different optimization levels and various optimization strategies on power
consumption. In a series of experiments, it was established that the average
power consumption tends to peak for the programs with optimized source code.
The articles also describes the impact of changing computer architecture on
power consumption graphs. The relationships between the average and median
values of power consumption by example programs are considered. The possibility
of creating program energy consumption profile for a parallel program is shown.
","['\nE. A. Kiselev\n', '\nP. N. Telegin\n', '\nA. V. Baranov\n']",,,http://arxiv.org/abs/2312.03315v1,cs.MS,"['cs.MS', 'cs.DC', '68M20']",,,[]
"A New Challenging Curve Fitting Benchmark Test Set for Global
  Optimization",http://arxiv.org/abs/2312.01709v4,2023-12-04T07:52:42Z,2024-02-07T19:27:42Z,"  Benchmark sets are extremely important for evaluating and developing global
optimization algorithms and related solvers. A new test set named PCC benchmark
is proposed especially for optimization problems of nonlinear curve fitting for
the first time, with the aspiration of helping developers to investigate and
compare the performance of different global optimization solvers, as well as
more effective optimization algorithms could be developed. Compared with the
well-known classical nonlinear curve fitting benchmark set given by the
National Institute of Standards and Technology (NIST) of USA, the most
distinguishable features of the PCC benchmark are small problem dimensions,
unconstrained with free search domain and high level of difficulty for
obtaining global optimization solutions, which make the PCC benchmark be not
only suitable for validating the effectiveness of different global optimization
algorithms, but also more ideal for verifying and comparing various related
solvers. Seven of the world's leading global optimization solvers, including
Baron, Antigone, Couenne, Lingo, Scip, Matlab-GA and 1stOpt, are employed to
test NIST and PCC benchmark thoroughly in terms of both effectiveness and
efficiency. The results showed that the NIST benchmark is relatively simple and
not suitable for global optimization testing, meanwhile the PCC benchmark is a
unique, challenging and effective test dataset for global optimization.
","['\nPeicong Cheng\n', '\nPeicheng Cheng\n']",,,http://arxiv.org/abs/2312.01709v4,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"A Framework for Self-Intersecting Surfaces (SOS): Symmetric Optimisation
  for Stability",http://arxiv.org/abs/2312.02113v1,2023-12-04T18:46:42Z,2023-12-04T18:46:42Z,"  In this paper, we give a stable and efficient method for fixing
self-intersections and non-manifold parts in a given embedded simplicial
complex. In addition, we show how symmetric properties can be used for further
optimisation. We prove an initialisation criterion for computation of the outer
hull of an embedded simplicial complex. To regularise the outer hull of the
retriangulated surface, we present a method to remedy non-manifold edges and
points. We also give a modification of the outer hull algorithm to determine
chambers of complexes which gives rise to many new insights. All of these
methods have applications in many areas, for example in 3D-printing, artistic
realisations of 3D models or fixing errors introduced by scanning equipment
applied for tomography. Implementations of the proposed algorithms are given in
the computer algebra system GAP4. For verification of our methods, we use a
data-set of highly self-intersecting symmetric icosahedra.
","['\nChristian Amend\n', '\nTom Goertzen\n']",,,http://arxiv.org/abs/2312.02113v1,cs.CG,"['cs.CG', 'cs.MS', 'math.CO']",,,[]
Ricci-Notation Tensor Framework for Model-Based Approaches to Imaging,http://arxiv.org/abs/2312.04018v2,2023-12-07T03:25:40Z,2024-01-10T23:18:02Z,"  Model-based approaches to imaging, like specialized image enhancements in
astronomy, facilitate explanations of relationships between observed inputs and
computed outputs. These models may be expressed with extended matrix-vector
(EMV) algebra, especially when they involve only scalars, vectors, and
matrices, and with n-mode or index notations, when they involve
multidimensional arrays, also called numeric tensors or, simply, tensors. While
this paper features an example, inspired by exoplanet imaging, that employs
tensors to reveal embedded 2D fast Fourier transforms in an image enhancement
model, the work is actually about the tensor algebra and software, or tensor
frameworks, available for model-based imaging. The paper proposes a
Ricci-notation tensor (RT) framework, comprising a dual-variant index notation,
with Einstein summation convention, and codesigned object-oriented software,
called the RTToolbox for MATLAB. Extensions to Ricci notation offer novel
representations for entrywise, pagewise, and broadcasting operations popular in
EMV frameworks for imaging. Complementing the EMV algebra computable with
MATLAB, the RTToolbox demonstrates programmatic and computational efficiency
thanks to careful design of tensor and dual-variant index classes. Compared to
its closest competitor, also a numeric tensor framework that uses index
notation, the RT framework enables superior ways to model imaging problems and,
thereby, to develop solutions.
","['\nDileepan Joseph\nElectrical and Computer Engineering, University of Alberta\n']","39 pages, 7 figures, 5 tables",,http://arxiv.org/abs/2312.04018v2,cs.MS,"['cs.MS', 'astro-ph.IM', 'eess.IV', 'G.4; I.4.3']",,,"['Electrical and Computer Engineering, University of Alberta']"
Mathematical Supplement for the $\texttt{gsplat}$ Library,http://arxiv.org/abs/2312.02121v1,2023-12-04T18:50:41Z,2023-12-04T18:50:41Z,"  This report provides the mathematical details of the gsplat library, a
modular toolbox for efficient differentiable Gaussian splatting, as proposed by
Kerbl et al. It provides a self-contained reference for the computations
involved in the forward and backward passes of differentiable Gaussian
splatting. To facilitate practical usage and development, we provide a user
friendly Python API that exposes each component of the forward and backward
passes in rasterization at github.com/nerfstudio-project/gsplat .
","['\nVickie Ye\n', '\nAngjoo Kanazawa\n']",Find the library at: https://docs.gsplat.studio/,,http://arxiv.org/abs/2312.02121v1,cs.MS,"['cs.MS', 'cs.CV', 'cs.GR', 'cs.NA', 'math.NA']",,,[]
"Deriving Algorithms for Triangular Tridiagonalization a (Skew-)Symmetric
  Matrix",http://arxiv.org/abs/2311.10700v1,2023-11-17T18:44:40Z,2023-11-17T18:44:40Z,"  We apply the FLAME methodology to derive algorithms hand in hand with their
proofs of correctness for the computation of the $ L T L^T $ decomposition
(with and without pivoting) of a skew-symmetric matrix. The approach yields
known as well as new algorithms, presented using the FLAME notation. A number
of BLAS-like primitives are exposed at the core of blocked algorithms that can
attain high performance. The insights can be easily extended to yield
algorithms for computing the $ L T L^T $ decomposition of a symmetric matrix.
","['\nRobert van de Geijn\n', '\nMaggie Myers\n', '\nRuQing G. Xu\n', '\nDevin Matthews\n']",28 pages,,http://arxiv.org/abs/2311.10700v1,cs.MS,['cs.MS'],,,[]
DisCoPy: the Hierarchy of Graphical Languages in Python,http://arxiv.org/abs/2311.10608v1,2023-11-17T16:03:08Z,2023-11-17T16:03:08Z,"  DisCoPy is a Python toolkit for computing with monoidal categories. It comes
with two flexible data structures for string diagrams: the first one for planar
monoidal categories based on lists of layers, the second one for symmetric
monoidal categories based on cospans of hypergraphs. Algorithms for functor
application then allow to translate string diagrams into code for numerical
computation, be it differentiable, probabilistic or quantum. This report gives
an overview of the library and the new developments released in its version
1.0. In particular, we showcase the implementation of diagram equality for a
large fragment of the hierarchy of graphical languages for monoidal categories,
as well as a new syntax for defining string diagrams as Python functions.
","['\nAlexis Toumi\n', '\nRichie Yeung\n', '\nBoldizsár Poór\n', '\nGiovanni de Felice\n']","14 pages, 10 figures",,http://arxiv.org/abs/2311.10608v1,math.CT,"['math.CT', 'cs.MS']",,,[]
"p-adaptive discontinuous Galerkin method for the shallow water equations
  on heterogeneous computing architectures",http://arxiv.org/abs/2311.11348v1,2023-11-19T15:19:59Z,2023-11-19T15:19:59Z,"  Heterogeneous computing and exploiting integrated CPU-GPU architectures has
become a clear current trend since the flattening of Moore's Law. In this work,
we propose a numerical and algorithmic re-design of a p-adaptive
quadrature-free discontinuous Galerkin method (DG) for the shallow water
equations (SWE). Our new approach separates the computations of the
non-adaptive (lower-order) and adaptive (higher-order) parts of the
discretization form each other. Thereby, we can overlap computations of the
lower-order and the higher-order DG solution components. Furthermore, we
investigate execution times of main computational kernels and use automatic
code generation to optimize their distribution between the CPU and GPU. Several
setups, including a prototype of a tsunami simulation in a tide-driven flow
scenario, are investigated, and the results show that significant performance
improvements can be achieved in suitable setups.
","['\nSara Faghih-Naini\n', '\nVadym Aizinger\n', '\nSebastian Kuckuk\n', '\nRichard Angersbach\n', '\nHarald Köstler\n']",,,http://arxiv.org/abs/2311.11348v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"An Assessment of PC-mer's Performance in Alignment-Free Phylogenetic
  Tree Construction",http://arxiv.org/abs/2311.12898v1,2023-11-21T09:19:45Z,2023-11-21T09:19:45Z,"  Background: Sequence comparison is essential in bioinformatics, serving
various purposes such as taxonomy, functional inference, and drug discovery.
The traditional method of aligning sequences for comparison is time-consuming,
especially with large datasets. To overcome this, alignment-free methods have
emerged as an alternative approach, prioritizing comparison scores over
alignment itself. These methods directly compare sequences without the need for
alignment. However, accurately representing the relationships between sequences
is a significant challenge in the design of these tools. Methods:One of the
alignment-free comparison approaches utilizes the frequency of fixed-length
substrings, known as K-mers, which serves as the foundation for many sequence
comparison methods. However, a challenge arises in these methods when
increasing the length of the substring (K), as it leads to an exponential
growth in the number of possible states. In this work, we explore the PC-mer
method, which utilizes a more limited set of words that experience slower
growth 2^k instead of 4^k compared to K. We conducted a comparison of sequences
and evaluated how the reduced input vector size influenced the performance of
the PC-mer method. Results: For the evaluation, we selected the Clustal Omega
method as our reference approach, alongside three alignment-free methods:
kmacs, FFP, and alfpy (word count). These methods also leverage the frequency
of K-mers. We applied all five methods to 9 datasets for comprehensive
analysis. The results were compared using phylogenetic trees and metrics such
as Robinson-Foulds and normalized quartet distance (nQD). Conclusion: Our
findings indicate that, unlike reducing the input features in other
alignment-independent methods, the PC-mer method exhibits competitive
performance when compared to the aforementioned methods especially when input
sequences are very varied.
","['\nSaeedeh Akbari Rokn Abadi\n', '\nMelika Honarmand\n', '\nAli Hajialinaghi\n', '\nSomayyeh Koohi\n']",,,http://arxiv.org/abs/2311.12898v1,q-bio.QM,"['q-bio.QM', 'cs.MS']",,,[]
"Exact Combinatorial Optimization with Temporo-Attentional Graph Neural
  Networks",http://arxiv.org/abs/2311.13843v1,2023-11-23T08:07:15Z,2023-11-23T08:07:15Z,"  Combinatorial optimization finds an optimal solution within a discrete set of
variables and constraints. The field has seen tremendous progress both in
research and industry. With the success of deep learning in the past decade, a
recent trend in combinatorial optimization has been to improve state-of-the-art
combinatorial optimization solvers by replacing key heuristic components with
machine learning (ML) models. In this paper, we investigate two essential
aspects of machine learning algorithms for combinatorial optimization: temporal
characteristics and attention. We argue that for the task of variable selection
in the branch-and-bound (B&B) algorithm, incorporating the temporal information
as well as the bipartite graph attention improves the solver's performance. We
support our claims with intuitions and numerical results over several standard
datasets used in the literature and competitions. Code is available at:
https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=047c6cf2-8463-40d7-b92f-7b2ca998e935
","['\nMehdi Seyfi\n', '\nAmin Banitalebi-Dehkordi\n', '\nZirui Zhou\n', '\nYong Zhang\n']",ECML PKDD 2023,ECML PKDD 2023,http://arxiv.org/abs/2311.13843v1,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS']",,,[]
"Mathematical Modelling and a Numerical Solution for High Precision
  Satellite Ephemeris Determination",http://arxiv.org/abs/2311.15028v1,2023-11-25T13:47:10Z,2023-11-25T13:47:10Z,"  In this paper, we develop a high-precision satellite orbit determination
model for satellites orbiting the Earth. Solving this model entails numerically
integrating the differential equation of motion governing a two-body system,
employing Fehlberg's formulation and the Runge-Kutta class of embedded
integrators with adaptive stepsize control. Relevant primary perturbing forces
included in this mathematical model are the full force gravitational field
model, Earth's atmospheric drag, third body gravitational effects and solar
radiation pressure. Development of the high-precision model required accounting
for the perturbing influences of Earth radiation pressure, Earth tides and
relativistic effects. The model is then implemented to obtain a high-fidelity
Earth orbiting satellite propagator, namely the Satellite Ephemeris Determiner
(SED), which is comparable to the popular High Precision Orbit Propagator
(HPOP). The architecture of SED, the methodology employed, and the numerical
results obtained are presented.
","['\nAravind Gundakaram\n', '\nAbhirath Sangala\n', '\nAditya Sai Ellendula\n', '\nPrachi Kansal\n', '\nLanii Lakshitaa\n', '\nSuchir Reddy Punuru\n', '\nNethra Naveen\n', '\nSanjitha Jaggumantri\n']","Accepted and Presented at 9th International Conference and Exhibition
  on Satellite and Space Missions",,http://arxiv.org/abs/2311.15028v1,astro-ph.EP,"['astro-ph.EP', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"Cache Optimization and Performance Modeling of Batched, Small, and
  Rectangular Matrix Multiplication on Intel, AMD, and Fujitsu Processors",http://arxiv.org/abs/2311.07602v1,2023-11-11T02:33:10Z,2023-11-11T02:33:10Z,"  Factorization and multiplication of dense matrices and tensors are critical,
yet extremely expensive pieces of the scientific toolbox. Careful use of low
rank approximation can drastically reduce the computation and memory
requirements of these operations. In addition to a lower arithmetic complexity,
such methods can, by their structure, be designed to efficiently exploit modern
hardware architectures. The majority of existing work relies on batched BLAS
libraries to handle the computation of many small dense matrices. We show that
through careful analysis of the cache utilization, register accumulation using
SIMD registers and a redesign of the implementation, one can achieve
significantly higher throughput for these types of batched low-rank matrices
across a large range of block and batch sizes. We test our algorithm on 3 CPUs
using diverse ISAs -- the Fujitsu A64FX using ARM SVE, the Intel Xeon 6148
using AVX-512 and AMD EPYC 7502 using AVX-2, and show that our new batching
methodology is able to obtain more than twice the throughput of vendor
optimized libraries for all CPU architectures and problem sizes.
","['\nSameer Deshmukh\n', '\nRio Yokota\n', '\nGeorge Bosilca\n']",,,http://arxiv.org/abs/2311.07602v1,cs.PF,"['cs.PF', 'cs.MS']",,,[]
A Case Study in Analytic Protocol Analysis in ACL2,http://arxiv.org/abs/2311.08855v1,2023-11-15T10:46:33Z,2023-11-15T10:46:33Z,"  When verifying computer systems we sometimes want to study their asymptotic
behaviors, i.e., how they behave in the long run. In such cases, we need real
analysis, the area of mathematics that deals with limits and the foundations of
calculus. In a prior work, we used real analysis in ACL2s to study the
asymptotic behavior of the RTO computation, commonly used in congestion control
algorithms across the Internet. One key component in our RTO computation
analysis was proving in ACL2s that for all alpha in [0, 1), the limit as n
approaches infinity of alpha raised to n is zero. Whereas the most obvious
proof strategy involves the logarithm, whose codomain includes irrationals, by
default ACL2 only supports rationals, which forced us to take a non-standard
approach. In this paper, we explore different approaches to proving the above
result in ACL2(r) and ACL2s, from the perspective of a relatively new user to
each. We also contextualize the theorem by showing how it allowed us to prove
important asymptotic properties of the RTO computation. Finally, we discuss
tradeoffs between the various proof strategies and directions for future
research.
","['\nMax von Hippel\nNortheastern University\n', '\nPanagiotis Manolios\nNortheastern University\n', '\nKenneth L. McMillan\nUniversity of Texas at Austin\n', '\nCristina Nita-Rotaru\nNortheastern University\n', '\nLenore Zuck\nUniversity of Illinois Chicago\n']","In Proceedings ACL2-2023, arXiv:2311.08373","EPTCS 393, 2023, pp. 50-66",http://dx.doi.org/10.4204/EPTCS.393.6,cs.LO,"['cs.LO', 'cs.MS']",10.4204/EPTCS.393.6,,"['Northeastern University', 'Northeastern University', 'University of Texas at Austin', 'Northeastern University', 'University of Illinois Chicago']"
Semidefinite Programming by Projective Cutting Planes,http://arxiv.org/abs/2311.09365v1,2023-11-15T20:57:43Z,2023-11-15T20:57:43Z,"  Seeking tighter relaxations of combinatorial optimization problems,
semidefinite programming is a generalization of linear programming that offers
better bounds and is still polynomially solvable. Yet, in practice, a
semidefinite program is still significantly harder to solve than a similar-size
Linear Program (LP). It is well-known that a semidefinite program can be
written as an LP with infinitely-many cuts that could be solved by repeated
separation in a Cutting-Planes scheme; this approach is likely to end up in
failure. We proposed in [Projective Cutting-Planes, Daniel Porumbel, Siam
Journal on Optimization, 2020] the Projective Cutting-Planes method that
upgrades t he well-known separation sub-problem to the projection sub-problem:
given a feasible $y$ inside a polytope $P$ and a direction $d$, find the
maximum $t^*$ so that $y+t^*d\in P$. Using this new sub-problem, one can
generate a sequence of both inner and outer solutions that converge to the
optimum over $P$. This paper shows that the projection sub-problem can be
solved very efficiently in a semidefinite programming context, enabling the
resulting method to compete very well with state-of-the-art semidefinite
optimization software (refined over decades). Results suggest it may the
fastest method for matrix sizes larger than $2000\times 2000$.
",['\nDaniel Porumbel\n'],,,http://arxiv.org/abs/2311.09365v1,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
A Survey of Methods for Estimating Hurst Exponent of Time Sequence,http://arxiv.org/abs/2310.19051v1,2023-10-29T15:56:53Z,2023-10-29T15:56:53Z,"  The Hurst exponent is a significant indicator for characterizing the
self-similarity and long-term memory properties of time sequences. It has wide
applications in physics, technologies, engineering, mathematics, statistics,
economics, psychology and so on. Currently, available methods for estimating
the Hurst exponent of time sequences can be divided into different categories:
time-domain methods and spectrum-domain methods based on the representation of
time sequence, linear regression methods and Bayesian methods based on
parameter estimation methods. Although various methods are discussed in
literature, there are still some deficiencies: the descriptions of the
estimation algorithms are just mathematics-oriented and the pseudo-codes are
missing; the effectiveness and accuracy of the estimation algorithms are not
clear; the classification of estimation methods is not considered and there is
a lack of guidance for selecting the estimation methods. In this work, the
emphasis is put on thirteen dominant methods for estimating the Hurst exponent.
For the purpose of decreasing the difficulty of implementing the estimation
methods with computer programs, the mathematical principles are discussed
briefly and the pseudo-codes of algorithms are presented with necessary
details. It is expected that the survey could help the researchers to select,
implement and apply the estimation algorithms of interest in practical
situations in an easy way.
","['\nHong-Yan Zhang\n', '\nZhi-Qiang Feng\n', '\nSi-Yu Feng\n', '\nYu Zhou\n']","46 pages, 8 figures, 4 tables, 24 algorithms with pseudo-codes",,http://arxiv.org/abs/2310.19051v1,stat.ME,"['stat.ME', 'cs.MS']",,,[]
"Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel
  Max Series GPU",http://arxiv.org/abs/2311.00368v1,2023-11-01T08:43:59Z,2023-11-01T08:43:59Z,"  In this paper, we focus on three sparse matrix operations that are relevant
for machine learning applications, namely, the sparse-dense matrix
multiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM),
and the composition of the SDDMM with SPMM, also termed as FusedMM. We develop
optimized implementations for SPMM, SDDMM, and FusedMM operations utilizing
Intel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or
SYCL, the ESIMD API enables the writing of explicitly vectorized kernel code.
Sparse matrix algorithms implemented with the ESIMD API achieved performance
close to the peak of the targeted Intel Data Center GPU. We compare our
performance results to Intel's oneMKL library on Intel GPUs and to a recent
CUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and
demonstrate that our implementations for sparse matrix operations outperform
either.
","['\nMohammad Zubair\n', '\nChristoph Bauinger\n']","20 pages, 1 Table, 19 Figures, preprint",,http://arxiv.org/abs/2311.00368v1,cs.LG,"['cs.LG', 'cs.MS', '68-04 (Primary) 68T07, 68W10 (Secondary)', 'I.2.5; G.4']",,,[]
Tackling the Matrix Multiplication Micro-kernel Generation with Exo,http://arxiv.org/abs/2310.17408v2,2023-10-26T14:09:57Z,2023-10-27T08:28:03Z,"  The optimization of the matrix multiplication (or GEMM) has been a need
during the last decades. This operation is considered the flagship of current
linear algebra libraries such as BLIS, OpenBLAS, or Intel OneAPI because of its
widespread use in a large variety of scientific applications. The GEMM is
usually implemented following the GotoBLAS philosophy, which tiles the GEMM
operands and uses a series of nested loops for performance improvement. These
approaches extract the maximum computational power of the architectures through
small pieces of hardware-oriented, high-performance code called micro-kernel.
However, this approach forces developers to generate, with a non-negligible
effort, a dedicated micro-kernel for each new hardware.
  In this work, we present a step-by-step procedure for generating
micro-kernels with the Exo compiler that performs close to (or even better
than) manually developed microkernels written with intrinsic functions or
assembly language. Our solution also improves the portability of the generated
code, since a hardware target is fully specified by a concise library-based
description of its instructions.
","['\nAdrián Castelló\n', '\nJulian Bellavita\n', '\nGrace Dinh\n', '\nYuka Ikarashi\n', '\nHéctor Martínez\n']","11 pages, 18 figures. Presented at CGO 2024. It includes a software
  artifact step-by-step execution",,http://arxiv.org/abs/2310.17408v2,cs.MS,"['cs.MS', 'cs.CL', 'cs.PF']",,,[]
"Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank
  Matrices",http://arxiv.org/abs/2310.19214v1,2023-10-30T00:52:17Z,2023-10-30T00:52:17Z,"  We consider multilevel low rank (MLR) matrices, defined as a row and column
permutation of a sum of matrices, each one a block diagonal refinement of the
previous one, with all blocks low rank given in factored form. MLR matrices
extend low rank matrices but share many of their properties, such as the total
storage required and complexity of matrix-vector multiplication. We address
three problems that arise in fitting a given matrix by an MLR matrix in the
Frobenius norm. The first problem is factor fitting, where we adjust the
factors of the MLR matrix. The second is rank allocation, where we choose the
ranks of the blocks in each level, subject to the total rank having a given
value, which preserves the total storage needed for the MLR matrix. The final
problem is to choose the hierarchical partition of rows and columns, along with
the ranks and factors. This paper is accompanied by an open source package that
implements the proposed methods.
","['\nTetiana Parshakova\n', '\nTrevor Hastie\n', '\nEric Darve\n', '\nStephen Boyd\n']",,,http://arxiv.org/abs/2310.19214v1,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS', 'math.OC']",,,[]
NoMoPy: Noise Modeling in Python,http://arxiv.org/abs/2311.00084v1,2023-10-31T18:52:05Z,2023-10-31T18:52:05Z,"  NoMoPy is a code for fitting, analyzing, and generating noise modeled as a
hidden Markov model (HMM) or, more generally, factorial hidden Markov model
(FHMM). This code, written in Python, implements approximate and exact
expectation maximization (EM) algorithms for performing the parameter
estimation process, model selection procedures via cross-validation, and
parameter confidence region estimation. Here, we describe in detail the
functionality implemented in NoMoPy and provide examples of its use and
performance on example problems.
","['\nDylan Albrecht\n', '\nN. Tobias Jacobson\n']","55 pages, 68 figures, citation paper",,http://arxiv.org/abs/2311.00084v1,stat.CO,"['stat.CO', 'cs.CE', 'cs.MS', 'stat.ML']",,,[]
"$O(N)$ distributed direct factorization of structured dense matrices
  using runtime systems",http://arxiv.org/abs/2311.00921v1,2023-11-02T01:28:47Z,2023-11-02T01:28:47Z,"  Structured dense matrices result from boundary integral problems in
electrostatics and geostatistics, and also Schur complements in sparse
preconditioners such as multi-frontal methods. Exploiting the structure of such
matrices can reduce the time for dense direct factorization from $O(N^3)$ to
$O(N)$. The Hierarchically Semi-Separable (HSS) matrix is one such low rank
matrix format that can be factorized using a Cholesky-like algorithm called ULV
factorization. The HSS-ULV algorithm is highly parallel because it removes the
dependency on trailing sub-matrices at each HSS level. However, a key merge
step that links two successive HSS levels remains a challenge for efficient
parallelization. In this paper, we use an asynchronous runtime system PaRSEC
with the HSS-ULV algorithm. We compare our work with STRUMPACK and LORAPO, both
state-of-the-art implementations of dense direct low rank factorization, and
achieve up to 2x better factorization time for matrices arising from a diverse
set of applications on up to 128 nodes of Fugaku for similar or better accuracy
for all the problems that we survey.
","['\nSameer Deshmukh\n', '\nQinxiang Ma\n', '\nRio Yokota\n', '\nGeorge Bosilca\n']",,,http://arxiv.org/abs/2311.00921v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"An Efficient Framework for Global Non-Convex Polynomial Optimization
  with Nonlinear Polynomial Constraints",http://arxiv.org/abs/2311.02037v1,2023-11-03T17:10:26Z,2023-11-03T17:10:26Z,"  We present an efficient framework for solving constrained global non-convex
polynomial optimization problems. We prove the existence of an equivalent
nonlinear reformulation of such problems that possesses essentially no spurious
local minima. We show through numerical experiments that polynomial scaling in
dimension and degree is achievable for computing the optimal value and location
of previously intractable global constrained polynomial optimization problems
in high dimension.
","['\nMitchell Tong Harris\n', '\nPierre-David Letourneau\n', '\nDalton Jones\n', '\nM. Harper Langston\n']",,,http://arxiv.org/abs/2311.02037v1,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"HyperNetX: A Python package for modeling complex network data as
  hypergraphs",http://arxiv.org/abs/2310.11626v1,2023-10-17T23:24:11Z,2023-10-17T23:24:11Z,"  HyperNetX (HNX) is an open source Python library for the analysis and
visualization of complex network data modeled as hypergraphs. Initially
released in 2019, HNX facilitates exploratory data analysis of complex networks
using algebraic topology, combinatorics, and generalized hypergraph and graph
theoretical methods on structured data inputs. With its 2023 release, the
library supports attaching metadata, numerical and categorical, to nodes
(vertices) and hyperedges, as well as to node-hyperedge pairings (incidences).
HNX has a customizable Matplotlib-based visualization module as well as
HypernetX-Widget, its JavaScript addon for interactive exploration and
visualization of hypergraphs within Jupyter Notebooks. Both packages are
available on GitHub and PyPI. With a growing community of users and
collaborators, HNX has become a preeminent tool for hypergraph analysis.
","['\nBrenda Praggastis\n', '\nSinan Aksoy\n', '\nDustin Arendt\n', '\nMark Bonicillo\n', '\nCliff Joslyn\n', '\nEmilie Purvine\n', '\nMadelyn Shapiro\n', '\nJi Young Yun\n']","3 pages, 2 figures",,http://arxiv.org/abs/2310.11626v1,cs.MS,['cs.MS'],,,[]
"A Number Representation Systems Library Supporting New Representations
  Based on Morris Tapered Floating-point with Hidden Exponent Bit",http://arxiv.org/abs/2310.09797v1,2023-10-15T10:59:41Z,2023-10-15T10:59:41Z,"  The introduction of posit reopened the debate about the utility of IEEE754 in
specific domains. In this context, we propose a high-level language (Scala)
library that aims to reduce the effort of designing and testing new number
representation systems (NRSs). The library's efficiency is tested with three
new NRSs derived from Morris Tapered Floating-Point by adding a hidden exponent
bit. We call these NRSs MorrisHEB, MorrisBiasHEB, and MorrisUnaryHEB,
respectively. We show that they offer a better dynamic range, better decimal
accuracy for unary operations, more exact results for addition (37.61% in the
case of MorrisUnaryHEB), and better average decimal accuracy for inexact
results on binary operations than posit and IEEE754. Going through existing
benchmarks in the literature, and favorable/unfavorable examples for
IEEE754/posit, we show that these new NRSs produce similar (less than one
decimal accuracy difference) or even better results than IEEE754 and posit.
Given the entire spectrum of results, there are arguments for MorrisBiasHEB to
be used as a replacement for IEEE754 in general computations. MorrisUnaryHEB
has a more populated ``golden zone'' (+13.6%) and a better dynamic range (149X)
than posit, making it a candidate for machine learning computations.
","['\nStefan-Dan Ciocirlan\n', '\nDumitrel Loghin\n']",,,http://arxiv.org/abs/2310.09797v1,cs.MS,"['cs.MS', 'cs.IT', 'math.IT']",,,[]
"Smoothing Methods for Automatic Differentiation Across Conditional
  Branches",http://arxiv.org/abs/2310.03585v2,2023-10-05T15:08:37Z,2024-01-04T14:17:30Z,"  Programs involving discontinuities introduced by control flow constructs such
as conditional branches pose challenges to mathematical optimization methods
that assume a degree of smoothness in the objective function's response
surface. Smooth interpretation (SI) is a form of abstract interpretation that
approximates the convolution of a program's output with a Gaussian kernel, thus
smoothing its output in a principled manner. Here, we combine SI with automatic
differentiation (AD) to efficiently compute gradients of smoothed programs. In
contrast to AD across a regular program execution, these gradients also capture
the effects of alternative control flow paths. The combination of SI with AD
enables the direct gradient-based parameter synthesis for branching programs,
allowing for instance the calibration of simulation models or their combination
with neural network models in machine learning pipelines. We detail the effects
of the approximations made for tractability in SI and propose a novel Monte
Carlo estimator that avoids the underlying assumptions by estimating the
smoothed programs' gradients through a combination of AD and sampling. Using
DiscoGrad, our tool for automatically translating simple C++ programs to a
smooth differentiable form, we perform an extensive evaluation. We compare the
combination of SI with AD and our Monte Carlo estimator to existing
gradient-free and stochastic methods on four non-trivial and originally
discontinuous problems ranging from classical simulation-based optimization to
neural network-driven control. While the optimization progress with the
SI-based estimator depends on the complexity of the program's control flow, our
Monte Carlo estimator is competitive in all problems, exhibiting the fastest
convergence by a substantial margin in our highest-dimensional problem.
","['\nJustin N. Kreikemeyer\n', '\nPhilipp Andelfinger\n']","21 pages, 17 figures, updated content to reflect journal version.
  Published in IEEE Access, available at
  https://ieeexplore.ieee.org/abstract/document/10356054","IEEE Access, vol. 11 (2023), pp. 143190-143211",http://dx.doi.org/10.1109/ACCESS.2023.3342136,cs.LG,"['cs.LG', 'cs.MS', 'math.OC']",10.1109/ACCESS.2023.3342136,,[]
"Algorithm xxxx: HiPPIS A High-Order Positivity-Preserving Mapping
  Software for Structured Meshes",http://arxiv.org/abs/2310.08818v1,2023-10-13T02:12:16Z,2023-10-13T02:12:16Z,"  Polynomial interpolation is an important component of many computational
problems. In several of these computational problems, failure to preserve
positivity when using polynomials to approximate or map data values between
meshes can lead to negative unphysical quantities. Currently, most
polynomial-based methods for enforcing positivity are based on splines and
polynomial rescaling. The spline-based approaches build interpolants that are
positive over the intervals in which they are defined and may require solving a
minimization problem and/or system of equations. The linear polynomial
rescaling methods allow for high-degree polynomials but enforce positivity only
at limited locations (e.g., quadrature nodes). This work introduces open-source
software (HiPPIS) for high-order data-bounded interpolation (DBI) and
positivity-preserving interpolation (PPI) that addresses the limitations of
both the spline and polynomial rescaling methods. HiPPIS is suitable for
approximating and mapping physical quantities such as mass, density, and
concentration between meshes while preserving positivity. This work provides
Fortran and Matlab implementations of the DBI and PPI methods, presents an
analysis of the mapping error in the context of PDEs, and uses several 1D and
2D numerical examples to demonstrate the benefits and limitations of HiPPIS.
","['\nTimbwaoga A. J. Ouermi\n', '\nRobert M Kirby\n', '\nMartin Berzins\n']",,,http://arxiv.org/abs/2310.08818v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65D05, 65D15']",,,[]
"A Generic Software Framework for Distributed Topological Analysis
  Pipelines",http://arxiv.org/abs/2310.08339v1,2023-10-12T13:57:32Z,2023-10-12T13:57:32Z,"  This system paper presents a software framework for the support of
topological analysis pipelines in a distributed-memory model. While several
recent papers introduced topology-based approaches for distributed-memory
environments, these were reporting experiments obtained with tailored,
mono-algorithm implementations. In contrast, we describe in this paper a
general-purpose, generic framework for topological analysis pipelines, i.e. a
sequence of topological algorithms interacting together, possibly on distinct
numbers of processes. Specifically, we instantiated our framework with the MPI
model, within the Topology ToolKit (TTK). While developing this framework, we
faced several algorithmic and software engineering challenges, which we
document in this paper. We provide a taxonomy for the distributed-memory
topological algorithms supported by TTK, depending on their communication needs
and provide examples of hybrid MPI+thread parallelizations. Detailed
performance analyses show that parallel efficiencies range from $20\%$ to
$80\%$ (depending on the algorithms), and that the MPI-specific preconditioning
introduced by our framework induces a negligible computation time overhead. We
illustrate the new distributed-memory capabilities of TTK with an example of
advanced analysis pipeline, combining multiple algorithms, run on the largest
publicly available dataset we have found (120 billion vertices) on a standard
cluster with 64 nodes (for a total of 1,536 cores). Finally, we provide a
roadmap for the completion of TTK's MPI extension, along with generic
recommendations for each algorithm communication category.
","['\nEve Le Guillou\n', '\nMichael Will\n', '\nPierre Guillou\n', '\nJonas Lukasczyk\n', '\nPierre Fortin\n', '\nChristoph Garth\n', '\nJulien Tierny\n']","18 pages, 12 figures",,http://arxiv.org/abs/2310.08339v1,cs.DC,"['cs.DC', 'cs.CG', 'cs.CV', 'cs.LG', 'cs.MS']",,,[]
"Parallel local time stepping for rigid bodies represented by
  triangulated meshes",http://arxiv.org/abs/2309.15417v1,2023-09-27T05:46:57Z,2023-09-27T05:46:57Z,"  Discrete Element Methods (DEM), i.e.~the simulation of many rigid particles,
suffer from very stiff differential equations plus multiscale challenges in
space and time. The particles move smoothly through space until they interact
almost instantaneously due to collisions. Dense particle packings hence require
tiny time step sizes, while free particles can advance with large time steps.
Admissible time step sizes can span multiple orders of magnitudes. We propose
an adaptive local time stepping algorithm which identifies clusters of
particles that can be updated independently, advances them optimistically and
independently in time, determines collision time stamps in space-time such that
we maximise the time step sizes used, and resolves the momentum exchange
implicitly. It is combined with various acceleration techniques which exploit
multiscale geometry representations and multiscale behaviour in time. The
collision time stamp detection in space-time in combination with the implicit
solve of the actual collision equations avoids that particles get locked into
tiny time step sizes, the clustering yields a high concurrency level, and the
acceleration techniques plus local time stepping avoid unnecessary
computations. This brings a scaling, adaptive time stepping for DEM for
real-world challenges into reach.
","['\nPeter Noble\n', '\nTobias Weinzierl\n']",,,http://arxiv.org/abs/2309.15417v1,cs.MS,['cs.MS'],,,[]
"pyPPG: A Python toolbox for comprehensive photoplethysmography signal
  analysis",http://arxiv.org/abs/2309.13767v1,2023-09-24T22:37:49Z,2023-09-24T22:37:49Z,"  Photoplethysmography is a non-invasive optical technique that measures
changes in blood volume within tissues. It is commonly and increasingly used
for in a variety of research and clinical application to assess vascular
dynamics and physiological parameters. Yet, contrary to heart rate variability
measures, a field which has seen the development of stable standards and
advanced toolboxes and software, no such standards and open tools exist for
continuous photoplethysmogram (PPG) analysis. Consequently, the primary
objective of this research was to identify, standardize, implement and validate
key digital PPG biomarkers. This work describes the creation of a standard
Python toolbox, denoted pyPPG, for long-term continuous PPG time series
analysis recorded using a standard finger-based transmission pulse oximeter.
The improved PPG peak detector had an F1-score of 88.19% for the
state-of-the-art benchmark when evaluated on 2,054 adult polysomnography
recordings totaling over 91 million reference beats. This algorithm
outperformed the open-source original Matlab implementation by ~5% when
benchmarked on a subset of 100 randomly selected MESA recordings. More than
3,000 fiducial points were manually annotated by two annotators in order to
validate the fiducial points detector. The detector consistently demonstrated
high performance, with a mean absolute error of less than 10 ms for all
fiducial points. Based on these fiducial points, pyPPG engineers a set of 74
PPG biomarkers. Studying the PPG time series variability using pyPPG can
enhance our understanding of the manifestations and etiology of diseases. This
toolbox can also be used for biomarker engineering in training data-driven
models. pyPPG is available on physiozoo.org
","['\nMarton A. Goda\n', '\nPeter H. Charlton\n', '\nJoachim A. Behar\n']","The manuscript was submitted to ""Physiological Measurement"" on
  September 5, 2023",,http://arxiv.org/abs/2309.13767v1,physics.med-ph,"['physics.med-ph', 'cs.MS']",,,[]
Asymptote-based scientific animation,http://arxiv.org/abs/2310.06860v1,2023-09-30T16:12:30Z,2023-09-30T16:12:30Z,"  This article discusses a universal way to create animation using Asymptote
the language for vector graphics. The Asymptote language itself has a built-in
library for creating animations, but its practical use is complicated by an
extremely brief description in the official documentation and unstable
execution of existing examples. The purpose of this article is to eliminate
this gap. The method we describe is based on creating a PDF file with frames
using Asymptote, with further converting it into a set of PNG images and
merging them into a video using FFmpeg. All stages are described in detail,
which allows the reader to use the described method without being familiar with
the used utilities.
","['\nMigran N. Gevorkyan\n', '\nAnna V. Korolkova\n', '\nDmitry S. Kulyabov\n']",in English; in Russian,,http://dx.doi.org/10.22363/2658-4670-2023-31-2-139-149,cs.GR,"['cs.GR', 'cs.MS']",10.22363/2658-4670-2023-31-2-139-149,,[]
A Sparse Fast Chebyshev Transform for High-Dimensional Approximation,http://arxiv.org/abs/2309.14584v2,2023-09-26T00:15:09Z,2023-10-02T16:38:27Z,"  We present the Fast Chebyshev Transform (FCT), a fast, randomized algorithm
to compute a Chebyshev approximation of functions in high-dimensions from the
knowledge of the location of its nonzero Chebyshev coefficients. Rather than
sampling a full-resolution Chebyshev grid in each dimension, we randomly sample
several grids with varied resolutions and solve a least-squares problem in
coefficient space in order to compute a polynomial approximating the function
of interest across all grids simultaneously. We theoretically and empirically
show that the FCT exhibits quasi-linear scaling and high numerical accuracy on
challenging and complex high-dimensional problems. We demonstrate the
effectiveness of our approach compared to alternative Chebyshev approximation
schemes. In particular, we highlight our algorithm's effectiveness in high
dimensions, demonstrating significant speedups over commonly-used alternative
techniques.
","['\nDalton Jones\n', '\nPierre-David Letourneau\n', '\nMatthew J. Morse\n', '\nM. Harper Langston\n']",,,http://arxiv.org/abs/2309.14584v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.OC', '90C23, 41A50, 65Y20, 65D15, 93E24, 65T50, 14Q15']",,,[]
CausalGPS: An R Package for Causal Inference With Continuous Exposures,http://arxiv.org/abs/2310.00561v1,2023-10-01T03:31:01Z,2023-10-01T03:31:01Z,"  Quantifying the causal effects of continuous exposures on outcomes of
interest is critical for social, economic, health, and medical research.
However, most existing software packages focus on binary exposures. We develop
the CausalGPS R package that implements a collection of algorithms to provide
algorithmic solutions for causal inference with continuous exposures. CausalGPS
implements a causal inference workflow, with algorithms based on generalized
propensity scores (GPS) as the core, extending propensity scores (the
probability of a unit being exposed given pre-exposure covariates) from binary
to continuous exposures. As the first step, the package implements efficient
and flexible estimations of the GPS, allowing multiple user-specified modeling
options. As the second step, the package provides two ways to adjust for
confounding: weighting and matching, generating weighted and matched data sets,
respectively. Lastly, the package provides built-in functions to fit flexible
parametric, semi-parametric, or non-parametric regression models on the
weighted or matched data to estimate the exposure-response function relating
the outcome with the exposures. The computationally intensive tasks are
implemented in C++, and efficient shared-memory parallelization is achieved by
OpenMP API. This paper outlines the main components of the CausalGPS R package
and demonstrates its application to assess the effect of long-term exposure to
PM2.5 on educational attainment using zip code-level data from the contiguous
United States from 2000-2016.
","['\nNaeem Khoshnevis\n', '\nXiao Wu\n', '\nDanielle Braun\n']","22 pages, 8 figures",,http://arxiv.org/abs/2310.00561v1,stat.CO,"['stat.CO', 'cs.MS', 'econ.EM']",,,[]
"Implicit Gaussian process representation of vector fields over arbitrary
  latent manifolds",http://arxiv.org/abs/2309.16746v2,2023-09-28T16:02:39Z,2024-01-17T13:20:12Z,"  Gaussian processes (GPs) are popular nonparametric statistical models for
learning unknown functions and quantifying the spatiotemporal uncertainty in
data. Recent works have extended GPs to model scalar and vector quantities
distributed over non-Euclidean domains, including smooth manifolds appearing in
numerous fields such as computer vision, dynamical systems, and neuroscience.
However, these approaches assume that the manifold underlying the data is
known, limiting their practical utility. We introduce RVGP, a generalisation of
GPs for learning vector signals over latent Riemannian manifolds. Our method
uses positional encoding with eigenfunctions of the connection Laplacian,
associated with the tangent bundle, readily derived from common graph-based
approximation of data. We demonstrate that RVGP possesses global regularity
over the manifold, which allows it to super-resolve and inpaint vector fields
while preserving singularities. Furthermore, we use RVGP to reconstruct
high-density neural dynamics derived from low-density EEG recordings in healthy
individuals and Alzheimer's patients. We show that vector field singularities
are important disease markers and that their reconstruction leads to a
comparable classification accuracy of disease states to high-density
recordings. Thus, our method overcomes a significant practical limitation in
experimental and clinical applications.
","['\nRobert L. Peach\n', '\nMatteo Vinao-Carl\n', '\nNir Grossman\n', '\nMichael David\n', '\nEmma Mallas\n', '\nDavid Sharp\n', '\nParesh A. Malhotra\n', '\nPierre Vandergheynst\n', '\nAdam Gosztolai\n']","ICLR 2024 conference paper. Associated code:
  https://github.com/agosztolai/RVGP",,http://arxiv.org/abs/2309.16746v2,cs.LG,"['cs.LG', 'cs.MS', 'physics.data-an', 'q-bio.QM', 'stat.ML']",,,[]
"A directional regularization method for the limited-angle Helsinki
  Tomography Challenge using the Core Imaging Library (CIL)",http://arxiv.org/abs/2310.01671v1,2023-10-02T22:02:29Z,2023-10-02T22:02:29Z,"  This article presents the algorithms developed by the Core Imaging Library
(CIL) developer team for the Helsinki Tomography Challenge 2022. The challenge
focused on reconstructing 2D phantom shapes from limited-angle computed
tomography (CT) data. The CIL team designed and implemented five reconstruction
methods using CIL (https://ccpi.ac.uk/cil/), an open-source Python package for
tomographic imaging. The CIL team adopted a model-based reconstruction
strategy, unique to this challenge with all other teams relying on
deep-learning techniques. The CIL algorithms showcased exceptional performance,
with one algorithm securing the third place in the competition. The
best-performing algorithm employed careful CT data pre-processing and an
optimization problem with single-sided directional total variation
regularization combined with isotropic total variation and tailored lower and
upper bounds. The reconstructions and segmentations achieved high quality for
data with angular ranges down to 50 degrees, and in some cases acceptable
performance even at 40 and 30 degrees. This study highlights the effectiveness
of model-based approaches in limited-angle tomography and emphasizes the
importance of proper algorithmic design leveraging on available prior knowledge
to overcome data limitations. Finally, this study highlights the flexibility of
CIL for prototyping and comparison of different optimization methods.
","['\nJakob Sauer Jørgensen\n', '\nEvangelos Papoutsellis\n', '\nLaura Murgatroyd\n', '\nGemma Fardell\n', '\nEdoardo Pasca\n']","20 pages, 14 figures",,http://arxiv.org/abs/2310.01671v1,physics.med-ph,"['physics.med-ph', 'cs.MS', 'cs.NA', 'math.NA', 'math.OC', '65R32, 94A08, 65K10', 'G.1.6; G.1.10; G.4']",,,[]
"Physics Informed Neural Network Code for 2D Transient Problems
  (PINN-2DT) Compatible with Google Colab",http://arxiv.org/abs/2310.03755v2,2023-09-24T07:08:36Z,2024-02-19T21:08:45Z,"  We present an open-source Physics Informed Neural Network environment for
simulations of transient phenomena on two-dimensional rectangular domains, with
the following features: (1) it is compatible with Google Colab which allows
automatic execution on cloud environment; (2) it supports two dimensional
time-dependent PDEs; (3) it provides simple interface for definition of the
residual loss, boundary condition and initial loss, together with their
weights; (4) it support Neumann and Dirichlet boundary conditions; (5) it
allows for customizing the number of layers and neurons per layer, as well as
for arbitrary activation function; (6) the learning rate and number of epochs
are available as parameters; (7) it automatically differentiates PINN with
respect to spatial and temporal variables; (8) it provides routines for
plotting the convergence (with running average), initial conditions learnt, 2D
and 3D snapshots from the simulation and movies (9) it includes a library of
problems: (a) non-stationary heat transfer; (b) wave equation modeling a
tsunami; (c) atmospheric simulations including thermal inversion; (d) tumor
growth simulations.
","['\nPaweł Maczuga\n', '\nMaciej Sikora\n', '\nMaciej Skoczeń\n', '\nPrzemysław Rożnawski\n', '\nFilip Tłuszcz\n', '\nMarcin Szubert\n', '\nMarcin Łoś\n', '\nWitold Dzwinel\n', '\nKeshav Pingali\n', '\nMaciej Paszyński\n']","21 pages, 13 figures",,http://arxiv.org/abs/2310.03755v2,cs.CE,"['cs.CE', 'cs.LG', 'cs.MS', 'cs.NA', 'math.NA', 'G.1.8; G.1.10; J.2; J.3; G.4; I.6.4; I.m']",,,[]
"CDL: A fast and flexible library for the study of permutation sets with
  structural restrictions",http://arxiv.org/abs/2309.06306v2,2023-09-12T15:17:16Z,2024-01-25T11:04:46Z,"  In this paper, we introduce CDL, a software library designed for the analysis
of permutations and linear orders subject to various structural restrictions.
Prominent examples of these restrictions include pattern avoidance, a topic of
interest in both computer science and combinatorics, and ""never conditions""
utilized in social choice and voting theory.
  CDL offers a range of fundamental functionalities, including identifying the
permutations that meet specific restrictions and determining the isomorphism of
such sets. To facilitate exploration of large permutation sets or domains, CDL
incorporates multiple search strategies and heuristics.
","['\nBei Zhou\n', '\nKlas Markstrōm\n', '\nSøren Riis\n']",7 pages,,http://arxiv.org/abs/2309.06306v2,cs.MS,['cs.MS'],,,[]
Satisfiability.jl: Satisfiability Modulo Theories in Julia,http://arxiv.org/abs/2309.08778v2,2023-09-15T21:44:49Z,2023-12-16T01:55:49Z,"  Satisfiability modulo theories (SMT) is a core tool in formal verification.
While the SMT-LIB specification language can be used to interact with theorem
proving software, a high-level interface allows for faster and easier
specifications of complex SMT formulae. In this paper we present a novel
open-source package for interacting with SMT-LIB compliant solvers in the Julia
programming language.
","['\nEmiko Soroka\n', '\nMykel J. Kochenderfer\n', '\nSanjay Lall\n']","7 pages, revised from a previous longer version to comply with a
  conference length requirement. Submitted to NASA Formal Methods 2024",,http://arxiv.org/abs/2309.08778v2,cs.LO,"['cs.LO', 'cs.MS', 'D.2.4']",,,[]
"Integration of Quantum Accelerators with High Performance Computing -- A
  Review of Quantum Programming Tools",http://arxiv.org/abs/2309.06167v2,2023-09-12T12:24:12Z,2023-09-18T08:02:54Z,"  Quantum computing (QC) introduces a novel mode of computation with the
possibility of greater computational power that remains to be exploited -
presenting exciting opportunities for high performance computing (HPC)
applications. However, recent advancements in the field have made clear that QC
does not supplant conventional HPC, but can rather be incorporated into current
heterogeneous HPC infrastructures as an additional accelerator, thereby
enabling the optimal utilization of both paradigms. The desire for such
integration significantly affects the development of software for quantum
computers, which in turn influences the necessary software infrastructure. To
date, previous review papers have investigated various quantum programming
tools (QPTs) (such as languages, libraries, frameworks) in their ability to
program, compile, and execute quantum circuits. However, the integration effort
with classical HPC frameworks or systems has not been addressed. This study
aims to characterize existing QPTs from an HPC perspective, investigating if
existing QPTs have the potential to be efficiently integrated with classical
computing models and determining where work is still required. This work
structures a set of criteria into an analysis blueprint that enables HPC
scientists to assess whether a QPT is suitable for the quantum-accelerated
classical application at hand.
","['\nAmr Elsharkawy\n', '\nXiao-Ting Michelle To\n', '\nPhilipp Seitz\n', '\nYanbin Chen\n', '\nYannick Stade\n', '\nManuel Geiger\n', '\nQunsheng Huang\n', '\nXiaorang Guo\n', '\nMuhammad Arslan Ansari\n', '\nChristian B. Mendl\n', '\nDieter Kranzlmüller\n', '\nMartin Schulz\n']","35 pages, 8 figures and 4 tables",,http://arxiv.org/abs/2309.06167v2,cs.ET,"['cs.ET', 'cs.MS', 'quant-ph']",,,[]
"A Distributed Data-Parallel PyTorch Implementation of the Distributed
  Shampoo Optimizer for Training Neural Networks At-Scale",http://arxiv.org/abs/2309.06497v1,2023-09-12T18:11:10Z,2023-09-12T18:11:10Z,"  Shampoo is an online and stochastic optimization algorithm belonging to the
AdaGrad family of methods for training neural networks. It constructs a
block-diagonal preconditioner where each block consists of a coarse Kronecker
product approximation to full-matrix AdaGrad for each parameter of the neural
network. In this work, we provide a complete description of the algorithm as
well as the performance optimizations that our implementation leverages to
train deep networks at-scale in PyTorch. Our implementation enables fast
multi-GPU distributed data-parallel training by distributing the memory and
computation associated with blocks of each parameter via PyTorch's DTensor data
structure and performing an AllGather primitive on the computed search
directions at each iteration. This major performance enhancement enables us to
achieve at most a 10% performance reduction in per-step wall-clock time
compared against standard diagonal-scaling-based adaptive gradient methods. We
validate our implementation by performing an ablation study on training
ImageNet ResNet50, demonstrating Shampoo's superiority over standard training
recipes with minimal hyperparameter tuning.
","['\nHao-Jun Michael Shi\n', '\nTsung-Hsien Lee\n', '\nShintaro Iwasaki\n', '\nJose Gallego-Posada\n', '\nZhijing Li\n', '\nKaushik Rangadurai\n', '\nDheevatsa Mudigere\n', '\nMichael Rabbat\n']","38 pages, 8 figures, 5 tables",,http://arxiv.org/abs/2309.06497v1,cs.LG,"['cs.LG', 'cs.DC', 'cs.MS', 'math.OC']",,,[]
"Unlocking massively parallel spectral proper orthogonal decompositions
  in the PySPOD package",http://arxiv.org/abs/2309.11808v1,2023-09-21T06:28:07Z,2023-09-21T06:28:07Z,"  We propose a parallel (distributed) version of the spectral proper orthogonal
decomposition (SPOD) technique. The parallel SPOD algorithm distributes the
spatial dimension of the dataset preserving time. This approach is adopted to
preserve the non-distributed fast Fourier transform of the data in time,
thereby avoiding the associated bottlenecks. The parallel SPOD algorithm is
implemented in the PySPOD (https://github.com/MathEXLab/PySPOD) library and
makes use of the standard message passing interface (MPI) library, implemented
in Python via mpi4py (https://mpi4py.readthedocs.io/en/stable/). An extensive
performance evaluation of the parallel package is provided, including strong
and weak scalability analyses. The open-source library allows the analysis of
large datasets of interest across the scientific community. Here, we present
applications in fluid dynamics and geophysics, that are extremely difficult (if
not impossible) to achieve without a parallel algorithm. This work opens the
path toward modal analyses of big quasi-stationary data, helping to uncover new
unexplored spatio-temporal patterns.
","['\nMarcin Rogowski\n', '\nBrandon C. Y. Yeung\n', '\nOliver T. Schmidt\n', '\nRomit Maulik\n', '\nLisandro Dalcin\n', '\nMatteo Parsani\n', '\nGianmarco Mengaldo\n']",,,http://arxiv.org/abs/2309.11808v1,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS']",,,[]
"$\texttt{ChisholmD.wl}$- Automated rational approximant for bi-variate
  series",http://arxiv.org/abs/2309.07687v1,2023-09-14T13:03:24Z,2023-09-14T13:03:24Z,"  The Chisholm rational approximant is a natural generalization to two
variables of the well-known single variable Pad\'e approximant, and has the
advantage of reducing to the latter when one of the variables is set equals to
0. We present, to our knowledge, the first automated Mathematica package to
evaluate diagonal Chisholm approximants of two variable series. For the moment,
the package can only be used to evaluate diagonal approximants i.e. the maximum
powers of both the variables, in both the numerator and the denominator, is
equal to some integer $M$. We further modify the original method so as to allow
us to evaluate the approximants around some general point $(x,y)$ not
necessarily $(0,0)$. Using the approximants around general point $(x,y)$,
allows us to get a better estimate of the result when the point of evaluation
is far from $(0,0)$. Several examples of the elementary functions have been
studied which shows that the approximants can be useful for analytic
continuation and convergence acceleration purposes. We continue our study using
various examples of two variable hypergeometric series,
$\mathrm{Li}_{2,2}(x,y)$ etc that arise in particle physics and in the study of
critical phenomena in condensed matter physics. The demonstration of the
package is discussed in detail and the Mathematica package is provided as an
ancillary file.
","['\nSouvik Bera\n', '\nTanay Pathak\n']","23 pages, 3 figures, 1 ancillary file",,http://arxiv.org/abs/2309.07687v1,cs.MS,"['cs.MS', 'cs.NA', 'hep-ph', 'math-ph', 'math.MP', 'math.NA']",,,[]
A FAIR File Format for Mathematical Software,http://arxiv.org/abs/2309.00465v1,2023-09-01T14:03:44Z,2023-09-01T14:03:44Z,"  We describe a generic JSON based file format which is suitable for
computations in computer algebra. This is implemented in the computer algebra
system OSCAR, but we also indicate how it can be used in a different context.
","['\nAntony Della Vecchia\n', '\nMichael Joswig\n', '\nBenjamin Lorenz\n']",,,http://arxiv.org/abs/2309.00465v1,cs.MS,['cs.MS'],,,[]
"Enhancing Missing Data Imputation of Non-stationary Signals with
  Harmonic Decomposition",http://arxiv.org/abs/2309.04630v1,2023-09-08T22:45:54Z,2023-09-08T22:45:54Z,"  Dealing with time series with missing values, including those afflicted by
low quality or over-saturation, presents a significant signal processing
challenge. The task of recovering these missing values, known as imputation,
has led to the development of several algorithms. However, we have observed
that the efficacy of these algorithms tends to diminish when the time series
exhibit non-stationary oscillatory behavior. In this paper, we introduce a
novel algorithm, coined Harmonic Level Interpolation (HaLI), which enhances the
performance of existing imputation algorithms for oscillatory time series.
After running any chosen imputation algorithm, HaLI leverages the harmonic
decomposition based on the adaptive nonharmonic model of the initial imputation
to improve the imputation accuracy for oscillatory time series. Experimental
assessments conducted on synthetic and real signals consistently highlight that
HaLI enhances the performance of existing imputation algorithms. The algorithm
is made publicly available as a readily employable Matlab code for other
researchers to use.
","['\nJoaquin Ruiz\n', '\nHau-tieng Wu\n', '\nMarcelo A. Colominas\n']",,,http://arxiv.org/abs/2309.04630v1,eess.SP,"['eess.SP', 'cs.MS']",,,[]
"A Novel Immersed Boundary Approach for Irregular Topography with
  Acoustic Wave Equations",http://arxiv.org/abs/2309.03600v1,2023-09-07T09:51:05Z,2023-09-07T09:51:05Z,"  Irregular terrain has a pronounced effect on the propagation of seismic and
acoustic wavefields but is not straightforwardly reconciled with structured
finite-difference (FD) methods used to model such phenomena. Methods currently
detailed in the literature are generally limited in scope application-wise or
non-trivial to apply to real-world geometries. With this in mind, a general
immersed boundary treatment capable of imposing a range of boundary conditions
in a relatively equation-agnostic manner has been developed, alongside a
framework implementing this approach, intending to complement emerging
code-generation paradigms. The approach is distinguished by the use of
N-dimensional Taylor-series extrapolants constrained by boundary conditions
imposed at some suitably-distributed set of surface points. The extrapolation
process is encapsulated in modified derivative stencils applied in the vicinity
of the boundary, utilizing hyperspherical support regions. This method ensures
boundary representation is consistent with the FD discretization: both must be
considered in tandem. Furthermore, high-dimensional and vector boundary
conditions can be applied without approximation prior to discretization. A
consistent methodology can thus be applied across free and rigid surfaces with
the first and second-order acoustic wave equation formulations. Application to
both equations is demonstrated, and numerical examples based on analytic and
real-world topography implementing free and rigid surfaces in 2D and 3D are
presented.
","['\nEdward Caunt\n', '\nRhodri Nelson\n', '\nFabio Luporini\n', '\nGerard Gorman\n']","Submitted to Geophysics. 24 pages, 26 figures",,http://arxiv.org/abs/2309.03600v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Alternative quadrant representations with Morton index and AVX2
  vectorization for AMR algorithms within the p4est software library",http://arxiv.org/abs/2308.13615v1,2023-08-24T14:05:05Z,2023-08-24T14:05:05Z,"  We present a technical enhancement within the p4est software for parallel
adaptive mesh refinement. In p4est primitives are stored as octants in three
and quadrants in two dimensions. While, classically, they are encoded by the
native approach using its spatial and refinement level, any other
mathematically equivalent encoding might be used instead.
  Recognizing this, we add two alternative representations to the classical,
explicit version, based on a long monotonic index and 128-bit AVX quad
integers, respectively. The first one requires changes in logic for low-level
quadrant manipulating algorithms, while the other exploits data level
parallelism and requires algorithms to be adapted to SIMD instructions. The
resultant algorithms and data structures lead to higher performance and lesser
memory usage in comparison with the standard baseline.
  We benchmark selected algorithms on a cluster with two Intel(R) Xeon(R) Gold
6130 Skylake family CPUs per node, which provides support for AVX2 extensions,
192 GB RAM per node, and up to 512 computational cores in total.
","['\nMikhail Kirilin\nINS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany\n', '\nCarsten Burstedde\nINS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany\n']","10 pages, 7 figures and 12 algorithms, submitted to Proceedings of
  the 2024 SIAM Conference on Parallel Processing for Scientific Computing
  (PP). For reprodusing results use branches
  https://github.com/cburstedde/p4est/tree/p4est-virtual and
  https://github.com/cburstedde/libsc/tree/feature-sc3 and executable
  build_dir>/example/timings/p8est3_p3time",,http://arxiv.org/abs/2308.13615v1,cs.MS,"['cs.MS', 'G.4; I.6.8; E.2']",,,"['INS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany', 'INS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany']"
Hierarchical Lowrank Arithmetic with Binary Compression,http://arxiv.org/abs/2308.10960v1,2023-08-21T18:15:05Z,2023-08-21T18:15:05Z,"  With lowrank approximation the storage requirements for dense data are
reduced down to linear complexity and with the addition of hierarchy this also
works for data without global lowrank properties. However, the lowrank factors
itself are often still stored using double precision numbers. Newer approaches
exploit the different IEEE754 floating point formats available nowadays in a
mixed precision approach. However, these formats show a significant gap in
storage (and accuracy), e.g. between half, single and double precision. We
therefore look beyond these standard formats and use adaptive compression for
storing the lowrank and dense data and investigate how that affects the
arithmetic of such matrices.
",['\nRonald Kriemann\n'],,,http://arxiv.org/abs/2308.10960v1,cs.MS,"['cs.MS', 'cs.DS', '65Y05, 65Y20, 68W10, 68W25, 68P30']",,,[]
"Evolutionary Dynamic Optimization Laboratory: A MATLAB Optimization
  Platform for Education and Experimentation in Dynamic Environments",http://arxiv.org/abs/2308.12644v1,2023-08-24T08:37:32Z,2023-08-24T08:37:32Z,"  Many real-world optimization problems possess dynamic characteristics.
Evolutionary dynamic optimization algorithms (EDOAs) aim to tackle the
challenges associated with dynamic optimization problems. Looking at the
existing works, the results reported for a given EDOA can sometimes be
considerably different. This issue occurs because the source codes of many
EDOAs, which are usually very complex algorithms, have not been made publicly
available. Indeed, the complexity of components and mechanisms used in many
EDOAs makes their re-implementation error-prone. In this paper, to assist
researchers in performing experiments and comparing their algorithms against
several EDOAs, we develop an open-source MATLAB platform for EDOAs, called
Evolutionary Dynamic Optimization LABoratory (EDOLAB). This platform also
contains an education module that can be used for educational purposes. In the
education module, the user can observe a) a 2-dimensional problem space and how
its morphology changes after each environmental change, b) the behaviors of
individuals over time, and c) how the EDOA reacts to environmental changes and
tries to track the moving optimum. In addition to being useful for research and
education purposes, EDOLAB can also be used by practitioners to solve their
real-world problems. The current version of EDOLAB includes 25 EDOAs and three
fully-parametric benchmark generators. The MATLAB source code for EDOLAB is
publicly available and can be accessed from
[https://github.com/EDOLAB-platform/EDOLAB-MATLAB].
","['\nMai Peng\n', '\nZeneng She\n', '\nDelaram Yazdani\n', '\nDanial Yazdani\n', '\nWenjian Luo\n', '\nChanghe Li\n', '\nJuergen Branke\n', '\nTrung Thanh Nguyen\n', '\nAmir H. Gandomi\n', '\nYaochu Jin\n', '\nXin Yao\n']","This work was submitted to ACM Transactions on Mathematical Software
  on December 7, 2022",,http://arxiv.org/abs/2308.12644v1,cs.NE,"['cs.NE', 'cs.MS']",,,[]
Computation of GIT quotients of semisimple groups,http://arxiv.org/abs/2308.08049v1,2023-08-15T21:29:22Z,2023-08-15T21:29:22Z,"  We describe three algorithms to determine the stable, semistable, and
torus-polystable loci of the GIT quotient of a projective variety by a
reductive group. The algorithms are efficient when the group is semisimple. By
using an implementation of our algorithms for simple groups, we provide several
applications to the moduli theory of algebraic varieties, including the
K-moduli of algebraic varieties, the moduli of algebraic curves and the Mukai
models of the moduli space of curves for low genus. We also discuss a number of
potential improvements and some natural open problems arising from this work.
","['\nPatricio Gallardo\n', '\nJesus Martinez-Garcia\n', '\nHan-Bom Moon\n', '\nDavid Swinarski\n']","32 pages, 3 figures. 1 table",,http://arxiv.org/abs/2308.08049v1,math.AG,"['math.AG', 'cs.MS', '14L24, 14Q20, 14-04, 13A50']",,,[]
Graph4J -- A computationally efficient Java library for graph algorithms,http://arxiv.org/abs/2308.09920v1,2023-08-19T06:08:24Z,2023-08-19T06:08:24Z,"  Graph algorithms play an important role in many computer science areas. In
order to solve problems that can be modeled using graphs, it is necessary to
use a data structure that can represent those graphs in an efficient manner. On
top of this, an infrastructure should be build that will assist in implementing
common algorithms or developing specialized ones. Here, a new Java library is
introduced, called Graph4J, that uses a different approach when compared to
existing, well-known Java libraries such as JGraphT, JUNG and Guava Graph.
Instead of using object-oriented data structures for graph representation, a
lower-level model based on arrays of primitive values is utilized, that
drastically reduces the required memory and the running times of the algorithm
implementations. The design of the library, the space complexity of the graph
structures and the time complexity of the most common graph operations are
presented in detail, along with an experimental study that evaluates its
performance, when compared to the other libraries. Emphasis is given to
infrastructure related aspects, that is graph creation, inspection, alteration
and traversal. The improvements obtained for other implemented algorithms are
also analyzed and it is shown that the proposed library significantly
outperforms the existing ones.
","['\nCristian Frăsinaru\n', '\nEmanuel Florentin Olariu\n']",,,http://arxiv.org/abs/2308.09920v1,cs.MS,"['cs.MS', 'cs.DS']",,,[]
"Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for
  Tetrad Causal Search",http://arxiv.org/abs/2308.07346v1,2023-08-13T16:29:05Z,2023-08-13T16:29:05Z,"  We give novel Python and R interfaces for the (Java) Tetrad project for
causal modeling, search, and estimation. The Tetrad project is a mainstay in
the literature, having been under consistent development for over 30 years.
Some of its algorithms are now classics, like PC and FCI; others are recent
developments. It is increasingly the case, however, that researchers need to
access the underlying Java code from Python or R. Existing methods for doing
this are inadequate. We provide new, up-to-date methods using the JPype
Python-Java interface and the Reticulate Python-R interface, directly solving
these issues. With the addition of some simple tools and the provision of
working examples for both Python and R, using JPype and Reticulate to interface
Python and R with Tetrad is straightforward and intuitive.
","['\nJoseph D. Ramsey\n', '\nBryan Andrews\n']","Causal Analysis Workshop Series (CAWS) 2023, 12 pages, 4 Figures, 2
  Tables",,http://arxiv.org/abs/2308.07346v1,cs.MS,"['cs.MS', 'cs.AI', 'cs.PL', '62D20', 'I.2.5; D.1.m']",,,[]
"Performant low-order matrix-free finite element kernels on GPU
  architectures",http://arxiv.org/abs/2308.09839v2,2023-08-18T22:21:54Z,2023-08-22T19:52:43Z,"  Numerical methods such as the Finite Element Method (FEM) have been
successfully adapted to utilize the computational power of GPU accelerators.
However, much of the effort around applying FEM to GPU's has been focused on
high-order FEM due to higher arithmetic intensity and order of accuracy. For
applications such as the simulation of subsurface processes, high levels of
heterogeneity results in high-resolution grids characterized by highly
discontinuous (cell-wise) material property fields. Moreover, due to the
significant uncertainties in the characterization of the domain of interest,
e.g. geologic reservoirs, the benefits of high order accuracy are reduced, and
low-order methods are typically employed. In this study, we present a strategy
for implementing highly performant low-order matrix-free FEM operator kernels
in the context of the conjugate gradient (CG) method. Performance results of
matrix-free Laplace and isotropic elasticity operator kernels are presented and
are shown to compare favorably to matrix-based SpMV operators on V100, A100,
and MI250X GPUs.
","['\nRandolph R. Settgast\n', '\nYohann Dudouit\n', '\nNicola Castelletto\n', '\nWilliam R. Tobin\n', '\nBenjamin C. Corbett\n', '\nSergey Klevtsov\n']",,,http://arxiv.org/abs/2308.09839v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Leveraging MLIR for Loop Vectorization and GPU Porting of FFT Libraries,http://arxiv.org/abs/2308.00497v1,2023-08-01T12:32:26Z,2023-08-01T12:32:26Z,"  FFTc is a Domain-Specific Language (DSL) for designing and generating Fast
Fourier Transforms (FFT) libraries. The FFTc uniqueness is that it leverages
and extend Multi-Level Intermediate Representation (MLIR) dialects to optimize
FFT code generation. In this work, we present FFTc extensions and improvements
such as the possibility of using different data layout for complex-value
arrays, and sparsification to enable efficient vectorization, and a seamless
porting of FFT libraries to GPU systems. We show that, on CPUs, thanks to
vectorization, the performance of the FFTc-generated FFT is comparable to
performance of FFTW, a state-of-the-art FFT libraries. We also present the
initial performance results for FFTc on Nvidia GPUs.
","['\nYifei He\n', '\nArtur Podobas\n', '\nStefano Markidis\n']",,,http://arxiv.org/abs/2308.00497v1,cs.MS,['cs.MS'],,,[]
Bandicoot: C++ Library for GPU Linear Algebra and Scientific Computing,http://arxiv.org/abs/2308.03120v1,2023-08-06T14:01:12Z,2023-08-06T14:01:12Z,"  This report provides an introduction to the Bandicoot C++ library for linear
algebra and scientific computing on GPUs, overviewing its user interface and
performance characteristics, as well as the technical details of its internal
design. Bandicoot is the GPU-enabled counterpart to the well-known Armadillo
C++ linear algebra library, aiming to allow users to take advantage of
GPU-accelerated computation for their existing codebases without significant
changes. Adapting the same internal template meta-programming techniques that
Armadillo uses, Bandicoot is able to provide compile-time optimisation of
mathematical expressions within user code. The library is ready for production
use and is available at https://coot.sourceforge.io. Bandicoot is distributed
under the Apache 2.0 License.
","['\nRyan R. Curtin\n', '\nMarcus Edel\n', '\nConrad Sanderson\n']",,,http://arxiv.org/abs/2308.03120v1,cs.MS,"['cs.MS', '65Y05, 65F45, 15-04', 'G.1.3; G.4; I.3.1; I.3.6']",,,[]
"PyPartMC: A Pythonic interface to a particle-resolved, Monte Carlo
  aerosol simulation framework",http://arxiv.org/abs/2308.02052v3,2023-08-03T21:10:44Z,2023-12-19T19:39:34Z,"  PyPartMC is a Pythonic interface to PartMC, a stochastic, particle-resolved
aerosol model implemented in Fortran. Both PyPartMC and PartMC are free, libre,
and open-source. PyPartMC reduces the number of steps and mitigates the effort
necessary to install and utilize the resources of PartMC. Without PyPartMC,
setting up PartMC requires: working with UNIX shell, providing Fortran and C
libraries, and performing standard Fortran and C source code configuration,
compilation and linking. This can be challenging for those less experienced
with computational research or those intending to use PartMC in environments
where provision of UNIX tools is less straightforward (e.g., on Windows).
PyPartMC offers a single-step installation/upgrade process of PartMC and all
dependencies through the pip Python package manager on Linux, macOS, and
Windows. This allows streamlined access to the unmodified and versioned Fortran
internals of the PartMC codebase from both Python and other interoperable
environments (e.g., Julia through PyCall). Consequently, users of PyPartMC can
setup, run, process and visualize output of PartMC simulations using a single
general-purpose programming language.
","[""\nZachary D'Aquino\n"", '\nSylwester Arabas\n', '\nJeffrey Curtis\n', '\nAkshunna Vaishnav\n', '\nNicole Riemer\n', '\nMatthew West\n']",,"SoftwareX, 25 (2023), 101613",http://dx.doi.org/10.1016/j.softx.2023.101613,cs.MS,"['cs.MS', 'physics.ao-ph']",10.1016/j.softx.2023.101613,,[]
Automatic Conversion of MiniZinc Programs to QUBO,http://arxiv.org/abs/2307.10032v1,2023-07-19T15:16:01Z,2023-07-19T15:16:01Z,"  Obtaining Quadratic Unconstrained Binary Optimisation models for various
optimisation problems, in order to solve those on physical quantum computers
(such as the the DWave annealers) is nowadays a lengthy and tedious process
that requires one to remodel all problem variables as binary variables and
squeeze the target function and the constraints into a single quadratic
polynomial into these new variables.
  We report here on the basis of our automatic converter from MiniZinc to QUBO,
which is able to process a large set of constraint optimisation and constraint
satisfaction problems and turn them into equivalent QUBOs, effectively
optimising the whole process.
","['\nArmin Wolf\n', '\nCristian Grozea\n']",,,http://arxiv.org/abs/2307.10032v1,cs.MS,"['cs.MS', 'cs.AI']",,,[]
GPU-accelerated Parallel Solutions to the Quadratic Assignment Problem,http://arxiv.org/abs/2307.11248v1,2023-07-20T21:38:52Z,2023-07-20T21:38:52Z,"  The Quadratic Assignment Problem (QAP) is an important combinatorial
optimization problem with applications in many areas including logistics and
manufacturing. QAP is known to be NP-hard, a computationally challenging
problem, which requires the use of sophisticated heuristics in finding
acceptable solutions for most real-world data sets.
  In this paper, we present GPU-accelerated implementations of a 2opt and a
tabu search algorithm for solving the QAP. For both algorithms, we extract
parallelism at multiple levels and implement novel code optimization techniques
that fully utilize the GPU hardware. On a series of experiments on the
well-known QAPLIB data sets, our solutions, on average run an
order-of-magnitude faster than previous implementations and deliver up to a
factor of 63 speedup on specific instances. The quality of the solutions
produced by our implementations of 2opt and tabu is within 1.03% and 0.15% of
the best known values. The experimental results also provide key insight into
the performance characteristics of accelerated QAP solvers. In particular, the
results reveal that both algorithmic choice and the shape of the input data
sets are key factors in finding efficient implementations.
","['\nClara Novoa\n', '\nApan Qasem\n']","25 pages, 9 figures; parts of this work appeared as short papers in
  XSEDE14 and XSEDE15 conferences. This version of the paper is a substantial
  extension of previous work with optimizations for newer GPU platforms and
  extended experimental results",,http://arxiv.org/abs/2307.11248v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Integrating Enzyme-generated functions into CoDiPack,http://arxiv.org/abs/2307.06075v1,2023-07-12T10:53:02Z,2023-07-12T10:53:02Z,"  In operator overloading algorithmic differentiation, it can be beneficial to
create custom derivative functions for some parts of the code base. For manual
implementations of the derivative functions, it can be quite cumbersome to
derive, implement, test, and maintain these. The process can be automated with
source transformation algorithmic differentiation tools like Tapenade or
compiler-based algorithmic differentiation tools like Enzyme. This eliminates
most of the work required from a manual implementation but usually has the same
efficiency with respect to timing and memory. We present a new helper in
CoDiPack that allows Enzyme-generated derivative functions to be automatically
added during the recording process of CoDiPack. The validity of the approach is
demonstrated on a synthetic benchmark, which shows promising results.
","['\nM. Sagebaum\n', '\nM. Aehle\n', '\nN. R. Gauger\n']",,,http://arxiv.org/abs/2307.06075v1,cs.MS,"['cs.MS', '65D25 (Primary), 68N30 (Secondary)', 'G.1.4; G.4; D.2.2']",,,[]
"A framework to test interval arithmetic libraries and their IEEE
  1788-2015 compliance",http://arxiv.org/abs/2307.06953v1,2023-07-12T19:48:29Z,2023-07-12T19:48:29Z,"  As developers of libraries implementing interval arithmetic, we faced the
same difficulties when it comes to testing our libraries. What must be tested?
How can we devise relevant test cases for unit testing? How can we ensure a
high (and possibly 100%) test coverage? Before considering these questions, we
briefly recall the main features of interval arithmetic and of the IEEE
1788-2015 standard for interval arithmetic. After listing the different aspects
that, in our opinion, must be tested, we contribute a first step towards
offering a test suite for an interval arithmetic library. First we define a
format that enables the exchange of test cases, so that they can be read and
tried easily. Then we offer a first set of test cases, for a selected set of
mathematical functions. Next, we examine how the Julia interval arithmetic
library, IntervalArithmetic.jl, actually performs to these tests. As this is an
ongoing work, we list extra tests that we deem important to perform.
","['\nLuis Benet\n', '\nLuca Ferranti\n', '\nNathalie Revol\n']",2 figures,,http://arxiv.org/abs/2307.06953v1,cs.MS,"['cs.MS', '65G99', 'G.0']",,,[]
ProtoX: A First Look,http://arxiv.org/abs/2307.07931v1,2023-07-16T03:33:19Z,2023-07-16T03:33:19Z,"  We present a first look at ProtoX, a code generation framework for stencil
and pointwise operations that occur frequently in the numerical solution of
partial differential equations. ProtoX has Proto as its library frontend and
SPIRAL as the backend. Proto is a C++ based domain specific library which
optimizes the algorithms used to compute the numerical solution of partial
differential equations. Meanwhile, SPIRAL is a code generation system that
focuses on generating highly optimized target code. Although the current design
layout of Proto and its high level of abstractions provide a user friendly set
up, there is still a room for improving it's performance by applying various
techniques either at a compiler level or at an algorithmic level. Hence, in
this paper we propose adding SPIRAL as the library backend for Proto enabling
abstraction fusion, which is usually difficult to perform by any compiler. We
demonstrate the construction of ProtoX by considering the 2D Poisson equation
as a model problem from Proto. We provide the final generated code for CPU,
Multi-core CPU, and GPU as well as some performance numbers for CPU.
","['\nHet Mankad\n', '\nSanil Rao\n', '\nBrian Van Straalen\n', '\nPhillip Colella\n', '\nFranz Franchetti\n']",,,http://arxiv.org/abs/2307.07931v1,cs.MS,['cs.MS'],,,[]
"MindOpt Tuner: Boost the Performance of Numerical Software by Automatic
  Parameter Tuning",http://arxiv.org/abs/2307.08085v1,2023-07-16T15:57:25Z,2023-07-16T15:57:25Z,"  Numerical software is usually shipped with built-in hyperparameters. By
carefully tuning those hyperparameters, significant performance enhancements
can be achieved for specific applications. We developed MindOpt Tuner, a new
automatic tuning tool that supports a wide range of numerical software,
including optimization and other solvers. MindOpt Tuner uses elastic cloud
resources, features a web-based task management panel and integration with
ipython notebook with both command-line tools and Python APIs. Our experiments
with COIN-OR Cbc, an open-source mixed-integer optimization solver, demonstrate
remarkable improvements with the tuned parameters compared to the default ones
on the MIPLIB2017 test set, resulting in over 100x acceleration on several
problem instances. Additionally, the results demonstrate that Tuner has a
higher tuning efficiency compared to the state-of-the-art automatic tuning tool
SMAC3.
","['\nMengyuan Zhang\n', '\nWotao Yin\n', '\nMengchang Wang\n', '\nYangbin Shen\n', '\nPeng Xiang\n', '\nYou Wu\n', '\nLiang Zhao\n', '\nJunqiu Pan\n', '\nHu Jiang\n', '\nKuoLing Huang\n']",,,http://arxiv.org/abs/2307.08085v1,cs.MS,['cs.MS'],,,[]
AsaPy: A Python Library for Aerospace Simulation Analysis,http://arxiv.org/abs/2310.00001v1,2023-07-12T00:02:37Z,2023-07-12T00:02:37Z,"  AsaPy is a custom-made Python library designed to simplify and optimize the
analysis of simulation data. It offers a range of features, including the
design of experiment methods, statistical analysis techniques, machine learning
algorithms, and data visualization tools. AsaPy's flexibility and
customizability make it a viable solution for engineers and researchers who
need to quickly gain insights into constructive simulations. AsaPy is built on
top of popular scientific computing libraries, ensuring high performance and
scalability. In this work, we provide an overview of the key features and
capabilities of AsaPy, followed by an exposition of its architecture and
demonstrations of its effectiveness through some use cases applied in military
operational simulations. We also evaluate how other simulation tools deal with
data science, highlighting AsaPy's strengths and advantages. Finally, we
discuss potential use cases and applications of AsaPy and outline future
directions for the development and improvement of the library.
","['\nJoao P. A. Dantas\n', '\nSamara R. Silva\n', '\nVitor C. F. Gomes\n', '\nAndre N. Costa\n', '\nAdrisson R. Samersla\n', '\nDiego Geraldo\n', '\nMarcos R. O. A. Maximo\n', '\nTakashi Yoneyama\n']",,,http://arxiv.org/abs/2310.00001v1,cs.MS,['cs.MS'],,,[]
"scda: A Minimal, Serial-Equivalent Format for Parallel I/O",http://arxiv.org/abs/2307.06789v1,2023-07-13T14:59:22Z,2023-07-13T14:59:22Z,"  We specify a file-oriented data format suitable for parallel,
partition-independent disk I/O. Here, a partition refers to a disjoint and
ordered distribution of the data elements between one or more processes. The
format is designed such that the file contents are invariant under linear (i.
e., unpermuted), parallel repartition of the data prior to writing. The file
contents are indistinguishable from writing in serial. In the same vein, the
file can be read on any number of processes that agree on any partition of the
number of elements stored.
  In addition to the format specification we propose an optional convention to
implement transparent per-element data compression. The compressed data and
metadata is layered inside ordinary format elements. Overall, we pay special
attention to both human and machine readability. If pure ASCII data is written,
or compressed data is reencoded to ASCII, the entire file including its header
and sectioning metadata remains entirely in ASCII. If binary data is written,
the metadata stays easy on the human eye.
  We refer to this format as scda. Conceptually, it lies one layer below and is
oblivious to the definition of variables, the binary representation of numbers,
considerations of endianness, and self-describing headers, which may all be
specified on top of scda. The main purpose of the format is to abstract any
parallelism and provide sufficient structure as a foundation for a generic and
flexible archival and checkpoint/restart. A documented reference implementation
is available as part of the general-purpose libsc free software library.
","['\nTim Griesbach\nINS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany\n', '\nCarsten Burstedde\nINS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany\n']","17 pages, 7 figures and 2 tables",,http://arxiv.org/abs/2307.06789v1,cs.DC,"['cs.DC', 'cs.MS', 'H.3.2; I.6.7; G.4']",,,"['INS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany', 'INS, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany']"
SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees,http://arxiv.org/abs/2307.04849v1,2023-07-10T18:40:25Z,2023-07-10T18:40:25Z,"  Gradient boosted trees (GBTs) are ubiquitous models used by researchers,
machine learning (ML) practitioners, and data scientists because of their
robust performance, interpretable behavior, and ease-of-use. One critical
challenge in training GBTs is the tuning of their hyperparameters. In practice,
selecting these hyperparameters is often done manually. Recently, the ML
community has advocated for tuning hyperparameters through black-box
optimization and developed state-of-the-art systems to do so. However, applying
such systems to tune GBTs suffers from two drawbacks. First, these systems are
not \textit{model-aware}, rather they are designed to apply to a
\textit{generic} model; this leaves significant optimization performance on the
table. Second, using these systems requires \textit{domain knowledge} such as
the choice of hyperparameter search space, which is an antithesis to the
automatic experimentation that black-box optimization aims to provide. In this
paper, we present SigOpt Mulch, a model-aware hyperparameter tuning system
specifically designed for automated tuning of GBTs that provides two
improvements over existing systems. First, Mulch leverages powerful techniques
in metalearning and multifidelity optimization to perform model-aware
hyperparameter optimization. Second, it automates the process of learning
performant hyperparameters by making intelligent decisions about the
optimization search space, thus reducing the need for user domain knowledge.
These innovations allow Mulch to identify good GBT hyperparameters far more
efficiently -- and in a more seamless and user-friendly way -- than existing
black-box hyperparameter tuning systems.
","['\nAleksei Sorokin\n', '\nXinran Zhu\n', '\nEric Hans Lee\n', '\nBolong Cheng\n']",,"Knowledge-Based Systems Volume 273, 3 August 2023, 110604",http://dx.doi.org/10.1016/j.knosys.2023.110604,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS']",10.1016/j.knosys.2023.110604,,[]
"Minimum Cost Loop Nests for Contraction of a Sparse Tensor with a Tensor
  Network",http://arxiv.org/abs/2307.05740v1,2023-07-11T19:08:06Z,2023-07-11T19:08:06Z,"  Sparse tensor decomposition and completion are common in numerous
applications, ranging from machine learning to computational quantum chemistry.
Typically, the main bottleneck in optimization of these models are contractions
of a single large sparse tensor with a network of several dense matrices or
tensors (SpTTN). Prior works on high-performance tensor decomposition and
completion have focused on performance and scalability optimizations for
specific SpTTN kernels. We present algorithms and a runtime system for
identifying and executing the most efficient loop nest for any SpTTN kernel. We
consider both enumeration of such loop nests for autotuning and efficient
algorithms for finding the lowest cost loop-nest for simpler metrics, such as
buffer size or cache miss models. Our runtime system identifies the best choice
of loop nest without user guidance, and also provides a distributed-memory
parallelization of SpTTN kernels. We evaluate our framework using both
real-world and synthetic tensors. Our results demonstrate that our approach
outperforms available generalized state-of-the-art libraries and matches the
performance of specialized codes.
","['\nRaghavendra Kanakagiri\n', '\nEdgar Solomonik\n']","17 pages, 13 figures",,http://arxiv.org/abs/2307.05740v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF', 'cs.PL']",,,[]
Differentiable Forward Projector for X-ray Computed Tomography,http://arxiv.org/abs/2307.05801v1,2023-07-11T20:52:46Z,2023-07-11T20:52:46Z,"  Data-driven deep learning has been successfully applied to various computed
tomographic reconstruction problems. The deep inference models may outperform
existing analytical and iterative algorithms, especially in ill-posed CT
reconstruction. However, those methods often predict images that do not agree
with the measured projection data. This paper presents an accurate
differentiable forward and back projection software library to ensure the
consistency between the predicted images and the original measurements. The
software library efficiently supports various projection geometry types while
minimizing the GPU memory footprint requirement, which facilitates seamless
integration with existing deep learning training and inference pipelines. The
proposed software is available as open source: https://github.com/LLNL/LEAP.
","['\nHyojin Kim\n', '\nKyle Champley\n']","ICML 2023 Workshop: Differentiable Almost Everything: Differentiable
  Relaxations, Algorithms, Operators, and Simulators",,http://arxiv.org/abs/2307.05801v1,cs.LG,"['cs.LG', 'cs.CV', 'cs.MS']",,,[]
An R package for parametric estimation of causal effects,http://arxiv.org/abs/2307.08686v2,2023-07-17T17:47:50Z,2023-07-18T01:20:01Z,"  This article explains the usage of R package CausalModels, which is publicly
available on the Comprehensive R Archive Network. While packages are available
for sufficiently estimating causal effects, there lacks a package that provides
a collection of structural models using the conventional statistical approach
developed by Hernan and Robins (2020). CausalModels addresses this deficiency
of software in R concerning causal inference by offering tools for methods that
account for biases in observational data without requiring extensive
statistical knowledge. These methods should not be ignored and may be more
appropriate or efficient in solving particular problems. While implementations
of these statistical models are distributed among a number of causal packages,
CausalModels introduces a simple and accessible framework for a consistent
modeling pipeline among a variety of statistical methods for estimating causal
effects in a single R package. It consists of common methods including
standardization, IP weighting, G-estimation, outcome regression, instrumental
variables and propensity matching.
","['\nJoshua Wolff Anderson\n', '\nCyril Rakovski\n']",,,http://arxiv.org/abs/2307.08686v2,stat.ME,"['stat.ME', 'cs.LG', 'cs.MS', 'stat.AP']",,,[]
Rigorous Function Calculi in Ariadne,http://arxiv.org/abs/2306.17541v1,2023-06-30T10:53:27Z,2023-06-30T10:53:27Z,"  Almost all problems in applied mathematics, including the analysis of
dynamical systems, deal with spaces of real-valued functions on Euclidean
domains in their formulation and solution. In this paper, we describe the the
tool Ariadne, which provides a rigorous calculus for working with Euclidean
functions. We first introduce the Ariadne framework, which is based on a clean
separation of objects as providing exact, effective, validated and approximate
information. We then discuss the function calculus as implemented in \Ariadne,
including polynomial function models which are the fundamental class for
concrete computations. We then consider solution of some core problems of
functional analysis, namely solution of algebraic equations and differential
equations, and briefly discuss their use for the analysis of hybrid systems. We
will give examples of C++ and Python code for performing the various
calculations. Finally, we will discuss progress on extensions, including
improvements to the function calculus and extensions to more complicated
classes of system.
","['\nPieter Collins\n', '\nLuca Geretti\n', '\nSanja Zivanovic Gonzalez\n', '\nDavide Bresolin\n', '\nTiziano Villa\n']",,,http://arxiv.org/abs/2306.17541v1,cs.MS,['cs.MS'],,,[]
"Towards a Benchmark Framework for Model Order Reduction in the
  Mathematical Research Data Initiative (MaRDI)",http://arxiv.org/abs/2307.00137v1,2023-06-30T21:05:58Z,2023-06-30T21:05:58Z,"  The race for the most efficient, accurate, and universal algorithm in
scientific computing drives innovation. At the same time, this healthy
competition is only beneficial if the research output is actually comparable to
prior results. Fairly comparing algorithms can be a complex endeavor, as the
implementation, configuration, compute environment, and test problems need to
be well-defined. Due to the increase in computer-based experiments, new
infrastructure for facilitating the exchange and comparison of new algorithms
is also needed. To this end, we propose a benchmark framework, as a set of
generic specifications for comparing implementations of algorithms using test
cases native to a community. Its value lies in its ability to fairly compare
and validate existing methods for new applications, as well as compare newly
developed methods with existing ones. As a prototype for a more general
framework, we have begun building a benchmark tool for the model order
reduction (MOR) community. The data basis of the tool is the collection of the
Model Order Reduction Wiki (MORWiki). The wiki features three main categories:
benchmarks, methods, and software. An editorial board curates submissions and
patrols edited entries. Data sets for linear and parametric-linear models are
already well represented in the existing collection. Data sets for non-linear
or procedural models, for which only evaluation data, or codes / algorithmic
descriptions, rather than equations, are available, are being added and
extended. Properties and interesting characteristics used for benchmark
selection and later assessments are recorded in the model metadata. Our tool,
the Model Order Reduction Benchmarker (MORB) is under active development for
linear time-invariant systems and solvers.
","['\nPeter Benner\n', '\nKathryn Lund\n', '\nJens Saak\n']","8 pages, 2 figures",,http://dx.doi.org/10.1002/pamm.202300147,cs.MS,"['cs.MS', '65-04, 93-04, 93-11, 93C05']",10.1002/pamm.202300147,,[]
SpComp: A Sparsity Structure-Specific Compilation of Matrix Operations,http://arxiv.org/abs/2307.06109v1,2023-07-04T12:44:28Z,2023-07-04T12:44:28Z,"  Sparse matrix operations involve a large number of zero operands which makes
most of the operations redundant. The amount of redundancy magnifies when a
matrix operation repeatedly executes on sparse data. Optimizing matrix
operations for sparsity involves either reorganization of data or
reorganization of computations, performed either at compile-time or run-time.
Although compile-time techniques avert from introducing run-time overhead,
their application either is limited to simple sparse matrix operations
generating dense output and handling immutable sparse matrices or requires
manual intervention to customize the technique to different matrix operations.
We contribute a compile time technique called SpComp that optimizes a sparse
matrix operation by automatically customizing its computations to the positions
of non-zero values of the data. Our approach neither incurs any run-time
overhead nor requires any manual intervention. It is also applicable to complex
matrix operations generating sparse output and handling mutable sparse
matrices. We introduce a data-flow analysis, named Essential Indices Analysis,
that statically collects the symbolic information about the computations and
helps the code generator to reorganize the computations. The generated code
includes piecewise-regular loops, free from indirect references and amenable to
further optimization. We see a substantial performance gain by SpComp-generated
SpMSpV code when compared against the state-of-the-art TACO compiler and
piecewise-regular code generator. On average, we achieve 79% performance gain
against TACO and 83% performance gain against the piecewise-regular code
generator. When compared against the CHOLMOD library, SpComp generated sparse
Cholesky decomposition code showcases 65% performance gain on average.
","['\nBarnali Basak\n', '\nUday P. Khedker\n', '\nSupratim Biswas\n']",,,http://arxiv.org/abs/2307.06109v1,cs.MS,['cs.MS'],,,[]
Collective-Optimized FFTs,http://arxiv.org/abs/2306.16589v2,2023-06-28T22:41:14Z,2023-07-04T18:37:18Z,"  This paper measures the impact of the various alltoallv methods. Results are
analyzed within Beatnik, a Z-model solver that is bottlenecked by HeFFTe and
representative of applications that rely on FFTs.
","['\nEvelyn Namugwanya\n', '\nAmanda Bienz\n', '\nDerek Schafer\n', '\nAnthony Skjellum\n']",,,http://arxiv.org/abs/2306.16589v2,cs.MS,"['cs.MS', 'cs.PF']",,,[]
SYCL compute kernels for ExaHyPE,http://arxiv.org/abs/2306.16731v5,2023-06-29T07:14:17Z,2023-10-31T21:43:49Z,"  We discuss three SYCL realisations of a simple Finite Volume scheme over
multiple Cartesian patches. The realisation flavours differ in the way how they
map the compute steps onto loops and tasks: We compare an implementation that
is exclusively using a sequence of for-loops to a version that uses nested
parallelism, and finally benchmark these against a version modelling the
calculations as task graph. Our work proposes realisation idioms to realise
these flavours within SYCL. The results suggest that a mixture of classic task
and data parallelism performs if we map this hybrid onto a solely data-parallel
SYCL implementation, taking into account SYCL specifics and the problem size.
","['\nChung Ming Loi\n', '\nHeinrich Bockhorst\n', '\nTobias Weinzierl\n']",,,http://arxiv.org/abs/2306.16731v5,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"RamanSPy: An open-source Python package for integrative Raman
  spectroscopy data analysis",http://arxiv.org/abs/2307.13650v1,2023-07-05T08:56:45Z,2023-07-05T08:56:45Z,"  Raman spectroscopy is a non-destructive and label-free chemical analysis
technique, which plays a key role in the analysis and discovery cycle of
various branches of science. Nonetheless, progress in Raman spectroscopic
analysis is still impeded by the lack of software, methodological and data
standardisation, and the ensuing fragmentation and lack of reproducibility of
analysis workflows thereof. To address these issues, we introduce RamanSPy, an
open-source Python package for Raman spectroscopic research and analysis.
RamanSPy provides a comprehensive library of ready-to-use tools for
spectroscopic analysis, which streamlines day-to-day tasks, integrative
analyses, as well as novel research and algorithmic development. RamanSPy is
modular and open source, not tied to a particular technology or data format,
and can be readily interfaced with the burgeoning ecosystem for data science,
statistical analysis and machine learning in Python.
","['\nDimitar Georgiev\n', '\nSimon Vilms Pedersen\n', '\nRuoxiao Xie\n', '\nÁlvaro Fernández-Galiana\n', '\nMolly M. Stevens\n', '\nMauricio Barahona\n']",,,http://arxiv.org/abs/2307.13650v1,cond-mat.mtrl-sci,"['cond-mat.mtrl-sci', 'cs.MS', 'physics.data-an']",,,[]
"SparseOptimizer: Sparsify Language Models through Moreau-Yosida
  Regularization and Accelerate via Compiler Co-design",http://arxiv.org/abs/2306.15656v3,2023-06-27T17:50:26Z,2023-07-18T17:52:28Z,"  This paper introduces SparseOptimizer, a novel deep learning optimizer that
exploits Moreau-Yosida regularization to naturally induce sparsity in large
language models such as BERT, ALBERT and GPT. Key to the design of
SparseOptimizer is an embedded shrinkage operator, which imparts sparsity
directly within the optimization process. This operator, backed by a sound
theoretical framework, includes an analytical solution, thereby reinforcing the
optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play
functionality eradicates the need for code modifications, making it a
universally adaptable tool for a wide array of large language models. Empirical
evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2
confirm that SparseBERT and SparseALBERT, when sparsified using
SparseOptimizer, achieve performance comparable to their dense counterparts,
BERT and ALBERT, while significantly reducing their parameter count. Further,
this work proposes an innovative optimizer-compiler co-design strategy,
demonstrating the potential of inference acceleration (\textbf{3.37x},
\textbf{6.30x}, and \textbf{7.15x} in comparison with Pytorch, TensorFlow, and
LLVM generic compile, respectively) in SparseBERT when paired with an
appropriately designed compiler. This study represents a significant step
forward in the evolution of efficient, scalable, and high-performing large
language models, setting a precedent for future exploration and optimization in
this domain. The SparseOptimizer code and SparseALBERT model will be publicly
available upon paper acceptance.
",['\nFu-Ming Guo\n'],,,http://arxiv.org/abs/2306.15656v3,cs.LG,"['cs.LG', 'cs.AI', 'cs.CC', 'cs.CL', 'cs.MS']",,,[]
"From array algebra to energy efficiency on GPUs: Data and hardware
  shapes with dimension-lifting to optimize memory-processor layouts",http://arxiv.org/abs/2306.11148v1,2023-06-19T20:10:23Z,2023-06-19T20:10:23Z,"  We present a new formulation for parallel matrix multiplication (MM) to
out-perform the standard row-column code design. This algorithm is formulated
in the MoA formalism (A Mathematics of Arrays) and combines an array view of
hardware (dimension-lifting) to extend indexing to physical memory/processing
units, with a contiguous data layout derived from static transformations. This
view of a hardware-software model is thus a bridging model in the sense of
Valiant's BSP. OpenACCcode was derived from the MoA expressions's normal form,
producing optimal block sizes using the static information of types and shapes.
Experiments were run on Nvidia V100 GPUs and reveal energy consumption which is
quadratic in N, i.e. linear in the size of matrix. More generally this approach
may be an ideal way of formulating, optimizing, and mapping array algorithms to
embedded hardware. This work builds upon recently published results of NREL
scientists.
  .
",['\nLenore M. R. Mullin\n'],"9 pages, 12 figures",,http://arxiv.org/abs/2306.11148v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Calculating the matrix profile from noisy data,http://arxiv.org/abs/2306.10151v1,2023-06-16T19:41:07Z,2023-06-16T19:41:07Z,"  The matrix profile (MP) is a data structure computed from a time series which
encodes the data required to locate motifs and discords, corresponding to
recurring patterns and outliers respectively. When the time series contains
noisy data then the conventional approach is to pre-filter it in order to
remove noise but this cannot apply in unsupervised settings where patterns and
outliers are not annotated. The resilience of the algorithm used to generate
the MP when faced with noisy data remains unknown. We measure the similarities
between the MP from original time series data with MPs generated from the same
data with noisy data added under a range of parameter settings including adding
duplicates and adding irrelevant data. We use three real world data sets drawn
from diverse domains for these experiments Based on dissimilarities between the
MPs, our results suggest that MP generation is resilient to a small amount of
noise being introduced into the data but as the amount of noise increases this
resilience disappears
","['\nColin Hehir\n', '\nAlan F. Smeaton\n']",16 pages,PLoS ONE 18(6): e0286763,http://dx.doi.org/10.1371/journal.pone.0286763,cs.LG,"['cs.LG', 'cs.MS', 'cs.NA', 'math.NA']",10.1371/journal.pone.0286763,,[]
An algorithm to approximate the real trilogarithm for a real argument,http://arxiv.org/abs/2308.11619v2,2023-06-21T15:53:14Z,2023-08-25T15:02:20Z,"  We present an algorithm to approximate the real trilogarithm for a real
argument with IEEE 754-1985 double precision accuracy. The approximation is
structured such that it can make use of instruction-level parallelism when
executed on appropriate CPUs.
",['\nAlexander Voigt\n'],"4 pages, 3 tables, attached source code",,http://arxiv.org/abs/2308.11619v2,cs.MS,"['cs.MS', 'cs.NA', 'hep-ph', 'math.NA', '33-04, 33E20, 33F05, 65D20']",,,[]
"Extending JumpProcess.jl for fast point process simulation with
  time-varying intensities",http://arxiv.org/abs/2306.06992v3,2023-06-12T09:39:20Z,2023-07-24T07:39:38Z,"  Point processes model the occurrence of a countable number of random points
over some support. They can model diverse phenomena, such as chemical
reactions, stock market transactions and social interactions. We show that
JumpProcesses.jl is a fast, general-purpose library for simulating point
processes. JumpProcesses.jl was first developed for simulating jump processes
via stochastic simulation algorithms (SSAs) (including Doob's method,
Gillespie's methods, and Kinetic Monte Carlo methods). Historically, jump
processes have been developed in the context of dynamical systems to describe
dynamics with discrete jumps. In contrast, the development of point processes
has been more focused on describing the occurrence of random events. In this
paper, we bridge the gap between the treatment of point and jump process
simulation. The algorithms previously included in JumpProcesses.jl can be
mapped to three general methods developed in statistics for simulating
evolutionary point processes. Our comparative exercise revealed that the
library initially lacked an efficient algorithm for simulating processes with
variable intensity rates. We, therefore, extended JumpProcesses.jl with a new
simulation algorithm, Coevolve, that enables the rapid simulation of processes
with locally-bounded variable intensity rates. It is now possible to
efficiently simulate any point process on the real line with a non-negative,
left-continuous, history-adapted and locally bounded intensity rate coupled or
not with differential equations. This extension significantly improves the
computational performance of JumpProcesses.jl when simulating such processes,
enabling it to become one of the few readily available, fast, general-purpose
libraries for simulating evolutionary point processes.
","['\nGuilherme Augusto Zagatti\nInstitute of Data Science, National University of Singapore, Singapore\n', '\nSamuel A. Isaacson\nDepartment of Mathematics and Statistics, Boston University\n', '\nChristopher Rackauckas\nComputer Science and AI Laboratory\n', '\nVasily Ilin\nDepartment of Mathematics, University of Washington\n', '\nSee-Kiong Ng\nInstitute of Data Science, National University of Singapore, Singapore\nSchool of Computing, National University of Singapore, Singapore\n', '\nStéphane Bressan\nInstitute of Data Science, National University of Singapore, Singapore\nSchool of Computing, National University of Singapore, Singapore\n']",,,http://arxiv.org/abs/2306.06992v3,stat.CO,"['stat.CO', 'cs.MS', '60G55', 'G.3; G.4']",,,"['Institute of Data Science, National University of Singapore, Singapore', 'Department of Mathematics and Statistics, Boston University', 'Computer Science and AI Laboratory', 'Department of Mathematics, University of Washington', 'Institute of Data Science, National University of Singapore, Singapore', 'School of Computing, National University of Singapore, Singapore', 'Institute of Data Science, National University of Singapore, Singapore', 'School of Computing, National University of Singapore, Singapore']"
"Comparison of SeDuMi and SDPT3 Solvers for Stability of Continuous-time
  Linear System",http://arxiv.org/abs/2306.04531v1,2023-06-07T15:40:15Z,2023-06-07T15:40:15Z,"  SeDuMi and SDPT3 are two solvers for solving Semi-definite Programming (SDP)
or Linear Matrix Inequality (LMI) problems. A computational performance
comparison of these two are undertaken in this paper regarding the Stability of
Continuous-time Linear Systems. The comparison mainly focuses on computational
times and memory requirements for different scales of problems. To implement
and compare the two solvers on a set of well-posed problems, we employ YALMIP,
a widely used toolbox for modeling and optimization in MATLAB. The primary goal
of this study is to provide an empirical assessment of the relative
computational efficiency of SeDuMi and SDPT3 under varying problem conditions.
Our evaluation indicates that SDPT3 performs much better in large-scale,
high-precision calculations.
",['\nGuangda Xu\n'],"13 pages, 12 figures",,http://arxiv.org/abs/2306.04531v1,math.OC,"['math.OC', 'cs.MS', 'cs.PF', '68N30 (Primary) 90C22 (Secondary)', 'G.4']",,,[]
Accelerating 128-bit Floating-Point Matrix Multiplication on FPGAs,http://arxiv.org/abs/2306.04087v1,2023-06-07T01:16:50Z,2023-06-07T01:16:50Z,"  General Matrix Multiplication (GEMM) is a fundamental operation widely used
in scientific computations. Its performance and accuracy significantly impact
the performance and accuracy of applications that depend on it. One such
application is semidefinite programming (SDP), and it often requires binary128
or higher precision arithmetic to solve problems involving SDP stably. However,
only some processors support binary128 arithmetic, which makes SDP solvers
generally slow. In this study, we focused on accelerating GEMM with binary128
arithmetic on field-programmable gate arrays (FPGAs) to enable the flexible
design of accelerators for the desired computations. Our binary128 GEMM designs
on a recent high-performance FPGA achieved approximately 90GFlops, 147x faster
than the computation executed on a recent CPU with 20 threads for large
matrices. Using our binary128 GEMM design on the FPGA, we successfully
accelerated two numerical applications: LU decomposition and SDP problems, for
the first time.
","['\nFumiya Kono\n', '\nNaohito Nakasato\n', '\nMaho Nakata\n']","12 pages, 8 figures",,http://arxiv.org/abs/2306.04087v1,cs.DC,"['cs.DC', 'cs.AR', 'cs.MS', 'cs.PF', 'math.OC']",,,[]
"CUQIpy -- Part I: computational uncertainty quantification for inverse
  problems in Python",http://arxiv.org/abs/2305.16949v1,2023-05-26T14:01:09Z,2023-05-26T14:01:09Z,"  This paper introduces CUQIpy, a versatile open-source Python package for
computational uncertainty quantification (UQ) in inverse problems, presented as
Part I of a two-part series. CUQIpy employs a Bayesian framework, integrating
prior knowledge with observed data to produce posterior probability
distributions that characterize the uncertainty in computed solutions to
inverse problems. The package offers a high-level modeling framework with
concise syntax, allowing users to easily specify their inverse problems, prior
information, and statistical assumptions. CUQIpy supports a range of efficient
sampling strategies and is designed to handle large-scale problems. Notably,
the automatic sampler selection feature analyzes the problem structure and
chooses a suitable sampler without user intervention, streamlining the process.
With a selection of probability distributions, test problems, computational
methods, and visualization tools, CUQIpy serves as a powerful, flexible, and
adaptable tool for UQ in a wide selection of inverse problems. Part II of the
series focuses on the use of CUQIpy for UQ in inverse problems with partial
differential equations (PDEs).
","['\nNicolai A B Riis\n', '\nAmal M A Alghamdi\n', '\nFelipe Uribe\n', '\nSilja L Christensen\n', '\nBabak M Afkham\n', '\nPer Christian Hansen\n', '\nJakob S Jørgensen\n']","37 pages, 11 figures",,http://arxiv.org/abs/2305.16949v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65R32, 65C20, 94A08, 65K10', 'G.3; I.4; G.1.0']",,,[]
"CUQIpy -- Part II: computational uncertainty quantification for
  PDE-based inverse problems in Python",http://arxiv.org/abs/2305.16951v1,2023-05-26T14:03:04Z,2023-05-26T14:03:04Z,"  Inverse problems, particularly those governed by Partial Differential
Equations (PDEs), are prevalent in various scientific and engineering
applications, and uncertainty quantification (UQ) of solutions to these
problems is essential for informed decision-making. This second part of a
two-paper series builds upon the foundation set by the first part, which
introduced CUQIpy, a Python software package for computational UQ in inverse
problems using a Bayesian framework. In this paper, we extend CUQIpy's
capabilities to solve PDE-based Bayesian inverse problems through a general
framework that allows the integration of PDEs in CUQIpy, whether expressed
natively or using third-party libraries such as FEniCS. CUQIpy offers concise
syntax that closely matches mathematical expressions, streamlining the modeling
process and enhancing the user experience. The versatility and applicability of
CUQIpy to PDE-based Bayesian inverse problems are demonstrated on examples
covering parabolic, elliptic and hyperbolic PDEs. This includes problems
involving the heat and Poisson equations and application case studies in
electrical impedance tomography (EIT) and photo-acoustic tomography (PAT),
showcasing the software's efficiency, consistency, and intuitive interface.
This comprehensive approach to UQ in PDE-based inverse problems provides
accessibility for non-experts and advanced features for experts.
","['\nAmal M A Alghamdi\n', '\nNicolai A B Riis\n', '\nBabak M Afkham\n', '\nFelipe Uribe\n', '\nSilja L Christensen\n', '\nPer Christian Hansen\n', '\nJakob S Jørgensen\n']","39 pages, 12 figures",,http://arxiv.org/abs/2305.16951v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65R32, 65C20, 94A08, 65K10, 65M32', 'G.3; G.1.8']",,,[]
"Power Grid Transient Analysis via Open-Source Circuit Simulator: A Case
  Study of HVDC",http://arxiv.org/abs/2305.09122v1,2023-05-16T03:08:45Z,2023-05-16T03:08:45Z,"  This paper proposes an electronic circuit simulator-based method to
accelerate the power system transient simulation, where the modeling of a
generic HVDC (High Voltage Direct Current) system is focused. The electronic
circuit simulation equations and the backward differentiation formula for
numerical solving are described. Then, the circuit modeling process for power
system components such as slack bus, constant power load, and HVDC are
respectively illustrated. Finally, a case study is conducted on a four-bus
power system to demonstrate the effectiveness of the proposed modeling and
simulation method.
","['\nYongli Zhu\n', '\nXiang Zhang\n', '\nRenchang Dai\n']",This paper has been accepted by the IEEE KPEC 2023 conference,,http://arxiv.org/abs/2305.09122v1,eess.SY,"['eess.SY', 'cs.MS', 'cs.SY', 'math.DS']",,,[]
Blendstrings: an environment for computing with smooth functions,http://arxiv.org/abs/2305.11076v1,2023-05-18T16:03:32Z,2023-05-18T16:03:32Z,"  A ""blendstring"" is a piecewise polynomial interpolant with high-degree
two-point Hermite interpolational polynomials on each piece, analogous to a
cubic spline. Blendstrings are smoother and can be more accurate than cubic
splines, and can be used to represent smooth functions on a line segment or
polygonal path in the complex plane. I sketch some properties of blendstrings,
including efficient methods for evaluation, differentiation, and integration,
as well as a prototype Maple implementation. Blendstrings can be differentiated
and integrated exactly and can be combined algebraically. I also show
applications of blendstrings to solving differential equations and computing
Mathieu functions and generalized Mathieu eigenfunctions.
",['\nRobert M. Corless\n'],"16 pages, 3 figures, accepted to Proceedings of the International
  Symposium on Symbolic and Algebraic Computation (ISSAC) 2023",,http://arxiv.org/abs/2305.11076v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65D15']",,,[]
OpenLB User Guide: Associated with Release 1.6 of the Code,http://arxiv.org/abs/2307.11752v1,2023-05-17T22:47:34Z,2023-05-17T22:47:34Z,"  OpenLB is an object-oriented implementation of LBM. It is the first
implementation of a generic platform for LBM programming, which is shared with
the open source community (GPLv2). Since the first release in 2007, the code
has been continuously improved and extended which is documented by thirteen
releases as well as the corresponding release notes which are available on the
OpenLB website (https://www.openlb.net). The OpenLB code is written in C++ and
is used by application programmers as well as developers, with the ability to
implement custom models OpenLB supports complex data structures that allow
simulations in complex geometries and parallel execution using MPI, OpenMP and
CUDA on high-performance computers. The source code uses the concepts of
interfaces and templates, so that efficient, direct and intuitive
implementations of the LBM become possible. The efficiency and scalability has
been checked and proved by code reviews. This user manual and a source code
documentation by DoxyGen are available on the OpenLB project website.
","['\nAdrian Kummerländer\n', '\nSamuel J. Avis\n', '\nHalim Kusumaatmaja\n', '\nFedor Bukreev\n', '\nMichael Crocoll\n', '\nDavide Dapelo\n', '\nSimon Großmann\n', '\nNicolas Hafen\n', '\nShota Ito\n', '\nJulius Jeßberger\n', '\nEliane Kummer\n', '\nJan E. Marquardt\n', '\nJohanna Mödl\n', '\nTim Pertzel\n', '\nFrantišek Prinz\n', '\nFlorian Raichle\n', '\nMartin Sadric\n', '\nMaximilian Schecher\n', '\nDennis Teutscher\n', '\nStephan Simonis\n', '\nMathias J. Krause\n']",,,http://arxiv.org/abs/2307.11752v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', '97N80, 74S30, 76M25, 80M25, 82C80,', 'G.4']",,,[]
"Using Hierarchical Parallelism to Accelerate the Solution of Many Small
  Partial Differential Equations",http://arxiv.org/abs/2305.07030v1,2023-05-05T05:42:03Z,2023-05-05T05:42:03Z,"  This paper presents efforts to improve the hierarchical parallelism of a two
scale simulation code. Two methods to improve the GPU parallel performance were
developed and compared. The first used the NVIDIA Multi-Process Service and the
second moved the entire sub-problem loop into a single kernel using Kokkos
hierarchical parallelism and a PackedView data structure. Both approaches
improved parallel performance with the second method providing the greatest
improvements.
","['\nJacob Merson\n', '\nMark S. Shephard\n']","Originally presented at the HiPar workshop at The International
  Conference for High Performance Computing, Networking, Storage, and Analysis
  (2020)",,http://arxiv.org/abs/2305.07030v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
NUBO: A Transparent Python Package for Bayesian Optimisation,http://arxiv.org/abs/2305.06709v1,2023-05-11T10:34:27Z,2023-05-11T10:34:27Z,"  NUBO, short for Newcastle University Bayesian Optimisation, is a Bayesian
optimisation framework for the optimisation of expensive-to-evaluate black-box
functions, such as physical experiments and computer simulators. Bayesian
optimisation is a cost-efficient optimisation strategy that uses surrogate
modelling via Gaussian processes to represent an objective function and
acquisition functions to guide the selection of candidate points to approximate
the global optimum of the objective function. NUBO itself focuses on
transparency and user experience to make Bayesian optimisation easily
accessible to researchers from all disciplines. Clean and understandable code,
precise references, and thorough documentation ensure transparency, while user
experience is ensured by a modular and flexible design, easy-to-write syntax,
and careful selection of Bayesian optimisation algorithms. NUBO allows users to
tailor Bayesian optimisation to their specific problem by writing the
optimisation loop themselves using the provided building blocks. It supports
sequential single-point, parallel multi-point, and asynchronous optimisation of
bounded, constrained, and/or mixed (discrete and continuous) parameter input
spaces. Only algorithms and methods that are extensively tested and validated
to perform well are included in NUBO. This ensures that the package remains
compact and does not overwhelm the user with an unnecessarily large number of
options. The package is written in Python but does not require expert knowledge
of Python to optimise your simulators and experiments. NUBO is distributed as
open-source software under the BSD 3-Clause licence.
","['\nMike Diessner\n', '\nKevin Wilson\n', '\nRichard D. Whalley\n']",,,http://arxiv.org/abs/2305.06709v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
"lifex-cfd: an open-source computational fluid dynamics solver for
  cardiovascular applications",http://arxiv.org/abs/2304.12032v5,2023-04-24T12:11:20Z,2023-11-20T09:27:28Z,"  Computational fluid dynamics (CFD) is an important tool for the simulation of
the cardiovascular function and dysfunction. Due to the complexity of the
anatomy, the transitional regime of blood flow in the heart, and the strong
mutual influence between the flow and the physical processes involved in the
heart function, the development of accurate and efficient CFD solvers for
cardiovascular flows is still a challenging task. In this paper we present
lifex-cfd, an open-source CFD solver for cardiovascular simulations based on
the lifex finite element library, written in modern C++ and exploiting
distributed memory parallelism. We model blood flow in both physiological and
pathological conditions via the incompressible Navier-Stokes equations,
accounting for moving cardiac valves, moving domains, and
transition-to-turbulence regimes. In this paper, we provide an overview of the
underlying mathematical formulation, numerical discretization, implementation
details and examples on how to use lifex-cfd. We verify the code through
rigorous convergence analyses, and we show its almost ideal parallel speedup.
We demonstrate the accuracy and reliability of the numerical methods
implemented through a series of idealized and patient-specific vascular and
cardiac simulations, in different physiological flow regimes. The lifex-cfd
source code is available under the LGPLv3 license, to ensure its accessibility
and transparency to the scientific community, and to facilitate collaboration
and further developments.
","['\nPasquale Claudio Africa\n', '\nIvan Fumagalli\n', '\nMichele Bucelli\n', '\nAlberto Zingaro\n', '\nMarco Fedele\n', ""\nLuca Dede'\n"", '\nAlfio Quarteroni\n']",,,http://arxiv.org/abs/2304.12032v5,physics.flu-dyn,"['physics.flu-dyn', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"A framework for rigorous computational methods using Haar wavelets for
  differential equations",http://arxiv.org/abs/2304.14536v1,2023-04-27T21:08:17Z,2023-04-27T21:08:17Z,"  This work presents a framework for a-posteriori error-estimating algorithms
for differential equations which combines the radii polynomial approach with
Haar wavelets. By using Haar wavelets, we obtain recursive structures for the
matrix representations of the differential operators and quadratic
nonlinearities, which can be exploited for the radii polynomial method in order
to get error estimates in the $L^2$ sense. This allows the method to be
applicable when the system or solution is not continuous, which is a limitation
of other radii-polynomial-based methods. Numerical examples show how the method
is implemented in practice.
","['\nGuilherme Nakassima\n', '\nMarcio Gameiro\n']",,,http://arxiv.org/abs/2304.14536v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.DS', '34A34, 34L30, 65G20, 65H10, 65T60']",,,[]
"Exponentially Convergent Numerical Method for Abstract Cauchy Problem
  with Fractional Derivative of Caputo Type",http://arxiv.org/abs/2304.13099v2,2023-04-25T19:10:58Z,2023-07-05T13:56:46Z,"  We present an exponentially convergent numerical method to approximate the
solution of the Cauchy problem for the inhomogeneous fractional differential
equation with an unbounded operator coefficient and Caputo fractional
derivative in time. The numerical method is based on the newly obtained
solution formula that consolidates the mild solution representations of
sub-parabolic, parabolic and sub-hyperbolic equations with sectorial operator
coefficient $A$ and non-zero initial data. The involved integral operators are
approximated using the sinc-quadrature formulas that are tailored to the
spectral parameters of $A$, fractional order $\alpha$ and the smoothness of the
first initial condition, as well as to the properties of the equation's
right-hand side $f(t)$. The resulting method possesses exponential convergence
for positive sectorial $A$, any finite $t$, including $t = 0$ and the whole
range $\alpha \in (0,2)$. It is suitable for a practically important case, when
no knowledge of $f(t)$ is available outside the considered interval $t \in [0,
T]$. The algorithm of the method is capable of multi-level parallelism. We
provide numerical examples that confirm the theoretical error estimates.
","['\nDmytro Sytnyk\n', '\nBarbara Wohlmuth\n']","This version supersedes the official publication
  (https://www.mdpi.com/2227-7390/11/10/2312) at present time. Several
  misprints were corrected","Mathematics 11, no. 10: 2312 (2023)",http://dx.doi.org/10.3390/math11102312,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.AP', 'math.CA', '34A08, 35R11, 34G10, 35R20, 65L05, 65J08, 65J1']",10.3390/math11102312,,[]
LLT: An R package for Linear Law-based Feature Space Transformation,http://arxiv.org/abs/2304.14211v2,2023-04-27T14:18:29Z,2023-05-15T19:26:13Z,"  The goal of the linear law-based feature space transformation (LLT) algorithm
is to assist with the classification of univariate and multivariate time
series. The presented R package, called LLT, implements this algorithm in a
flexible yet user-friendly way. This package first splits the instances into
training and test sets. It then utilizes time-delay embedding and spectral
decomposition techniques to identify the governing patterns (called linear
laws) of each input sequence (initial feature) within the training set.
Finally, it applies the linear laws of the training set to transform the
initial features of the test set. These steps are performed by three separate
functions called trainTest, trainLaw, and testTrans. Their application requires
a predefined data structure; however, for fast calculation, they use only
built-in functions. The LLT R package and a sample dataset with the appropriate
data structure are publicly available on GitHub.
","['\nMarcell T. Kurbucz\n', '\nPéter Pósfay\n', '\nAntal Jakovác\n']","15 pages, 5 figures, 1 table",,http://arxiv.org/abs/2304.14211v2,cs.LG,"['cs.LG', 'cs.AI', 'cs.CV', 'cs.MS', 'stat.ML', '62H30, 68T10, 62M10, 60-04', 'I.5; G.3; J.0; I.2.0']",,,[]
The growclusters Package for R,http://arxiv.org/abs/2304.06145v1,2023-04-12T20:03:44Z,2023-04-12T20:03:44Z,"  The growclusters package for R implements an enhanced version of k-means
clustering that allows discovery of local clusterings or partitions for a
collection of data sets that each draw their cluster means from a single,
global partition. The package contains functions to estimate a partition
structure for multivariate data. Estimation is performed under a penalized
optimization derived from Bayesian non-parametric formulations. This paper
describes some of the functions and capabilities of the growclusters package,
including the creation of R Shiny applications designed to visually illustrate
the operation and functionality of the growclusters package.
","['\nRandall Powers\n', '\nWendy Martinez\n', '\nTerrance Savitsky\n']","10 pages, 6 figures, paper presented at 2022 Joint Statistical
  Meetings",,http://arxiv.org/abs/2304.06145v1,cs.MS,"['cs.MS', 'cs.LG', 'I.5.3; I.3.8; J.0']",,,[]
"Designing a Framework for Solving Multiobjective Simulation Optimization
  Problems",http://arxiv.org/abs/2304.06881v2,2023-04-14T01:16:53Z,2023-07-06T16:25:37Z,"  Multiobjective simulation optimization (MOSO) problems are optimization
problems with multiple conflicting objectives, where evaluation of at least one
of the objectives depends on a black-box numerical code or real-world
experiment, which we refer to as a simulation. This paper describes the design
goals driving the development of the parallel MOSO library ParMOO. We derive
these goals from the research trends and real-world requirements that arise
when designing and deploying solvers for generic MOSO problems. Our specific
design goals were to provide a customizable MOSO framework that allows for
exploitation of simulation-based problem structures, ease of deployment in
scientific workflows, maintainability, and flexibility in our support for many
problem types. We explain how we have achieved these goals in the ParMOO
library and provide two examples demonstrating how customized ParMOO solvers
can be quickly built and deployed in real-world MOSO problems.
","['\nTyler H. Chang\n', '\nStefan M. Wild\n']",,,http://arxiv.org/abs/2304.06881v2,math.OC,"['math.OC', 'cs.MS']",,,[]
"An open-source pipeline for solving continuous reaction-diffusion models
  in image-based geometries of porous media",http://arxiv.org/abs/2304.11165v2,2023-04-17T13:34:11Z,2023-10-16T09:40:18Z,"  We present a versatile open-source pipeline for simulating inhomogeneous
reaction-diffusion processes in highly resolved, image-based geometries of
porous media with reactive boundaries. Resolving realistic pore-scale
geometries in numerical models is challenging and computationally demanding, as
the scale differences between the sizes of the interstitia and the whole system
can lead to prohibitive memory requirements. The present pipeline combines a
level-set method with geometry-adapted sparse block grids on GPUs to
efficiently simulate reaction-diffusion processes in image-based geometries. We
showcase the method by applying it to fertilizer diffusion in soil, heat
transfer in porous ceramics, and determining effective diffusion coefficients
and tortuosity. The present approach enables solving reaction-diffusion partial
differential equations in real-world geometries applicable to porous media
across fields such as engineering, environmental science, and biology.
","['\nJustina Stark\n', '\nIvo F. Sbalzarini\n']","12 figures, 1 appendix figure","J. Comput. Sci., 72:102118, 2023",http://dx.doi.org/10.1016/j.jocs.2023.102118,cs.MS,"['cs.MS', 'physics.comp-ph']",10.1016/j.jocs.2023.102118,,[]
"tomoCAM: Fast Model-based Iterative Reconstruction via GPU Acceleration
  and Non-Uniform Fast Fourier Transforms",http://arxiv.org/abs/2304.12934v1,2023-04-18T04:50:18Z,2023-04-18T04:50:18Z,"  X-Ray based computed tomography (CT) is a well-established technique for
determining the three-dimensional structure of an object from its
two-dimensional projections. In the past few decades, there have been
significant advancements in the brightness and detector technology of
tomography instruments at synchrotron sources. These advancements have led to
the emergence of new observations and discoveries, with improved capabilities
such as faster frame rates, larger fields of view, higher resolution, and
higher dimensionality. These advancements have enabled the material science
community to expand the scope of tomographic measurements towards increasingly
in-situ and in-operando measurements. In these new experiments, samples can be
rapidly evolving, have complex geometries, and restrictions on the field of
view, limiting the number of projections that can be collected. In such cases,
standard filtered back-projections (FBP) for the reconstructions often result
in poor-quality reconstructions. Iterative reconstruction algorithms, such as
model-based iterative reconstructions (MBIR), have demonstrated considerable
success in producing high-quality reconstructions under such restrictions, but
typically require high-performance computing resources with hundreds of compute
nodes to solve the problem in a reasonable time.
","['\nDinesh Kumar\n', '\nDilworth Y. Parkinson\n', '\nJeffrey J. Donatelli\n']",,,http://arxiv.org/abs/2304.12934v1,physics.med-ph,"['physics.med-ph', 'cs.MS']",,,[]
Consistent Point Data Assimilation in Firedrake and Icepack,http://arxiv.org/abs/2304.06058v5,2023-04-12T13:26:41Z,2023-08-09T13:40:50Z,"  When estimating quantities and fields that are difficult to measure directly,
such as the fluidity of ice, from point data sources, such as satellite
altimetry, it is important to solve a numerical inverse problem that is
formulated with Bayesian consistency. Otherwise, the resultant probability
density function for the difficult to measure quantity or field will not be
appropriately clustered around the truth. In particular, the inverse problem
should be formulated by evaluating the numerical solution at the true point
locations for direct comparison with the point data source. If the data are
first fitted to a gridded or meshed field on the computational grid or mesh,
and the inverse problem formulated by comparing the numerical solution to the
fitted field, the benefits of additional point data values below the grid
density will be lost. We demonstrate, with examples in the fields of
groundwater hydrology and glaciology, that a consistent formulation can
increase the accuracy of results and aid discourse between modellers and
observationalists.
  To do this, we bring point data into the finite element method ecosystem as
discontinuous fields on meshes of disconnected vertices. Point evaluation can
then be formulated as a finite element interpolation operation
(dual-evaluation). This new abstraction is well-suited to automation, including
automatic differentiation. We demonstrate this through implementation in
Firedrake, which generates highly optimised code for solving Partial
Differential Equations (PDEs) with the finite element method. Our solution
integrates with dolfin-adjoint/pyadjoint, allowing PDE-constrained optimisation
problems, such as data assimilation, to be solved through forward and adjoint
mode automatic differentiation.
","['\nReuben W. Nixon-Hill\n', '\nDaniel Shapero\n', '\nColin J. Cotter\n', '\nDavid A. Ham\n']",This version: Added missing affiliation,,http://arxiv.org/abs/2304.06058v5,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Automated Translation and Accelerated Solving of Differential Equations
  on Multiple GPU Platforms",http://arxiv.org/abs/2304.06835v3,2023-04-13T21:57:51Z,2023-11-13T05:11:50Z,"  We demonstrate a high-performance vendor-agnostic method for massively
parallel solving of ensembles of ordinary differential equations (ODEs) and
stochastic differential equations (SDEs) on GPUs. The method is integrated with
a widely used differential equation solver library in a high-level language
(Julia's DifferentialEquations.jl) and enables GPU acceleration without
requiring code changes by the user. Our approach achieves state-of-the-art
performance compared to hand-optimized CUDA-C++ kernels while performing
20--100$\times$ faster than the vectorizing map (vmap) approach implemented in
JAX and PyTorch. Performance evaluation on NVIDIA, AMD, Intel, and Apple GPUs
demonstrates performance portability and vendor-agnosticism. We show
composability with MPI to enable distributed multi-GPU workflows. The
implemented solvers are fully featured -- supporting event handling, automatic
differentiation, and incorporation of datasets via the GPU's texture memory --
allowing scientists to take advantage of GPU acceleration on all major current
architectures without changing their model code and without loss of
performance. We distribute the software as an open-source library
https://github.com/SciML/DiffEqGPU.jl
","['\nUtkarsh Utkarsh\n', '\nValentin Churavy\n', '\nYingbo Ma\n', '\nTim Besard\n', '\nPrakitr Srisuma\n', '\nTim Gymnich\n', '\nAdam R. Gerlach\n', '\nAlan Edelman\n', '\nGeorge Barbastathis\n', '\nRichard D. Braatz\n', '\nChristopher Rackauckas\n']",14 figures,"Computer Methods in Applied Mechanics and Engineering, Volume 419,
  2024",http://dx.doi.org/10.1016/j.cma.2023.116591,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",10.1016/j.cma.2023.116591,,[]
Groebner.jl: A package for Gröbner bases computations in Julia,http://arxiv.org/abs/2304.06935v3,2023-04-14T05:47:34Z,2024-02-12T16:25:18Z,"  We present Groebner.jl, a Julia package for computing Groebner bases with the
F4 algorithm. Groebner.jl is an efficient, portable, and open-source software.
Groebner.jl works over integers modulo a prime and over the rationals, supports
basic multi-threading, and specializes in computation in the degree reverse
lexicographical monomial ordering. The implementation incorporates various
symbolic computation techniques and leverages the Julia type system and
tooling, which allows Groebner.jl to compete with the existing state of the
art, in many instances outperform it, and exceed them in extensibility.
Groebner.jl is freely available at https://github.com/sumiya11/Groebner.jl.
","['\nAlexander Demin\n', '\nShashi Gowda\n']",10 pages,,http://arxiv.org/abs/2304.06935v3,cs.MS,"['cs.MS', 'cs.SC', 'math.AC']",,,[]
"clotFoam: An Open-Source Framework to Simulate Blood Clot Formation
  Under Arterial Flow",http://arxiv.org/abs/2304.09180v3,2023-04-17T20:22:15Z,2023-08-01T23:44:23Z,"  Blood clotting involves the coupled processes of platelet aggregation and
coagulation. Simulating clotting under flow in complex geometries is
challenging due to multiple temporal and spatial scales and high computational
cost. clotFoam is an open-source software developed in OpenFOAM that employs a
continuum model of platelet advection, diffusion, and aggregation in a dynamic
fluid environment and a simplified coagulation model with proteins that advect,
diffuse, and react within the fluid and with wall-bound species through
reactive boundary conditions. Our framework provides the foundation on which
one can build more complex models and perform reliable simulations in almost
any computational domain.
","['\nDavid Montgomery\n', '\nFederico Municchi\n', '\nKarin Leiderman\n']",Repository: https://github.com/d-montgomery/clotFoam,SoftwareX (2023) 101483,http://dx.doi.org/10.1016/j.softx.2023.101483,physics.flu-dyn,"['physics.flu-dyn', 'cs.MS', 'physics.bio-ph']",10.1016/j.softx.2023.101483,,[]
"Learned multiphysics inversion with differentiable programming and
  machine learning",http://arxiv.org/abs/2304.05592v1,2023-04-12T03:38:22Z,2023-04-12T03:38:22Z,"  We present the Seismic Laboratory for Imaging and Modeling/Monitoring (SLIM)
open-source software framework for computational geophysics and, more
generally, inverse problems involving the wave-equation (e.g., seismic and
medical ultrasound), regularization with learned priors, and learned neural
surrogates for multiphase flow simulations. By integrating multiple layers of
abstraction, our software is designed to be both readable and scalable. This
allows researchers to easily formulate their problems in an abstract fashion
while exploiting the latest developments in high-performance computing. We
illustrate and demonstrate our design principles and their benefits by means of
building a scalable prototype for permeability inversion from time-lapse
crosswell seismic data, which aside from coupling of wave physics and
multiphase flow, involves machine learning.
","['\nMathias Louboutin\n', '\nZiyi Yin\n', '\nRafael Orozco\n', '\nThomas J. Grady II\n', '\nAli Siahkoohi\n', '\nGabrio Rizzuti\n', '\nPhilipp A. Witte\n', '\nOlav Møyner\n', '\nGerard J. Gorman\n', '\nFelix J. Herrmann\n']",,,http://dx.doi.org/10.1190/tle42070474.1,cs.MS,"['cs.MS', 'cs.DC', 'cs.LG', 'physics.comp-ph', 'physics.geo-ph']",10.1190/tle42070474.1,,[]
Formal Derivation of LU Factorization with Pivoting,http://arxiv.org/abs/2304.03068v1,2023-04-06T13:36:20Z,2023-04-06T13:36:20Z,"  The FLAME methodology for deriving linear algebra algorithms from
specification, first introduced around 2000, has been successfully applied to a
broad cross section of operations. An open question has been whether it can
yield algorithms for the best-known operation in linear algebra, LU
factorization with partial pivoting (Gaussian elimination with row swapping).
This paper shows that it can.
","['\nRobert van de Geijn\n', '\nMaggie Myers\n']",30 pages,,http://arxiv.org/abs/2304.03068v1,cs.MS,"['cs.MS', 'G.4']",,,[]
Automatic Differentiation of Binned Likelihoods With Roofit and Clad,http://arxiv.org/abs/2304.02650v1,2023-04-04T14:23:40Z,2023-04-04T14:23:40Z,"  RooFit is a toolkit for statistical modeling and fitting used by most
experiments in particle physics. Just as data sets from next-generation
experiments grow, processing requirements for physics analysis become more
computationally demanding, necessitating performance optimizations for RooFit.
One possibility to speed-up minimization and add stability is the use of
Automatic Differentiation (AD). Unlike for numerical differentiation, the
computation cost scales linearly with the number of parameters, making AD
particularly appealing for statistical models with many parameters. In this
paper, we report on one possible way to implement AD in RooFit. Our approach is
to add a facility to generate C++ code for a full RooFit model automatically.
Unlike the original RooFit model, this generated code is free of virtual
function calls and other RooFit-specific overhead. In particular, this code is
then used to produce the gradient automatically with Clad. Clad is a source
transformation AD tool implemented as a plugin to the clang compiler, which
automatically generates the derivative code for input C++ functions. We show
results demonstrating the improvements observed when applying this code
generation strategy to HistFactory and other commonly used RooFit models.
HistFactory is the subcomponent of RooFit that implements binned likelihood
models with probability densities based on histogram templates. These models
frequently have a very large number of free parameters and are thus an
interesting first target for AD support in RooFit.
","['\nGarima Singh\n', '\nJonas Rembser\n', '\nLorenzo Moneta\n', '\nDavid Lange\n', '\nVassil Vassilev\n']","6 pages, 5 figures, 21st International Workshop on Advanced Computing
  and Analysis Techniques in Physics Research",,http://arxiv.org/abs/2304.02650v1,cs.MS,"['cs.MS', 'stat.CO', 'G.4; J.2']",,,[]
Monotonicity of Multi-Term Floating-Point Adders,http://arxiv.org/abs/2304.01407v2,2023-04-03T22:45:14Z,2023-12-04T19:07:14Z,"  In the literature on algorithms for performing the multi-term addition
$s_n=\sum_{i=1}^n x_i$ using floating-point arithmetic it is often shown that a
hardware unit that has single normalization and rounding improves precision,
area, latency, and power consumption, compared with the use of standard add or
fused multiply-add units. However, non-monotonicity can appear when computing
sums with a subclass of multi-term addition units, which currently is not
explored in the literature. We demonstrate that common techniques for
performing multi-term addition with $n\geq 4$, without normalization of
intermediate quantities, can result in non-monotonicity -- increasing one of
the addends $x_i$ decreases the sum $s_n$. Summation is required in dot product
and matrix multiplication operations, operations that have increasingly started
appearing in the hardware of supercomputers, thus knowing where monotonicity is
preserved can be of interest to the users of these machines. Our results
suggest that non-monotonicity of summation, in some of the commercial hardware
devices that implement a specific class of multi-term adders, is a feature that
may have appeared unintentionally as a consequence of design choices that
reduce circuit area and other metrics. To demonstrate our findings, we use
formal proofs as well as a numerical simulation of non-monotonic multi-term
adders in MATLAB.
",['\nMantas Mikaitis\n'],,,http://arxiv.org/abs/2304.01407v2,cs.MS,"['cs.MS', 'cs.AR', 'cs.NA', 'math.NA']",,,[]
"Torch-Choice: A PyTorch Package for Large-Scale Choice Modelling with
  Python",http://arxiv.org/abs/2304.01906v3,2023-04-04T16:00:48Z,2023-07-14T21:42:04Z,"  The $\texttt{torch-choice}$ is an open-source library for flexible, fast
choice modeling with Python and PyTorch. $\texttt{torch-choice}$ provides a
$\texttt{ChoiceDataset}$ data structure to manage databases flexibly and
memory-efficiently. The paper demonstrates constructing a
$\texttt{ChoiceDataset}$ from databases of various formats and functionalities
of $\texttt{ChoiceDataset}$. The package implements two widely used models,
namely the multinomial logit and nested logit models, and supports
regularization during model estimation. The package incorporates the option to
take advantage of GPUs for estimation, allowing it to scale to massive datasets
while being computationally efficient. Models can be initialized using either
R-style formula strings or Python dictionaries. We conclude with a comparison
of the computational efficiencies of $\texttt{torch-choice}$ and
$\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the
number of covariates increases, and (3) the expansion of item sets. Finally, we
demonstrate the scalability of $\texttt{torch-choice}$ on large-scale datasets.
","['\nTianyu Du\n', '\nAyush Kanodia\n', '\nSusan Athey\n']",,,http://arxiv.org/abs/2304.01906v3,cs.LG,"['cs.LG', 'cs.MS', 'econ.EM']",,,[]
"TransPimLib: A Library for Efficient Transcendental Functions on
  Processing-in-Memory Systems",http://arxiv.org/abs/2304.01951v5,2023-04-03T12:41:46Z,2023-09-05T19:55:48Z,"  Processing-in-memory (PIM) promises to alleviate the data movement bottleneck
in modern computing systems. However, current real-world PIM systems have the
inherent disadvantage that their hardware is more constrained than in
conventional processors (CPU, GPU), due to the difficulty and cost of building
processing elements near or inside the memory. As a result, general-purpose PIM
architectures support fairly limited instruction sets and struggle to execute
complex operations such as transcendental functions and other hard-to-calculate
operations (e.g., square root). These operations are particularly important for
some modern workloads, e.g., activation functions in machine learning
applications.
  In order to provide support for transcendental (and other hard-to-calculate)
functions in general-purpose PIM systems, we present \emph{TransPimLib}, a
library that provides CORDIC-based and LUT-based methods for trigonometric
functions, hyperbolic functions, exponentiation, logarithm, square root, etc.
We develop an implementation of TransPimLib for the UPMEM PIM architecture and
perform a thorough evaluation of TransPimLib's methods in terms of performance
and accuracy, using microbenchmarks and three full workloads (Blackscholes,
Sigmoid, Softmax). We open-source all our code and datasets
at~\url{https://github.com/CMU-SAFARI/transpimlib}.
","['\nMaurus Item\n', '\nJuan Gómez-Luna\n', '\nYuxin Guo\n', '\nGeraldo F. Oliveira\n', '\nMohammad Sadrosadati\n', '\nOnur Mutlu\n']","Our open-source software is available at
  https://github.com/CMU-SAFARI/transpimlib",,http://arxiv.org/abs/2304.01951v5,cs.MS,"['cs.MS', 'cs.AR', 'cs.DC', 'cs.LG']",,,[]
Spectral Toolkit of Algorithms for Graphs: Technical Report (1),http://arxiv.org/abs/2304.03170v1,2023-04-05T10:39:39Z,2023-04-05T10:39:39Z,"  Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library
for efficient spectral graph algorithms, and its development starts in
September 2022. We have so far finished the component on local graph
clustering, and this technical report presents a user's guide to STAG, showcase
studies, and several technical considerations behind our development.
","['\nPeter Macgregor\n', '\nHe Sun\n']",,,http://arxiv.org/abs/2304.03170v1,cs.SI,"['cs.SI', 'cs.DS', 'cs.LG', 'cs.MS']",,,[]
"A Practitioner's Guide to Bayesian Inference in Pharmacometrics using
  Pumas",http://arxiv.org/abs/2304.04752v1,2023-03-31T04:00:53Z,2023-03-31T04:00:53Z,"  This paper provides a comprehensive tutorial for Bayesian practitioners in
pharmacometrics using Pumas workflows. We start by giving a brief motivation of
Bayesian inference for pharmacometrics highlighting limitations in existing
software that Pumas addresses. We then follow by a description of all the steps
of a standard Bayesian workflow for pharmacometrics using code snippets and
examples. This includes: model definition, prior selection, sampling from the
posterior, prior and posterior simulations and predictions, counter-factual
simulations and predictions, convergence diagnostics, visual predictive checks,
and finally model comparison with cross-validation. Finally, the background and
intuition behind many advanced concepts in Bayesian statistics are explained in
simple language. This includes many important ideas and precautions that users
need to keep in mind when performing Bayesian analysis. Many of the algorithms,
codes, and ideas presented in this paper are highly applicable to clinical
research and statistical learning at large but we chose to focus our
discussions on pharmacometrics in this paper to have a narrower scope in mind
and given the nature of Pumas as a software primarily for pharmacometricians.
","['\nMohamed Tarek\n', '\nJose Storopoli\n', '\nCasey Davis\n', '\nChris Elrod\n', '\nJulius Krumbiegel\n', '\nChris Rackauckas\n', '\nVijay Ivaturi\n']",,,http://arxiv.org/abs/2304.04752v1,stat.AP,"['stat.AP', 'cs.LG', 'cs.MS', 'stat.CO']",,,[]
"TOPress: a MATLAB implementation for topology optimization of structures
  subjected to design-dependent pressure loads",http://arxiv.org/abs/2303.14690v4,2023-03-26T11:31:22Z,2024-01-06T13:06:35Z,"  In a topology optimization setting, design-dependent fluidic pressure loads
pose several challenges as their direction, magnitude, and location alter with
topology evolution. This paper offers a compact 100-line MATLAB code, TOPress,
for topology optimization of structures subjected to fluidic pressure loads
using the method of moving asymptotes. The code is intended for pedagogical
purposes and aims to ease the beginners' and students' learning toward topology
optimization with design-dependent fluidic pressure loads. TOPress is developed
per the approach first reported in Kumar et al. (Struct Multidisc Optim
61(4):1637-1655, 2020). The Darcy law, in conjunction with the drainage term,
is used to model the applied pressure load. The consistent nodal loads are
determined from the obtained pressure field. The employed approach facilitates
inexpensive computation of the load sensitivities using the adjoint-variable
method. Compliance minimization subject to volume constraint optimization
problems are solved. The success and efficacy of the code are demonstrated by
solving benchmark numerical examples involving pressure loads, wherein the
importance of load sensitivities is also demonstrated. TOPress contains six
main parts, is described in detail, and is extended to solve different
problems. Steps to include a projection filter are provided to achieve
loadbearing designs close to~0-1. The code is provided in Appendix~B and can
also be downloaded along with its extensions from
\url{https://github.com/PrabhatIn/TOPress}.
",['\nPrabhat Kumar\n'],"19 Figures, MATLAB codes","Structural and Multidisciplinary Optimization, 2023",http://dx.doi.org/10.1007/s00158-023-03533-9,cs.MS,"['cs.MS', 'cs.CE']",10.1007/s00158-023-03533-9,,[]
waywiser: Ergonomic Methods for Assessing Spatial Models,http://arxiv.org/abs/2303.11312v1,2023-03-20T17:51:36Z,2023-03-20T17:51:36Z,"  Assessing predictive models can be challenging. Modelers must navigate a wide
array of evaluation methodologies implemented with incompatible interfaces
across multiple packages which may give different or even contradictory
results, while ensuring that their chosen approach properly estimates the
performance of their model when generalizing to new observations. Assessing
models fit to spatial data can be particularly difficult, given that model
errors may exhibit spatial autocorrelation, model predictions are often
aggregated to multiple spatial scales by end users, and models are often tasked
with generalizing into spatial regions outside the boundaries of their initial
training data.
  The waywiser package for the R language attempts to make assessing spatial
models easier by providing an ergonomic toolkit for model evaluation tasks,
with functions for multiple assessment methodologies sharing a unified
interface. Functions from waywiser share standardized argument names and
default values, making the user-facing interface simple and easy to learn.
These functions are additionally designed to be easy to integrate into a wide
variety of modeling workflows, accepting standard classes as inputs and
returning size- and type-stable outputs, ensuring that their results are of
consistent and predictable data types and dimensions. Additional features make
it particularly easy to use waywiser along packages and workflows in the
tidymodels ecosystem.
",['\nMichael J Mahoney\n'],"29 pages, 6 figures. Submitted to The Journal of Statistical Software",,http://arxiv.org/abs/2303.11312v1,cs.MS,"['cs.MS', 'stat.CO', 'stat.ME']",,,[]
"The regularization continuation method for optimization problems with
  nonlinear equality constraints",http://arxiv.org/abs/2303.14692v2,2023-03-26T11:40:42Z,2023-08-04T13:53:58Z,"  This paper considers the regularization continuation method and the
trust-region updating strategy for the nonlinearly equality-constrained
optimization problem. Namely, it uses the inverse of the regularization
quasi-Newton matrix as the pre-conditioner to improve its computational
efficiency in the well-posed phase, and it adopts the inverse of the
regularization two-sided projection of the Hessian as the pre-conditioner to
improve its robustness in the ill-conditioned phase. Since it only solves a
linear system of equations at every iteration and the sequential quadratic
programming (SQP) needs to solve a quadratic programming subproblem at every
iteration, it is faster than SQP. Numerical results also show that it is more
robust and faster than SQP (the built-in subroutine fmincon.m of the
MATLAB2020a environment and the subroutine SNOPT executed in GAMS v28.2 (2019)
environment). The computational time of the new method is about one third of
that of fmincon.m for the large-scale problem. Finally, the global convergence
analysis of the new method is also given.
","['\nXin-long Luo\n', '\nHang Xiao\n', '\nSen Zhang\n']",arXiv admin note: substantial text overlap with arXiv:2106.01122,,http://arxiv.org/abs/2303.14692v2,math.OC,"['math.OC', 'cs.CE', 'cs.MS', 'cs.NA', 'math.DS', 'math.NA']",,,[]
"Efficient simulation of individual-based population models: the R
  Package IBMPopSim",http://arxiv.org/abs/2303.06183v2,2023-03-10T19:31:50Z,2024-02-27T14:56:53Z,"  The R Package IBMPopSim aims to simulate the random evolution of
heterogeneous populations using stochastic Individual-Based Models (IBMs).
  The package enables users to simulate population evolution, in which
individuals are characterized by their age and some characteristics, and the
population is modified by different types of events, including births/arrivals,
death/exit events, or changes of characteristics. The frequency at which an
event can occur to an individual can depend on their age and characteristics,
but also on the characteristics of other individuals (interactions). Such
models have a wide range of applications in fields including actuarial science,
biology, ecology or epidemiology.
  IBMPopSim overcomes the limitations of time-consuming IBMs simulations by
implementing new efficient algorithms based on thinning methods, which are
compiled using the Rcpp package while providing a user-friendly interface.
","['\nDaphné Giorgi\n', '\nSarah Kaakai\n', '\nVincent Lemaire\n']",,,http://arxiv.org/abs/2303.06183v2,q-bio.PE,"['q-bio.PE', 'cs.MS', 'math.PR', '60-08, 60-04, 92D25, 60G55, 60G57, 65C30, 91G05', 'G.3; G.4; I.6']",,,[]
"AutoOptLib: Tailoring Metaheuristic Optimizers via Automated Algorithm
  Design",http://arxiv.org/abs/2303.06536v2,2023-03-12T01:45:05Z,2023-11-14T09:18:43Z,"  Metaheuristics are prominent gradient-free optimizers for solving hard
problems that do not meet the rigorous mathematical assumptions of analytical
solvers. The canonical manual optimizer design could be laborious, untraceable
and error-prone, let alone human experts are not always available. This arises
increasing interest and demand in automating the optimizer design process. In
response, this paper proposes AutoOptLib, the first platform for accessible
automated design of metaheuristic optimizers. AutoOptLib leverages computing
resources to conceive, build up, and verify the design choices of the
optimizers. It requires much less labor resources and expertise than manual
design, democratizing satisfactory metaheuristic optimizers to a much broader
range of researchers and practitioners. Furthermore, by fully exploring the
design choices with computing resources, AutoOptLib has the potential to
surpass human experience, subsequently gaining enhanced performance compared
with human problem-solving. To realize the automated design, AutoOptLib
provides 1) a rich library of metaheuristic components for continuous,
discrete, and permutation problems; 2) a flexible algorithm representation for
evolving diverse algorithm structures; 3) different design objectives and
techniques for different optimization scenarios; and 4) a graphic user
interface for accessibility and practicability. AutoOptLib is fully written in
Matlab/Octave; its source code and documentation are available at
https://github.com/qz89/AutoOpt and https://AutoOpt.readthedocs.io/,
respectively.
","['\nQi Zhao\n', '\nBai Yan\n', '\nTaiwei Hu\n', '\nXianglong Chen\n', '\nQiqi Duan\n', '\nJian Yang\n', '\nYuhui Shi\n']",,,http://arxiv.org/abs/2303.06536v2,cs.NE,"['cs.NE', 'cs.LG', 'cs.MS']",,,[]
$\nabla$SD: Differentiable Programming for Sparse Tensors,http://arxiv.org/abs/2303.07030v1,2023-03-13T11:45:48Z,2023-03-13T11:45:48Z,"  Sparse tensors are prevalent in many data-intensive applications, yet
existing differentiable programming frameworks are tailored towards dense
tensors. This presents a significant challenge for efficiently computing
gradients through sparse tensor operations, as their irregular sparsity
patterns can result in substantial memory and computational overheads. In this
work, we introduce a novel framework that enables the efficient and automatic
differentiation of sparse tensors, addressing this fundamental issue. Our
experiments demonstrate the effectiveness of the proposed framework in terms of
performance and scalability, outperforming state-of-the-art frameworks across a
range of synthetic and real-world datasets. Our approach offers a promising
direction for enabling efficient and scalable differentiable programming with
sparse tensors, which has significant implications for numerous applications in
machine learning, natural language processing, and scientific computing.
","['\nAmir Shaikhha\n', '\nMathieu Huot\n', '\nShideh Hashemian\n']",,,http://arxiv.org/abs/2303.07030v1,cs.PL,"['cs.PL', 'cs.LG', 'cs.MS']",,,[]
Physics-driven machine learning models coupling PyTorch and Firedrake,http://arxiv.org/abs/2303.06871v3,2023-03-13T05:42:58Z,2023-04-01T12:05:32Z,"  Partial differential equations (PDEs) are central to describing and modelling
complex physical systems that arise in many disciplines across science and
engineering. However, in many realistic applications PDE modelling provides an
incomplete description of the physics of interest. PDE-based machine learning
techniques are designed to address this limitation. In this approach, the PDE
is used as an inductive bias enabling the coupled model to rely on fundamental
physical laws while requiring less training data. The deployment of
high-performance simulations coupling PDEs and machine learning to complex
problems necessitates the composition of capabilities provided by machine
learning and PDE-based frameworks. We present a simple yet effective coupling
between the machine learning framework PyTorch and the PDE system Firedrake
that provides researchers, engineers and domain specialists with a high
productive way of specifying coupled models while only requiring trivial
changes to existing code.
","['\nNacime Bouziani\n', '\nDavid A. Ham\n']",Accepted at the ICLR 2023 Workshop on Physics for Machine Learning,,http://arxiv.org/abs/2303.06871v3,cs.LG,"['cs.LG', 'cs.MS', 'cs.NA', 'math.NA', 'physics.comp-ph']",,,[]
The Awkward World of Python and C++,http://arxiv.org/abs/2303.02205v1,2023-03-03T20:33:50Z,2023-03-03T20:33:50Z,"  There are undeniable benefits of binding Python and C++ to take advantage of
the best features of both languages. This is especially relevant to the HEP and
other scientific communities that have invested heavily in the C++ frameworks
and are rapidly moving their data analyses to Python. Version 2 of Awkward
Array, a Scikit-HEP Python library, introduces a set of header-only C++
libraries that do not depend on any application binary interface. Users can
directly include these libraries in their compilation rather than linking
against platform-specific libraries. This new development makes the integration
of Awkward Arrays into other projects easier and more portable as the
implementation is easily separable from the rest of the Awkward Array codebase.
The code is minimal, it does not include all of the code needed to use Awkward
Arrays in Python, nor does it include references to Python or pybind11. The C++
users can use it to make arrays and then copy them to Python without any
specialized data types - only raw buffers, strings, and integers. This C++ code
also simplifies the process of just-in-time (JIT) compilation in ROOT. This
implementation approach solves some of the drawbacks, like packaging projects
where native dependencies can be challenging. In this paper, we demonstrate the
technique to integrate C++ and Python by using a header-only approach. We also
describe the implementation of a new LayoutBuilder and a GrowableBuffer.
Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing
Awkward Arrays to C++ without copying them are discussed.
","['\nManasvi Goyal\n', '\nIanna Osborne\n', '\nJim Pivarski\n']","6 pages, 2 figures; submitted to ACAT 2022 proceedings",,http://arxiv.org/abs/2303.02205v1,cs.MS,"['cs.MS', 'hep-ex']",,,[]
"Multi-GPU aggregation-based AMG preconditioner for iterative linear
  solvers",http://arxiv.org/abs/2303.02352v1,2023-03-04T08:29:54Z,2023-03-04T08:29:54Z,"  We present and release in open source format a sparse linear solver which
efficiently exploits heterogeneous parallel computers. The solver can be easily
integrated into scientific applications that need to solve large and sparse
linear systems on modern parallel computers made of hybrid nodes hosting NVIDIA
Graphics Processing Unit (GPU) accelerators.
  The work extends our previous efforts in the exploitation of a single GPU
accelerator and proposes an implementation, based on the hybrid MPI-CUDA
software environment, of a Krylov-type linear solver relying on an efficient
Algebraic MultiGrid (AMG) preconditioner already available in the BootCMatchG
library. Our design for the hybrid implementation has been driven by the best
practices for minimizing data communication overhead when multiple GPUs are
employed, yet preserving the efficiency of the single GPU kernels. Strong and
weak scalability results on well-known benchmark test cases of the new version
of the library are discussed. Comparisons with the Nvidia AmgX solution show an
improvement of up to 2.0x in the solve phase.
","['\nMassimo Bernaschi\n', '\nAlessandro Celestini\n', ""\nPasqua D'Ambra\n"", '\nFlavio Vella\n']",,IEEE Transactions on Parallel and Distributed Systems (2023),http://dx.doi.org/10.1109/TPDS.2023.3287238,cs.DC,"['cs.DC', 'cs.MS']",10.1109/TPDS.2023.3287238,,[]
QCLAB++: Simulating Quantum Circuits on GPUs,http://arxiv.org/abs/2303.00123v1,2023-02-28T22:56:48Z,2023-02-28T22:56:48Z,"  We introduce qclab++, a light-weight, fully-templated C++ package for
GPU-accelerated quantum circuit simulations. The code offers a high degree of
portability as it has no external dependencies and the GPU kernels are
generated through OpenMP offloading. qclab++ is designed for performance and
numerical stability through highly optimized gate simulation algorithms for
1-qubit, controlled 1-qubit, and 2-qubit gates. Furthermore, we also introduce
qclab, a quantum circuit toolbox for Matlab with a syntax that mimics qclab++.
This provides users the flexibility and ease of use of a scripting language
like Matlab for studying their quantum algorithms, while offering
high-performance GPU acceleration when required. As such, the qclab++ library
offers a unique combination of features. We compare the CPU simulator in
qclab++ with the GPU kernels generated by OpenMP and observe a speedup of over
$40\times$. Furthermore, we also compare qclab++ to other circuit simulation
packages, such as cirq-qsim and qibo, in a series of benchmarks conducted on
NERSC's Perlmutter system and illustrate its competitiveness.
","['\nRoel Van Beeumen\n', '\nDaan Camps\n', '\nNeil Mehta\n']","13 pages, 10 figures",,http://arxiv.org/abs/2303.00123v1,quant-ph,"['quant-ph', 'cs.MS', 'cs.PF']",,,[]
"Robust and Practical Solution of Laplacian Equations by Approximate
  Elimination",http://arxiv.org/abs/2303.00709v2,2023-03-01T18:07:51Z,2023-06-14T08:26:46Z,"  We introduce a new algorithm and software for solving linear equations in
symmetric diagonally dominant matrices with non-positive off-diagonal entries
(SDDM matrices), including Laplacian matrices. We use pre-conditioned conjugate
gradient (PCG) to solve the system of linear equations. Our preconditioner is a
variant of the Approximate Cholesky factorization of Kyng and Sachdeva (FOCS
2016). Our factorization approach is simple: we eliminate matrix rows/columns
one at a time and update the remaining matrix using sampling to approximate the
outcome of complete Cholesky factorization. Unlike earlier approaches, our
sampling always maintains a connectivity in the remaining non-zero structure.
Our algorithm comes with a tuning parameter that upper bounds the number of
samples made per original entry. We implement our algorithm in Julia, providing
two versions, AC and AC2, that respectively use 1 and 2 samples per original
entry. We compare their single-threaded performance to that of current
state-of-the-art solvers Combinatorial Multigrid (CMG),
BoomerAMG-preconditioned Krylov solvers from HyPre and PETSc, Lean Algebraic
Multigrid (LAMG), and MATLAB's with Incomplete Cholesky Factorization (ICC).
Our evaluation uses a broad class of problems, including all large SDDM
matrices from the SuiteSparse collection and diverse programmatically generated
instances. Our experiments suggest that our algorithm attains a level of
robustness and reliability not seen before in SDDM solvers, while retaining
good performance across all instances. Our code and data are public, and we
provide a tutorial on how to replicate our tests. We hope that others will
adopt this suite of tests as a benchmark, which we refer to as SDDM2023. Our
solver code is available at: https://github.com/danspielman/Laplacians.jl/ Our
benchmarking data and tutorial are available at:
https://rjkyng.github.io/SDDM2023/
","['\nYuan Gao\n', '\nRasmus Kyng\n', '\nDaniel A. Spielman\n']",,,http://arxiv.org/abs/2303.00709v2,math.NA,"['math.NA', 'cs.DS', 'cs.MS', 'cs.NA']",,,[]
Robust Parameter Estimation for Rational Ordinary Differential Equations,http://arxiv.org/abs/2303.02159v3,2023-03-02T14:33:06Z,2023-12-17T12:01:55Z,"  We present a new approach for estimating parameters in rational ODE models
from given (measured) time series data.
  In typical existing approaches, an initial guess for the parameter values is
made from a given search interval. Then, in a loop, the corresponding outputs
are computed by solving the ODE numerically, followed by computing the error
from the given time series data. If the error is small, the loop terminates and
the parameter values are returned. Otherwise, heuristics/theories are used to
possibly improve the guess and continue the loop.
  These approaches tend to be non-robust in the sense that their accuracy
depend on the search interval and the true parameter values; furthermore, they
cannot handle the case where the parameters are locally identifiable.
  In this paper, we propose a new approach, which does not suffer from the
above non-robustness. In particular, it does not require making good initial
guesses for the parameter values or specifying search intervals. Instead, it
uses differential algebra, interpolation of the data using rational functions,
and multivariate polynomial system solving. We also compare the performance of
the resulting software with several other estimation software packages.
","['\nOren Bassik\n', '\nYosef Berman\n', '\nSoo Go\n', '\nHoon Hong\n', '\nIlia Ilmer\n', '\nAlexey Ovchinnikov\n', '\nChris Rackauckas\n', '\nPedro Soto\n', '\nChee Yap\n']",Updates regarding robustness,,http://arxiv.org/abs/2303.02159v3,cs.MS,"['cs.MS', 'cs.SC', 'math.DS', 'q-bio.QM']",,,[]
"Acceleration of a production Solar MHD code with Fortran standard
  parallelism: From OpenACC to `do concurrent'",http://arxiv.org/abs/2303.03398v2,2023-03-05T21:37:34Z,2023-03-08T20:18:20Z,"  There is growing interest in using standard language constructs for
accelerated computing, avoiding the need for (often vendor-specific) external
APIs. These constructs hold the potential to be more portable and much more
`future-proof'. For Fortran codes, the current focus is on the {\tt do
concurrent} (DC) loop. While there have been some successful examples of
GPU-acceleration using DC for benchmark and/or small codes, its widespread
adoption will require demonstrations of its use in full-size applications.
Here, we look at the current capabilities and performance of using DC in a
production application called Magnetohydrodynamic Algorithm outside a Sphere
(MAS). MAS is a state-of-the-art model for studying coronal and heliospheric
dynamics, is over 70,000 lines long, and has previously been ported to GPUs
using MPI+OpenACC. We attempt to eliminate as many of its OpenACC directives as
possible in favor of DC. We show that using the NVIDIA {\tt nvfortran}
compiler's Fortran 202X preview implementation, unified managed memory, and
modified MPI launch methods, we can achieve GPU acceleration across multiple
GPUs without using a single OpenACC directive. However, doing so results in a
slowdown between 1.25x and 3x. We discuss what future improvements are needed
to avoid this loss, and show how we can still retain close
","['\nRonald M. Caplan\n', '\nMiko M. Stulajter\n', '\nJon A. Linker\n']","10 pages, 2 tables, 4 figures, accepted to the AsHES workshop at
  IPDPS 2023",,http://arxiv.org/abs/2303.03398v2,cs.MS,"['cs.MS', 'astro-ph.IM', 'cs.DC', 'cs.PL', '65Y05']",,,[]
EZtune: A Package for Automated Hyperparameter Tuning in R,http://arxiv.org/abs/2303.12177v1,2023-03-03T03:38:31Z,2023-03-03T03:38:31Z,"  Statistical learning models have been growing in popularity in recent years.
Many of these models have hyperparameters that must be tuned for models to
perform well. Tuning these parameters is not trivial. EZtune is an R package
with a simple user interface that can tune support vector machines, adaboost,
gradient boosting machines, and elastic net. We first provide a brief summary
of the the models that EZtune can tune, including a discussion of each of their
hyperparameters. We then compare the ease of using EZtune, caret, and
tidymodels. This is followed with a comparison of the accuracy and computation
times for models tuned with EZtune and tidymodels. We conclude with a
demonstration of how how EZtune can be used to help select a final model with
optimal predictive power. Our comparison shows that EZtune can tune support
vector machines and gradient boosting machines with EZtune also provides a user
interface that is easy to use for a novice to statistical learning models or R.
",['\nJill Lundell\n'],"10 pages, 2 figures, submitted to the R Journal",,http://arxiv.org/abs/2303.12177v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.CO']",,,[]
GEMMFIP: Unifying GEMM in BLIS,http://arxiv.org/abs/2302.08417v2,2023-02-16T16:52:49Z,2023-02-17T03:24:04Z,"  Matrix libraries often focus on achieving high performance for problems
considered to be either ""small"" or ""large"", as these two scenarios tend to
respond best to different optimization strategies. We propose a unified
technique for implementing matrix operations like general matrix multiplication
(GEMM) that can achieve high performance for both small and large problem
sizes. The key is to fuse packing -- an operation that copies data to a
contiguous layout in memory and which is critical for large matrix performance
-- with the first computational ""pass"" over that data. This boosts performance
across the problem size spectrum. As a result, tuning general-purpose libraries
becomes simpler since it obviates the need to carefully express and
parameterize logic that chooses between a ""small matrix"" strategy and a ""large
matrix"" strategy. A prototype implementation of the technique built with the
BLAS-like Library Instantiation Software (BLIS) framework is described and
performance on a range of architectures is reported.
","['\nRuQing G. Xu\n', '\nField G. Van Zee\n', '\nRobert A. van de Geijn\n']","16 pages, 7 figures, 2 algorithms",,http://arxiv.org/abs/2302.08417v2,cs.MS,"['cs.MS', 'G.4']",,,[]
GPU Offloading in ExaHyPE Through C++ Standard Algorithms,http://arxiv.org/abs/2302.09005v1,2023-02-17T17:19:41Z,2023-02-17T17:19:41Z,"  The ISO C++17 standard introduces \emph{parallel algorithms}, a parallel
programming model promising portability across a wide variety of parallel
hardware including multi-core CPUs, GPUs, and FPGAs. Since 2019, the NVIDIA HPC
SDK compiler suite supports this programming model for multi-core CPUs and
GPUs. ExaHyPE is a solver engine for hyperbolic partial differential equations
for complex wave phenomena. It supports multiple numerical methods including
Finite Volumes and ADER-DG, and employs adaptive mesh refinement with dynamic
load balancing via space-filling curves as well as task-based parallelism and
offloading to GPUs. This study ports ExaHyPE's tasks over blocks of Finite
Volumes to the ISO C++ parallel algorithms programming model, and compares its
performance and usability against an OpenMP implementation with offloading via
OpenMP target directives. It shows that ISO C++ is a feasible programming model
for non-trivial applications like our task-based AMR code. The realisation is
bare of vendor-specific or non-C++ extensions. It however is slower than its
OpenMP counterpart. \vspace{-1cm}
","['\nUzmar Gomez\n', '\nGonzalo Brito Gadeschi\n', '\nTobias Weinzierl\n']",,,http://arxiv.org/abs/2302.09005v1,cs.MS,['cs.MS'],,,[]
PNet: A Python Library for Petri Net Modeling and Simulation,http://arxiv.org/abs/2302.12054v1,2023-02-23T14:27:50Z,2023-02-23T14:27:50Z,"  Petri Net is a formalism to describe changes between 2 or more states across
discrete time and has been used to model many systems. We present PNet - a pure
Python library for Petri Net modeling and simulation in Python programming
language. The design of PNet focuses on reducing the learning curve needed to
define a Petri Net by using a text-based language rather than programming
constructs to define transition rules. Complex transition rules can be refined
as regular Python functions. To demonstrate the simplicity of PNet, we present
2 examples - bread baking, and epidemiological models.
","['\nZhu En Chay\n', '\nBing Feng Goh\n', '\nMaurice HT Ling\n']",,"Advances in Computer Science: an international journal 5(4): 24-30
  (2016)",http://arxiv.org/abs/2302.12054v1,cs.MS,['cs.MS'],,,[]
"Unique Compact Representation of Magnetic Fields using Truncated Solid
  Harmonic Expansions",http://arxiv.org/abs/2302.07591v1,2023-02-15T11:09:19Z,2023-02-15T11:09:19Z,"  Precise knowledge of magnetic fields is crucial in many medical imaging
applications like magnetic resonance imaging or magnetic particle imaging (MPI)
as they are the foundation of these imaging systems. For the investigation of
the influence of field imperfections on imaging, a compact and unique
representation of the magnetic fields using real solid spherical harmonics,
which can be obtained by measuring a few points of the magnetic field only, is
of great assistance. In this manuscript, we review real solid harmonic
expansions as a general solution of Laplace's equation including an efficient
calculation of their coefficients using spherical t-designs. We also provide a
method to shift the reference point of an expansion by calculating the
coefficients of the shifted expansion from the initial ones. These methods are
used to obtain the magnetic fields of an MPI system. Here, the field-free-point
of the spatial encoding field serves as unique expansion point. Lastly, we
quantify the severity of the distortions of the static and dynamic fields in
MPI by analyzing the expansion coefficients.
","['\nMarija Boberg\n', '\nTobias Knopp\n', '\nMartin Möddel\n']",25 pages,,http://arxiv.org/abs/2302.07591v1,physics.med-ph,"['physics.med-ph', 'cs.MS', '33C55, 35Q60, 41A30, 41A55, 41A58, 41-04']",,,[]
"TAPPS Release 1: Plugin-Extensible Platform for Technical Analysis and
  Applied Statistics",http://arxiv.org/abs/2302.12056v1,2023-02-23T14:30:20Z,2023-02-23T14:30:20Z,"  We present the first release of TAPPS (Technical Analysis and Applied
Statistics System); a Python implementation of a thin software platform aimed
towards technical analyses and applied statistics. The core of TAPPS is a
container for 2-dimensional data frame objects and a TAPPS command language.
TAPPS language is not meant to be a programming language for script and plugin
development but for the operational purposes. In this aspect, TAPPS language
takes on the flavor of SQL rather than R, resulting in a shallower learning
curve. All analytical functions are implemented as plugins. This results in a
defined plugin system, which enables rapid development and incorporation of
analysis functions. TAPPS Release 1 is released under GNU General Public
License 3 for academic and non-commercial use. TAPPS code repository can be
found at http://github.com/mauriceling/tapps.
","['\nJustin Sam Chew\n', '\nMaurice HT Ling\n']",,"Advances in Computer Science: an international journal 5(1):
  132-141 (2016)",http://arxiv.org/abs/2302.12056v1,cs.MS,"['cs.MS', 'stat.AP']",,,[]
SubalgebraBases in Macaulay2,http://arxiv.org/abs/2302.12473v2,2023-02-24T06:16:21Z,2024-01-16T14:47:36Z,"  We describe a recently revived version of the software package
SubalgberaBases, which is distributed in the Macaulay2 computer algebra system.
The package allows the user to compute and manipulate subagebra bases -- which
are also known as SAGBI bases or canonical bases and form a special class of
Khovanskii bases -- for polynomial rings and their quotients. We provide an
overview of the design and functionality of SubalgberaBases and demonstrate how
the package works on several motivating examples.
","['\nMichael Burr\n', '\nOliver Clarke\n', '\nTimothy Duff\n', '\nJackson Leaman\n', '\nNathan Nichols\n', '\nElise Walker\n']","Revised version. 11 pages w/ refs. Ancillary file
  ""accompanyingCode.m2"" available on arXiv",,http://arxiv.org/abs/2302.12473v2,math.AC,"['math.AC', 'cs.MS', '68W30']",,,[]
"An Incremental Singular Value Decomposition Approach for Large-Scale
  Spatially Parallel & Distributed but Temporally Serial Data -- Applied to
  Technical Flows",http://arxiv.org/abs/2302.09149v1,2023-02-17T21:19:54Z,2023-02-17T21:19:54Z,"  The paper presents a strategy to construct an incremental Singular Value
Decomposition (SVD) for time-evolving, spatially 3D discrete data sets. A low
memory access procedure for reducing and deploying the snapshot data is
presented. Considered examples refer to Computational Fluid Dynamic (CFD)
results extracted from unsteady flow simulations, which are computed spatially
parallel using domain decomposition strategies. The framework addresses state
of the art PDE-solvers dedicated to practical applications. Although the
approach is applied to technical flows, it is applicable in similar
applications under the umbrella of Computational Science and Engineering (CSE).
To this end, we introduce a bunch matrix that allows the aggregation of
multiple time steps and SVD updates, and significantly increases the
computational efficiency. The incremental SVD strategy is initially verified
and validated by simulating the 2D laminar single-phase flow around a circular
cylinder. Subsequent studies analyze the proposed strategy for a 2D submerged
hydrofoil located in turbulent two-phase flows. Attention is directed to the
accuracy of the SVD-based reconstruction based on local and global flow
quantities, their physical realizability, the independence of the domain
partitioning, and related implementation aspects. Moreover, the influence of
lower and (adaptive) upper construction rank thresholds on both the effort and
the accuracy are assessed. The incremental SVD process is applied to analyze
and compress the predicted flow field around a Kriso container ship in harmonic
head waves at Fn = 0.26 and ReL = 1.4E+07. With a numerical overhead of O(10%),
the snapshot matrix of size O(R10E+08 x 10E+04) computed on approximately 3000
processors can be incrementally compressed by O(95%). The storage reduction is
accompanied by errors in integral force and local wave elevation quantities of
O(1E-02%).
","['\nNiklas Kühl\n', '\nHendrik Fischer\n', '\nMichael Hinze\n', '\nThomas Rung\n']",,,http://arxiv.org/abs/2302.09149v1,cs.MS,"['cs.MS', 'cs.DC', 'physics.comp-ph', 'physics.flu-dyn']",,,[]
SurvLIMEpy: A Python package implementing SurvLIME,http://arxiv.org/abs/2302.10571v2,2023-02-21T09:54:32Z,2023-03-17T21:41:38Z,"  In this paper we present SurvLIMEpy, an open-source Python package that
implements the SurvLIME algorithm. This method allows to compute local feature
importance for machine learning algorithms designed for modelling Survival
Analysis data. Our implementation takes advantage of the parallelisation
paradigm as all computations are performed in a matrix-wise fashion which
speeds up execution time. Additionally, SurvLIMEpy assists the user with
visualization tools to better understand the result of the algorithm. The
package supports a wide variety of survival models, from the Cox Proportional
Hazards Model to deep learning models such as DeepHit or DeepSurv. Two types of
experiments are presented in this paper. First, by means of simulated data, we
study the ability of the algorithm to capture the importance of the features.
Second, we use three open source survival datasets together with a set of
survival algorithms in order to demonstrate how SurvLIMEpy behaves when applied
to different models.
","['\nCristian Pachón-García\n', '\nCarlos Hernández-Pérez\n', '\nPedro Delicado\n', '\nVerónica Vilaplana\n']",,,http://arxiv.org/abs/2302.10571v2,stat.ML,"['stat.ML', 'cs.AI', 'cs.LG', 'cs.MS']",,,[]
"Randomized Numerical Linear Algebra : A Perspective on the Field With an
  Eye to Software",http://arxiv.org/abs/2302.11474v2,2023-02-22T16:21:37Z,2023-04-12T20:56:40Z,"  Randomized numerical linear algebra - RandNLA, for short - concerns the use
of randomization as a resource to develop improved algorithms for large-scale
linear algebra computations.
  The origins of contemporary RandNLA lay in theoretical computer science,
where it blossomed from a simple idea: randomization provides an avenue for
computing approximate solutions to linear algebra problems more efficiently
than deterministic algorithms. This idea proved fruitful in the development of
scalable algorithms for machine learning and statistical data analysis
applications. However, RandNLA's true potential only came into focus upon
integration with the fields of numerical analysis and ""classical"" numerical
linear algebra. Through the efforts of many individuals, randomized algorithms
have been developed that provide full control over the accuracy of their
solutions and that can be every bit as reliable as algorithms that might be
found in libraries such as LAPACK. Recent years have even seen the
incorporation of certain RandNLA methods into MATLAB, the NAG Library, NVIDIA's
cuSOLVER, and SciKit-Learn.
  For all its success, we believe that RandNLA has yet to realize its full
potential. In particular, we believe the scientific community stands to benefit
significantly from suitably defined ""RandBLAS"" and ""RandLAPACK"" libraries, to
serve as standards conceptually analogous to BLAS and LAPACK. This 200-page
monograph represents a step toward defining such standards. In it, we cover
topics spanning basic sketching, least squares and optimization, low-rank
approximation, full matrix decompositions, leverage score sampling, and
sketching data with tensor product structures (among others). Much of the
provided pseudo-code has been tested via publicly available MATLAB and Python
implementations.
","['\nRiley Murray\n', '\nJames Demmel\n', '\nMichael W. Mahoney\n', '\nN. Benjamin Erichson\n', '\nMaksim Melnichenko\n', '\nOsman Asif Malik\n', '\nLaura Grigori\n', '\nPiotr Luszczek\n', '\nMichał Dereziński\n', '\nMiles E. Lopes\n', '\nTianyu Liang\n', '\nHengrui Luo\n', '\nJack Dongarra\n']","v1: this is the first arXiv release of LAPACK Working Note 299. v2:
  complete rewrite of the subsection on trace estimation, among other changes.
  See frontmatter page ii (pdf page 5) for revision history",,http://arxiv.org/abs/2302.11474v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.OC']",,,[]
A note on the standard diffusion curve of TAP analysis,http://arxiv.org/abs/2302.03772v1,2023-02-07T22:05:26Z,2023-02-07T22:05:26Z,"  The standard diffusion curve used in models of TAP reactors, as it is usually
defined, is numerically unstable for small values. We use a functional equation
satisfied by the curve to define a numerically stable way of computing it for
all values.
",['\nToby Isaac\n'],"3 pages, 2 figures, 2 code listings",,http://arxiv.org/abs/2302.03772v1,cs.MS,['cs.MS'],,,[]
"General framework for re-assuring numerical reliability in parallel
  Krylov solvers: A case of BiCGStab methods",http://arxiv.org/abs/2302.04180v1,2023-02-08T16:39:01Z,2023-02-08T16:39:01Z,"  Parallel implementations of Krylov subspace methods often help to accelerate
the procedure of finding an approximate solution of a linear system. However,
such parallelization coupled with asynchronous and out-of-order execution often
enlarge the non-associativity impact in floating-point operations. These
problems are even amplified when communication-hiding pipelined algorithms are
used to improve the parallelization of Krylov subspace methods. Introducing
reproducibility in the implementations avoids these problems by getting more
robust and correct solutions. This paper proposes a general framework for
deriving reproducible and accurate variants of Krylov subspace methods. The
proposed algorithmic strategies are reinforced by programmability suggestions
to assure deterministic and accurate executions. The framework is illustrated
on the preconditioned BiCGStab method and its pipelined modification, which in
fact is a distinctive method from the Krylov subspace family, for the solution
of non-symmetric linear systems with message-passing. Finally, we verify the
numerical behaviour of the two reproducible variants of BiCGStab on a set of
matrices from the SuiteSparse Matrix Collection and a 3D Poisson's equation.
","['\nRoman Iakymchuk\n', '\nJose I. Aliaga\n']",arXiv admin note: text overlap with arXiv:2005.07282,,http://arxiv.org/abs/2302.04180v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"Modern Methods for Signal Analysis: Empirical Mode Decomposition Theory
  and Hybrid Operator-Based Methods Using B-Splines",http://arxiv.org/abs/2302.03334v1,2023-02-07T09:16:54Z,2023-02-07T09:16:54Z,"  This thesis examines the empirical mode decomposition (EMD), a method for
decomposing multicomponent signals, from a modern, both theoretical and
practical, perspective. The motivation is to further formalize the concept and
develop new methods to approach it numerically.
  The theoretical part introduces a new formalization of the method as an
optimization problem over ordered function vector spaces. Using the theory of
'convex-like' optimization and B-splines, Slater-regularity and thus strong
duality of this optimization problem is shown. This results in a theoretical
justification for the modern null-space-pursuit (NSP) operator-based
signal-separation (OSS) EMD-approach for signal decomposition and spectral
analysis.
  The practical part considers the identified strengths and weaknesses in OSS
and NSP and proposes a hybrid EMD method that utilizes these modern, but also
classic, methods, implementing them in a toolbox called ETHOS (EMD Toolbox
using Hybrid Operator-Based Methods and B-splines) and applying them to
comparative examples. In the course of this part a new envelope estimation
method called 'iterative slope envelope estimation' is proposed.
",['\nLaslo Hunhold\n'],"151 pages, 33 figures, code attached in the submitted archive",,http://arxiv.org/abs/2302.03334v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '94A12 (Primary) 65D05, 65D07, 65D10, 65D15 (Secondary)']",,,[]
"mlpack 4: a fast, header-only C++ machine learning library",http://arxiv.org/abs/2302.00820v1,2023-02-02T02:03:22Z,2023-02-02T02:03:22Z,"  For over 15 years, the mlpack machine learning library has served as a ""swiss
army knife"" for C++-based machine learning. Its efficient implementations of
common and cutting-edge machine learning algorithms have been used in a wide
variety of scientific and industrial applications. This paper overviews mlpack
4, a significant upgrade over its predecessor. The library has been
significantly refactored and redesigned to facilitate an easier
prototyping-to-deployment pipeline, including bindings to other languages
(Python, Julia, R, Go, and the command line) that allow prototyping to be
seamlessly performed in environments other than C++. mlpack is open-source
software, distributed under the permissive 3-clause BSD license; it can be
obtained at https://mlpack.org
","['\nRyan R. Curtin\n', '\nMarcus Edel\n', '\nOmar Shrit\n', '\nShubham Agrawal\n', '\nSuryoday Basak\n', '\nJames J. Balamuta\n', '\nRyan Birmingham\n', '\nKartik Dutt\n', '\nDirk Eddelbuettel\n', '\nRishabh Garg\n', '\nShikhar Jaiswal\n', '\nAakash Kaushik\n', '\nSangyeon Kim\n', '\nAnjishnu Mukherjee\n', '\nNanubala Gnana Sai\n', '\nNippun Sharma\n', '\nYashwant Singh Parihar\n', '\nRoshan Swain\n', '\nConrad Sanderson\n']",,"Journal of Open Source Software, Vol. 8, No. 82, 2023",http://dx.doi.org/10.21105/joss.05026,cs.MS,['cs.MS'],10.21105/joss.05026,,[]
Ananke: A Python Package For Causal Inference Using Graphical Models,http://arxiv.org/abs/2301.11477v1,2023-01-27T00:46:38Z,2023-01-27T00:46:38Z,"  We implement Ananke: an object-oriented Python package for causal inference
with graphical models. At the top of our inheritance structure is an easily
extensible Graph class that provides an interface to several broadly useful
graph-based algorithms and methods for visualization. We use best practices of
object-oriented programming to implement subclasses of the Graph superclass
that correspond to types of causal graphs that are popular in the current
literature. This includes directed acyclic graphs for modeling causally
sufficient systems, acyclic directed mixed graphs for modeling unmeasured
confounding, and chain graphs for modeling data dependence and interference.
  Within these subclasses, we implement specialized algorithms for common
statistical and causal modeling tasks, such as separation criteria for reading
conditional independence, nonparametric identification, and parametric and
semiparametric estimation of model parameters. Here, we present a broad
overview of the package and example usage for a problem with unmeasured
confounding. Up to date documentation is available at
\url{https://ananke.readthedocs.io/en/latest/}.
","['\nJaron J. R. Lee\n', '\nRohit Bhattacharya\n', '\nRazieh Nabi\n', '\nIlya Shpitser\n']",,,http://arxiv.org/abs/2301.11477v1,stat.ME,"['stat.ME', 'cs.MS']",,,[]
Disciplined Saddle Programming,http://arxiv.org/abs/2301.13427v2,2023-01-31T05:48:22Z,2024-01-10T17:59:15Z,"  We consider convex-concave saddle point problems, and more generally convex
optimization problems we refer to as $\textit{saddle problems}$, which include
the partial supremum or infimum of convex-concave saddle functions. Saddle
problems arise in a wide range of applications, including game theory, machine
learning, and finance. It is well known that a saddle problem can be reduced to
a single convex optimization problem by dualizing either the convex (min) or
concave (max) objectives, reducing a min-max problem into a min-min (or
max-max) problem. Carrying out this conversion by hand can be tedious and error
prone. In this paper we introduce $\textit{disciplined saddle programming}$
(DSP), a domain specific language (DSL) for specifying saddle problems, for
which the dualizing trick can be automated. The language and methods are based
on recent work by Juditsky and Nemirovski arXiv:2102.01002 [math.OC], who
developed the idea of conic-representable saddle point programs, and showed how
to carry out the required dualization automatically using conic duality.
Juditsky and Nemirovski's conic representation of saddle problems extends
Nesterov and Nemirovski's earlier development of conic representable convex
problems; DSP can be thought of as extending disciplined convex programming
(DCP) to saddle problems. Just as DCP makes it easy for users to formulate and
solve complex convex problems, DSP allows users to easily formulate and solve
saddle problems. Our method is implemented in an open-source package, also
called DSP.
","['\nPhilipp Schiele\n', '\nEric Luxenberg\n', '\nStephen Boyd\n']",,,http://arxiv.org/abs/2301.13427v2,math.OC,"['math.OC', 'cs.MS', 'G.4']",,,[]
"Exact hierarchical reductions of dynamical models via linear
  transformations",http://arxiv.org/abs/2301.11653v2,2023-01-27T11:08:55Z,2024-01-03T19:53:51Z,"  Dynamical models described by ordinary differential equations (ODEs) are a
fundamental tool in the sciences and engineering. Exact reduction aims at
producing a lower-dimensional model in which each macro-variable can be
directly related to the original variables, and it is thus a natural step
towards the model's formal analysis and mechanistic understanding. We present
an algorithm which, given a polynomial ODE model, computes a longest possible
chain of exact linear reductions of the model such that each reduction refines
the previous one, thus giving a user control of the level of detail preserved
by the reduction. This significantly generalizes over the existing approaches
which compute only the reduction of the lowest dimension subject to an
approach-specific constraint. The algorithm reduces finding exact linear
reductions to a question about representations of finite-dimensional algebras.
We provide an implementation of the algorithm, demonstrate its performance on a
set of benchmarks, and illustrate the applicability via case studies. Our
implementation is freely available at
https://github.com/x3042/ExactODEReduction.jl
","['\nAlexander Demin\n', '\nElizaveta Demitraki\n', '\nGleb Pogudin\n']",,,http://arxiv.org/abs/2301.11653v2,eess.SY,"['eess.SY', 'cs.MS', 'cs.SC', 'cs.SY', 'math.DS', '34C20, 34-04, 16G10']",,,[]
"GPU Accelerated Newton for Taylor Series Solutions of Polynomial
  Homotopies in Multiple Double Precision",http://arxiv.org/abs/2301.12659v1,2023-01-30T04:41:28Z,2023-01-30T04:41:28Z,"  A polynomial homotopy is a family of polynomial systems, typically in one
parameter $t$. Our problem is to compute power series expansions of the
coordinates of the solutions in the parameter $t$, accurately, using multiple
double arithmetic. One application of this problem is the location of the
nearest singular solution in a polynomial homotopy, via the theorem of Fabry.
Power series serve as input to construct Pad\'{e} approximations.
  Exploiting the massive parallelism of Graphics Processing Units capable of
performing several trillions floating-point operations per second, the
objective is to compensate for the cost overhead caused by arithmetic with
power series in multiple double precision. The application of Newton's method
for this problem requires the evaluation and differentiation of polynomials,
followed by solving a blocked lower triangular linear system. Experimental
results are obtained on NVIDIA GPUs, in particular the RTX 2080, P100 and V100.
  Code generated by the CAMPARY software is used to obtain results in double
double, quad double, and octo double precision. The programs in this study are
self contained, available in a public github repository under the GPL-v3.0
License.
",['\nJan Verschelde\n'],,,http://arxiv.org/abs/2301.12659v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA', 'math.AG']",,,[]
"DarSIA: An open-source Python toolbox for two-scale image processing of
  dynamics in porous media",http://arxiv.org/abs/2301.05455v1,2023-01-13T09:48:36Z,2023-01-13T09:48:36Z,"  Understanding porous media flow is inherently a multi-scale challenge, where
at the core lies the aggregation of pore-level processes to a continuum, or
Darcy-scale, description. This challenge is directly mirrored in image
processing, where grains and interfaces may be clearly visible, yet continuous
parameters are desirable to measure. Classical image processing is poorly
adapted to this setting, as most techniques do not explicitly utilize the fact
that the image contains explicit physical processes.
  Here, we adapt classical image processing concepts to what we define as
physical images of porous materials and processes within them. This is realized
through the development of a new open-source image analysis toolbox
specifically adapted to time-series of images of porous materials.
","['\nJan Martin Nordbotten\n', '\nBenyamine Benali\n', '\nJakub Wiktor Both\n', '\nBergit Brattekås\n', '\nErlend Storvik\n', '\nMartin A. Fernø\n']",,,http://arxiv.org/abs/2301.05455v1,cs.MS,['cs.MS'],,,[]
"PyOED: An Extensible Suite for Data Assimilation and Model-Constrained
  Optimal Design of Experiments",http://arxiv.org/abs/2301.08336v3,2023-01-19T21:51:58Z,2023-12-19T18:40:53Z,"  This paper describes PyOED, a highly extensible scientific package that
enables developing and testing model-constrained optimal experimental design
(OED) for inverse problems. Specifically, PyOED aims to be a comprehensive
Python toolkit for model-constrained OED. The package targets scientists and
researchers interested in understanding the details of OED formulations and
approaches. It is also meant to enable researchers to experiment with standard
and innovative OED technologies with a wide range of test problems (e.g.,
simulation models). OED, inverse problems (e.g., Bayesian inversion), and data
assimilation (DA) are closely related research fields, and their formulations
overlap significantly. Thus, PyOED is continuously being expanded with a
plethora of Bayesian inversion, DA, and OED methods as well as new scientific
simulation models, observation error models, and observation operators. These
pieces are added such that they can be permuted to enable testing OED methods
in various settings of varying complexities. The PyOED core is completely
written in Python and utilizes the inherent object-oriented capabilities;
however, the current version of PyOED is meant to be extensible rather than
scalable. Specifically, PyOED is developed to enable rapid development and
benchmarking of OED methods with minimal coding effort and to maximize code
reutilization. This paper provides a brief description of the PyOED layout and
philosophy and provides a set of exemplary test cases and tutorials to
demonstrate the potential of the package.
","['\nAbhijit Chowdhary\n', '\nShady E. Ahmed\n', '\nAhmed Attia\n']","22 pages, 8 figures",,http://arxiv.org/abs/2301.08336v3,cs.MS,"['cs.MS', '68Vxx']",,,[]
Parallel two-stage reduction to Hessenberg-triangular form,http://arxiv.org/abs/2301.07964v1,2023-01-19T09:40:15Z,2023-01-19T09:40:15Z,"  We present a two-stage algorithm for the parallel reduction of a pencil to
Hessenberg-triangular form. Traditionally, two-stage Hessenberg-triangular
reduction algorithms achieve high performance in the first stage, but struggle
to achieve high performance in the second stage. Our algorithm extends
techniques described by Karlsson et al. to also achieve high performance in the
second stage. Experiments in a shared memory environment demonstrate that the
algorithm can outperform state-of-the-art implementations.
","['\nThijs Steel\n', '\nRaf Vandebril\n']","19 pages, 11 figures",,http://arxiv.org/abs/2301.07964v1,cs.DC,"['cs.DC', 'cs.MS', '65F15, 65Y05']",,,[]
"Multi-output multilevel best linear unbiased estimators via semidefinite
  programming",http://arxiv.org/abs/2301.07831v2,2023-01-19T00:21:01Z,2023-05-15T21:31:11Z,"  Multifidelity forward uncertainty quantification (UQ) problems often involve
multiple quantities of interest and heterogeneous models (e.g., different
grids, equations, dimensions, physics, surrogate and reduced-order models).
While computational efficiency is key in this context, multi-output strategies
in multilevel/multifidelity methods are either sub-optimal or non-existent. In
this paper we extend multilevel best linear unbiased estimators (MLBLUE) to
multi-output forward UQ problems and we present new semidefinite programming
formulations for their optimal setup. Not only do these formulations yield the
optimal number of samples required, but also the optimal selection of
low-fidelity models to use. While existing MLBLUE approaches are single-output
only and require a non-trivial nonlinear optimization procedure, the new
multi-output formulations can be solved reliably and efficiently. We
demonstrate the efficacy of the new methods and formulations in practical UQ
problems with model heterogeneity.
","['\nM. Croci\n', '\nK. E. Willcox\n', '\nS. J. Wright\n']","22 pages, 5 figures, 3 tables",,http://dx.doi.org/10.1016/j.cma.2023.116130,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'stat.CO']",10.1016/j.cma.2023.116130,,[]
Implementation of hyperbolic complex numbers in Julia language,http://arxiv.org/abs/2301.01707v1,2023-01-04T17:10:39Z,2023-01-04T17:10:39Z,"  Background: Hyperbolic complex numbers are used in the description of
hyperbolic spaces. One of the well-known examples of such spaces is the
Minkowski space, which plays a leading role in the problems of the special
theory of relativity and electrodynamics. However, such numbers are not very
common in different programming languages. Purpose: Of interest is the
implementation of hyperbolic complex in scientific programming languages, in
particular, in the Julia language. Methods: The Julia language is based on the
concept of multiple dispatch. This concept is an extension of the concept of
polymorphism for object-oriented programming languages. To implement hyperbolic
complex numbers, the multiple dispatching approach of the Julia language was
used. Results: The result is a library that implements hyperbolic numbers.
Conclusions: Based on the results of the study, we can conclude that the
concept of multiple dispatching in scientific programming languages is
convenient and natural.
","['\nAnna V. Korolkova\n', '\nMigran N. Gevorkyan\n', '\nDmitry S. Kulyabov\n']",in English; in Russian,,http://dx.doi.org/10.22363/2658-4670-2022-30-4-318-329,cs.MS,['cs.MS'],10.22363/2658-4670-2022-30-4-318-329,,[]
"An Automatic Method for Generating Symbolic Expressions of Zernike
  Circular Polynomials",http://arxiv.org/abs/2301.01859v3,2023-01-05T00:33:55Z,2023-06-19T14:55:29Z,"  Zernike circular polynomials (ZCP) play a significant role in optics
engineering. The symbolic expressions for ZCP are valuable for theoretic
analysis and engineering designs. However, there are still two problems which
remain open: firstly, there is a lack of sufficient mathematical formulas of
the ZCP for optics designers; secondly the formulas for inter-conversion of
Noll's single index and Born-Wolf's double indices of ZCP are neither uniquely
determinate nor satisfactory. An automatic method for generating symbolic
expressions for ZCP is proposed based on five essential factors: the new
theorems for converting the single/double indices of the ZCP, the robust and
effective numeric algorithms for computing key parameters of ZCP, the symbolic
algorithms for generating mathematical expressions of ZCP, and meta-programming
\& \LaTeX{} programming for generating the table of ZCP. The theorems, method,
algorithms and system architecture proposed are beneficial to both optics
design process, optics software, computer-output typesetting in publishing
industry as well as STEM education.
","['\nHong-Yan Zhang\n', '\nYu Zhou\n', '\nFu-Yun Li\n']","This paper has proposed a method for creating mathematical table as
  demonstrated by generating Zenike circular polynomials. The code is available
  on GitHub site, please see:
  https://github.com/GrAbsRD/ZernikeSymbolicExpression","Hong-Yan zhang, Yu Zhou and Fu-Yun Li. ""An Automatic Method for
  Generating Symbolic Expressions of Zernike Circular Polynomials"", IEEE
  Access, 2023, Vol. 11, No. 6, pp: 56481--56493",http://dx.doi.org/10.1109/ACCESS.2023.3283028,cs.SC,"['cs.SC', 'cs.MS']",10.1109/ACCESS.2023.3283028,,[]
Smooth forecasting with the smooth package in R,http://arxiv.org/abs/2301.01790v1,2023-01-04T19:12:38Z,2023-01-04T19:12:38Z,"  There are many forecasting related packages in R with varied popularity, the
most famous of all being \texttt{forecast}, which implements several important
forecasting approaches, such as ARIMA, ETS, TBATS and others. However, the main
issue with the existing functionality is the lack of flexibility for research
purposes, when it comes to modifying the implemented models. The R package
\texttt{smooth} introduces a new approach to univariate forecasting,
implementing ETS and ARIMA models in Single Source of Error (SSOE) state space
form and implementing an advanced functionality for experiments and time series
analysis. It builds upon the SSOE model and extends it by including explanatory
variables, multiple frequencies, and introducing advanced forecasting
instruments. In this paper, we explain the philosophy behind the package and
show how the main functions work.
",['\nIvan Svetunkov\n'],"20 pages, 5 figures, 1 table",,http://arxiv.org/abs/2301.01790v1,stat.ME,"['stat.ME', 'cs.MS', 'stat.AP', 'G.3']",,,[]
Reverse-Mode Automatic Differentiation of Compiled Programs,http://arxiv.org/abs/2212.13760v1,2022-12-28T09:27:02Z,2022-12-28T09:27:02Z,"  Tools for algorithmic differentiation (AD) provide accurate derivatives of
computer-implemented functions for use in, e. g., optimization and machine
learning (ML). However, they often require the source code of the function to
be available in a restricted set of programming languages. As a step towards
making AD accessible for code bases with cross-language or closed-source
components, we recently presented the forward-mode AD tool Derivgrind. It
inserts forward-mode AD logic into the machine code of a compiled program using
the Valgrind dynamic binary instrumentation framework. This work extends
Derivgrind, adding the capability to record the real-arithmetic evaluation
tree, and thus enabling operator overloading style reverse-mode AD for compiled
programs. We maintain the high level of correctness reported for Derivgrind's
forward mode, failing the same few testcases in an extensive test suite for the
same well-understood reasons. Runtime-wise, the recording slows down the
execution of a compiled 64-bit benchmark program by a factor of about 180.
","['\nMax Aehle\n', '\nJohannes Blühdorn\n', '\nMax Sagebaum\n', '\nNicolas R. Gauger\n']","17 pages, 5 figures, 1 listing",,http://arxiv.org/abs/2212.13760v1,cs.MS,['cs.MS'],,,[]
"Exploring the Versal AI engines for accelerating stencil-based
  atmospheric advection simulation",http://arxiv.org/abs/2301.13016v1,2022-12-28T17:28:24Z,2022-12-28T17:28:24Z,"  AMD Xilinx's new Versal Adaptive Compute Acceleration Platform (ACAP) is an
FPGA architecture combining reconfigurable fabric with other on-chip hardened
compute resources. AI engines are one of these and, by operating in a highly
vectorized manner, they provide significant raw compute that is potentially
beneficial for a range of workloads including HPC simulation. However, this
technology is still early-on, and as yet unproven for accelerating HPC codes,
with a lack of benchmarking and best practice.
  This paper presents an experience report, exploring porting of the Piacsek
and Williams (PW) advection scheme onto the Versal ACAP, using the chip's AI
engines to accelerate the compute. A stencil-based algorithm, advection is
commonplace in atmospheric modelling, including several Met Office codes who
initially developed this scheme. Using this algorithm as a vehicle, we explore
optimal approaches for structuring AI engine compute kernels and how best to
interface the AI engines with programmable logic. Evaluating performance using
a VCK5000 against non-AI engine FPGA configurations on the VCK5000 and Alveo
U280, as well as a 24-core Xeon Platinum Cascade Lake CPU and Nvidia V100 GPU,
we found that whilst the number of channels between the fabric and AI engines
are a limitation, by leveraging the ACAP we can double performance compared to
an Alveo U280.
",['\nNick Brown\n'],"Accepted version of paper appearing in the 2023 ACM/SIGDA
  International Symposium on Field Programmable Gate Arrays (FPGA '23),
  February 12--14, 2023, Monterey, CA, US",,http://dx.doi.org/10.1145/3543622.3573047,cs.DC,"['cs.DC', 'cs.MS']",10.1145/3543622.3573047,,[]
"Fast and energy-efficient derivatives risk analysis: Streaming option
  Greeks on Xilinx and Intel FPGAs",http://arxiv.org/abs/2212.13977v2,2022-12-28T17:51:54Z,2024-02-02T12:29:47Z,"  Whilst FPGAs have enjoyed success in accelerating high-frequency financial
workloads for some time, their use for quantitative finance, which is the use
of mathematical models to analyse financial markets and securities, has been
far more limited to-date. Currently, CPUs are the most common architecture for
such workloads, and an important question is whether FPGAs can ameliorate some
of the bottlenecks encountered on those architectures. In this paper we extend
our previous work accelerating the industry standard Securities Technology
Analysis Center's (STAC\textregistered) derivatives risk analysis benchmark
STAC-A2\texttrademark{}, by first porting this from our previous Xilinx
implementation to an Intel Stratix-10 FPGA, exploring the challenges
encountered when moving from one FPGA architecture to another and suitability
of techniques. We then present a host-data-streaming approach that ultimately
outperforms our previous version on a Xilinx Alveo U280 FPGA by up to 4.6 times
and requiring 9 times less energy at the largest problem size, while
outperforming the CPU and GPU versions by up to 8.2 and 5.2 times respectively.
The result of this work is a significant enhancement in FPGA performance
against the previous version for this industry standard benchmark running on
both Xilinx and Intel FPGAs, and furthermore an exploration of optimisation and
porting techniques that can be applied to other HPC workloads.
","['\nMark Klaisoongnoen\n', '\nNick Brown\n', '\nOliver Brown\n']","This work uses a benchmark of STAC, whilst this was approved at the
  time they have asked we remove the paper as it needs to be made more explicit
  that these are unofficial ports and are entirely independent from any vendor
  and don't follow STAC rules. As we are comparing vendor hardware in the
  paper, it was felt that this could easily be mistaken to be representing
  something that the paper is not",,http://dx.doi.org/10.1109/H2RC56700.2022.00008,cs.DC,"['cs.DC', 'cs.AR', 'cs.MS']",10.1109/H2RC56700.2022.00008,,[]
"ADEV: Sound Automatic Differentiation of Expected Values of
  Probabilistic Programs",http://arxiv.org/abs/2212.06386v1,2022-12-13T05:54:22Z,2022-12-13T05:54:22Z,"  Optimizing the expected values of probabilistic processes is a central
problem in computer science and its applications, arising in fields ranging
from artificial intelligence to operations research to statistical computing.
Unfortunately, automatic differentiation techniques developed for deterministic
programs do not in general compute the correct gradients needed for widely used
solutions based on gradient-based optimization.
  In this paper, we present ADEV, an extension to forward-mode AD that
correctly differentiates the expectations of probabilistic processes
represented as programs that make random choices. Our algorithm is a
source-to-source program transformation on an expressive, higher-order language
for probabilistic computation, with both discrete and continuous probability
distributions. The result of our transformation is a new probabilistic program,
whose expected return value is the derivative of the original program's
expectation. This output program can be run to generate unbiased Monte Carlo
estimates of the desired gradient, which can then be used within the inner loop
of stochastic gradient descent. We prove ADEV correct using logical relations
over the denotations of the source and target probabilistic programs. Because
it modularly extends forward-mode AD, our algorithm lends itself to a concise
implementation strategy, which we exploit to develop a prototype in just a few
dozen lines of Haskell (https://github.com/probcomp/adev).
","['\nAlexander K. Lew\n', '\nMathieu Huot\n', '\nSam Staton\n', '\nVikash K. Mansinghka\n']",to appear at POPL 2023,POPL 2023,http://dx.doi.org/10.1145/3571198,cs.PL,"['cs.PL', 'cs.MS', 'stat.CO']",10.1145/3571198,,[]
"Efficient and Sound Differentiable Programming in a Functional
  Array-Processing Language",http://arxiv.org/abs/2212.10307v1,2022-12-20T14:54:47Z,2022-12-20T14:54:47Z,"  Automatic differentiation (AD) is a technique for computing the derivative of
a function represented by a program. This technique is considered as the
de-facto standard for computing the differentiation in many machine learning
and optimisation software tools. Despite the practicality of this technique,
the performance of the differentiated programs, especially for functional
languages and in the presence of vectors, is suboptimal. We present an AD
system for a higher-order functional array-processing language. The core
functional language underlying this system simultaneously supports both
source-to-source forward-mode AD and global optimisations such as loop
transformations. In combination, gradient computation with forward-mode AD can
be as efficient as reverse mode, and the Jacobian matrices required for
numerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be
efficiently computed.
","['\nAmir Shaikhha\n', '\nMathieu Huot\n', '\nShabnam Ghasemirad\n', '\nAndrew Fitzgibbon\n', '\nSimon Peyton Jones\n', '\nDimitrios Vytiniotis\n']",arXiv admin note: substantial text overlap with arXiv:1806.02136,,http://arxiv.org/abs/2212.10307v1,cs.PL,"['cs.PL', 'cs.LG', 'cs.MS']",,,[]
"Scalable Recovery-based Adaptation on Quadtree Meshes for
  Advection-Diffusion-Reaction Problems",http://arxiv.org/abs/2212.05945v1,2022-12-12T14:57:02Z,2022-12-12T14:57:02Z,"  We propose a mesh adaptation procedure for Cartesian quadtree meshes, to
discretize scalar advection-diffusion-reaction problems. The adaptation process
is driven by a recovery-based a posteriori estimator for the $L^2(\Omega)$-norm
of the discretization error, based on suitable higher order approximations of
both the solution and the associated gradient. In particular, a metric-based
approach exploits the information furnished by the estimator to iteratively
predict the new adapted mesh. The new mesh adaptation algorithm is successfully
assessed on different configurations, and turns out to perform well also when
dealing with discontinuities in the data as well as in the presence of internal
layers not aligned with the Cartesian directions. A cross-comparison with a
standard estimate--mark--refine approach and with other adaptive strategies
available in the literature shows the remarkable accuracy and parallel
scalability of the proposed approach.
","['\nPasquale Claudio Africa\n', '\nSimona Perotto\n', '\nCarlo de Falco\n']",,,http://arxiv.org/abs/2212.05945v1,math.NA,"['math.NA', 'cs.DC', 'cs.DS', 'cs.MS', 'cs.NA']",,,[]
Parallelism detection using graph labelling,http://arxiv.org/abs/2212.04818v1,2022-12-09T12:46:24Z,2022-12-09T12:46:24Z,"  Usage of multiprocessor and multicore computers implies parallel programming.
Tools for preparing parallel programs include parallel languages and libraries
as well as parallelizing compilers and convertors that can perform automatic
parallelization. The basic approach for parallelism detection is analysis of
data dependencies and properties of program components, including data use and
predicates. In this article a suite of used data and predicates sets for
program components is proposed and an algorithm for computing these sets is
suggested. The algorithm is based on wave propagation on graphs with cycles and
labelling. This method allows analyzing complex program components, improving
data localization and thus providing enhanced data parallelism detection.
","['\nPavel Telegin\n', '\nAnton Baranov\n', '\nBoris Shabanov\n', '\nArtem Tikhomirov\n']",,,http://arxiv.org/abs/2212.04818v1,cs.MS,"['cs.MS', '68W10', 'D.1.3']",,,[]
"JAX-FEM: A differentiable GPU-accelerated 3D finite element solver for
  automatic inverse design and mechanistic data science",http://arxiv.org/abs/2212.00964v1,2022-12-02T04:39:14Z,2022-12-02T04:39:14Z,"  This paper introduces JAX-FEM, an open-source differentiable finite element
method (FEM) library. Constructed on top of Google JAX, a rising machine
learning library focusing on high-performance numerical computing, JAX-FEM is
implemented with pure Python while scalable to efficiently solve problems with
moderate to large sizes. For example, in a 3D tensile loading problem with 7.7
million degrees of freedom, JAX-FEM with GPU achieves around 10$\times$
acceleration compared to a commercial FEM code depending on platform. Beyond
efficiently solving forward problems, JAX-FEM employs the automatic
differentiation technique so that inverse problems are solved in a fully
automatic manner without the need to manually derive sensitivities. Examples of
3D topology optimization of nonlinear materials are shown to achieve optimal
compliance. Finally, JAX-FEM is an integrated platform for machine
learning-aided computational mechanics. We show an example of data-driven
multi-scale computations of a composite material where JAX-FEM provides an
all-in-one solution from microscopic data generation and model training to
macroscopic FE computations. The source code of the library and these examples
are shared with the community to facilitate computational mechanics research.
","['\nTianju Xue\n', '\nShuheng Liao\n', '\nZhengtao Gan\n', '\nChanwook Park\n', '\nXiaoyu Xie\n', '\nWing Kam Liu\n', '\nJian Cao\n']",,,http://dx.doi.org/10.1016/j.cpc.2023.108802,cs.MS,"['cs.MS', 'cs.CE']",10.1016/j.cpc.2023.108802,,[]
CDOpt: A Python Package for a Class of Riemannian Optimization,http://arxiv.org/abs/2212.02698v2,2022-12-06T01:43:29Z,2023-03-28T09:53:19Z,"  Optimization over the embedded submanifold defined by constraints $c(x) = 0$
has attracted much interest over the past few decades due to its wide
applications in various areas. Plenty of related optimization packages have
been developed based on Riemannian optimization approaches, which rely on some
basic geometrical materials of Riemannian manifolds, including retractions,
vector transports, etc. These geometrical materials can be challenging to
determine in general. Existing packages only accommodate a few well-known
manifolds whose geometrical materials are easily accessible. For other
manifolds which are not contained in these packages, the users have to develop
the geometric materials by themselves. In addition, it is not always tractable
to adopt advanced features from various state-of-the-art unconstrained
optimization solvers to Riemannian optimization approaches.
  We introduce CDOpt (available at https://cdopt.github.io/), a user-friendly
Python package for a class Riemannian optimization. Based on constraint
dissolving approaches, Riemannian optimization problems are transformed into
their equivalent unconstrained counterparts in CDOpt. Therefore, solving
Riemannian optimization problems through CDOpt directly benefits from various
existing solvers and the rich expertise gained over decades for unconstrained
optimization. Moreover, all the computations in CDOpt related to any manifold
in question are conducted on its constraints expression, hence users can easily
define new manifolds in CDOpt without any background on differential geometry.
Furthermore, CDOpt extends the neural layers from PyTorch and Flax, thus allows
users to train manifold constrained neural networks directly by the solvers for
unconstrained optimization. Extensive numerical experiments demonstrate that
CDOpt is highly efficient and robust in solving various classes of Riemannian
optimization problems.
","['\nNachuan Xiao\n', '\nXiaoyin Hu\n', '\nXin Liu\n', '\nKim-Chuan Toh\n']",31 pages,,http://arxiv.org/abs/2212.02698v2,math.OC,"['math.OC', 'cs.MS']",,,[]
Parametric information geometry with the package Geomstats,http://arxiv.org/abs/2211.11643v1,2022-11-21T16:56:45Z,2022-11-21T16:56:45Z,"  We introduce the information geometry module of the Python package Geomstats.
The module first implements Fisher-Rao Riemannian manifolds of widely used
parametric families of probability distributions, such as normal, gamma, beta,
Dirichlet distributions, and more. The module further gives the Fisher-Rao
Riemannian geometry of any parametric family of distributions of interest,
given a parameterized probability density function as input. The implemented
Riemannian geometry tools allow users to compare, average, interpolate between
distributions inside a given family. Importantly, such capabilities open the
door to statistics and machine learning on probability distributions. We
present the object-oriented implementation of the module along with
illustrative examples and show how it can be used to perform learning on
manifolds of parametric probability distributions.
","['\nAlice Le Brigant\n', '\nJules Deschamps\n', '\nAntoine Collas\n', '\nNina Miolane\n']",,,http://arxiv.org/abs/2211.11643v1,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"A framework for structural shape optimization based on automatic
  differentiation, the adjoint method and accelerated linear algebra",http://arxiv.org/abs/2211.15409v1,2022-11-23T21:42:43Z,2022-11-23T21:42:43Z,"  Shape optimization is of great significance in structural engineering, as an
efficient geometry leads to better performance of structures. However, the
application of gradient-based shape optimization for structural and
architectural design is limited, which is partly due to the difficulty and the
complexity in gradient evaluation. In this work, an efficient framework based
on automatic differentiation (AD), the adjoint method and accelerated linear
algebra (XLA) is proposed to promote the implementation of gradient-based shape
optimization. The framework is realized by the implementation of the
high-performance computing (HPC) library JAX. We leverage AD for gradient
evaluation in the sensitivity analysis stage. Compared to numerical
differentiation, AD is more accurate; compared to analytical and symbolic
differentiation, AD is more efficient and easier to apply. In addition, the
adjoint method is used to reduce the complexity of computation of the
sensitivity. The XLA feature is exploited by an efficient programming
architecture that we proposed, which can boost gradient evaluation. The
proposed framework also supports hardware acceleration such as GPUs. The
framework is applied to the form finding of arches and different free-form
gridshells: gridshell inspired by Mannheim Multihalle, four-point supported
gridshell, and canopy-like structures. Two geometric descriptive methods are
used: non-parametric and parametric description via B\'ezier surface.
Non-constrained and constrained shape optimization problems are considered,
where the former is solved by gradient descent and the latter is solved by
sequential quadratic programming (SQP). Through these examples, the proposed
framework is shown to be able to provide structural engineers with a more
efficient tool for shape optimization, enabling better design for the built
environment.
",['\nGaoyuan Wu\n'],,"Struct Multidisc Optim 66, 151 (2023)",http://dx.doi.org/10.1007/s00158-023-03601-0,cs.MS,"['cs.MS', 'cs.CE', 'math.OC']",10.1007/s00158-023-03601-0,,[]
"Development of an Equation-based Parallelization Method for Multiphase
  Particle-in-Cell Simulations",http://arxiv.org/abs/2211.15605v1,2022-11-28T18:02:06Z,2022-11-28T18:02:06Z,"  Manufacturers have been developing new graphics processing unit (GPU) nodes
with large capacity, high bandwidth memory and very high bandwidth intra-node
interconnects. This enables moving large amounts of data between GPUs on the
same node at low cost. However, small packet bandwidths and latencies have not
decreased which makes global dot products expensive. These characteristics
favor a new kind of problem decomposition called ""equation decomposition""
rather than traditional domain decomposition. In this approach, each GPU is
assigned one equation set to solve in parallel so that the frequent and
expensive dot product synchronization points in traditional distributed linear
solvers are eliminated. In exchange, the method involves infrequent movement of
state variables over the high bandwidth, intra-node interconnects. To test this
theory, our flagship code Multiphase Flow with Interphase eXchanges (MFiX) was
ported to TensorFlow. This new product is known as MFiX-AI and can produce near
identical results to the original version of MFiX with significant acceleration
in multiphase particle-in-cell (MP-PIC) simulations. The performance of a
single node with 4 NVIDIA A100s connected over NVLINK 2.0 was shown to be
competitive to 1000 CPU cores (25 nodes) on the JOULE 2.0 supercomputer,
leading to an energy savings of up to 90%. This is a substantial performance
benefit for small- to intermediate-sized problems. This benefit is expected to
grow as GPU nodes become more powerful. Further, MFiX-AI is poised to accept
native artificial intelligence/machine learning models for further acceleration
and development.
","['\nMino Woo\n', '\nTerry Jordan\n', '\nTarak Nandi\n', '\nJean Francois Dietiker\n', '\nChristopher Guenther\n', '\nDirk Van Essendelft\n']","28 pages, 11 figures",,http://arxiv.org/abs/2211.15605v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.SE']",,,[]
TorchOpt: An Efficient Library for Differentiable Optimization,http://arxiv.org/abs/2211.06934v1,2022-11-13T15:59:17Z,2022-11-13T15:59:17Z,"  Recent years have witnessed the booming of various differentiable
optimization algorithms. These algorithms exhibit different execution patterns,
and their execution needs massive computational resources that go beyond a
single CPU and GPU. Existing differentiable optimization libraries, however,
cannot support efficient algorithm development and multi-CPU/GPU execution,
making the development of differentiable optimization algorithms often
cumbersome and expensive. This paper introduces TorchOpt, a PyTorch-based
efficient library for differentiable optimization. TorchOpt provides a unified
and expressive differentiable optimization programming abstraction. This
abstraction allows users to efficiently declare and analyze various
differentiable optimization programs with explicit gradients, implicit
gradients, and zero-order gradients. TorchOpt further provides a
high-performance distributed execution runtime. This runtime can fully
parallelize computation-intensive differentiation operations (e.g. tensor tree
flattening) on CPUs / GPUs and automatically distribute computation to
distributed devices. Experimental results show that TorchOpt achieves
$5.2\times$ training time speedup on an 8-GPU server. TorchOpt is available at:
https://github.com/metaopt/torchopt/.
","['\nJie Ren\n', '\nXidong Feng\n', '\nBo Liu\n', '\nXuehai Pan\n', '\nYao Fu\n', '\nLuo Mai\n', '\nYaodong Yang\n']",NeurIPS 2022 OPT Workshop,,http://arxiv.org/abs/2211.06934v1,cs.MS,"['cs.MS', 'cs.AI', 'cs.DC', 'cs.LG', 'math.OC']",,,[]
IM: An R-Package for Computation of Image Moments and Moment Invariants,http://arxiv.org/abs/2210.16485v1,2022-10-29T03:54:37Z,2022-10-29T03:54:37Z,"  Moment invariants are well-established and effective shape descriptors for
image classification. In this report, we introduce a package for R-language,
named IM, that implements the calculation of moments for images and allows the
reconstruction of images from moments within an object-oriented framework.
Several types of moments may be computed using the IM library, including
discrete and continuous Chebyshev, Gegenbauer, Legendre, Krawtchouk, dual Hahn,
generalized pseudo-Zernike, Fourier-Mellin, and radial harmonic Fourier
moments. In addition, custom bivariate types of moments can be calculated using
combinations of two different types of polynomials. A method of polar
transformation of pixel coordinates is used to provide an approximate
invariance to rotation for moments that are orthogonal over a rectangle. The
different types of polynomials used to calculate moments are discussed in this
report, as well as comparisons of reconstruction and running time. Examples of
image classification using image moments are provided.
","['\nAllison Irvine\n', '\nTan Dang\n', '\nM. Murat Dundar\n', '\nBartek Rajwa\n']","Apr 2014, technical report",,http://arxiv.org/abs/2210.16485v1,cs.CV,"['cs.CV', 'cs.MS', 'I.4.7']",,,[]
"Exploiting Kronecker structure in exponential integrators: fast
  approximation of the action of $\varphi$-functions of matrices via quadrature",http://arxiv.org/abs/2211.00696v1,2022-11-01T18:40:50Z,2022-11-01T18:40:50Z,"  In this article, we propose an algorithm for approximating the action of
$\varphi-$functions of matrices against vectors, which is a key operation in
exponential time integrators. In particular, we consider matrices with
Kronecker sum structure, which arise from problems admitting a tensor product
representation. The method is based on quadrature approximations of the
integral form of the $\varphi-$functions combined with a scaling and modified
squaring method. Owing to the Kronecker sum representation, only actions of 1D
matrix exponentials are needed at each quadrature node and assembly of the full
matrix can be avoided. Additionally, we derive \emph{a priori} bounds for the
quadrature error, which show that, as expected by classical theory, the rate of
convergence of our method is supergeometric. Guided by our analysis, we
construct a fast and robust method for estimating the optimal scaling factor
and number of quadrature nodes that minimizes the total cost for a prescribed
error tolerance. We investigate the performance of our algorithm by solving
several linear and semilinear time-dependent problems in 2D and 3D. The results
show that our method is accurate and orders of magnitude faster than the
current state-of-the-art.
","['\nMatteo Croci\n', '\nJudit Muñoz-Matute\n']","20 pages, 3 figures, 7 tables",,http://arxiv.org/abs/2211.00696v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
scikit-fda: A Python Package for Functional Data Analysis,http://arxiv.org/abs/2211.02566v2,2022-11-04T16:34:03Z,2023-06-22T06:49:33Z,"  The library scikit-fda is a Python package for Functional Data Analysis
(FDA). It provides a comprehensive set of tools for representation,
preprocessing, and exploratory analysis of functional data. The library is
built upon and integrated in Python's scientific ecosystem. In particular, it
conforms to the scikit-learn application programming interface so as to take
advantage of the functionality for machine learning provided by this package:
pipelines, model selection, and hyperparameter tuning, among others. The
scikit-fda package has been released as free and open-source software under a
3-Clause BSD license and is open to contributions from the FDA community. The
library's extensive documentation includes step-by-step tutorials and detailed
examples of use.
","['\nCarlos Ramos-Carreño\n', '\nJosé Luis Torrecilla\n', '\nMiguel Carbajo-Berrocal\n', '\nPablo Marcos\n', '\nAlberto Suárez\n']",,,http://arxiv.org/abs/2211.02566v2,stat.CO,"['stat.CO', 'cs.LG', 'cs.MS', 'stat.ML']",,,[]
"Advanced Automatic Code Generation for Multiple Relaxation-Time Lattice
  Boltzmann Methods",http://arxiv.org/abs/2211.02435v1,2022-11-04T13:20:19Z,2022-11-04T13:20:19Z,"  The scientific code generation package lbmpy supports the automated design
and the efficient implementation of lattice Boltzmann methods (LBMs) through
metaprogramming. It is based on a new, concise calculus for describing multiple
relaxation-time LBMs, including techniques that enable the numerically
advantageous subtraction of the constant background component from the
populations. These techniques are generalized to a wide range of collision
spaces and equilibrium distributions. The article contains an overview of
lbmpy's front-end and its code generation pipeline, which implements the new
LBM calculus by means of symbolic formula manipulation tools and
object-oriented programming. The generated codes have only a minimal number of
arithmetic operations. Their automatic derivation rests on two novel Chimera
transforms that have been specifically developed for efficiently computing raw
and central moments. Information contained in the symbolic representation of
the methods is further exploited in a customized sequence of algebraic
simplifications, further reducing computational cost. When combined, these
algebraic transformations lead to concise and compact numerical kernels.
Specifically, with these optimizations, the advanced central moment- and
cumulant-based methods can be realized with only little additional cost as when
compared with the simple BGK method. The effectiveness and flexibility of the
new lbmpy code generation system is demonstrated in simulating Taylor-Green
vortex decay and the automatic derivation of an LBM algorithm to solve the
shallow water equations.
","['\nFrederik Hennig\n', '\nMarkus Holzer\n', '\nUlrich Rüde\n']","23 pages, 6 figures",,http://dx.doi.org/10.1137/22M1531348,cs.MS,"['cs.MS', 'cs.CE', 'cs.NA', 'math.NA', 'physics.comp-ph']",10.1137/22M1531348,,[]
"Development of information system suited for statistical analysis of
  global brands distributions",http://arxiv.org/abs/2210.11409v1,2022-10-19T10:24:17Z,2022-10-19T10:24:17Z,"  This qualification work studies methods of statistical analysis of global
brands distributions and development process of information system which is
represented by computer program. Algorithm of estimation of correspondance to
distribution laws was shown. Correspondance of datasets (3) to Pareto Law and
Zipf's Law were defined.
  Key words: analysis, method, distribution, data, function, statistics,
solution, program.
",['\nVladyslav Solohub\n'],"40 pages, in Ukranian language, 24 figures. Specialty 122 Computer
  science. Vasyl' Stus Donetsk National University, Vinnytsia, 2022",,http://arxiv.org/abs/2210.11409v1,stat.AP,"['stat.AP', 'cs.MS']",,,[]
Redistributor: Transforming Empirical Data Distributions,http://arxiv.org/abs/2210.14219v1,2022-10-25T17:59:03Z,2022-10-25T17:59:03Z,"  We present an algorithm and package, Redistributor, which forces a collection
of scalar samples to follow a desired distribution. When given independent and
identically distributed samples of some random variable $S$ and the continuous
cumulative distribution function of some desired target $T$, it provably
produces a consistent estimator of the transformation $R$ which satisfies
$R(S)=T$ in distribution. As the distribution of $S$ or $T$ may be unknown, we
also include algorithms for efficiently estimating these distributions from
samples. This allows for various interesting use cases in image processing,
where Redistributor serves as a remarkably simple and easy-to-use tool that is
capable of producing visually appealing results. The package is implemented in
Python and is optimized to efficiently handle large data sets, making it also
suitable as a preprocessing step in machine learning. The source code is
available at https://gitlab.com/paloha/redistributor.
","['\nPavol Harar\n', '\nDennis Elbrächter\n', '\nMonika Dörfler\n', '\nKory D. Johnson\n']","19 pages, 8 figures",,http://arxiv.org/abs/2210.14219v1,cs.CV,"['cs.CV', 'cs.MS']",,,[]
Mapping Out the HPC Dependency Chaos,http://arxiv.org/abs/2211.05118v2,2022-10-22T20:50:10Z,2022-11-11T02:35:48Z,"  High Performance Computing~(HPC) software stacks have become complex, with
the dependencies of some applications numbering in the hundreds. Packaging,
distributing, and administering software stacks of that scale is a complex
undertaking anywhere. HPC systems deal with esoteric compilers, hardware, and a
panoply of uncommon combinations. In this paper, we explore the mechanisms
available for packaging software to find its own dependencies in the context of
a taxonomy of software distribution, and discuss their benefits and pitfalls.
We discuss workarounds for some common problems caused by using these composed
stacks and introduce Shrinkwrap: A solution to producing binaries that directly
load their dependencies from precise locations and in a precise order. Beyond
simplifying the use of the binaries, this approach also speeds up loading as
much as 7x for a large dynamically-linked MPI application in our evaluation.
","['\nFarid Zakaria\n', '\nThomas R. W. Scogland\n', '\nTodd Gamblin\n', '\nCarlos Maltzahn\n']","Presented at SuperComputing 2022
  (https://sc22.supercomputing.org/program/)",,http://arxiv.org/abs/2211.05118v2,cs.SE,"['cs.SE', 'cs.MS']",,,[]
"End-to-end GPU acceleration of low-order-refined preconditioning for
  high-order finite element discretizations",http://arxiv.org/abs/2210.12253v1,2022-10-21T21:12:57Z,2022-10-21T21:12:57Z,"  In this paper, we present algorithms and implementations for the end-to-end
GPU acceleration of matrix-free low-order-refined preconditioning of high-order
finite element problems. The methods described here allow for the construction
of effective preconditioners for high-order problems with optimal memory usage
and computational complexity. The preconditioners are based on the construction
of a spectrally equivalent low-order discretization on a refined mesh, which is
then amenable to, for example, algebraic multigrid preconditioning. The
constants of equivalence are independent of mesh size and polynomial degree.
For vector finite element problems in $H({\rm curl})$ and $H({\rm div})$ (e.g.
for electromagnetic or radiation diffusion problems) a specially constructed
interpolation-histopolation basis is used to ensure fast convergence. Detailed
performance studies are carried out to analyze the efficiency of the GPU
algorithms. The kernel throughput of each of the main algorithmic components is
measured, and the strong and weak parallel scalability of the methods is
demonstrated. The different relative weighting and significance of the
algorithmic components on GPUs and CPUs is discussed. Results on problems
involving adaptively refined nonconforming meshes are shown, and the use of the
preconditioners on a large-scale magnetic diffusion problem using all spaces of
the finite element de Rham complex is illustrated.
","['\nWill Pazner\n', '\nTzanio Kolev\n', '\nJean-Sylvain Camier\n']","23 pages, 13 figures",,http://dx.doi.org/10.1177/10943420231175462,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1177/10943420231175462,,[]
Fast Evaluation of Real and Complex Polynomials,http://arxiv.org/abs/2211.06320v1,2022-10-20T06:35:25Z,2022-10-20T06:35:25Z,"  We propose an algorithm for quickly evaluating polynomials. It pre-conditions
a complex polynomial $P$ of degree $d$ in time $O(d\log d)$, with a low
multiplicative constant independent of the precision. Subsequent evaluations of
$P$ computed with a fixed precision of $p$ bits are performed in average
arithmetic complexity $O\big(\sqrt{d(p+\log d)}\big)$ and memory $O(dp)$. The
average complexity is computed with respect to points $z \in \mathbb{C}$,
weighted by the spherical area of $\overline{\mathbb{C}}$. The worst case does
not exceed the complexity of H{\""o}rner's scheme. In particular, our algorithm
performs asymptotically as $O(\sqrt{d\log d})$ per evaluation. For many classes
of polynomials, in particular those with random coefficients in a bounded
region of $\mathbb{C}$, or for sparse polynomials, our algorithm performs much
better than this upper bound, without any modification or parameterization.The
article contains a detailed analysis of the complexity and a full error
analysis, which guarantees that the algorithm performs as well as H\''orner's
scheme, only faster. Our algorithm is implemented in a companion library,
written in standard C and released as an open-source project [MV22].Our claims
regarding complexity and accuracy are confirmed in practice by a set of
comprehensive benchmarks.
","['\nRamona Anton\nIMJ-PRG\n', '\nNicolae Mihalache\nLAMA\n', '\nFrançois Vigneron\nLMR\n']",,,http://arxiv.org/abs/2211.06320v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.DS']",,,"['IMJ-PRG', 'LAMA', 'LMR']"
MOS: A Mathematical Optimization Service,http://arxiv.org/abs/2210.03813v1,2022-10-07T20:50:53Z,2022-10-07T20:50:53Z,"  We introduce MOS, a software application designed to facilitate the
deployment, integration, management, and analysis of mathematical optimization
models. MOS approaches mathematical optimization at a higher level of
abstraction than existing optimization modeling systems, enabling its use with
all of them. The sole requirement to harness MOS is a simple annotation of the
code specifying the formulation of an optimization model. With this, the model
becomes accessible to humans through the automatic generation of a user
interface, and to machines through an associated API and client libraries. All
this is achieved while avoiding the ad hoc code typically required to obtain
such features.
","['\nJames Hubert Merrick\n', '\nTomás Tinoco De Rubira\n']","7 pages, 4 figures",,http://arxiv.org/abs/2210.03813v1,math.OC,"['math.OC', 'cs.MS']",,,[]
Memory-Efficient Recursive Evaluation of 3-Center Gaussian Integrals,http://arxiv.org/abs/2210.03192v2,2022-10-06T20:16:36Z,2023-01-17T00:40:00Z,"  To improve the efficiency of Gaussian integral evaluation on modern
accelerated architectures FLOP-efficient Obara-Saika-based recursive evaluation
schemes are optimized for the memory footprint. For the 3-center 2-particle
integrals that are key for the evaluation of Coulomb and other 2-particle
interactions in the density-fitting approximation the use of multi-quantal
recurrences (in which multiple quanta are created or transferred at once) is
shown to produce significant memory savings. Other innovation include
leveraging register memory for reduced memory footprint and direct compile-time
generation of optimized kernels (instead of custom code generation) with
compile-time features of modern C++/CUDA. Performance of conventional and
CUDA-based implementations of the proposed schemes is illustrated for both the
individual batches of integrals involving up to Gaussians with low and high
angular momenta (up to $L=6$) and contraction degrees, as well as for the
density-fitting-based evaluation of the Coulomb potential. The computer
implementation is available in the open-source LibintX library.
","['\nAndrey Asadchev\n', '\nEdward F. Valeev\n']","37 pages, 2 figures, 6 tables",,http://arxiv.org/abs/2210.03192v2,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'physics.chem-ph']",,,[]
Rieoptax: Riemannian Optimization in JAX,http://arxiv.org/abs/2210.04840v1,2022-10-10T16:55:32Z,2022-10-10T16:55:32Z,"  We present Rieoptax, an open source Python library for Riemannian
optimization in JAX. We show that many differential geometric primitives, such
as Riemannian exponential and logarithm maps, are usually faster in Rieoptax
than existing frameworks in Python, both on CPU and GPU. We support various
range of basic and advanced stochastic optimization solvers like Riemannian
stochastic gradient, stochastic variance reduction, and adaptive gradient
methods. A distinguishing feature of the proposed toolbox is that we also
support differentially private optimization on Riemannian manifolds.
","['\nSaiteja Utpala\n', '\nAndi Han\n', '\nPratik Jawanpuria\n', '\nBamdev Mishra\n']",,,http://arxiv.org/abs/2210.04840v1,math.OC,"['math.OC', 'cs.LG', 'cs.MS']",,,[]
Designing a general library for convolutions,http://arxiv.org/abs/2210.07693v1,2022-10-14T10:35:54Z,2022-10-14T10:35:54Z,"  We will discuss our experiences and design decisions obtained from building a
formal library for the convolution of two functions. Convolution is a
fundamental concept with applications throughout mathematics. We will focus on
the design decisions we made to make the convolution general and easy to use,
and the incorporation of this development in Lean's mathematical library
mathlib.
",['\nFloris van Doorn\n'],"24 pages, submitted to CPP 2023",,http://arxiv.org/abs/2210.07693v1,cs.LO,"['cs.LO', 'cs.MS', 'math.FA', '68V20, 42A85, 44A35', 'F.4.1; G.3']",,,[]
"CyRSoXS: A GPU-accelerated virtual instrument for Polarized Resonant
  Soft X-ray Scattering (P-RSoXS)",http://arxiv.org/abs/2209.13121v1,2022-09-27T02:29:08Z,2022-09-27T02:29:08Z,"  Polarized Resonant Soft X-ray scattering (P-RSoXS) has emerged as a powerful
synchrotron-based tool that combines principles of X-ray scattering and X-ray
spectroscopy. P-RSoXS provides unique sensitivity to molecular orientation and
chemical heterogeneity in soft materials such as polymers and biomaterials.
Quantitative extraction of orientation information from P-RSoXS pattern data is
challenging because the scattering processes originate from sample properties
that must be represented as energy-dependent three-dimensional tensors with
heterogeneities at nanometer to sub-nanometer length scales. We overcome this
challenge by developing an open-source virtual instrument that uses GPUs to
simulate P-RSoXS patterns from real-space material representations with
nanoscale resolution. Our computational framework CyRSoXS
(https://github.com/usnistgov/cyrsoxs) is designed to maximize GPU performance.
We demonstrate the accuracy and robustness of our approach by validating
against an extensive set of test cases, which include both analytical solutions
and numerical comparisons, demonstrating a speedup of over three orders
relative to the current state-of-the-art simulation software. Such fast
simulations open up a variety of applications that were previously
computationally infeasible, including (a) pattern fitting, (b) co-simulation
with the physical instrument for operando analytics, data exploration, and
decision support, (c) data creation and integration into machine learning
workflows, and (d) utilization in multi-modal data assimilation approaches.
Finally, we abstract away the complexity of the computational framework from
the end-user by exposing CyRSoXS to Python using Pybind. This eliminates I/O
requirements for large-scale parameter exploration and inverse design, and
democratizes usage by enabling seamless integration with a Python ecosystem
(https://github.com/usnistgov/nrss).
","['\nKumar Saurabh\n', '\nPeter J. Dudenas\n', '\nEliot Gann\n', '\nVeronica G. Reynolds\n', '\nSubhrangsu Mukherjee\n', '\nDaniel Sunday\n', '\nTyler B. Martin\n', '\nPeter A. Beaucage\n', '\nMichael L. Chabinyc\n', '\nDean M. DeLongchamp\n', '\nAdarsh Krishnamurthy\n', '\nBaskar Ganapathysubramanian\n']","41 pages, 19 figures",,http://arxiv.org/abs/2209.13121v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",,,[]
"Disruptive Changes in Field Equation Modeling: A Simple Interface for
  Wafer Scale Engines",http://arxiv.org/abs/2209.13768v2,2022-09-28T01:33:23Z,2022-09-29T00:38:36Z,"  We present a high-level and accessible Application Programming Interface
(API) for the solution of field equations on the Cerebras Systems Wafer-Scale
Engine (WSE) with over two orders of magnitude performance gain relative to
traditional distributed computing approaches. The domain-specific API is called
the WSE Field-equation API (WFA). The WFA outperforms OpenFOAM on NETL's Joule
2.0 supercomputer by over two orders of magnitude in time to solution. While
this performance is consistent with hand-optimized assembly codes, the WFA
provides an easy-to-use, high-level Python interface that allows users to form
and solve field equations effortlessly. We report here the WFA programming
methodology and achieved performance on the latest generation of WSE, the CS-2.
","['\nMino Woo\n', '\nTerry Jordan\n', '\nRobert Schreiber\n', '\nIlya Sharapov\n', '\nShaheer Muhammad\n', '\nAbhishek Koneru\n', '\nMichael James\n', '\nDirk Van Essendelft\n']","22 pages, 5 figures, 2 Tables",,http://arxiv.org/abs/2209.13768v2,cs.DC,"['cs.DC', 'cs.AR', 'cs.MS', 'cs.PF', 'J.2; I.6']",,,[]
"Cadabra and Python algorithms in General Relativity and Cosmology I:
  Generalities",http://arxiv.org/abs/2210.00005v1,2022-09-30T16:44:57Z,2022-09-30T16:44:57Z,"  The aim of this work is to present a series of concrete examples which
illustrate how the computer algebra system Cadabra can be used to manipulate
expressions appearing in General Relativity and other gravitational theories.
We highlight the way in which Cadabra's philosophy differs from other systems
with related functionality. The use of various new built-in packages is
discussed, and we show how such packages can also be created by end-users
directly using the notebook interface.
  The current paper focuses on fairly generic applications in gravitational
theories, including the use of differential forms, the derivation of field
equations and the construction of their solutions. A follow-up paper discusses
more specific applications related to the analysis of gravitational waves.
","['\nOscar Castillo-Felisola\n', '\nDominic T. Price\n', '\nMattia Scomparin\n']","30 pages, 3 figures, cadabra code blocks. For associated files, see
  https://gitlab.com/cdbgr/cadabra-gravity-I",,http://arxiv.org/abs/2210.00005v1,gr-qc,"['gr-qc', 'cs.MS', 'physics.class-ph', 'physics.comp-ph']",,,[]
"Cadabra and Python algorithms in General Relativity and Cosmology II:
  Gravitational Waves",http://arxiv.org/abs/2210.00007v1,2022-09-30T16:58:21Z,2022-09-30T16:58:21Z,"  Computer Algebra Systems (CASs) like Cadabra Software play a prominent role
in a wide range of research activities in physics and related fields. We show
how Cadabra language is easily implemented in the well established Python
programming framework, gaining excellent flexibility and customization to
address the issue of tensor perturbations in General Relativity. We obtain a
performing algorithm to decompose tensorial quantities up to any perturbative
order of the metric. The features of our code are tested by discussing some
concrete computational issues in research activities related to
first/higher-order gravitational waves.
","['\nOscar Castillo-Felisola\n', '\nDominic T. Price\n', '\nMattia Scomparin\n']","32 pages, 3 figures, cadabra code blocks. For associated files, see
  https://gitlab.com/cdbgr/cadabra-gravity-II",,http://dx.doi.org/10.1016/j.cpc.2023.108748,gr-qc,"['gr-qc', 'cs.MS', 'physics.class-ph', 'physics.comp-ph']",10.1016/j.cpc.2023.108748,,[]
"NCVX: A General-Purpose Optimization Solver for Constrained Machine and
  Deep Learning",http://arxiv.org/abs/2210.00973v2,2022-10-03T14:41:26Z,2022-11-14T00:21:55Z,"  Imposing explicit constraints is relatively new but increasingly pressing in
deep learning, stimulated by, e.g., trustworthy AI that performs robust
optimization over complicated perturbation sets and scientific applications
that need to respect physical laws and constraints. However, it can be hard to
reliably solve constrained deep learning problems without optimization
expertise. The existing deep learning frameworks do not admit constraints.
General-purpose optimization packages can handle constraints but do not perform
auto-differentiation and have trouble dealing with nonsmoothness. In this
paper, we introduce a new software package called NCVX, whose initial release
contains the solver PyGRANSO, a PyTorch-enabled general-purpose optimization
package for constrained machine/deep learning problems, the first of its kind.
NCVX inherits auto-differentiation, GPU acceleration, and tensor variables from
PyTorch, and is built on freely available and widely used open-source
frameworks. NCVX is available at https://ncvx.org, with detailed documentation
and numerous examples from machine/deep learning and other fields.
","['\nBuyun Liang\n', '\nTim Mitchell\n', '\nJu Sun\n']","Accepted by the NeurIPS Workshop on Optimization for Machine Learning
  (OPT 2022). arXiv admin note: text overlap with arXiv:2111.13984",,http://arxiv.org/abs/2210.00973v2,cs.LG,"['cs.LG', 'cs.CV', 'cs.MS', 'eess.SP', 'math.OC']",,,[]
IGraph/M: graph theory and network analysis for Mathematica,http://arxiv.org/abs/2209.09145v1,2022-09-19T16:04:57Z,2022-09-19T16:04:57Z,"  IGraph/M is an efficient general purpose graph theory and network analysis
package for Mathematica. IGraph/M serves as the Wolfram Language interfaces to
the igraph C library, and also provides several unique pieces of functionality
not yet present in igraph, but made possible by combining its capabilities with
Mathematica's. The package is designed to support both graph theoretical
research as well as the analysis of large-scale empirical networks.
","['\nSzabolcs Horvát\n', '\nJakub Podkalicki\n', '\nGábor Csárdi\n', '\nTamás Nepusz\n', '\nVincent Traag\n', '\nFabio Zanini\n', '\nDaniel Noom\n']","submitted to Journal of Open Source Software on August 30, 2022",,http://dx.doi.org/10.21105/joss.04899,physics.soc-ph,"['physics.soc-ph', 'cs.MS', 'math.CO']",10.21105/joss.04899,,[]
Forward-Mode Automatic Differentiation of Compiled Programs,http://arxiv.org/abs/2209.01895v2,2022-09-05T10:48:24Z,2023-07-07T08:42:31Z,"  Algorithmic differentiation (AD) is a set of techniques that provide partial
derivatives of computer-implemented functions. Such a function can be supplied
to state-of-the-art AD tools via its source code, or via an intermediate
representation produced while compiling its source code.
  We present the novel AD tool Derivgrind, which augments the machine code of
compiled programs with forward-mode AD logic. Derivgrind leverages the Valgrind
instrumentation framework for a structured access to the machine code, and a
shadow memory tool to store dot values. Access to the source code is required
at most for the files in which input and output variables are defined.
  Derivgrind's versatility comes at the price of scaling the run-time by a
factor between 30 and 75, measured on a benchmark based on a numerical solver
for a partial differential equation. Results of our extensive regression test
suite indicate that Derivgrind produces correct results on GCC- and
Clang-compiled programs, including a Python interpreter, with a small number of
exceptions. While we provide a list of scenarios that Derivgrind does not
handle correctly, nearly all of them are academic counterexamples or originate
from highly optimized math libraries. As long as differentiating those is
avoided, Derivgrind can be applied to an unprecedentedly wide range of
cross-language or partially closed-source software with little integration
efforts.
","['\nMax Aehle\n', '\nJohannes Blühdorn\n', '\nMax Sagebaum\n', '\nNicolas R. Gauger\n']","21 pages, 3 figures, 3 tables, 5 listings",,http://arxiv.org/abs/2209.01895v2,cs.MS,['cs.MS'],,,[]
A Test for FLOPs as a Discriminant for Linear Algebra Algorithms,http://arxiv.org/abs/2209.03258v3,2022-09-07T16:08:17Z,2022-11-30T17:10:52Z,"  Linear algebra expressions, which play a central role in countless scientific
computations, are often computed via a sequence of calls to existing libraries
of building blocks (such as those provided by BLAS and LAPACK). A sequence
identifies a computing strategy, i.e., an algorithm, and normally for one
linear algebra expression many alternative algorithms exist. Although
mathematically equivalent, those algorithms might exhibit significant
differences in terms of performance. Several high-level languages and tools for
matrix computations such as Julia, Armadillo, Linnea, etc., make algorithmic
choices by minimizing the number of Floating Point Operations (FLOPs). However,
there can be several algorithms that share the same (or have nearly identical)
number of FLOPs; in many cases, these algorithms exhibit execution times which
are statistically equivalent and one could arbitrarily select one of them as
the best algorithm. It is however not unlikely to find cases where the
execution times are significantly different from one another (despite the FLOP
count being almost the same). It is also possible that the algorithm that
minimizes FLOPs is not the one that minimizes execution time. In this work, we
develop a methodology to test the reliability of FLOPs as discriminant for
linear algebra algorithms. Given a set of algorithms (for an instance of a
linear algebra expression) as input, the methodology ranks them into
performance classes; i.e., multiple algorithms are allowed to share the same
rank. To this end, we measure the algorithms iteratively until the changes in
the ranks converge to a value close to zero. FLOPs are a valid discriminant for
an instance if all the algorithms with minimum FLOPs are assigned the best
rank; otherwise, the instance is regarded as an anomaly, which can then be used
in the investigation of the root cause of performance differences.
","['\nAravind Sankaran\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/2209.03258v3,cs.PF,"['cs.PF', 'cs.MS']",,,[]
Looplets: A Language For Structured Coiteration,http://arxiv.org/abs/2209.05250v1,2022-09-08T20:16:41Z,2022-09-08T20:16:41Z,"  Real world arrays often contain underlying structure, such as sparsity, runs
of repeated values, or symmetry. Specializing for structure yields significant
speedups. But automatically generating efficient code for structured data is
challenging, especially when arrays with different structure interact. We show
how to abstract over array structures so that the compiler can generate code to
coiterate over any combination of them. Our technique enables new array formats
(such as 1DVBL for irregular clustered sparsity), new iteration strategies
(such as galloping intersections), and new operations over structured data
(such as concatenation or convolution).
","['\nWillow Ahrens\n', '\nDaniel Donenfeld\n', '\nFredrik Kjolstad\n', '\nSaman Amarasinghe\n']",,,http://arxiv.org/abs/2209.05250v1,cs.PL,"['cs.PL', 'cs.MS']",,,[]
"Performance optimization and analysis of the unstructured Discontinuous
  Galerkin solver on multi-core and many-core architectures",http://arxiv.org/abs/2209.01877v1,2022-09-05T10:23:30Z,2022-09-05T10:23:30Z,"  The discontinuous Galerkin (DG) algorithm is a representative high order
method in Computational Fluid Dynamics (CFD) area which possesses considerable
mathematical advantages such as high resolution, low dissipation, and
dispersion. However, DG is rather computationally intensive to demonstrate
practical engineering problems. This paper discusses the implementation of our
in-house practical DG application in three different programming models, as
well as some optimization techniques, including grid renumbering and mixed
precision to maximize the performance improvements in a single node system. The
experiment on CPU and GPU shows that our CUDA, OpenACC, and OpenMP-based code
obtains a maximum speedup of 42.9x, 35.3x, and 8.1x compared with serial
execution by the original application, respectively. Besides, we systematically
compare the programming models in two aspects: performance and productivity.
Our empirical conclusions facilitate the programmers to select the right
platform with a suitable programming model according to their target
applications.
","['\nZhe Dai\n', '\nLiang D\n', '\nYueqin Wang\n', '\nFang Wang\n', '\nLi Ming\n', '\nJian Zhang\n']","8pages,conference",,http://arxiv.org/abs/2209.01877v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC']",,,[]
"I'm stuck! How to efficiently debug computational solid mechanics models
  so you can enjoy the beauty of simulations",http://arxiv.org/abs/2209.04198v2,2022-09-09T09:25:53Z,2022-10-26T11:10:57Z,"  A substantial fraction of the time that computational modellers dedicate to
developing their models is actually spent trouble-shooting and debugging their
code. However, how this process unfolds is seldom spoken about, maybe because
it is hard to articulate as it relies mostly on the mental catalogues we have
built with the experience of past failures. To help newcomers to the field of
material modelling, here we attempt to fill this gap and provide a perspective
on how to identify and fix mistakes in computational solid mechanics models. To
this aim, we describe the components that make up such a model and then
identify possible sources of errors. In practice, finding mistakes is often
better done by considering the symptoms of what is going wrong. As a
consequence, we provide strategies to narrow down where in the model the
problem may be, based on observation and a catalogue of frequent causes of
observed errors. In a final section, we also discuss how one-time bug-free
models can be kept bug-free in view of the fact that computational models are
typically under continual development. We hope that this collection of
approaches and suggestions serves as a ""road map"" to find and fix mistakes in
computational models, and more importantly, keep the problems solved so that
modellers can enjoy the beauty of material modelling and simulation.
","['\nEster Comellas\n', '\nJean-Paul Pelteret\n', '\nWolfgang Bangerth\n']","13 pages, 2 figures, accepted manuscript to be published in VSI:Joy
  of Mechanics of the European Journal of Mechanics / A Solids. Replacement of
  2209.04198. Main changes w.r.t. preprint version are addition of sec 3.1.3;
  footnote 3 in sec 3.1.4, sec 3.1.6, final pargraph in sec 4.1.1 and sec 4.1.3",,http://dx.doi.org/10.1016/j.euromechsol.2022.104845,cs.CE,"['cs.CE', 'cs.MS', 'cs.NA', 'math.NA']",10.1016/j.euromechsol.2022.104845,,[]
"On topological data analysis for SHM; an introduction to persistent
  homology",http://arxiv.org/abs/2209.06155v1,2022-09-12T12:02:39Z,2022-09-12T12:02:39Z,"  This paper aims to discuss a method of quantifying the 'shape' of data, via a
methodology called topological data analysis. The main tool within topological
data analysis is persistent homology; this is a means of measuring the shape of
data, from the homology of a simplicial complex, calculated over a range of
values. The required background theory and a method of computing persistent
homology is presented here, with applications specific to structural health
monitoring. These results allow for topological inference and the ability to
deduce features in higher-dimensional data, that might otherwise be overlooked.
  A simplicial complex is constructed for data for a given distance parameter.
This complex encodes information about the local proximity of data points. A
singular homology value can be calculated from this simplicial complex.
Extending this idea, the distance parameter is given for a range of values, and
the homology is calculated over this range. The persistent homology is a
representation of how the homological features of the data persist over this
interval. The result is characteristic to the data. A method that allows for
the comparison of the persistent homology for different data sets is also
discussed.
","['\nTristan Gowdridge\n', '\nNikolaos Devilis\n', '\nKeith Worden\n']",,,http://arxiv.org/abs/2209.06155v1,math.AT,"['math.AT', 'cs.LG', 'cs.MS']",,,[]
"Distributed Objective Function Evaluation for Optimization of Radiation
  Therapy Treatment Plans",http://arxiv.org/abs/2208.11395v1,2022-08-24T09:34:44Z,2022-08-24T09:34:44Z,"  The modern workflow for radiation therapy treatment planning involves
mathematical optimization to determine optimal treatment machine parameters for
each patient case. The optimization problems can be computationally expensive,
requiring iterative optimization algorithms to solve. In this work, we
investigate a method for distributing the calculation of objective functions
and gradients for radiation therapy optimization problems across computational
nodes. We test our approach on the TROTS dataset -- which consists of
optimization problems from real clinical patient cases -- using the IPOPT
optimization solver in a leader/follower type approach for parallelization. We
show that our approach can utilize multiple computational nodes efficiently,
with a speedup of approximately 2-3.5 times compared to the serial version.
","['\nFelix Liu\n', '\nMåns I. Andersson\n', '\nAlbin Fredriksson\n', '\nStefano Markidis\n']",Accepted for publication at the PPAM22 conference,"Parallel Processing and Applied Mathematics. PPAM 2022. Lecture
  Notes in Computer Science, vol 13826. Springer, Cham",http://dx.doi.org/10.1007/978-3-031-30442-2_29,cs.MS,"['cs.MS', 'cs.DC']",10.1007/978-3-031-30442-2_29,,[]
Cardinal Optimizer (COPT) User Guide,http://arxiv.org/abs/2208.14314v2,2022-08-30T14:52:44Z,2022-10-28T03:52:56Z,"  Cardinal Optimizer is a high-performance mathematical programming solver for
efficiently solving largescale optimization problem. This documentation
provides basic introduction to the Cardinal Optimizer.
","['\nDongdong Ge\n', '\nQi Huangfu\n', '\nZizhuo Wang\n', '\nJian Wu\n', '\nYinyu Ye\n']",,,http://arxiv.org/abs/2208.14314v2,math.OC,"['math.OC', 'cs.MS']",,,[]
"Solving the One-Dimensional Time-Independent Schrödinger Equation with
  High Accuracy: The LagrangeMesh Mathematica Package",http://arxiv.org/abs/2208.14340v2,2022-08-30T15:33:14Z,2023-05-26T22:32:28Z,"  In order to find the spectrum associated with the one-dimensional
Schr\""oodinger equation, we discuss the Lagrange Mesh method (LMM) and its
numerical implementation for bound states. After presenting a general overview
of the theory behind the LMM, we introduce the LagrangeMesh package: the
numerical implementation of the LMM in Mathematica. Using few lines of code,
the package enables a quick home-computer computation of the spectrum and
provides a practical tool to study a large class of systems in quantum
mechanics. The main properties of the package are (i) the input is basically
the potential function and the interval on which is defined; and (ii) the
accuracy in calculations and final results is controllable by the user. As
illustration, a highly accurate spectrum of some relevant quantum systems is
obtained by employing the commands that the package offers. In fact, the
present work can be regarded as a user guide based on worked examples.
",['\nJ. C. del Valle\n'],"File LagrangeMesh.wl can be provided to the interested reader, just
  contact the author via email. Alternatively, it can be found at
  https://github.com/JuanCarlosdelValle/LagrangeMesh-Package",,http://dx.doi.org/10.1142/S0129183124500116,quant-ph,"['quant-ph', 'cs.MS']",10.1142/S0129183124500116,,[]
"Flash-X, a multiphysics simulation software instrument",http://arxiv.org/abs/2208.11630v1,2022-08-24T16:05:03Z,2022-08-24T16:05:03Z,"  Flash-X is a highly composable multiphysics software system that can be used
to simulate physical phenomena in several scientific domains. It derives some
of its solvers from FLASH, which was first released in 2000. Flash-X has a new
framework that relies on abstractions and asynchronous communications for
performance portability across a range of increasingly heterogeneous hardware
platforms. Flash-X is meant primarily for solving Eulerian formulations of
applications with compressible and/or incompressible reactive flows. It also
has a built-in, versatile Lagrangian framework that can be used in many
different ways, including implementing tracers, particle-in-cell simulations,
and immersed boundary methods.
","['\nAnshu Dubey\n', '\nKlaus Weide\n', ""\nJared O'Neal\n"", '\nAkash Dhruv\n', '\nSean Couch\n', '\nJ. Austin Harris\n', '\nTom Klosterman\n', '\nRajeev Jain\n', '\nJohann Rudi\n', '\nBronson Messer\n', '\nMichael Pajkos\n', '\nJared Carlson\n', '\nRan Chu\n', '\nMohamed Wahib\n', '\nSaurabh Chawdhary\n', '\nPaul M. Ricker\n', '\nDongwook Lee\n', '\nKatie Antypas\n', '\nKatherine M. Riley\n', '\nChristopher Daley\n', '\nMurali Ganapathy\n', '\nFrancis X. Timmes\n', '\nDean M. Townsley\n', '\nMarcos Vanella\n', '\nJohn Bachan\n', '\nPaul Rich\n', '\nShravan Kumar\n', '\nEirik Endeve\n', '\nW. Raphael Hix\n', '\nAnthony Mezzacappa\n', '\nThomas Papatheodore\n']","16 pages, 5 Figures, published open access in SoftwareX","SoftwareX, Volume 19, 2022, 101168,ISSN 2352-7110",http://dx.doi.org/10.1016/j.softx.2022.101168,physics.comp-ph,"['physics.comp-ph', 'astro-ph.IM', 'cs.MS']",10.1016/j.softx.2022.101168,,[]
"SOniCS: Develop intuition on biomechanical systems through interactive
  error controlled simulations",http://arxiv.org/abs/2208.11676v1,2022-08-24T17:14:08Z,2022-08-24T17:14:08Z,"  This new approach allows the user to experiment with model choices easily and
quickly without requiring in-depth expertise, as constitutive models can be
modified by one line of code only. This ease in building new models makes
SOniCS ideal to develop surrogate, reduced order models and to train machine
learning algorithms for uncertainty quantification or to enable
patient-specific simulations. SOniCS is thus not only a tool that facilitates
the development of surgical training simulations but also, and perhaps more
importantly, paves the way to increase the intuition of users or otherwise
non-intuitive behaviors of (bio)mechanical systems. The plugin uses new
developments of the FEniCSx project enabling automatic generation with FFCx of
finite element tensors such as the local residual vector and Jacobian matrix.
We validate our approach with numerical simulations such as manufactured
solutions, cantilever beams, and benchmarks provided by FEBio. We reach machine
precision accuracy and demonstrate the use of the plugin for a real-time haptic
simulation involving a surgical tool controlled by the user in contact with a
hyperelastic liver. We include complete examples showing the use of our plugin
for simulations involving Saint Venant-Kirchhoff, Neo-Hookean, Mooney-Rivlin,
and Holzapfel Ogden anisotropic models as supplementary material.
","['\nArnaud Mazier\nUniversity of Luxembourg\n', '\nSidaty El Hadramy\nINRIA, MIMESIS Team\n', '\nJean-Nicolas Brunet\nINRIA, MIMESIS Team\n', '\nJack S. Hale\nUniversity of Luxembourg\n', '\nStéphane Cotin\nINRIA, MIMESIS Team\n', '\nStéphane P. A. Bordas\nUniversity of Luxembourg\n']",,,http://arxiv.org/abs/2208.11676v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.SE']",,,"['University of Luxembourg', 'INRIA, MIMESIS Team', 'INRIA, MIMESIS Team', 'University of Luxembourg', 'INRIA, MIMESIS Team', 'University of Luxembourg']"
"DelayDiffEq: Generating Delay Differential Equation Solvers via
  Recursive Embedding of Ordinary Differential Equation Solvers",http://arxiv.org/abs/2208.12879v1,2022-08-26T22:14:32Z,2022-08-26T22:14:32Z,"  Traditional solvers for delay differential equations (DDEs) are designed
around only a single method and do not effectively use the infrastructure of
their more-developed ordinary differential equation (ODE) counterparts. In this
work we present DelayDiffEq, a Julia package for numerically solving delay
differential equations (DDEs) which leverages the multitude of numerical
algorithms in OrdinaryDiffEq for solving both stiff and non-stiff ODEs, and
manages to solve challenging stiff DDEs. We describe how compiling the ODE
integrator within itself, and accounting for discontinuity propagation, leads
to a design that is effective for DDEs while using all of the ODE internals. We
highlight some difficulties that a numerical DDE solver has to address, and
explain how DelayDiffEq deals with these problems. We show how DelayDiffEq is
able to solve difficult equations, how its stiff DDE solvers give efficiency on
problems with time-scale separation, and how the design allows for generality
and flexibility in usage such as being repurposed for generating solvers for
stochastic delay differential equations.
","['\nDavid Widmann\n', '\nChris Rackauckas\n']","8 pages, 3 figures",,http://arxiv.org/abs/2208.12879v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.DS']",,,[]
"Survey of Methods for Solving Systems of Nonlinear Equations, Part I:
  Root-finding Approaches",http://arxiv.org/abs/2208.08530v1,2022-08-17T20:52:46Z,2022-08-17T20:52:46Z,"  This paper presents a comprehensive survey of methods which can be utilized
to search for solutions to systems of nonlinear equations (SNEs). Our
objectives with this survey are to synthesize pertinent literature in this
field by presenting a thorough description and analysis of the known methods
capable of finding one or many solutions to SNEs, and to assist interested
readers seeking to identify solution techniques which are well suited for
solving the various classes of SNEs which one may encounter in real world
applications.
  To accomplish these objectives, we present a multi-part survey. In part one,
we focus on root-finding approaches which can be used to search for solutions
to a SNE without transforming it into an optimization problem. In part two, we
will introduce the various transformations which have been utilized to
transform a SNE into an optimization problem, and we discuss optimization
algorithms which can then be used to search for solutions. In part three, we
will present a robust quantitative comparative analysis of methods capable of
searching for solutions to SNEs.
","['\nIlias S. Kotsireas\n', '\nPanos M. Pardalos\n', '\nAlexander Semenov\n', '\nWilliam T. Trevena\n', '\nMichael N. Vrahatis\n']",,,http://arxiv.org/abs/2208.08530v1,cs.MS,['cs.MS'],,,[]
"Survey of Methods for Solving Systems of Nonlinear Equations, Part II:
  Optimization Based Approaches",http://arxiv.org/abs/2208.08532v1,2022-08-17T20:58:11Z,2022-08-17T20:58:11Z,"  This paper presents a comprehensive survey of methods which can be utilized
to search for solutions to systems of nonlinear equations (SNEs). Our
objectives with this survey are to synthesize pertinent literature in this
field by presenting a thorough description and analysis of the known methods
capable of finding one or many solutions to SNEs, and to assist interested
readers seeking to identify solution techniques which are well suited for
solving the various classes of SNEs which one may encounter in real world
applications.
  To accomplish these objectives, we present a multi-part survey. In part one,
we focused on root-finding approaches which can be used to search for solutions
to a SNE without transforming it into an optimization problem. In part two, we
introduce the various transformations which have been utilized to transform a
SNE into an optimization problem, and we discuss optimization algorithms which
can then be used to search for solutions. We emphasize the important
characteristics of each method, and we discuss promising directions for future
research. In part three, we will present a robust quantitative comparative
analysis of methods capable of searching for solutions to SNEs.
","['\nIlias S. Kotsireas\n', '\nPanos M. Pardalos\n', '\nAlexander Semenov\n', '\nWilliam T. Trevena\n', '\nMichael N. Vrahatis\n']",,,http://arxiv.org/abs/2208.08532v1,cs.MS,['cs.MS'],,,[]
Tensor Algebra on an Optoelectronic Microchip,http://arxiv.org/abs/2208.06749v1,2022-08-13T23:28:31Z,2022-08-13T23:28:31Z,"  Tensor algebra lies at the core of computational science and machine
learning. Due to its high usage, entire libraries exist dedicated to improving
its performance. Conventional tensor algebra performance boosts focus on
algorithmic optimizations, which in turn lead to incremental improvements. In
this paper, we describe a method to accelerate tensor algebra a different way:
by outsourcing operations to an optical microchip. We outline a numerical
programming language developed to perform tensor algebra computations that is
designed to leverage our optical hardware's full potential. We introduce the
language's current grammar and go over the compiler design. We then show a new
way to store sparse rank-n tensors in RAM that outperforms conventional array
storage (used by C++, Java, etc.). This method is more memory-efficient than
Compressed Sparse Fiber (CSF) format and is specifically tuned for our optical
hardware. Finally, we show how the scalar-tensor product, rank-$n$ Kronecker
product, tensor dot product, Khatri-Rao product, face-splitting product, and
vector cross product can be compiled into operations native to our optical
microchip through various tensor decompositions.
","['\nSathvik Redrouthu\nProcyon Photonics\n', '\nRishi Athavale\nProcyon Photonics\n']","8 pages, 7 figures",,http://arxiv.org/abs/2208.06749v1,cs.PL,"['cs.PL', 'cs.MS', 'D.3.4']",,,"['Procyon Photonics', 'Procyon Photonics']"
Parallel QR Factorization of Block Low-Rank Matrices,http://arxiv.org/abs/2208.06194v1,2022-08-12T09:56:04Z,2022-08-12T09:56:04Z,"  We present two new algorithms for Householder QR factorization of Block
Low-Rank (BLR) matrices: one that performs block-column-wise QR, and another
that is based on tiled QR. We show how the block-column-wise algorithm exploits
BLR structure to achieve arithmetic complexity of $\mathcal{O}(mn)$, while the
tiled BLR-QR exhibits $\mathcal{O}(mn^{1.5})$ complexity. However, the tiled
BLR-QR has finer task granularity that allows parallel task-based execution on
shared memory systems. We compare the block-column-wise BLR-QR using fork-join
parallelism with tiled BLR-QR using task-based parallelism. We also compare
these two implementations of Householder BLR-QR with a block-column-wise
Modified Gram-Schmidt (MGS) BLR-QR using fork-join parallelism, and a
state-of-the-art vendor-optimized dense Householder QR in Intel MKL. For a
matrix of size 131k $\times$ 65k, all BLR methods are more than an order of
magnitude faster than the dense QR in MKL. Our methods are also robust to
ill-conditioning and produce better orthogonal factors than the existing
MGS-based method. On a CPU with 64 cores, our parallel tiled Householder and
block-column-wise Householder algorithms show a speedup of 50 and 37 times,
respectively.
","['\nM. Ridwan Apriansyah\n', '\nRio Yokota\n']","23 pages, 12 figures",,http://dx.doi.org/10.1145/3538647,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.1.3; G.1.2; G.4; D.1.3']",10.1145/3538647,,[]
Feature-Based Time-Series Analysis in R using the theft Package,http://arxiv.org/abs/2208.06146v4,2022-08-12T07:29:29Z,2023-07-03T09:02:40Z,"  Time series are measured and analyzed across the sciences. One method of
quantifying the structure of time series is by calculating a set of summary
statistics or `features', and then representing a time series in terms of its
properties as a feature vector. The resulting feature space is interpretable
and informative, and enables conventional statistical learning approaches,
including clustering, regression, and classification, to be applied to
time-series datasets. Many open-source software packages for computing sets of
time-series features exist across multiple programming languages, including
catch22 (22 features: Matlab, R, Python, Julia), feasts (42 features: R),
tsfeatures (63 features: R), Kats (40 features: Python), tsfresh (779 features:
Python), and TSFEL (390 features: Python). However, there are several issues:
(i) a singular access point to these packages is not currently available; (ii)
to access all feature sets, users must be fluent in multiple languages; and
(iii) these feature-extraction packages lack extensive accompanying
methodological pipelines for performing feature-based time-series analysis,
such as applications to time-series classification. Here we introduce a
solution to these issues in an R software package called theft: Tools for
Handling Extraction of Features from Time series. theft is a unified and
extendable framework for computing features from the six open-source
time-series feature sets listed above. It also includes a suite of functions
for processing and interpreting the performance of extracted features,
including extensive data-visualization templates, low-dimensional projections,
and time-series classification operations. With an increasing volume and
complexity of time-series datasets in the sciences and industry, theft provides
a standardized framework for comprehensively quantifying and interpreting
informative structure in time series.
","['\nTrent Henderson\n', '\nBen D. Fulcher\n']",,,http://arxiv.org/abs/2208.06146v4,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS', 'q-bio.QM', 'stat.AP', 'stat.ME']",,,[]
"The Object Oriented c++ library QIBSH++ for Hermite spline Quasi
  Interpolation",http://arxiv.org/abs/2208.03260v1,2022-08-05T16:27:45Z,2022-08-05T16:27:45Z,"  The library QIBSH++ is a C++ object oriented library for the solution of
Quasi Interpolation problems. The library is based on a Hermite Quasi
Interpolating operator, which was derived as continuous extensions of linear
multistep methods applied for the numerical solution of Boundary Value Problems
for Ordinary Differential Equations. The library includes the possibility to
use Hermite data or to apply a finite difference scheme for derivative
approximations, when derivative values are not directly available. The
generalization of the quasi interpolation procedure to surfaces and volumes
approximation by means of a tensor product technique is also implemented. The
method has been also generalized for one dimensional vectorial data, periodic
data, and for two dimensional data in cylindrical coordinates, periodic with
respect to the angular argument. Numerical tests show that the library could be
used efficiently in many practical problems.
","['\nEnrico Bertolazzi\n', '\nAntonella Falini\n', '\nFrancesca Mazzia\n']",,,http://arxiv.org/abs/2208.03260v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65D15, 65L10', 'G.1.1']",,,[]
HDSDP: Software for Semidefinite Programming,http://arxiv.org/abs/2207.13862v2,2022-07-28T02:35:08Z,2023-11-09T01:35:10Z,"  HDSDP is a numerical software solving the semidefinite programming problems.
The main framework of HDSDP resembles the dual-scaling interior point solver
DSDP [BY2008] and several new features, including a dual method based on the
simplified homogeneous self-dual embedding, have been implemented. The
embedding technique enhances stability of the dual method and several new
heuristics and computational techniques are designed to accelerate its
convergence. HDSDP aims to show how dual-scaling algorithm benefits from the
self-dual embedding and it is developed in parallel to DSDP5.8. Numerical
experiments over several classical benchmark datasets exhibit its robustness
and efficiency, and particularly its advantages on SDP instances featuring
low-rank structure and sparsity. HDSDP is open-sourced under MIT license and
available at https://github.com/COPT-Public/HDSDP.
","['\nWenzhi Gao\n', '\nDongdong Ge\n', '\nYinyu Ye\n']",,,http://arxiv.org/abs/2207.13862v2,cs.MS,"['cs.MS', 'math.OC']",,,[]
Sequential Models in the Synthetic Data Vault,http://arxiv.org/abs/2207.14406v1,2022-07-28T23:17:51Z,2022-07-28T23:17:51Z,"  The goal of this paper is to describe a system for generating synthetic
sequential data within the Synthetic data vault. To achieve this, we present
the Sequential model currently in SDV, an end-to-end framework that builds a
generative model for multi-sequence, real-world data. This includes a novel
neural network-based machine learning model, conditional probabilistic
auto-regressive (CPAR) model. The overall system and the model is available in
the open source Synthetic Data Vault (SDV) library
{https://github.com/sdv-dev/SDV}, along with a variety of other models for
different synthetic data needs.
  After building the Sequential SDV, we used it to generate synthetic data and
compared its quality against an existing, non-sequential generative adversarial
network based model called CTGAN. To compare the sequential synthetic data
against its real counterpart, we invented a new metric called Multi-Sequence
Aggregate Similarity (MSAS). We used it to conclude that our Sequential SDV
model learns higher level patterns than non-sequential models without any
trade-offs in synthetic data quality.
","['\nKevin Zhang\n', '\nNeha Patki\n', '\nKalyan Veeramachaneni\n']","17 pages, 8 figures",,http://arxiv.org/abs/2207.14406v1,cs.LG,"['cs.LG', 'cs.MS', '62H12', 'I.5.1']",,,[]
"Automated modeling of brain bioelectric activity within the 3D Slicer
  environment",http://arxiv.org/abs/2208.01747v1,2022-07-27T16:03:36Z,2022-07-27T16:03:36Z,"  Electrocorticography (ECoG) or intracranial electroencephalography (iEEG)
monitors electric potential directly on the surface of the brain and can be
used to inform treatment planning for epilepsy surgery when paired with
numerical modeling. For solving the inverse problem in epilepsy seizure onset
localization, accurate solution of the iEEG forward problem is critical which
requires accurate representation of the patient's brain geometry and tissue
electrical conductivity. In this study, we present an automatic framework for
constructing the brain volume conductor model for solving the iEEG forward
problem and visualizing the brain bioelectric field on a deformed
patient-specific brain model within the 3D Slicer environment. We solve the
iEEG forward problem on the predicted postoperative geometry using the finite
element method (FEM) which accounts for patient-specific inhomogeneity and
anisotropy of tissue conductivity. We use an epilepsy case study to illustrate
the workflow of our framework developed and integrated within 3D Slicer.
","['\nSaima Safdar\n', '\nBenjamin Zwick\n', '\nGeorge Bourantas\n', '\nGrand Joldes\n', '\nDamon Hyde\n', '\nSimon Warfield\n', '\nAdam Wittek\n', '\nKarol Miller\n']",,Computational Biomechanics for Medicine Workshop CBM XVII 2022,http://arxiv.org/abs/2208.01747v1,physics.med-ph,"['physics.med-ph', 'cs.MS']",,,[]
Digital Nets and Sequences for Quasi-Monte Carlo Methods,http://arxiv.org/abs/2207.13802v1,2022-07-27T21:33:18Z,2022-07-27T21:33:18Z,"  Quasi-Monte Carlo methods are a way of improving the efficiency of Monte
Carlo methods. Digital nets and sequences are one of the low discrepancy point
sets used in quasi-Monte Carlo methods. This thesis presents the three new
results pertaining to digital nets and sequences: implementing randomized
digital nets, finding the distribution of the discrepancy of scrambled digital
nets, and obtaining better quality of digital nets through evolutionary
computation. Finally, applications of scrambled and non-scrambled digital nets
are provided.
",['\nHee Sun Hong\n'],,,http://arxiv.org/abs/2207.13802v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"lifex: a flexible, high performance library for the numerical solution
  of complex finite element problems",http://arxiv.org/abs/2207.14668v3,2022-07-29T13:24:30Z,2022-11-11T13:25:20Z,"  Numerical simulations are ubiquitous in mathematics and computational
science. Several industrial and clinical applications entail modeling complex
multiphysics systems that evolve over a variety of spatial and temporal scales.
  This study introduces the design and capabilities of lifex, an open source
C++ library for high performance finite element simulations of multiphysics,
multiscale, and multidomain problems. lifex meets the emerging need for
versatile, efficient computational tools that are easily accessed by users and
developers. We showcase its flexibility and effectiveness on a number of
illustrative examples and advanced applications of use and demonstrate its
parallel performance up to thousands of cores.
",['\nPasquale Claudio Africa\n'],,"SoftwareX 20 (2022), p. 101252. issn: 2352-7110",http://dx.doi.org/10.1016/j.softx.2022.101252,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', '35-04 (Primary) 65-04, 65Y05, 65Y20, 68-04, 68N30 (Secondary)', 'G.4; G.1']",10.1016/j.softx.2022.101252,,[]
"NFFT.jl: Generic and Fast Julia Implementation of the Nonequidistant
  Fast Fourier Transform",http://arxiv.org/abs/2208.00049v2,2022-07-29T19:32:48Z,2023-01-28T07:05:39Z,"  The non-equidistant fast Fourier transform (NFFT) is an extension of the
famous fast Fourier transform (FFT), which can be applied to non-equidistantly
sampled data in time/space or frequency domain. It is an approximative
algorithm that allows to control the approximation error in such a way that
machine precision is reached while keeping the algorithmic complexity in the
same order as a regular FFT. The NFFT plays a major role in many signal
processing applications and has been intensively studied from a theoretical and
computational perspective. The fastest CPU implementations of the NFFT are
implemented in the low-level programming languages C and C++ and require a
compromise between code generalizability, code readability, and code
efficiency. The programming language Julia promises new opportunities in
optimizing these three conflicting goals. In this work we show that Julia
indeed allows to develop an NFFT implementation, which is completely generic,
dimension-agnostic and requires about 2-3 times less code than other famous
libraries while still being one of the fastest NFFT implementations developed
to date.
","['\nTobias Knopp\n', '\nMarija Boberg\n', '\nMirco Grosser\n']",26 pages,,http://arxiv.org/abs/2208.00049v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65T50, 65T40, 65Y05, 68N01']",,,[]
Compact representations of structured BFGS matrices,http://arxiv.org/abs/2208.00057v1,2022-07-29T20:09:16Z,2022-07-29T20:09:16Z,"  For general large-scale optimization problems compact representations exist
in which recursive quasi-Newton update formulas are represented as compact
matrix factorizations. For problems in which the objective function contains
additional structure, so-called structured quasi-Newton methods exploit
available second-derivative information and approximate unavailable second
derivatives. This article develops the compact representations of two
structured Broyden-Fletcher-Goldfarb-Shanno update formulas. The compact
representations enable efficient limited memory and initialization strategies.
Two limited memory line search algorithms are described and tested on a
collection of problems, including a real world large scale imaging application.
","['\nJohannes J. Brust\nWendy\n', '\n Zichao\nWendy\n', '\n Di\n', '\nSven Leyffer\n', '\nCosmin G. Petra\n']",,Computational Optimization and Applications 80:55-88 (2021),http://dx.doi.org/10.1007/s10589-021-00297-0,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'econ.EM', 'math.NA', 'stat.CO', '90C06, 90C53, 65K10,']",10.1007/s10589-021-00297-0,,"['Wendy', 'Wendy']"
"Reduction of the Random Access Memory Size in Adjoint Algorithmic
  Differentiation by Overloading",http://arxiv.org/abs/2207.07018v1,2022-07-13T13:09:40Z,2022-07-13T13:09:40Z,"  Adjoint algorithmic differentiation by operator and function overloading is
based on the interpretation of directed acyclic graphs resulting from
evaluations of numerical simulation programs. The size of the computer system
memory required to store the graph grows proportional to the number of
floating-point operations executed by the underlying program. It quickly
exceeds the available memory resources. Naive adjoint algorithmic
differentiation often becomes infeasible except for relatively simple numerical
simulations.
  Access to the data associated with the graph can be classified as sequential
and random. The latter refers to memory access patterns defined by the
adjacency relationship between vertices within the graph. Sequentially accessed
data can be decomposed into blocks. The blocks can be streamed across the
system memory hierarchy thus extending the amount of available memory, for
example, to hard discs. Asynchronous i/o can help to mitigate the increased
cost due to accesses to slower memory. Much larger problem instances can thus
be solved without resorting to technically challenging user intervention such
as checkpointing. Randomly accessed data should not have to be decomposed. Its
block-wise streaming is likely to yield a substantial overhead in computational
cost due to data accesses across blocks. Consequently, the size of the randomly
accessed memory required by an adjoint should be kept minimal in order to
eliminate the need for decomposition. We propose a combination of dedicated
memory for adjoint $L$-values with the exploitation of remainder bandwidth as a
possible solution. Test results indicate significant savings in random access
memory size while preserving overall computational efficiency.
",['\nUwe Naumann\n'],,,http://arxiv.org/abs/2207.07018v1,cs.MS,"['cs.MS', 'G.4']",,,[]
Proposed Consistent Exception Handling for the BLAS and LAPACK,http://arxiv.org/abs/2207.09281v1,2022-07-19T13:53:26Z,2022-07-19T13:53:26Z,"  Numerical exceptions, which may be caused by overflow, operations like
division by 0 or sqrt(-1), or convergence failures, are unavoidable in many
cases, in particular when software is used on unforeseen and difficult inputs.
As more aspects of society become automated, e.g., self-driving cars, health
monitors, and cyber-physical systems more generally, it is becoming
increasingly important to design software that is resilient to exceptions, and
that responds to them in a consistent way. Consistency is needed to allow users
to build higher-level software that is also resilient and consistent (and so on
recursively). In this paper we explore the design space of consistent exception
handling for the widely used BLAS and LAPACK linear algebra libraries, pointing
out a variety of instances of inconsistent exception handling in the current
versions, and propose a new design that balances consistency, complexity, ease
of use, and performance. Some compromises are needed, because there are
preexisting inconsistencies that are outside our control, including in or
between existing vendor BLAS implementations, different programming languages,
and even compilers for the same programming language. And user requests from
our surveys are quite diverse. We also propose our design as a possible model
for other numerical software, and welcome comments on our design choices.
","['\nJames Demmel\n', '\nJack Dongarra\n', '\nMark Gates\n', '\nGreg Henry\n', '\nJulien Langou\n', '\nXiaoye Li\n', '\nPiotr Luszczek\n', '\nWeslley Pereira\n', '\nJason Riedy\n', '\nCindy Rubio-González\n']",,,http://arxiv.org/abs/2207.09281v1,cs.MS,['cs.MS'],,,[]
"FFTc: An MLIR Dialect for Developing HPC Fast Fourier Transform
  Libraries",http://arxiv.org/abs/2207.06803v2,2022-07-14T10:31:21Z,2022-07-26T13:48:10Z,"  Discrete Fourier Transform (DFT) libraries are one of the most critical
software components for scientific computing. Inspired by FFTW, a widely used
library for DFT HPC calculations, we apply compiler technologies for the
development of HPC Fourier transform libraries. In this work, we introduce
FFTc, a domain-specific language, based on Multi-Level Intermediate
Representation (MLIR), for expressing Fourier Transform algorithms. We present
the initial design, implementation, and preliminary results of FFTc.
","['\nYifei He\n', '\nArtur Podobas\n', '\nMåns I. Andersson\n', '\nStefano Markidis\n']",,,http://arxiv.org/abs/2207.06803v2,cs.MS,"['cs.MS', 'cs.CL']",,,[]
"MCTensor: A High-Precision Deep Learning Library with Multi-Component
  Floating-Point",http://arxiv.org/abs/2207.08867v2,2022-07-18T18:26:43Z,2022-08-29T18:38:29Z,"  In this paper, we introduce MCTensor, a library based on PyTorch for
providing general-purpose and high-precision arithmetic for DL training.
MCTensor is used in the same way as PyTorch Tensor: we implement multiple
basic, matrix-level computation operators and NN modules for MCTensor with
identical PyTorch interface. Our algorithms achieve high precision computation
and also benefits from heavily-optimized PyTorch floating-point arithmetic. We
evaluate MCTensor arithmetic against PyTorch native arithmetic for a series of
tasks, where models using MCTensor in float16 would match or outperform the
PyTorch model with float32 or float64 precision.
","['\nTao Yu\n', '\nWentao Guo\n', '\nJianan Canal Li\n', '\nTiancheng Yuan\n', '\nChristopher De Sa\n']",HATE2022 in ICML2022,,http://arxiv.org/abs/2207.08867v2,cs.LG,"['cs.LG', 'cs.MS']",,,[]
PLSS: A Projected Linear Systems Solver,http://arxiv.org/abs/2207.07615v2,2022-07-15T17:20:07Z,2022-12-02T21:54:16Z,"  We propose iterative projection methods for solving square or rectangular
consistent linear systems Ax = b. Existing projection methods use sketching
matrices (possibly randomized) to generate a sequence of small projected
subproblems, but even the smaller systems can be costly. We develop a process
that appends one column to the sketching matrix each iteration and converges in
a finite number of iterations whether the sketch is random or deterministic. In
general, our process generates orthogonal updates to the approximate solution
xk. By choosing the sketch to be the set of all previous residuals, we obtain a
simple recursive update and convergence in at most rank(A) iterations (in exact
arithmetic). By choosing a sequence of identity columns for the sketch, we
develop a generalization of the Kaczmarz method. In experiments on large sparse
systems, our method (PLSS) with residual sketches is competitive with LSQR and
LSMR, and with residual and identity sketches compares favorably with
state-of-the-art randomized methods.
","['\nJohannes J. Brust\n', '\nMichael A. Saunders\n']",,"SIAM Journl. Sci. Comput. 45(2), 2023",http://dx.doi.org/10.1137/22M1509783,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'stat.CO', '15A06, 15B52, 65F10, 68W20, 65Y20, 90C20']",10.1137/22M1509783,,[]
"Parallelizing Explicit and Implicit Extrapolation Methods for Ordinary
  Differential Equations",http://arxiv.org/abs/2207.08135v2,2022-07-17T10:48:08Z,2022-09-10T05:14:20Z,"  Numerically solving ordinary differential equations (ODEs) is a naturally
serial process and as a result the vast majority of ODE solver software are
serial. In this manuscript we developed a set of parallelized ODE solvers using
extrapolation methods which exploit ""parallelism within the method"" so that
arbitrary user ODEs can be parallelized. We describe the specific choices made
in the implementation of the explicit and implicit extrapolation methods which
allow for generating low overhead static schedules to then exploit with
optimized multi-threaded implementations. We demonstrate that while the
multi-threading gives a noticeable acceleration on both explicit and implicit
problems, the explicit parallel extrapolation methods gave no significant
improvement over state-of-the-art even with a multi-threading advantage against
current optimized high order Runge-Kutta tableaus. However, we demonstrate that
the implicit parallel extrapolation methods are able to achieve
state-of-the-art performance (2x-4x) on standard multicore x86 CPUs for systems
of $<200$ stiff ODEs solved at low tolerance, a typical setup for a vast
majority of users of high level language equation solver suites. The resulting
method is distributed as the first widely available open source software for
within-method parallel acceleration targeting typical modest compute
architectures.
","['\n Utkarsh\n', '\nChris Elrod\n', '\nYingbo Ma\n', '\nChristopher Rackauckas\n']",6 figures,,http://arxiv.org/abs/2207.08135v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"PaMILO: A Solver for Multi-Objective Mixed Integer Linear Optimization
  and Beyond",http://arxiv.org/abs/2207.09155v2,2022-07-19T09:53:00Z,2023-04-21T13:24:20Z,"  In multi-objective optimization, several potentially conflicting objective
functions need to be optimized. Instead of one optimal solution, we look for
the set of so called non-dominated solutions.
  An important subset is the set of non-dominated extreme points. Finding it is
a computationally hard problem in general. While solvers for similar problems
exist, there are none known for multi-objective mixed integer linear programs
(MOMILPs) or multi-objective mixed integer quadratically constrained quadratic
programs (MOMIQCQPs). We present PaMILO, the first solver for finding
non-dominated extreme points of MOMILPs and MOMIQCQPs. It can be found on
github under github.com/FritzBo/PaMILO. PaMILO provides an easy-to-use
interface and is implemented in C++17. It solves occurring subproblems
employing either CPLEX or Gurobi.
  PaMILO adapts the Dual-Benson algorithm for multi-objective linear
programming (MOLP). As it was previously only defined for MOLPs, we describe
how it can be adapted for MOMILPs, MOMIQCQPs and even more problem classes in
the future.
","['\nFritz Bökler\n', '\nLevin Nemesch\n', '\nMirko H. Wagner\n']",,,http://arxiv.org/abs/2207.09155v2,cs.DM,"['cs.DM', 'cs.MS', 'math.OC']",,,[]
"A detailed introduction to density-based topology optimisation of fluid
  flow problems with implementation in MATLAB",http://arxiv.org/abs/2207.13695v1,2022-07-19T22:41:36Z,2022-07-19T22:41:36Z,"  This article presents a detailed introduction to density-based topology
optimisation of fluid flow problems. The goal is to allow new students and
researchers to quickly get started in the research area and to skip many of the
initial steps, often consuming unnecessarily long time from the scientific
advancement of the field. This is achieved by providing a step-by-step guide to
the components necessary to understand and implement the theory, as well as
extending the supplied MATLAB code. The continuous design representation used
and how it is connected to the Brinkman penalty approach, for simulating an
immersed solid in a fluid domain, is illustrated. The different interpretations
of the Brinkman penalty term and how to chose the penalty parameters are
explained. The accuracy of the Brinkman penalty approach is analysed through
parametric simulations of a reference geometry. The chosen finite element
formulation and the solution method is explained. The minimum dissipated energy
optimisation problem is defined and how to solve it using an optimality
criteria solver and a continuation scheme is discussed. The included MATLAB
implementation is documented, with details on the mesh, pre-processing,
optimisation and post-processing. The code has two benchmark examples
implemented and the application of the code to these is reviewed. Subsequently,
several modifications to the code for more complicated examples are presented
through provided code modifications and explanations. Lastly, the computational
performance of the code is examined through studies of the computational time
and memory usage, along with recommendations to decrease computational time
through approximations.
",['\nJoe Alexandersen\n'],"39 pages, 28 figures","Published in ""Structural and Multidisciplinary Optimization""
  (2023)",http://dx.doi.org/10.1007/s00158-022-03420-9,cs.CE,"['cs.CE', 'cs.MS', 'physics.flu-dyn']",10.1007/s00158-022-03420-9,,[]
"Tensor Decompositions for Count Data that Leverage Stochastic and
  Deterministic Optimization",http://arxiv.org/abs/2207.14341v2,2022-07-18T04:02:56Z,2023-08-26T21:46:53Z,"  There is growing interest to extend low-rank matrix decompositions to
multi-way arrays, or tensors. One fundamental low-rank tensor decomposition is
the canonical polyadic decomposition (CPD). The challenge of fitting a
low-rank, nonnegative CPD model to Poisson-distributed count data is of
particular interest. Several popular algorithms use local search methods to
approximate the global maximum likelihood estimator from local minima.
Simultaneously, a recent trend in theoretical computer science and numerical
linear algebra leverages randomization to solve very large, hard problems. The
typical approach is to use randomization for a fast approximation and
determinism for refinement to yield effective algorithms with theoretical
guarantees. Two popular algorithms for Poisson CPD reflect that emergent
dichotomy: CP Alternating Poisson Regression is a deterministic algorithm and
Generalized Canonical Polyadic decomposition makes use of stochastic algorithms
in several variants. This work extends recent work to develop two new methods
that leverage randomized and deterministic algorithms for improved accuracy and
performance.
","['\nJeremy M. Myers\n', '\nDaniel M. Dunlavy\n']",,,http://arxiv.org/abs/2207.14341v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.1.3; G.4']",,,[]
FLOPs as a Discriminant for Dense Linear Algebra Algorithms,http://arxiv.org/abs/2207.02070v1,2022-07-05T14:19:55Z,2022-07-05T14:19:55Z,"  Expressions that involve matrices and vectors, known as linear algebra
expressions, are commonly evaluated through a sequence of invocations to highly
optimised kernels provided in libraries such as BLAS and LAPACK. A sequence of
kernels represents an algorithm, and in general, because of associativity,
algebraic identities, and multiple kernels, one expression can be evaluated via
many different algorithms. These algorithms are all mathematically equivalent
(i.e., in exact arithmetic, they all compute the same result), but often differ
noticeably in terms of execution time. When faced with a decision, high-level
languages, libraries, and tools such as Julia, Armadillo, and Linnea choose by
selecting the algorithm that minimises the FLOP count. In this paper, we test
the validity of the FLOP count as a discriminant for dense linear algebra
algorithms, analysing ""anomalies"": problem instances for which the fastest
algorithm does not perform the least number of FLOPs.
  To do so, we focused on relatively simple expressions and analysed when and
why anomalies occurred. We found that anomalies exist and tend to cluster into
large contiguous regions. For one expression anomalies were rare, whereas for
the other they were abundant. We conclude that FLOPs is not a sufficiently
dependable discriminant even when building algorithms with highly optimised
kernels. Plus, most of the anomalies remained as such even after filtering out
the inter-kernel cache effects. We conjecture that combining FLOP counts with
kernel performance models will significantly improve our ability to choose
optimal algorithms.
","['\nFrancisco López\n', '\nLars Karlsson\n', '\nPaolo Bientinesi\n']","10 pages, 11 figures, 2 tables. Accepted in the 51st International
  Conference on Parallel Processing (ICPP'22)","Francisco L\'opez, Lars Karlsson, and Paolo Bientinesi. 2022.
  FLOPs as a Discriminant for Dense Linear Algebra Algorithms. In 51st
  International Conference on Parallel Processing (ICPP'22), August
  29-September 1, 2022, Bordeaux, France",http://dx.doi.org/10.1145/3545008.3545072,cs.PF,"['cs.PF', 'cs.MS', 'G.4']",10.1145/3545008.3545072,,[]
Tableless Calculation of Circular Functions on Dyadic Rationals,http://arxiv.org/abs/2207.00849v1,2022-07-02T14:35:33Z,2022-07-02T14:35:33Z,"  I would like to tell a story. A story about a beautiful mathematical
relationship that elucidates the computational view on the classic subject of
trigonometry. All stories need a language, and for this particular story an
algorithmic language ought to do well. What makes a language algorithmic? From
our perspective as the functional programming community, an algorithmic
language provides means to express computation in terms of functions, with no
implementation-imposed limitations. We develop a new algorithm for the
computation of trigonometric functions on dyadic rationals, together with the
language used to express it, in Scheme. We provide a mechanically-derived
algorithm for the computation of the inverses of our target functions. We
address efficiency and accuracy concerns that pertain to the implementation of
the proposed algorithm either in hardware or software.
",['\nPeter Kourzanov\nTU Delft\n'],"In Proceedings MSFP 2022, arXiv:2206.09534","EPTCS 360, 2022, pp. 45-70",http://dx.doi.org/10.4204/EPTCS.360.3,cs.DS,"['cs.DS', 'cs.MS', 'cs.PL']",10.4204/EPTCS.360.3,,['TU Delft']
"nlfem: A flexible 2d Fem Code for Nonlocal Convection-Diffusion and
  Mechanics",http://arxiv.org/abs/2207.03921v1,2022-07-08T14:22:20Z,2022-07-08T14:22:20Z,"  In this work we present the mathematical foundation of an assembly code for
finite element approximations of nonlocal models with compactly supported,
weakly singular kernels. We demonstrate the code on a nonlocal diffusion model
in various configurations and on a two-dimensional bond-based peridynamics
model. The code nlfem is published under the MIT License and can be freely
downloaded.
","['\nManuel Klar\n', '\nChristian Vollmann\n', '\nVolker Schulz\n']","22 pages, 5 figures",,http://arxiv.org/abs/2207.03921v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
hp3D User Manual,http://arxiv.org/abs/2207.12211v2,2022-06-29T15:54:16Z,2023-09-21T04:49:10Z,"  User Manual for the hp3D Finite Element Software, available on GitHub at
https://github.com/Oden-EAG/hp3d
","['\nStefan Henneking\n', '\nLeszek Demkowicz\n']",,,http://arxiv.org/abs/2207.12211v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
j-Wave: An open-source differentiable wave simulator,http://arxiv.org/abs/2207.01499v1,2022-06-30T16:19:21Z,2022-06-30T16:19:21Z,"  We present an open-source differentiable acoustic simulator, j-Wave, which
can solve time-varying and time-harmonic acoustic problems. It supports
automatic differentiation, which is a program transformation technique that has
many applications, especially in machine learning and scientific computing.
j-Wave is composed of modular components that can be easily customized and
reused. At the same time, it is compatible with some of the most popular
machine learning libraries, such as JAX and TensorFlow. The accuracy of the
simulation results for known configurations is evaluated against the widely
used k-Wave toolbox and a cohort of acoustic simulation software. j-Wave is
available from https://github.com/ucl-bug/jwave.
","['\nAntonio Stanziola\n', '\nSimon R. Arridge\n', '\nBen T. Cox\n', '\nBradley E. Treeby\n']",,,http://arxiv.org/abs/2207.01499v1,physics.comp-ph,"['physics.comp-ph', 'cs.LG', 'cs.MS', 'cs.SD', 'eess.AS', 'physics.med-ph']",,,[]
tntorch: Tensor Network Learning with PyTorch,http://arxiv.org/abs/2206.11128v2,2022-06-22T14:19:15Z,2022-09-21T07:06:51Z,"  We present tntorch, a tensor learning framework that supports multiple
decompositions (including Candecomp/Parafac, Tucker, and Tensor Train) under a
unified interface. With our library, the user can learn and handle low-rank
tensors with automatic differentiation, seamless GPU support, and the
convenience of PyTorch's API. Besides decomposition algorithms, tntorch
implements differentiable tensor algebra, rank truncation, cross-approximation,
batch processing, comprehensive tensor arithmetics, and more.
","['\nMikhail Usvyatsov\n', '\nRafael Ballester-Ripoll\n', '\nKonrad Schindler\n']",,JMLR (2022) 23-208,http://arxiv.org/abs/2206.11128v2,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"Large-Scale Direct Numerical Simulations of Turbulence Using GPUs and
  Modern Fortran",http://arxiv.org/abs/2207.07098v1,2022-06-23T12:41:19Z,2022-06-23T12:41:19Z,"  We present our approach to making direct numerical simulations of turbulence
with applications in sustainable shipping. We use modern Fortran and the
spectral element method to leverage and scale on supercomputers powered by the
Nvidia A100 and the recent AMD Instinct MI250X GPUs, while still providing
support for user software developed in Fortran. We demonstrate the efficiency
of our approach by performing the world's first direct numerical simulation of
the flow around a Flettner rotor at Re=30'000 and its interaction with a
turbulent boundary layer. We present one of the first performance comparisons
between the AMD Instinct MI250X and Nvidia A100 GPUs for scalable computational
fluid dynamics. Our results show that one MI250X offers performance on par with
two A100 GPUs and has a similar power efficiency.
","['\nMartin Karp\n', '\nDaniele Massaro\n', '\nNiclas Jansson\n', '\nAlistair Hart\n', '\nJacob Wahlgren\n', '\nPhilipp Schlatter\n', '\nStefano Markidis\n']","13 pages, 7 figures",,http://arxiv.org/abs/2207.07098v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC', 'physics.flu-dyn', 'G.4; J.2']",,,[]
"GPU-parallelisation of wavelet-based grid adaptation for fast finite
  volume modelling: application to shallow water flows",http://arxiv.org/abs/2206.05761v3,2022-06-12T15:07:38Z,2023-05-16T12:04:38Z,"  Wavelet-based grid adaptation driven by the ""multiresolution analysis"" (MRA)
of the Haar wavelet (HW) allows to devise an adaptive first-order finite volume
(FV1) model (HWFV1) that can readily preserve the modelling fidelity of its
reference uniform-grid FV1 counterpart. However, the MRA incurs a high
computational cost as it involves ""encoding"" (coarsening), ""decoding""
(refining), analysing and traversing modelled data across a deep hierarchy of
nested, uniform grids. GPU-parallelisation of the MRA is needed to reduce its
computational cost, but its algorithmic structure (1) hinders coalesced memory
access on the GPU, and (2) involves an inherently sequential tree traversal
problem. This work redesigns the algorithmic structure of the MRA in order to
parallelise it on the GPU, addressing (1) by applying Z-order space-filling
curves and addressing (2) by adopting a parallel tree traversal algorithm. This
results in a GPU-parallelised HWFV1 model (GPU-HWFV1). GPU-HWFV1 is verified
against its CPU predecessor (CPU-HWFV1) and its GPU-parallelised reference
uniform-grid counterpart (GPU-FV1) over five shallow water flow test cases.
GPU-HWFV1 preserves the modelling fidelity of GPU-FV1 while being up to 30
times faster. Compared to CPU-HWFV1, it is up to 200 times faster, suggesting
the GPU-parallelised MRA could be used to speed up other FV1 models.
","['\nAlovya Ahmed Chowdhury\n', '\nGeorges Kesserwani\n', '\nCharles Rougé\n', '\nPaul Richmond\n']",38 pages,,http://arxiv.org/abs/2206.05761v3,cs.CE,"['cs.CE', 'cs.MS']",,,[]
"qrpca: A Package for Fast Principal Component Analysis with GPU
  Acceleration",http://arxiv.org/abs/2206.06797v2,2022-06-14T12:35:24Z,2022-09-06T08:52:52Z,"  We present qrpca, a fast and scalable QR-decomposition principal component
analysis package. The software, written in both R and python languages, makes
use of torch for internal matrix computations, and enables GPU acceleration,
when available. qrpca provides similar functionalities to prcomp (R) and
sklearn (python) packages respectively. A benchmark test shows that qrpca can
achieve computational speeds 10-20 $\times$ faster for large dimensional
matrices than default implementations, and is at least twice as fast for a
standard decomposition of spectral data cubes. The qrpca source code is made
freely available to the community.
","['\nRafael S. de Souza\n', '\nXu Quanfeng\n', '\nShiyin Shen\n', '\nChen Peng\n', '\nZihao Mu\n']",,"Astronomy and Computing, 41, 100633 (2022)",http://dx.doi.org/10.1016/j.ascom.2022.100633,astro-ph.IM,"['astro-ph.IM', 'cs.MS']",10.1016/j.ascom.2022.100633,,[]
Thick-restarted joint Lanczos bidiagonalization for the GSVD,http://arxiv.org/abs/2206.03768v3,2022-06-08T09:31:06Z,2023-05-12T16:02:14Z,"  The computation of the partial generalized singular value decomposition
(GSVD) of large-scale matrix pairs can be approached by means of iterative
methods based on expanding subspaces, particularly Krylov subspaces. We
consider the joint Lanczos bidiagonalization method, and analyze the
feasibility of adapting the thick restart technique that is being used
successfully in the context of other linear algebra problems. Numerical
experiments illustrate the effectiveness of the proposed method. We also
compare the new method with an alternative solution via equivalent eigenvalue
problems, considering accuracy as well as computational performance. The
analysis is done using a parallel implementation in the SLEPc library.
","['\nFernando Alvarruiz\n', '\nCarmen Campos\n', '\nJose E. Roman\n']",,,http://arxiv.org/abs/2206.03768v3,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Flexible Differentiable Optimization via Model Transformations,http://arxiv.org/abs/2206.06135v3,2022-06-10T09:59:13Z,2023-07-31T08:04:07Z,"  We introduce DiffOpt.jl, a Julia library to differentiate through the
solution of optimization problems with respect to arbitrary parameters present
in the objective and/or constraints. The library builds upon MathOptInterface,
thus leveraging the rich ecosystem of solvers and composing well with modeling
languages like JuMP. DiffOpt offers both forward and reverse differentiation
modes, enabling multiple use cases from hyperparameter optimization to
backpropagation and sensitivity analysis, bridging constrained optimization
with end-to-end differentiable programming. DiffOpt is built on two known rules
for differentiating quadratic programming and conic programming standard forms.
However, thanks ability to differentiate through model transformation, the user
is not limited to these forms and can differentiate with respect to the
parameters of any model that can be reformulated into these standard forms.
This notably includes programs mixing affine conic constraints and convex
quadratic constraints or objective function.
","['\nMathieu Besançon\n', '\nJoaquim Dias Garcia\n', '\nBenoît Legat\n', '\nAkshay Sharma\n']",,,http://arxiv.org/abs/2206.06135v3,cs.LG,"['cs.LG', 'cs.MS', 'math.OC']",,,[]
Algorithms for Parallel Generic $hp$-adaptive Finite Element Software,http://arxiv.org/abs/2206.06512v2,2022-06-13T22:46:14Z,2023-04-27T07:25:06Z,"  The $hp$-adaptive finite element method (FEM) - where one independently
chooses the mesh size ($h$) and polynomial degree ($p$) to be used on each cell
- has long been known to have better theoretical convergence properties than
either $h$- or $p$-adaptive methods alone. However, it is not widely used,
owing at least in parts to the difficulty of the underlying algorithms and the
lack of widely usable implementations. This is particularly true when used with
continuous finite elements.
  Herein, we discuss algorithms that are necessary for a comprehensive and
generic implementation of $hp$-adaptive finite element methods on
distributed-memory, parallel machines. In particular, we will present a
multi-stage algorithm for the unique enumeration of degrees of freedom (DoFs)
suitable for continuous finite element spaces, describe considerations for
weighted load balancing, and discuss the transfer of variable size data between
processes. We illustrate the performance of our algorithms with numerical
examples, and demonstrate that they scale reasonably up to at least 16,384
Message Passing Interface (MPI) processes.
  We provide a reference implementation of our algorithms as part of the
open-source library deal.II.
","['\nMarc Fehling\n', '\nWolfgang Bangerth\n']","27 pages, 10 figures",,http://dx.doi.org/10.1145/3603372,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.1.8; G.4']",10.1145/3603372,,[]
"Accelerating CPU-Based Sparse General Matrix Multiplication With Binary
  Row Merging",http://arxiv.org/abs/2206.06611v2,2022-06-14T06:16:59Z,2022-08-19T08:13:56Z,"  Sparse general matrix multiplication (SpGEMM) is a fundamental building block
for many real-world applications. Since SpGEMM is a well-known memory-bounded
application with vast and irregular memory accesses, considering the memory
access efficiency is of critical importance for SpGEMM's performance. Yet, the
existing methods put less consideration into the memory subsystem and achieved
suboptimal performance. In this paper, we thoroughly analyze the memory access
patterns of SpGEMM and their influences on the memory subsystem. Based on the
analysis, we propose a novel and more efficient accumulation method named
BRMerge for the multi-core CPU architectures.
  The BRMerge accumulation method follows the row-wise dataflow. It first
accesses the $B$ matrix, generates the intermediate lists for one output row,
and stores these intermediate lists in a consecutive memory space, which is
implemented by a ping-pong buffer. It then immediately merges these
intermediate lists generated in the previous phase two by two in a tree-like
hierarchy between two ping-pong buffers. The architectural benefits of BRMerge
are 1) streaming access patterns, 2) minimized TLB cache miss rate, and 3)
reasonably high L1/L2 cache hit rates, which result in both low access latency
and high bandwidth utilization when performing SpGEMM. Based on the BRMerge
accumulation method, we propose two SpGEMM libraries named BRMerge-Upper and
BRMerge-Precise, which use different allocation methods. Performance
evaluations with 26 commonly used benchmarks on two CPU servers show that the
proposed SpGEMM libraries significantly outperform the state-of-the-art SpGEMM
libraries.
","['\nZhaoyang Du\n', '\nYijin Guan\n', '\nTianchan Guan\n', '\nDimin Niu\n', '\nHongzhong Zheng\n', '\nYuan Xie\n']","This work has been accepted by IEEE Access
  (DOI:10.1109/ACCESS.2022.3193937). There are 12 pages, 6 fgures, 2 tables",,http://arxiv.org/abs/2206.06611v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF', '68-02, 68W10, 65F50', 'D.1.3; G.1.3']",,,[]
"varFEM: variational formulation based programming for finite element
  methods in Matlab",http://arxiv.org/abs/2206.06918v1,2022-06-14T15:25:51Z,2022-06-14T15:25:51Z,"  This paper summarizes the development of varFEM, which provides a realization
of the programming style in FreeFEM by using the Matlab language.
",['\nYue Yu\n'],FreeFEM,,http://arxiv.org/abs/2206.06918v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Scalable First-Order Bayesian Optimization via Structured Automatic
  Differentiation",http://arxiv.org/abs/2206.08366v1,2022-06-16T17:59:48Z,2022-06-16T17:59:48Z,"  Bayesian Optimization (BO) has shown great promise for the global
optimization of functions that are expensive to evaluate, but despite many
successes, standard approaches can struggle in high dimensions. To improve the
performance of BO, prior work suggested incorporating gradient information into
a Gaussian process surrogate of the objective, giving rise to kernel matrices
of size $nd \times nd$ for $n$ observations in $d$ dimensions. Na\""ively
multiplying with (resp. inverting) these matrices requires
$\mathcal{O}(n^2d^2)$ (resp. $\mathcal{O}(n^3d^3$)) operations, which becomes
infeasible for moderate dimensions and sample sizes. Here, we observe that a
wide range of kernels gives rise to structured matrices, enabling an exact
$\mathcal{O}(n^2d)$ matrix-vector multiply for gradient observations and
$\mathcal{O}(n^2d^2)$ for Hessian observations. Beyond canonical kernel
classes, we derive a programmatic approach to leveraging this type of structure
for transformations and combinations of the discussed kernel classes, which
constitutes a structure-aware automatic differentiation algorithm. Our methods
apply to virtually all canonical kernels and automatically extend to complex
kernels, like the neural network, radial basis function network, and spectral
mixture kernels without any additional derivations, enabling flexible,
problem-dependent modeling while scaling first-order BO to high $d$.
","['\nSebastian Ament\n', '\nCarla Gomes\n']",,,http://arxiv.org/abs/2206.08366v1,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS', 'math.OC', 'stat.ML']",,,[]
"A novel statistical approach for two-sample testing based on the overlap
  coefficient",http://arxiv.org/abs/2206.03166v2,2022-06-07T10:27:23Z,2023-06-28T09:41:29Z,"  Here we propose a new nonparametric framework for two-sample testing, named
as the OVL-$q$ ($q = 1, 2, \ldots$). This can be regarded as a natural
extension of the Smirnov test, which is equivalent to the OVL-1. We
specifically focus on the OVL-2, implement its fast algorithm, and show its
superiority over other statistical tests in some experiments.
","['\nAtsushi Komaba\n', '\nHisashi Johno\n', '\nKazunori Nakamoto\n']","36 pages, 5 figures. Accepted for publication in Journal of
  Mathematical Sciences, the University of Tokyo",,http://arxiv.org/abs/2206.03166v2,math.ST,"['math.ST', 'cs.DM', 'cs.MS', 'math.PR', 'stat.ME', 'stat.TH', '62G10 (Primary), 62-04 (Secondary)']",,,[]
ARKODE: a flexible IVP solver infrastructure for one-step methods,http://arxiv.org/abs/2205.14077v2,2022-05-27T16:16:19Z,2022-12-21T21:50:25Z,"  We describe the ARKODE library of one-step time integration methods for
ordinary differential equation (ODE) initial-value problems (IVPs). In addition
to providing standard explicit and diagonally implicit Runge--Kutta methods,
ARKODE also supports one-step methods designed to treat additive splittings of
the IVP, including implicit-explicit (ImEx) additive Runge--Kutta methods and
multirate infinitesimal (MRI) methods. We present the role of ARKODE within the
SUNDIALS suite of time integration and nonlinear solver libraries, the core
ARKODE infrastructure for utilities common to large classes of one-step
methods, as well as its use of ``time stepper'' modules enabling easy
incorporation of novel algorithms into the library. Numerical results show
example problems of increasing complexity, highlighting the algorithmic
flexibility afforded through this infrastructure, and include a larger
multiphysics application leveraging multiple algorithmic features from ARKODE
and SUNDIALS.
","['\nDaniel R. Reynolds\n', '\nDavid J. Gardner\n', '\nCarol S. Woodward\n', '\nRujeko Chinomona\n']",,,http://dx.doi.org/10.1145/3594632,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1145/3594632,,[]
"bsnsing: A decision tree induction method based on recursive optimal
  boolean rule composition",http://arxiv.org/abs/2205.15263v1,2022-05-30T17:13:57Z,2022-05-30T17:13:57Z,"  This paper proposes a new mixed-integer programming (MIP) formulation to
optimize split rule selection in the decision tree induction process, and
develops an efficient search algorithm that is able to solve practical
instances of the MIP model faster than commercial solvers. The formulation is
novel for it directly maximizes the Gini reduction, an effective split
selection criterion which has never been modeled in a mathematical program for
its nonconvexity. The proposed approach differs from other optimal
classification tree models in that it does not attempt to optimize the whole
tree, therefore the flexibility of the recursive partitioning scheme is
retained and the optimization model is more amenable. The approach is
implemented in an open-source R package named bsnsing. Benchmarking experiments
on 75 open data sets suggest that bsnsing trees are the most capable of
discriminating new cases compared to trees trained by other decision tree codes
including the rpart, C50, party and tree packages in R. Compared to other
optimal decision tree packages, including DL8.5, OSDT, GOSDT and indirectly
more, bsnsing stands out in its training speed, ease of use and broader
applicability without losing in prediction accuracy.
",['\nYanchao Liu\n'],,,http://arxiv.org/abs/2205.15263v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
Holistic Generalized Linear Models,http://arxiv.org/abs/2205.15447v1,2022-05-30T22:08:47Z,2022-05-30T22:08:47Z,"  Holistic linear regression extends the classical best subset selection
problem by adding additional constraints designed to improve the model quality.
These constraints include sparsity-inducing constraints, sign-coherence
constraints and linear constraints. The $\textsf{R}$ package $\texttt{holiglm}$
provides functionality to model and fit holistic generalized linear models. By
making use of state-of-the-art conic mixed-integer solvers, the package can
reliably solve GLMs for Gaussian, binomial and Poisson responses with a
multitude of holistic constraints. The high-level interface simplifies the
constraint specification and can be used as a drop-in replacement for the
$\texttt{stats::glm()}$ function.
","['\nBenjamin Schwendinger\n', '\nFlorian Schwendinger\n', '\nLaura Vana\n']","34 pages, 2 figures, 4 tables",,http://arxiv.org/abs/2205.15447v1,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS', 'math.OC']",,,[]
"Enhancing data locality of the conjugate gradient method for high-order
  matrix-free finite-element implementations",http://arxiv.org/abs/2205.08909v1,2022-05-18T13:04:00Z,2022-05-18T13:04:00Z,"  This work investigates a variant of the conjugate gradient (CG) method and
embeds it into the context of high-order finite-element schemes with fast
matrix-free operator evaluation and cheap preconditioners like the matrix
diagonal. Relying on a data-dependency analysis and appropriate enumeration of
degrees of freedom, we interleave the vector updates and inner products in a CG
iteration with the matrix-vector product with only minor organizational
overhead. As a result, around 90% of the vector entries of the three active
vectors of the CG method are transferred from slow RAM memory exactly once per
iteration, with all additional access hitting fast cache memory. Node-level
performance analyses and scaling studies on up to 147k cores show that the CG
method with the proposed performance optimizations is around two times faster
than a standard CG solver as well as optimized pipelined CG and s-step CG
methods for large sizes that exceed processor caches, and provides similar
performance near the strong scaling limit.
","['\nMartin Kronbichler\n', '\nDmytro Sashko\n', '\nPeter Munch\n']","19 pages, 14 figures",,http://arxiv.org/abs/2205.08909v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'G.4']",,,[]
"pISTA: preconditioned Iterative Soft Thresholding Algorithm for
  Graphical Lasso",http://arxiv.org/abs/2205.10027v2,2022-05-20T08:48:26Z,2023-10-17T11:07:10Z,"  We propose a novel quasi-Newton method for solving the sparse inverse
covariance estimation problem also known as the graphical least absolute
shrinkage and selection operator (GLASSO). This problem is often solved using a
second-order quadratic approximation. However, in such algorithms the Hessian
term is complex and computationally expensive to handle. Therefore, our method
uses the inverse of the Hessian as a preconditioner to simplify and approximate
the quadratic element at the cost of a more complex \(\ell_1\) element. The
variables of the resulting preconditioned problem are coupled only by the
\(\ell_1\) sub-derivative of each other, which can be guessed with minimal cost
using the gradient itself, allowing the algorithm to be parallelized and
implemented efficiently on GPU hardware accelerators. Numerical results on
synthetic and real data demonstrate that our method is competitive with other
state-of-the-art approaches.
","['\nGal Shalom\n', '\nEran Treister\n', '\nIrad Yavneh\n']",,,http://arxiv.org/abs/2205.10027v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
VWSIM: A Circuit Simulator,http://arxiv.org/abs/2205.11698v1,2022-05-24T01:16:21Z,2022-05-24T01:16:21Z,"  VWSIM is a circuit simulator for rapid, single-flux, quantum (RSFQ) circuits.
The simulator is designed to model and simulate primitive-circuit devices such
as capacitors, inductors, Josephson Junctions, and can be extended to simulate
other circuit families, such as CMOS. Circuit models can be provided in the
native VWSIM netlist format or as SPICE-compatible netlists, which are
flattened and transformed into symbolic equations that can be manipulated and
simulated. Written in the ACL2 logic, VWSIM provides logical guarantees about
each of the circuit models it simulates. Note, our matrix solving and
evaluation routines use Common Lisp floating-point numbers, and work is ongoing
to admit these models into ACL2. We currently use VWSIM to help us design
self-timed, RSFQ-based circuits. Our eventual goal is to prove properties of
RSFQ circuit models. The ACL2-based definition of the VWSIM simulator offers a
path for specifying and verifying RSFQ circuit models.
","['\nWarren A. Hunt Jr.\nThe University of Texas, ForrestHunt, Inc.\n', '\nVivek Ramanathan\nThe University of Texas, ForrestHunt, Inc.\n', '\nJ Strother Moore\nThe University of Texas, ForrestHunt, Inc.\n']","In Proceedings ACL2 2022, arXiv:2205.11103","EPTCS 359, 2022, pp. 61-75",http://dx.doi.org/10.4204/EPTCS.359.7,cs.LO,"['cs.LO', 'cs.MS', 'cs.SC', 'B.1.2; B.7.2; D.1.1; D.2.4; F.3.1; F.4.1; G.1.3; I.1.3; I.2.3;\n  I.6.4; J.2']",10.4204/EPTCS.359.7,,"['The University of Texas, ForrestHunt, Inc.', 'The University of Texas, ForrestHunt, Inc.', 'The University of Texas, ForrestHunt, Inc.']"
"Accelerating High-Order Mesh Optimization Using Finite Element Partial
  Assembly on GPUs",http://arxiv.org/abs/2205.12721v2,2022-05-24T00:50:44Z,2022-12-02T00:39:59Z,"  In this paper we present a new GPU-oriented mesh optimization method based on
high-order finite elements. Our approach relies on node movement with fixed
topology, through the Target-Matrix Optimization Paradigm (TMOP) and uses a
global nonlinear solve over the whole computational mesh, i.e., all mesh nodes
are moved together. A key property of the method is that the mesh optimization
process is recast in terms of finite element operations, which allows us to
utilize recent advances in the field of GPU-accelerated high-order finite
element algorithms. For example, we reduce data motion by using tensor
factorization and matrix-free methods, which have superior performance
characteristics compared to traditional full finite element matrix assembly and
offer advantages for GPU-based HPC hardware. We describe the major mathematical
components of the method along with their efficient GPU-oriented
implementation. In addition, we propose an easily reproducible mesh
optimization test that can serve as a performance benchmark for the mesh
optimization community.
","['\nJean-Sylvain Camier\n', '\nVeselin Dobrev\n', '\nPatrick Knupp\n', '\nTzanio Kolev\n', '\nKetan Mittal\n', '\nRobert Rieben\n', '\nVladimir Tomov\n']","28 pages, 10 figures, 3 tables",,http://dx.doi.org/10.1016/j.jcp.2022.111808,cs.MS,"['cs.MS', 'cs.DC', 'physics.comp-ph']",10.1016/j.jcp.2022.111808,,[]
"Exasim: Generating Discontinuous Galerkin Codes for Numerical Solutions
  of Partial Differential Equations on Graphics Processors",http://arxiv.org/abs/2205.07824v1,2022-05-16T17:28:28Z,2022-05-16T17:28:28Z,"  This paper presents an overview of the functionalities and applications of
Exasim, an open-source code for generating high-order discontinuous Galerkin
codes to numerically solve parametrized partial differential equations (PDEs).
The software combines high-level and low-level languages to construct
parametrized PDE models via Julia, Python or Matlab scripts and produce
high-performance C++ codes for solving the PDE models on CPU and Nvidia GPU
processors with distributed memory. Exasim provides matrix-free discontinuous
Galerkin discretization schemes together with scalable reduced basis
preconditioners and Newton-GMRES solvers, making it suitable for accurate and
efficient approximation of wide-ranging classes of PDEs.
","['\nJordi Vila-Pérez\n', '\nR. Loek Van Heyningen\n', '\nNgoc-Cuong Nguyen\n', '\nJaume Peraire\n']","19 pages, 4 figures, 3 tables",,http://arxiv.org/abs/2205.07824v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.NA', 'math.NA', 'physics.comp-ph', 'physics.flu-dyn', '65M60, 65Y05, 65Y10, 65Z05, 68N99']",,,[]
"Residual regularization path-following methods for linear
  complementarity problems",http://arxiv.org/abs/2205.10727v2,2022-05-22T03:47:30Z,2023-01-29T01:43:18Z,"  In this article, we consider the residual regularization path-following
method with the trust-region updating strategy for the linear complementarity
problem. This time-stepping selection based on the trust-region updating
strategy overcomes the shortcoming of the line search method, which consumes
the unnecessary trial steps in the transient-state phase. In order to improve
the robustness of the path-following method, we use the residual regularization
parameter to replace the traditional complementarity regularization parameter.
Moreover, we prove the global convergence of the new method under the standard
assumptions without the traditional assumption condition of the priority to
feasibility over complementarity. Numerical results show that the new method is
robust and efficient for the linear complementarity problem, especially for the
dense cases. And it is more robust and faster than some state-of-the-art
solvers such as the built-in subroutines PATH and MILES of the GAMS v28.2
(2019) environment. The computational time of the new method is about 1/3 to
1/10 of that of PATH for the dense linear complementarity problem.
","['\nXin-long Luo\n', '\nSen Zhang\n', '\nHang Xiao\n']",,,http://arxiv.org/abs/2205.10727v2,math.OC,"['math.OC', 'cs.CE', 'cs.MS', 'cs.NA', 'math.DS', 'math.NA']",,,[]
MATLAB implementation of hp finite elements on rectangles,http://arxiv.org/abs/2205.07637v1,2022-05-10T15:50:54Z,2022-05-10T15:50:54Z,"  A simple MATLAB implementation of hierarchical shape functions on 2D
rectangles is explained and available for download. Global shape functions are
ordered for a given polynomial degree according to the indices of the nodes,
edges, or elements to which they belong. For a uniform p-refinement, the
hierarchical structure enables an effective assembly of mass and stiffness
matrices. A solution of a boundary value problem is approximated for various
levels of uniform h and p refinements.
","['\nAlexej Moskovka\n', '\nJan Valdman\n']","12 pages, 6 figures",,http://arxiv.org/abs/2205.07637v1,cs.MS,['cs.MS'],,,[]
KiT-RT: An extendable framework for radiative transfer and therapy,http://arxiv.org/abs/2205.08417v1,2022-05-12T12:30:24Z,2022-05-12T12:30:24Z,"  In this paper we present KiT-RT (Kinetic Transport Solver for Radiation
Therapy), an open-source C++ based framework for solving kinetic equations in
radiation therapy applications. The aim of this code framework is to provide a
collection of classical deterministic solvers for unstructured meshes that
allow for easy extendability. Therefore, KiT-RT is a convenient base to test
new numerical methods in various applications and compare them against
conventional solvers. The implementation includes spherical-harmonics, minimal
entropy, neural minimal entropy and discrete ordinates methods. Solution
characteristics and efficiency are presented through several test cases ranging
from radiation transport to electron radiation therapy. Due to the variety of
included numerical methods and easy extendability, the presented open source
code is attractive for both developers, who want a basis to build their own
numerical solvers and users or application engineers, who want to gain
experimental insights without directly interfering with the codebase.
","['\nJonas Kusch\n', '\nSteffen Schotthöfer\n', '\nPia Stammer\n', '\nJannick Wolters\n', '\nTianbai Xiao\n']","28 pages, 15 figures, journal submission",,http://arxiv.org/abs/2205.08417v1,physics.med-ph,"['physics.med-ph', 'cs.MS', '65M08', 'G.4; J.2']",,,[]
"ChASE -- A Distributed Hybrid CPU-GPU Eigensolver for Large-scale
  Hermitian Eigenvalue Problems",http://arxiv.org/abs/2205.02491v1,2022-05-05T08:01:25Z,2022-05-05T08:01:25Z,"  As modern massively parallel clusters are getting larger with beefier compute
nodes, traditional parallel eigensolvers, such as direct solvers, struggle
keeping the pace with the hardware evolution and being able to scale
efficiently due to additional layers of communication and synchronization. This
difficulty is especially important when porting traditional libraries to
heterogeneous computing architectures equipped with accelerators, such as
Graphics Processing Unit (GPU). Recently, there have been significant
scientific contributions to the development of filter-based subspace
eigensolver to compute partial eigenspectrum. The simpler structure of these
type of algorithms makes for them easier to avoid the communication and
synchronization bottlenecks typical of direct solvers. The Chebyshev
Accelerated Subspace Eigensolver (ChASE) is a modern subspace eigensolver to
compute partial extremal eigenpairs of large-scale Hermitian eigenproblems with
the acceleration of a filter based on Chebyshev polynomials. In this work, we
extend our previous work on ChASE by adding support for distributed hybrid
CPU-multi-GPU computing architectures. Our tests show that ChASE achieves very
good scaling performance up to 144 nodes with 526 NVIDIA A100 GPUs in total on
dense eigenproblems of size up to $360$k.
","['\nXinzhe Wu\n', '\nDavor Davidovic\n', '\nSebastian Achilles\n', '\nEdoardo Di Napoli\n']",Accepted for publication on the Proceedings of the PASC22 Conference,,http://arxiv.org/abs/2205.02491v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
"GOCPT: Generalized Online Canonical Polyadic Tensor Factorization and
  Completion",http://arxiv.org/abs/2205.03749v1,2022-05-08T01:11:24Z,2022-05-08T01:11:24Z,"  Low-rank tensor factorization or completion is well-studied and applied in
various online settings, such as online tensor factorization (where the
temporal mode grows) and online tensor completion (where incomplete slices
arrive gradually). However, in many real-world settings, tensors may have more
complex evolving patterns: (i) one or more modes can grow; (ii) missing entries
may be filled; (iii) existing tensor elements can change. Existing methods
cannot support such complex scenarios. To fill the gap, this paper proposes a
Generalized Online Canonical Polyadic (CP) Tensor factorization and completion
framework (named GOCPT) for this general setting, where we maintain the CP
structure of such dynamic tensors during the evolution. We show that existing
online tensor factorization and completion setups can be unified under the
GOCPT framework. Furthermore, we propose a variant, named GOCPTE, to deal with
cases where historical tensor elements are unavailable (e.g., privacy
protection), which achieves similar fitness as GOCPT but with much less
computational cost. Experimental results demonstrate that our GOCPT can improve
fitness by up to 2:8% on the JHU Covid data and 9:2% on a proprietary patient
claim dataset over baselines. Our variant GOCPTE shows up to 1:2% and 5:5%
fitness improvement on two datasets with about 20% speedup compared to the best
model.
","['\nChaoqi Yang\n', '\nCheng Qian\n', '\nJimeng Sun\n']","To appear in IJCAI 2022. This is the full version with Appendix. Use
  our software: `pip install GOCPT`, which is open-sourced in
  https://github.com/ycq091044/GOCPT",,http://arxiv.org/abs/2205.03749v1,cs.LG,"['cs.LG', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"A matrix-free high-order solver for the numerical solution of cardiac
  electrophysiology",http://arxiv.org/abs/2205.05136v3,2022-05-10T19:36:35Z,2023-01-31T12:42:14Z,"  We propose a matrix-free solver for the numerical solution of the cardiac
electrophysiology model consisting of the monodomain nonlinear
reaction-diffusion equation coupled with a system of ordinary differential
equations for the ionic species. Our numerical approximation is based on the
high-order Spectral Element Method (SEM) to achieve accurate numerical
discretization while employing a much smaller number of Degrees of Freedom than
first-order Finite Elements. We combine vectorization with sum-factorization,
thus allowing for a very efficient use of high-order polynomials in a high
performance computing framework. We validate the effectiveness of our
matrix-free solver in a variety of applications and perform different
electrophysiological simulations ranging from a simple slab of cardiac tissue
to a realistic four-chamber heart geometry. We compare SEM to SEM with
Numerical Integration (SEM-NI), showing that they provide comparable results in
terms of accuracy and efficiency. In both cases, increasing the local
polynomial degree $p$ leads to better numerical results and smaller
computational times than reducing the mesh size $h$. We also implement a
matrix-free Geometric Multigrid preconditioner that results in a comparable
number of linear solver iterations with respect to a state-of-the-art
matrix-based Algebraic Multigrid preconditioner. As a matter of fact, the
matrix-free solver proposed here yields up to 45$\times$ speed-up with respect
to a conventional matrix-based solver.
","['\nPasquale Claudio Africa\n', '\nMatteo Salvador\n', '\nPaola Gervasio\n', ""\nLuca Dede'\n"", '\nAlfio Quarteroni\n']",,,http://dx.doi.org/10.1016/j.jcp.2023.111984,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65Y20, 65F50 (Primary) 65M55, 65M60, 65M70, 65Z05 (Secondary)', 'G.1; G.4; J.3']",10.1016/j.jcp.2023.111984,,[]
Compositional Modeling with Stock and Flow Diagrams,http://arxiv.org/abs/2205.08373v3,2022-05-09T06:13:12Z,2023-07-31T10:28:03Z,"  Stock and flow diagrams are widely used in epidemiology to model the dynamics
of populations. Although tools already exist for building these diagrams and
simulating the systems they describe, we have created a new package called
StockFlow, part of the AlgebraicJulia ecosystem, which uses ideas from category
theory to overcome notable limitations of existing software. Compositionality
is provided by the theory of decorated cospans: stock and flow diagrams can be
composed to form larger ones in an intuitive way formalized by the operad of
undirected wiring diagrams. Our approach also cleanly separates the syntax of
stock and flow diagrams from the semantics they can be assigned. We consider
semantics in ordinary differential equations, although others are possible. As
an example, we explain code in StockFlow that implements a simplified version
of a COVID-19 model used in Canada.
","['\nJohn Baez\nDepartment of Mathematics, University of California, Riverside\n', '\nXiaoyan Li\nDepartment of Computer Science, University of Saskatchewan\n', '\nSophie Libkind\nDepartment of Mathematics, Stanford University\n', '\nNathaniel D. Osgood\nDepartment of Computer Science, University of Saskatchewan\n', '\nEvan Patterson\nTopos Institute\n']","In Proceedings ACT 2022, arXiv:2307.15519","EPTCS 380, 2023, pp. 77-96",http://dx.doi.org/10.4204/EPTCS.380.5,cs.LO,"['cs.LO', 'cs.MS', 'math.CT', 'q-bio.PE']",10.4204/EPTCS.380.5,,"['Department of Mathematics, University of California, Riverside', 'Department of Computer Science, University of Saskatchewan', 'Department of Mathematics, Stanford University', 'Department of Computer Science, University of Saskatchewan', 'Topos Institute']"
"Automated Generation of High-Performance Computational Fluid Dynamics
  Codes",http://arxiv.org/abs/2204.12120v2,2022-04-26T07:26:36Z,2022-04-27T06:50:57Z,"  Domain-Specific Languages (DSLs) improve programmers productivity by
decoupling problem descriptions from algorithmic implementations. However, DSLs
for High-Performance Computing (HPC) have two additional critical requirements:
performance and scalability. This paper presents the automated process of
generating, from abstract mathematical specifications of Computational Fluid
Dynamics (CFD) problems, optimised parallel codes that perform and scale as
manually optimised ones. We consciously combine within Saiph, a DSL for solving
CFD problems, low-level optimisations and parallelisation strategies, enabling
high-performance single-core executions which effectively scale to multi-core
and distributed environments. Our results demonstrate how high-level DSLs can
offer competitive performance by transparently leveraging state-of-the-art HPC
techniques.
","['\nSandra Macià\n', '\nPedro J. Martıínez-Ferrer\n', '\nEduard Ayguadé\n', '\nVicenç Beltran\n']","30 pages, 18 figures. Postprint submitted to the Journal of
  Computational Science (Elsevier). Article updated with reviewers' comments,
  additional material in section 4.3 including figures and correction of typos","Journal of Computational Science Volume 61, May 2022, 101664",http://dx.doi.org/10.1016/j.jocs.2022.101664,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC', 'D.1.3; J.2']",10.1016/j.jocs.2022.101664,,[]
"Black-Scholes Option Pricing on Intel CPUs and GPUs: Implementation on
  SYCL and Optimization Techniques",http://arxiv.org/abs/2204.13740v2,2022-04-28T18:54:47Z,2022-12-19T10:31:27Z,"  The Black-Scholes option pricing problem is one of the widely used financial
benchmarks. We explore the possibility of developing a high-performance
portable code using the SYCL (Data Parallel C++) programming language. We start
from a C++ code parallelized with OpenMP and show optimization techniques that
are beneficial on modern Intel Xeon CPUs. Then, we port the code to SYCL and
consider important optimization aspects on CPUs and GPUs (device-friendly
memory access patterns, relevant data management, employing vector data types).
We show that the developed SYCL code is only 10% inferior to the optimized C++
code when running on CPUs while achieving reasonable performance on Intel GPUs.
We hope that our experience of developing and optimizing the code on SYCL can
be useful to other researchers who plan to port their high-performance C++
codes to SYCL to get all the benefits of single-source programming.
","['\nElena Panova\n', '\nValentin Volokitin\n', '\nAnton Gorshkov\n', '\nIosif Meyerov\n']","15 pages, 2 figures","Lecture Notes in Computer Science, vol 13708 (Springer, Cham),
  2022, pp. 48-62",http://dx.doi.org/10.1007/978-3-031-22941-1_4,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",10.1007/978-3-031-22941-1_4,,[]
"Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with
  Grammar-Guided Genetic Programming",http://arxiv.org/abs/2204.12846v2,2022-04-27T11:13:34Z,2022-04-28T12:07:44Z,"  Solving the indefinite Helmholtz equation is not only crucial for the
understanding of many physical phenomena but also represents an
outstandingly-difficult benchmark problem for the successful application of
numerical methods. Here we introduce a new approach for evolving efficient
preconditioned iterative solvers for Helmholtz problems with multi-objective
grammar-guided genetic programming. Our approach is based on a novel
context-free grammar, which enables the construction of multigrid
preconditioners that employ a tailored sequence of operations on each
discretization level. To find solvers that generalize well over the given
domain, we propose a custom method of successive problem difficulty adaption,
in which we evaluate a preconditioner's efficiency on increasingly
ill-conditioned problem instances. We demonstrate our approach's effectiveness
by evolving multigrid-based preconditioners for a two-dimensional indefinite
Helmholtz problem that outperform several human-designed methods for different
wavenumbers up to systems of linear equations with more than a million
unknowns.
","['\nJonas Schmitt\n', '\nHarald Köstler\n']",,"Proceedings of the 2022 Genetic and Evolutionary Computation
  Conference (Boston, USA) (GECCO '22)",http://dx.doi.org/10.1145/3512290.3528688,math.NA,"['math.NA', 'cs.AI', 'cs.MS', 'cs.NA', 'cs.NE']",10.1145/3512290.3528688,,[]
"ParticLS: Object-oriented software for discrete element methods and
  peridynamics",http://arxiv.org/abs/2204.10855v1,2022-04-19T17:42:33Z,2022-04-19T17:42:33Z,"  ParticLS (\emph{Partic}le \emph{L}evel \emph{S}ets) is a software library
that implements the discrete element method (DEM) and meshfree methods.
ParticLS tracks the interaction between individual particles whose geometries
are defined by level sets capable of capturing complex shapes. These particles
either represent rigid bodies or material points within a continuum.
Particle-particle interactions using various contact laws numerically
approximate solutions to energy and mass conservation equations, simulating
rigid body dynamics or deformation/fracture. By leveraging multiple contact
laws, ParticLS can simulate interacting bodies that deform, fracture, and are
composed of many particles. In the continuum setting, we numerically solve the
peridynamic equations -- integro-differential equations capable of modeling
objects with discontinuous displacement fields and complex fracture dynamics.
We show that the discretized peridynamic equations can be solved using the same
software infrastructure that implements the DEM. Therefore, we design a unique
software library where users can easily add particles with arbitrary geometries
and new contact laws that model either rigid-body interaction or peridynamic
constitutive relationships. We demonstrate ParticLS' versatility on test
problems meant to showcase features applicable to a broad selection of fields
such as tectonics, granular media, multiscale simulations, glacier calving, and
sea ice.
","['\nAndrew D. Davis\n', '\nBrendan A. West\n', '\nNathanael J. Frisch\n', ""\nDevin T. O'Connor\n"", '\nMatthew D. Parno\n']",,Computational Particle Mechanics (2021),http://dx.doi.org/10.1007/s40571-021-00392-3,cs.MS,"['cs.MS', 'cs.CE']",10.1007/s40571-021-00392-3,,[]
"Iterative PDE-constrained optimization for seismic full-waveform
  inversion",http://arxiv.org/abs/2204.06489v1,2022-04-13T16:17:28Z,2022-04-13T16:17:28Z,"  This paper presents a novel numerical method for the Newton seismic
full-waveform inversion (FWI). The method is based on the full-space approach,
where the state, adjoint state, and control variables are optimized
simultaneously. Each Newton step is formulated as a PDE-constrained
optimization problem, which is cast in the form of the Karush-Kuhn-Tucker (KKT)
system of linear algebraic equitations. The KKT system is solved inexactly with
a preconditioned Krylov solver. We introduced two preconditioners: the one
based on the block-triangular factorization and its variant with an inexact
block solver. The method was benchmarked against the standard truncated Newton
FWI scheme on a part of the Marmousi velocity model. The algorithm demonstrated
a considerable runtime reduction compared to the standard FWI. Moreover, the
presented approach has a great potential for further acceleration. The central
result of this paper is that it establishes the feasibility of Newton-type
optimization of the KKT system in application to the seismic FWI.
","['\nM. Malovichko\n', '\nA. Orazbayev\n', '\nN. Khokhlov\n']",,,http://arxiv.org/abs/2204.06489v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'physics.geo-ph']",,,[]
"auton-survival: an Open-Source Package for Regression, Counterfactual
  Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data",http://arxiv.org/abs/2204.07276v4,2022-04-15T00:24:56Z,2022-08-03T10:27:05Z,"  Applications of machine learning in healthcare often require working with
time-to-event prediction tasks including prognostication of an adverse event,
re-hospitalization or death. Such outcomes are typically subject to censoring
due to loss of follow up. Standard machine learning methods cannot be applied
in a straightforward manner to datasets with censored outcomes. In this paper,
we present auton-survival, an open-source repository of tools to streamline
working with censored time-to-event or survival data. auton-survival includes
tools for survival regression, adjustment in the presence of domain shift,
counterfactual estimation, phenotyping for risk stratification, evaluation, as
well as estimation of treatment effects. Through real world case studies
employing a large subset of the SEER oncology incidence data, we demonstrate
the ability of auton-survival to rapidly support data scientists in answering
complex health and epidemiological questions.
","['\nChirag Nagpal\n', '\nWilla Potosnak\n', '\nArtur Dubrawski\n']",,,http://arxiv.org/abs/2204.07276v4,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
Massively scalable stencil algorithm,http://arxiv.org/abs/2204.03775v1,2022-04-07T23:27:51Z,2022-04-07T23:27:51Z,"  Stencil computations lie at the heart of many scientific and industrial
applications. Unfortunately, stencil algorithms perform poorly on machines with
cache based memory hierarchy, due to low re-use of memory accesses. This work
shows that for stencil computation a novel algorithm that leverages a localized
communication strategy effectively exploits the Cerebras WSE-2, which has no
cache hierarchy. This study focuses on a 25-point stencil finite-difference
method for the 3D wave equation, a kernel frequently used in earth modeling as
numerical simulation. In essence, the algorithm trades memory accesses for data
communication and takes advantage of the fast communication fabric provided by
the architecture. The algorithm -- historically memory bound -- becomes compute
bound. This allows the implementation to achieve near perfect weak scaling,
reaching up to 503 TFLOPs on WSE-2, a figure that only full clusters can
eventually yield.
","['\nMathias Jacquelin\n', '\nMauricio Araya-Polo\n', '\nJie Meng\n']",10 pages excl. bibliography. Submitted to SuperComputing 2022,,http://arxiv.org/abs/2204.03775v1,cs.MS,['cs.MS'],,,[]
mVEM: A MATLAB Software Package for the Virtual Element Methods,http://arxiv.org/abs/2204.01339v1,2022-04-04T09:22:42Z,2022-04-04T09:22:42Z,"  This paper summarizes the development of mVEM, a MATLAB software package
containing efficient and easy-following codes for various virtual element
methods (VEMs) published in the literature. We explain in detail the numerical
implementation of the mixed VEMs for the Darcy problem and the
three-dimensional linear VEMs for the Poisson equation. For other model
problems, we present the construction of the discrete methods and only provide
the implementation of the elliptic projection matrices. Some mesh related
functions are also given in the package, including the mesh generation and
refinement in two or three dimensions. mVEM is free and open source software.
",['\nYue Yu\n'],mVEM,,http://arxiv.org/abs/2204.01339v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"GPSAF: A Generalized Probabilistic Surrogate-Assisted Framework for
  Constrained Single- and Multi-objective Optimization",http://arxiv.org/abs/2204.04054v1,2022-04-06T13:22:30Z,2022-04-06T13:22:30Z,"  Significant effort has been made to solve computationally expensive
optimization problems in the past two decades, and various optimization methods
incorporating surrogates into optimization have been proposed. Most research
focuses on either exploiting the surrogate by defining a utility optimization
problem or customizing an existing optimization method to use one or multiple
approximation models. However, only a little attention has been paid to generic
concepts applicable to different types of algorithms and optimization problems
simultaneously. Thus this paper proposes a generalized probabilistic
surrogate-assisted framework (GPSAF), applicable to a broad category of
unconstrained and constrained, single- and multi-objective optimization
algorithms. The idea is based on a surrogate assisting an existing optimization
method. The assistance is based on two distinct phases, one facilitating
exploration and another exploiting the surrogates. The exploration and
exploitation of surrogates are automatically balanced by performing a
probabilistic knockout tournament among different clusters of solutions. A
study of multiple well-known population-based optimization algorithms is
conducted with and without the proposed surrogate assistance on single- and
multi-objective optimization problems with a maximum solution evaluation budget
of 300 or less. The results indicate the effectiveness of applying GPSAF to an
optimization algorithm and the competitiveness with other surrogate-assisted
algorithms.
","['\nJulian Blank\n', '\nKalyanmoy Deb\n']",,,http://arxiv.org/abs/2204.04054v1,math.OC,"['math.OC', 'cs.LG', 'cs.MS', '68U07', 'G.1.6; G.1.2; I.6.3']",,,[]
Performance Portable Solid Mechanics via Matrix-Free $p$-Multigrid,http://arxiv.org/abs/2204.01722v3,2022-04-04T04:41:24Z,2022-05-24T02:07:28Z,"  Finite element analysis of solid mechanics is a foundational tool of modern
engineering, with low-order finite element methods and assembled sparse
matrices representing the industry standard for implicit analysis. We use
performance models and numerical experiments to demonstrate that high-order
methods greatly reduce the costs to reach engineering tolerances while enabling
effective use of GPUs; these data structures also offer up to 2x benefit for
linear elements. We demonstrate the reliability, efficiency, and scalability of
matrix-free $p$-multigrid methods with algebraic multigrid coarse solvers
through large deformation hyperelastic simulations of multiscale structures. We
investigate accuracy, cost, and execution time on multi-node CPU and GPU
systems for moderate to large models (millions to billions of degrees of
freedom) using AMD MI250X (OLCF Crusher), NVIDIA A100 (NERSC Perlmutter), and
V100 (LLNL Lassen and OLCF Summit), resulting in order of magnitude efficiency
improvements over a broad range of model properties and scales. We discuss
efficient matrix-free representation of Jacobians and demonstrate how automatic
differentiation enables rapid development of nonlinear material models without
impacting debuggability and workflows targeting GPUs. The methods are broadly
applicable and amenable to common workflows, presented here via open source
libraries that encapsulate all GPU-specific aspects and are accessible to both
new and legacy code, allowing application code to be GPU-oblivious without
compromising end-to-end performance on GPUs.
","['\nJed Brown\n', '\nValeria Barra\n', '\nNatalie Beams\n', '\nLeila Ghaffari\n', '\nMatthew Knepley\n', '\nWilliam Moses\n', '\nRezgar Shakeri\n', '\nKaren Stengel\n', '\nJeremy L. Thompson\n', '\nJunchao Zhang\n']",,,http://arxiv.org/abs/2204.01722v3,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC', 'cs.NA', 'math.NA', 'G.1.8; G.1.5; G.1.10; G.4; J.2; J.6; D.1.3']",,,[]
"sympy2c: from symbolic expressions to fast C/C++ functions and ODE
  solvers in Python",http://arxiv.org/abs/2203.11945v1,2022-03-22T15:51:55Z,2022-03-22T15:51:55Z,"  Computer algebra systems play an important role in science as they facilitate
the development of new theoretical models. The resulting symbolic equations are
often implemented in a compiled programming language in order to provide fast
and portable codes for practical applications. We describe sympy2c, a new
Python package designed to bridge the gap between the symbolic development and
the numerical implementation of a theoretical model. sympy2c translates
symbolic equations implemented in the SymPy Python package to C/C++ code that
is optimized using symbolic transformations. The resulting functions can be
conveniently used as an extension module in Python. sympy2c is used within the
PyCosmo Python package to solve the Einstein-Boltzmann equations, a large
system of ODEs describing the evolution of linear perturbations in the
Universe. After reviewing the functionalities and usage of sympy2c, we describe
its implementation and optimization strategies. This includes, in particular, a
novel approach to generate optimized ODE solvers making use of the sparsity of
the symbolic Jacobian matrix. We demonstrate its performance using the
Einstein-Boltzmann equations as a test case. sympy2c is widely applicable and
may prove useful for various areas of computational physics. sympy2c is
publicly available at
https://cosmology.ethz.ch/research/software-lab/sympy2c.html
","['\nUwe Schmitt\n', '\nBeatrice Moser\n', '\nChristiane S. Lorenz\n', '\nAlexandre Refregier\n']","28 pages, 5 figures, 5 tables, Link to package:
  https://cosmology.ethz.ch/research/software-lab/sympy2c.html, the described
  packaged sympy2c is used within arXiv:2112.08395",,http://arxiv.org/abs/2203.11945v1,astro-ph.IM,"['astro-ph.IM', 'astro-ph.CO', 'cs.MS', 'physics.comp-ph']",,,[]
Preconditioned Least-Squares Petrov-Galerkin Reduced Order Models,http://arxiv.org/abs/2203.12180v1,2022-03-23T03:48:01Z,2022-03-23T03:48:01Z,"  This paper introduces a methodology for improving the accuracy and efficiency
of reduced order models (ROMs) constructed using the least-squares
Petrov-Galerkin (LSPG) projection method through the introduction of
preconditioning. Unlike prior related work, which focuses on preconditioning
the linear systems arising within the ROM numerical solution procedure to
improve linear solver performance, our approach leverages a preconditioning
matrix directly within the LSPG minimization problem. Applying preconditioning
in this way can improve ROM accuracy for several reasons. First,
preconditioning the LSPG formulation changes the norm defining the residual
minimization, which can improve the residual-based stability constant bounding
the ROM solution's error. The incorporation of a preconditioner into the LSPG
formulation can have the additional effect of scaling the components of the
residual being minimized, which can be beneficial for problems with disparate
scales. Importantly, we demonstrate that an 'ideal preconditioned' LSPG ROM (a
ROM preconditioned with the inverse of the Jacobian of its corresponding full
order model, or FOM) emulates projection of the FOM solution increment onto the
reduced basis, a lower bound on the ROM solution error for a given reduced
basis. By designing preconditioners that approximate the Jacobian inverse, a
ROM whose error approaches this lower bound can be obtained. The proposed
approach is evaluated in the predictive regime on several mechanical and
thermo-mechanical problems within the Albany HPC code. We demonstrate
numerically that the introduction of simple Jacobi, Gauss-Seidel and ILU
preconditioners into the Proper Orthogonal Decomposition/LSPG formulation
reduces significantly the ROM solution error, the reduced Jacobian condition
number, the number of nonlinear iterations required to reach convergence, and
the wall time.
","['\nPayton Lindsay\n', '\nJeffrey Fike\n', '\nIrina Tezaur\n', '\nKevin Carlberg\n']",,,http://arxiv.org/abs/2203.12180v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Efficient distributed matrix-free multigrid methods on locally refined
  meshes for FEM computations",http://arxiv.org/abs/2203.12292v2,2022-03-23T09:31:59Z,2022-04-10T08:43:41Z,"  This work studies three multigrid variants for matrix-free finite-element
computations on locally refined meshes: geometric local smoothing, geometric
global coarsening, and polynomial global coarsening. We have integrated the
algorithms into the same framework-the open-source finite-element library
deal.II-, which allows us to make fair comparisons regarding their
implementation complexity, computational efficiency, and parallel scalability
as well as to compare the measurements with theoretically derived performance
models. Serial simulations and parallel weak and strong scaling on up to
147,456 CPU cores on 3,072 compute nodes are presented. The results obtained
indicate that global coarsening algorithms show a better parallel behavior for
comparable smoothers due to the better load balance particularly on the
expensive fine levels. In the serial case, the costs of applying hanging-node
constraints might be significant, leading to advantages of local smoothing,
even though the number of solver iterations needed is slightly higher.
","['\nPeter Munch\n', '\nTimo Heister\n', '\nLaura Prieto Saavedra\n', '\nMartin Kronbichler\n']","34 pages, 17 figures",,http://arxiv.org/abs/2203.12292v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.4']",,,[]
"DPar2: Fast and Scalable PARAFAC2 Decomposition for Irregular Dense
  Tensors",http://arxiv.org/abs/2203.12798v2,2022-03-24T01:43:13Z,2022-06-02T05:56:41Z,"  Given an irregular dense tensor, how can we efficiently analyze it? An
irregular tensor is a collection of matrices whose columns have the same size
and rows have different sizes from each other. PARAFAC2 decomposition is a
fundamental tool to deal with an irregular tensor in applications including
phenotype discovery and trend analysis. Although several PARAFAC2 decomposition
methods exist, their efficiency is limited for irregular dense tensors due to
the expensive computations involved with the tensor. In this paper, we propose
DPar2, a fast and scalable PARAFAC2 decomposition method for irregular dense
tensors. DPar2 achieves high efficiency by effectively compressing each slice
matrix of a given irregular tensor, careful reordering of computations with the
compression results, and exploiting the irregularity of the tensor. Extensive
experiments show that DPar2 is up to 6.0x faster than competitors on real-world
irregular tensors while achieving comparable accuracy. In addition, DPar2 is
scalable with respect to the tensor size and target rank.
","['\nJun-Gi Jang\n', '\nU Kang\n']","14 pages, 11 figures. To appear at the 38th IEEE International
  Conference on Data Engineering (ICDE '22)",,http://arxiv.org/abs/2203.12798v2,cs.LG,"['cs.LG', 'cs.DB', 'cs.MS']",,,[]
"Accelerating innovation with software abstractions for scalable
  computational geophysics",http://arxiv.org/abs/2203.15038v1,2022-03-28T19:04:33Z,2022-03-28T19:04:33Z,"  We present the SLIM (https://github.com/slimgroup) open-source software
framework for computational geophysics, and more generally, inverse problems
based on the wave-equation (e.g., medical ultrasound). We developed a software
environment aimed at scalable research and development by designing multiple
layers of abstractions. This environment allows the researchers to easily
formulate their problem in an abstract fashion, while still being able to
exploit the latest developments in high-performance computing. We illustrate
and demonstrate the benefits of our software design on many geophysical
applications, including seismic inversion and physics-informed machine learning
for geophysics (e.g., loop unrolled imaging, uncertainty quantification), all
while facilitating the integration of external software.
","['\nMathias Louboutin\n', '\nPhilipp A. Witte\n', '\nAli Siahkoohi\n', '\nGabrio Rizzuti\n', '\nZiyi Yin\n', '\nRafael Orozco\n', '\nFelix J. Herrmann\n']",,,http://dx.doi.org/10.1190/image2022-3750561.1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'physics.geo-ph']",10.1190/image2022-3750561.1,,[]
GPU Accelerated Automatic Differentiation With Clad,http://arxiv.org/abs/2203.06139v2,2022-03-11T18:10:53Z,2022-05-16T16:53:14Z,"  Automatic Differentiation (AD) is instrumental for science and industry. It
is a tool to evaluate the derivative of a function specified through a computer
program. The range of AD application domain spans from Machine Learning to
Robotics to High Energy Physics. Computing gradients with the help of AD is
guaranteed to be more precise than the numerical alternative and have a low,
constant factor more arithmetical operations compared to the original function.
Moreover, AD applications to domain problems typically are computationally
bound. They are often limited by the computational requirements of
high-dimensional parameters and thus can benefit from parallel implementations
on graphics processing units (GPUs). Clad aims to enable differential analysis
for C/C++ and CUDA and is a compiler-assisted AD tool available both as a
compiler extension and in ROOT. Moreover, Clad works as a plugin extending the
Clang compiler; as a plugin extending the interactive interpreter Cling; and as
a Jupyter kernel extension based on xeus-cling. We demonstrate the advantages
of parallel gradient computations on GPUs with Clad. We explain how to bring
forth a new layer of optimization and a proportional speed up by extending Clad
to support CUDA. The gradients of well-behaved C++ functions can be
automatically executed on a GPU. The library can be easily integrated into
existing frameworks or used interactively. Furthermore, we demonstrate the
achieved application performance improvements, including (~10x) in ROOT
histogram fitting and corresponding performance gains from offloading to GPUs.
","['\nIoana Ifrim\n', '\nVassil Vassilev\n', '\nDavid J Lange\n']","7 pages, 2 figures, 20th International Workshop on Advanced Computing
  and Analysis Techniques in Physics Research",,http://dx.doi.org/10.1088/1742-6596/2438/1/012043,cs.MS,['cs.MS'],10.1088/1742-6596/2438/1/012043,,[]
On Distributed Gravitational N-Body Simulations,http://arxiv.org/abs/2203.08966v1,2022-03-16T22:05:11Z,2022-03-16T22:05:11Z,"  The N-body problem is a classic problem involving a system of N discrete
bodies mutually interacting in a dynamical system. At any moment in time there
are N*(N - 1)/2 such interactions occurring. This scaling as N^2 leads to
computational difficulties where simulations range from tens of thousands of
bodies to many millions. Approximation algorithms, such as the famous
Barnes-Hut algorithm, simplify the number of interactions to scale as N(log N).
Even still, this improvement in complexity is insufficient to achieve the
desired performance for very large simulations on computing clusters with many
nodes and many cores. In this work we explore a variety of algorithmic
techniques for distributed and parallel variations on the Barnes-Hut algorithm
to improve parallelism and reduce inter-process communication requirements.
Explicit algorithms and details are provided for reproducibility. Our MPI
implementation of distributed gravitational N-body simulation, freely available
on GitHub, is evaluated on a cluster of 10 nodes, each with two 6-core CPUs, to
test the effectiveness and scalability of the aforementioned techniques.
",['\nAlexander Brandt\n'],"41 pages, 10 figures",,http://arxiv.org/abs/2203.08966v1,cs.CE,"['cs.CE', 'cs.DC', 'cs.MS']",,,[]
"The Sparse Grids Matlab kit -- a Matlab implementation of sparse grids
  for high-dimensional function approximation and uncertainty quantification",http://arxiv.org/abs/2203.09314v3,2022-03-17T13:36:06Z,2023-10-09T19:37:45Z,"  The Sparse Grids Matlab Kit provides a Matlab implementation of sparse grids,
and can be used for approximating high-dimensional functions and, in
particular, for surrogate-model-based uncertainty quantification. It is
lightweight, high-level and easy to use, good for quick prototyping and
teaching; however, it is equipped with some features that allow its use also in
realistic applications. The goal of this paper is to provide an overview of the
data structure and of the mathematical aspects forming the basis of the
software, as well as comparing the current release of our package to similar
available software.
","['\nChiara Piazzola\n', '\nLorenzo Tamellini\n']",,,http://arxiv.org/abs/2203.09314v3,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Benchmarking a Proof-of-Concept Performance Portable SYCL-based Fast
  Fourier Transformation Library",http://arxiv.org/abs/2203.09384v1,2022-03-17T15:20:56Z,2022-03-17T15:20:56Z,"  In this paper, we present an early version of a SYCL-based FFT library,
capable of running on all major vendor hardware, including CPUs and GPUs from
AMD, ARM, Intel and NVIDIA. Although preliminary, the aim of this work is to
seed further developments for a rich set of features for calculating FFTs. It
has the advantage over existing portable FFT libraries in that it is
single-source, and therefore removes the complexities that arise due to
abundant use of pre-process macros and auto-generated kernels to target
different architectures. We exercise two SYCL-enabled compilers, Codeplay
ComputeCpp and Intel's open-source LLVM project, to evaluate performance
portability of our SYCL-based FFT on various heterogeneous architectures. The
current limitations of our library is it supports single-dimension FFTs up to
$2^{11}$ in length and base-2 input sequences. We compare our results with
highly optimized vendor specific FFT libraries and provide a detailed analysis
to demonstrate a fair level of performance, as well as potential sources of
performance bottlenecks.
","['\nVincent R. Pascuzzi\n', '\nMehdi Goli\n']","12 pages, 6 figures, submitted to IWOCL 2022","IWOCL'22: International Workshop on OpenCL, May 2022, Article No.:
  20, Pages 1-9",http://dx.doi.org/10.1145/3529538.3529996,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",10.1145/3529538.3529996,,[]
"Training the next generation of computational scientists through a new
  undergraduate course",http://arxiv.org/abs/2204.01488v1,2022-03-17T19:42:52Z,2022-03-17T19:42:52Z,"  We introduce a newly designed undergraduate-level interdisciplinary course in
scientific computing that aims to prepare students as the next generation of
research-oriented computational scientists and engineers. The course offers
students opportunities to explore a diverse set of projects and develop the
necessary programming skills to implement ideas and algorithms within high
performance computing environments. The training includes how to think about,
formulate, organize, and implement programs in scientific computing. The
emphasis of the course is on problem solving within a wide range of
applications in science and engineering.
","['\nTulin Kaman\n', '\nRouben Rostamian\n', '\nShannon W. Dingman\n']","16 pages, 4 figures",,http://arxiv.org/abs/2204.01488v1,physics.ed-ph,"['physics.ed-ph', 'cs.CY', 'cs.MS', 'math.HO', '97C90', 'K.3']",,,[]
CGAL Made More Accessible,http://arxiv.org/abs/2202.13889v2,2022-02-28T15:38:24Z,2023-06-07T12:10:19Z,"  We introduce bindings that enable the convenient, efficient, and reliable use
of software modules of CGAL (Computational Geometry Algorithm Library), which
are written in C++, from within code written in Python. There are different
tools that facilitate the creation of such bindings. We present a short study
that compares three main tools, which leads to the tool of choice. The
implementation of algorithms and data structures in computational geometry
presents tremendous difficulties, such as obtaining robust software despite the
use of (inexact) floating point arithmetic, found in standard hardware, and
meticulous handling of all degenerate cases, which typically are in abundance.
The code of CGAL extensively uses function and class templates in order to
handle these difficulties, which implies that the programmer has to make many
choices that are resolved during compile time (of the C++ modules). While
bindings take effect at run time (of the Python code), the type of the C++
objects that are bound must be known when the bindings are generated, that is,
when they are compiled. The types of the bound objects are instances
(instantiated types) of C++ function and class templates. The number of object
types that can potentially be bound, in implementation of generic
computational-geometry algorithms, is enormous; thus, the generation of the
bindings for all these types in advance is practically impossible. Often there
are several choices to make, resulting in a prohibitively large number of
combinations. We present a system that rapidly generates bindings for desired
object types according to user prescriptions, which enables the convenient use
of any subset of bound object types concurrently. The introduction of the
bindings made them easily accessible to newcomers and practitioners in
non-computing fields, as we report in the paper.
","['\nNir Goren\n', '\nEfi Fogel\n', '\nDan Halperin\n']",57 pages,,http://arxiv.org/abs/2202.13889v2,cs.CG,"['cs.CG', 'cs.MS']",,,[]
"Efficient Data Structures for Exploiting Sparsity and Structure in
  Representation of Polynomial Optimization Problems: Implementation in
  SOSTOOLS",http://arxiv.org/abs/2203.01910v5,2022-03-03T18:42:05Z,2022-09-02T17:12:18Z,"  We present a new data structure for representation of polynomial variables in
the parsing of sum-of-squares (SOS) programs. In SOS programs, the variables
$s(x;Q)$ are polynomial in the independent variables $x$, but linear in the
decision variables $Q$. Current SOS parsers, however, fail to exploit the
semi-linear structure of the polynomial variables, treating the decision
variables as independent variables in their representation. This results in
unnecessary overhead in storage and manipulation of the polynomial variables,
prohibiting the parser from addressing larger-scale optimization problems. To
eliminate this computational overhead, we introduce a new representation of
polynomial variables, the ""dpvar"" structure, that is affine in the decision
variables. We show that the complexity of operations on variables in the dpvar
representation scales favorably with the number of decision variables. We
further show that the required memory for storing polynomial variables is
relatively small using the dpvar structure, particularly when exploiting the
MATLAB sparse storage structure. Finally, we incorporate the dpvar data
structure into SOSTOOLS 4.00, and test the performance of the parser for
several polynomial optimization problems.
","['\nDeclan Jagt\n', '\nSachin Shivakumar\n', '\nPeter Seiler\n', '\nMatthew Peet\n']",,"IEEE Control Systems Letters, vol. 6, pp. 3493-3498, 2022",http://dx.doi.org/10.1109/LCSYS.2022.3183650,math.OC,"['math.OC', 'cs.MS']",10.1109/LCSYS.2022.3183650,,[]
"MooAFEM: An object oriented Matlab code for higher-order adaptive FEM
  for (nonlinear) elliptic PDEs",http://arxiv.org/abs/2203.01845v4,2022-03-03T16:51:11Z,2022-11-04T09:51:34Z,"  We present an easily accessible, object oriented code (written exclusively in
Matlab) for adaptive finite element simulations in 2D. It features various
refinement routines for triangular meshes as well as fully vectorized FEM
ansatz spaces of arbitrary polynomial order and allows for problems with very
general coefficients. In particular, our code can handle problems typically
arising from iterative linearization methods used to solve nonlinear PDEs. Due
to the object oriented programming paradigm, the code can be used easily and is
readily extensible. We explain the basic principles of our code and give
numerical experiments that underline its flexibility as well as its efficiency.
","['\nMichael Innerberger\n', '\nDirk Praetorius\n']",,,http://arxiv.org/abs/2203.01845v4,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"pylspack: Parallel algorithms and data structures for sketching, column
  subset selection, regression and leverage scores",http://arxiv.org/abs/2203.02798v2,2022-03-05T18:21:05Z,2022-08-04T22:09:46Z,"  We present parallel algorithms and data structures for three fundamental
operations in Numerical Linear Algebra: (i) Gaussian and CountSketch random
projections and their combination, (ii) computation of the Gram matrix and
(iii) computation of the squared row norms of the product of two matrices, with
a special focus on ""tall-and-skinny"" matrices, which arise in many
applications. We provide a detailed analysis of the ubiquitous CountSketch
transform and its combination with Gaussian random projections, accounting for
memory requirements, computational complexity and workload balancing. We also
demonstrate how these results can be applied to column subset selection, least
squares regression and leverage scores computation. These tools have been
implemented in pylspack, a publicly available Python package
(https://github.com/IBM/pylspack) whose core is written in C++ and parallelized
with OpenMP, and which is compatible with standard matrix data structures of
SciPy and NumPy. Extensive numerical experiments indicate that the proposed
algorithms scale well and significantly outperform existing libraries for
tall-and-skinny matrices.
","['\nAleksandros Sobczyk\n', '\nEfstratios Gallopoulos\n']",To appear in ACM TOMS,,http://dx.doi.org/10.1145/3555370,cs.DS,"['cs.DS', 'cs.DC', 'cs.MS', '65F50, 65F08, 65F20, 68W10, 68W20, 68P05', 'F.2.1; G.3; E.1']",10.1145/3555370,,[]
"An LLVM-based C++ Compiler Toolchain for Variational Hybrid
  Quantum-Classical Algorithms and Quantum Accelerators",http://arxiv.org/abs/2202.11142v1,2022-02-22T19:32:50Z,2022-02-22T19:32:50Z,"  Variational algorithms are a representative class of quantum computing
workloads that combine quantum and classical computing. This paper presents an
LLVM-based C++ compiler toolchain to efficiently execute variational hybrid
quantum-classical algorithms on a computational system in which the quantum
device acts as an accelerator. We introduce a set of extensions to the C++
language for programming these algorithms. We define a novel Executable and
Linking Format (ELF) for Quantum and create a quantum device compiler component
in the LLVM framework to compile the quantum part of the C++ source and reuse
the host compiler in the LLVM framework to compile the classical computing part
of the C++ source. A variational algorithm runs a quantum circuit repeatedly,
each time with different gate parameters. We add to the quantum runtime the
capability to execute dynamically a quantum circuit with different parameters.
Thus, programmers can call quantum routines the same way as classical routines.
With these capabilities, a variational hybrid quantum-classical algorithm can
be specified in a single-source code and only needs to be compiled once for all
iterations. The single compilation significantly reduces the execution latency
of variational algorithms. We evaluate the framework's performance by running
quantum circuits that prepare Thermofield Double (TFD) states, a
quantum-classical variational algorithm.
","['\nPradnya Khalate\n', '\nXin-Chuan Wu\n', '\nShavindra Premaratne\n', '\nJustin Hogaboam\n', '\nAdam Holmes\n', '\nAlbert Schmitz\n', '\nGian Giacomo Guerreschi\n', '\nXiang Zou\n', '\nA. Y. Matsuura\n']","13 pages, 10 figures, 1 appendix",,http://arxiv.org/abs/2202.11142v1,quant-ph,"['quant-ph', 'cs.MS']",,,[]
Compressed Matrix Computations,http://arxiv.org/abs/2202.13007v1,2022-02-25T22:49:49Z,2022-02-25T22:49:49Z,"  Frugal computing is becoming an important topic for environmental reasons. In
this context, several techniques have been proposed to reduce the storage of
scientific data by dedicated compression methods specially tailored for arrays
of floating-point numbers. While these techniques are quite efficient to save
memory, they introduce additional computations to compress and decompress the
data before processing them. In this article, we introduce a new lossy,
fixed-rate compression technique for 2D-arrays of floating-point numbers which
allows one to compute directly on the compressed data, without decompressing
them. We obtain important speedups since less operations are needed to compute
among the compressed data and since no decompression and re-compression is
needed. More precisely, our technique makes it possible to perform basic linear
algebra operations such as addition, multiplication by a constant among
compressed matrices and dot product and matrix multiplication among partly
uncompressed matrices. This work has been implemented into a tool named blaz
and a comparison with the well-known compressor zfp in terms of execution-time
and accuracy is presented.
",['\nMatthieu Martel\n'],,,http://arxiv.org/abs/2202.13007v1,cs.DS,"['cs.DS', 'cs.MS']",,,[]
"Efficient solution of 3D elasticity problems with smoothed aggregation
  algebraic multigrid and block arithmetics",http://arxiv.org/abs/2202.09056v1,2022-02-18T07:45:39Z,2022-02-18T07:45:39Z,"  Efficient solution of 3D elasticity problems is an important part of many
industrial and scientific applications. Smoothed aggregation algebraic
multigrid using rigid body modes for the tentative prolongation operator
construction is an efficient and robust choice for the solution of linear
systems arising from the discretization of elasticity equations. The system
matrices on every level of the multigrid hierarchy have block structure, so
using block representation and block arithmetics should significantly improve
the solver efficiency. However, the tentative prolongation operator
construction may only be done using scalar representation. The paper proposes a
couple of practical approaches for enabling the use of block arithmetics with
smoothed aggregation algebraic multigrid based on the open-source AMGCL
library. It is shown on the example of two real-world model problems that the
suggested improvements may speed up the solution by 50% and reduce the memory
requirements for the preconditioner by 30%. The implementation is
straightforward and only requires a minimal amount of code.
",['\nDenis Demidov\n'],"10 pages, 2 figures",,http://arxiv.org/abs/2202.09056v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80']",,,[]
Benchmarking the Linear Algebra Awareness of TensorFlow and PyTorch,http://arxiv.org/abs/2202.09888v1,2022-02-20T18:51:00Z,2022-02-20T18:51:00Z,"  Linear algebra operations, which are ubiquitous in machine learning, form
major performance bottlenecks. The High-Performance Computing community invests
significant effort in the development of architecture-specific optimized
kernels, such as those provided by the BLAS and LAPACK libraries, to speed up
linear algebra operations. However, end users are progressively less likely to
go through the error prone and time-consuming process of directly using said
kernels; instead, frameworks such as TensorFlow (TF) and PyTorch (PyT), which
facilitate the development of machine learning applications, are becoming more
and more popular. Although such frameworks link to BLAS and LAPACK, it is not
clear whether or not they make use of linear algebra knowledge to speed up
computations. For this reason, in this paper we develop benchmarks to
investigate the linear algebra optimization capabilities of TF and PyT. Our
analyses reveal that a number of linear algebra optimizations are still
missing; for instance, reducing the number of scalar operations by applying the
distributive law, and automatically identifying the optimal parenthesization of
a matrix chain. In this work, we focus on linear algebra computations in TF and
PyT; we both expose opportunities for performance enhancement to the benefit of
the developers of the frameworks and provide end users with guidelines on how
to achieve performance gains.
","['\nAravind Sankaran\n', '\nNavid Akbari Alashti\n', '\nChristos Psarras\n', '\nPaolo Bientinesi\n']",,"2022 IEEE International Parallel and Distributed Processing
  Symposium Workshops (IPDPSW) Pages: 924 - 933",http://dx.doi.org/10.1109/IPDPSW55747.2022.00150,cs.MS,"['cs.MS', 'cs.LG', 'cs.PF']",10.1109/IPDPSW55747.2022.00150,,[]
Adaptive time step control for multirate infinitesimal methods,http://arxiv.org/abs/2202.10484v2,2022-02-21T19:00:17Z,2022-08-26T01:54:38Z,"  Multirate methods have been used for decades to temporally evolve
initial-value problems in which different components evolve on distinct time
scales, and thus use of different step sizes for these components can result in
increased computational efficiency. Generally, such methods select these
different step sizes based on experimentation or stability considerations. For
problems that evolve on a single time scale, adaptivity approaches that strive
to control local temporal error are widely used to achieve numerical results of
a desired accuracy with minimal computational effort, while alleviating the
need for manual experimentation with different time step sizes. However, there
is a notable gap in the publication record on the development of adaptive
time-step controllers for multirate methods. In this paper, we extend the
single-rate controller work of Gustafsson (1994) to the multirate method
setting. Specifically, we develop controllers based on polynomial
approximations to the principal error functions for both the ""fast"" and ""slow""
time scales within multirate infinitesimal (MRI) methods. We additionally
investigate a variety of approaches for estimating the errors arising from each
time scale within MRI methods. We then numerically evaluate the proposed
multirate controllers and error estimation strategies on a range of multirate
test problems, comparing their performance against an estimated optimal
performance. Through this work, we combine the most performant of these
approaches to arrive at a set of multirate adaptive time step controllers that
robustly achieve desired solution accuracy with minimal computational effort.
","['\nAlex C. Fish\n', '\nDaniel R. Reynolds\n']",,,http://arxiv.org/abs/2202.10484v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65L50, 65L05, 65L06']",,,[]
"Solidfmm: A highly optimised library of operations on the solid
  harmonics for use in fast multipole methods",http://arxiv.org/abs/2202.02847v1,2022-02-06T20:38:12Z,2022-02-06T20:38:12Z,"  We present solidfmm, a highly optimised C++ library for the solid harmonics
as they are needed in fast multipole methods. The library provides efficient,
vectorised implementations of the translation operations M2M, M2L, and L2L, and
is available as free software. While asymptotically of complexity $O(P^3)$, for
all practically relevant expansion orders, the translation operators display an
empirical complexity of $O(P^2)$, outperforming the na\""ive implementation by
orders of magnitude.
",['\nMatthias Kirchhart\n'],,,http://arxiv.org/abs/2202.02847v1,cs.MS,"['cs.MS', '35-04']",,,[]
"The Factorial-Basis Method for Finding Definite-Sum Solutions of Linear
  Recurrences With Polynomial Coefficients",http://arxiv.org/abs/2202.05550v3,2022-02-11T11:07:39Z,2022-12-15T12:16:06Z,"  The problem of finding a nonzero solution of a linear recurrence $Ly = 0$
with polynomial coefficients where $y$ has the form of a definite
hypergeometric sum, related to the Inverse Creative Telescoping Problem of
[14][Sec. 8], has now been open for three decades. Here we present an algorithm
(implemented in a SageMath package) which, given such a recurrence and a
quasi-triangular, shift-compatible factorial basis $\mathcal{B} = \langle
P_k(n)\rangle_{k=0}^\infty$ of the polynomial space $\mathbb{K}[n]$ over a
field $\mathbb{K}$ of characteristic zero, computes a recurrence satisfied by
the coefficient sequence $c = \langle c_k\rangle_{k=0}^\infty$ of the solution
$y_n = \sum_{k=0}^\infty c_kP_k(n)$ (where, thanks to the quasi-triangularity
of $\mathcal{B}$, the sum on the right terminates for each $n \in \mathbb{N}$).
More generally, if $\mathcal{B}$ is $m$-sieved for some $m \in \mathbb{N}$, our
algorithm computes a system of $m$ recurrences satisfied by the $m$-sections of
the coefficient sequence $c$. If an explicit nonzero solution of this system
can be found, we obtain an explicit nonzero solution of $Ly = 0$.
","['\nAntonio Jiménez-Pastor\n', '\nMarko Petkovšek\n']",62 pages,Journal of Symbolic Computation 117 (2023) 15-50,http://dx.doi.org/10.1016/j.jsc.2022.11.002,cs.SC,"['cs.SC', 'cs.MS', '33F10, 39A06, 68W30']",10.1016/j.jsc.2022.11.002,,[]
"Exploration of Differentiability in a Proton Computed Tomography
  Simulation Framework",http://arxiv.org/abs/2202.05551v2,2022-02-11T11:07:46Z,2023-05-12T14:03:44Z,"  Objective. Algorithmic differentiation (AD) can be a useful technique to
numerically optimize design and algorithmic parameters by, and quantify
uncertainties in, computer simulations. However, the effectiveness of AD
depends on how ""well-linearizable"" the software is. In this study, we assess
how promising derivative information of a typical proton computed tomography
(pCT) scan computer simulation is for the aforementioned applications.
  Approach. This study is mainly based on numerical experiments, in which we
repeatedly evaluate three representative computational steps with perturbed
input values. We support our observations with a review of the algorithmic
steps and arithmetic operations performed by the software, using debugging
techniques.
  Main results. The model-based iterative reconstruction (MBIR) subprocedure
(at the end of the software pipeline) and the Monte Carlo (MC) simulation (at
the beginning) were piecewise differentiable. Jumps in the MBIR function arose
from the discrete computation of the set of voxels intersected by a proton
path. Jumps in the MC function likely arose from changes in the control flow
that affect the amount of consumed random numbers. The tracking algorithm
solves an inherently non-differentiable problem.
  Significance. The MC and MBIR codes are ready for the integration of AD, and
further research on surrogate models for the tracking subprocedure is
necessary.
","['\nMax Aehle\n', '\nJohan Alme\n', '\nGergely Gábor Barnaföldi\n', '\nJohannes Blühdorn\n', '\nTea Bodova\n', '\nVyacheslav Borshchov\n', '\nAnthony van den Brink\n', '\nViljar Eikeland\n', '\nGregory Feofilov\n', '\nChristoph Garth\n', '\nNicolas R. Gauger\n', '\nOla Grøttvik\n', '\nHåvard Helstrup\n', '\nSergey Igolkin\n', '\nRalf Keidel\n', '\nChinorat Kobdaj\n', '\nTobias Kortus\n', '\nLisa Kusch\n', '\nViktor Leonhardt\n', '\nShruti Mehendale\n', '\nRaju Ningappa Mulawade\n', '\nOdd Harald Odland\n', ""\nGeorge O'Neill\n"", '\nGábor Papp\n', '\nThomas Peitzmann\n', '\nHelge Egil Seime Pettersen\n', '\nPierluigi Piersimoni\n', '\nRohit Pochampalli\n', '\nMaksym Protsenko\n', '\nMax Rauch\n', '\nAttiq Ur Rehman\n', '\nMatthias Richter\n', '\nDieter Röhrich\n', '\nMax Sagebaum\n', '\nJoshua Santana\n', '\nAlexander Schilling\n', '\nJoao Seco\n', '\nArnon Songmoolnak\n', '\nÁkos Sudár\n', '\nGanesh Tambave\n', '\nIhor Tymchuk\n', '\nKjetil Ullaland\n', '\nMonika Varga-Kofarago\n', '\nLennart Volz\n', '\nBoris Wagner\n', '\nSteffen Wendzel\n', '\nAlexander Wiebel\n', '\nRenZheng Xiao\n', '\nShiming Yang\n', '\nSebastian Zillien\n']","27 pages, 11 figures",,http://arxiv.org/abs/2202.05551v2,physics.med-ph,"['physics.med-ph', 'cs.MS']",,,[]
FL_PyTorch: optimization research simulator for federated learning,http://arxiv.org/abs/2202.03099v2,2022-02-07T12:18:28Z,2022-07-18T14:42:47Z,"  Federated Learning (FL) has emerged as a promising technique for edge devices
to collaboratively learn a shared machine learning model while keeping training
data locally on the device, thereby removing the need to store and access the
full data in the cloud. However, FL is difficult to implement, test and deploy
in practice considering heterogeneity in common edge device settings, making it
fundamentally hard for researchers to efficiently prototype and test their
optimization algorithms. In this work, our aim is to alleviate this problem by
introducing FL_PyTorch : a suite of open-source software written in python that
builds on top of one the most popular research Deep Learning (DL) framework
PyTorch. We built FL_PyTorch as a research simulator for FL to enable fast
development, prototyping and experimenting with new and existing FL
optimization algorithms. Our system supports abstractions that provide
researchers with a sufficient level of flexibility to experiment with existing
and novel approaches to advance the state-of-the-art. Furthermore, FL_PyTorch
is a simple to use console system, allows to run several clients simultaneously
using local CPUs or GPU(s), and even remote compute devices without the need
for any distributed implementation provided by the user. FL_PyTorch also offers
a Graphical User Interface. For new methods, researchers only provide the
centralized implementation of their algorithm. To showcase the possibilities
and usefulness of our system, we experiment with several well-known
state-of-the-art FL algorithms and a few of the most common FL datasets.
","['\nKonstantin Burlachenko\n', '\nSamuel Horváth\n', '\nPeter Richtárik\n']","DistributedML '21: Proceedings of the 2nd ACM International Workshop
  on Distributed Machine Learning",,http://dx.doi.org/10.1145/3488659.3493775,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS', 'math.OC', 'G.4']",10.1145/3488659.3493775,,[]
L0Learn: A Scalable Package for Sparse Learning using L0 Regularization,http://arxiv.org/abs/2202.04820v2,2022-02-10T03:51:25Z,2023-06-09T16:20:37Z,"  We present L0Learn: an open-source package for sparse linear regression and
classification using $\ell_0$ regularization. L0Learn implements scalable,
approximate algorithms, based on coordinate descent and local combinatorial
optimization. The package is built using C++ and has user-friendly R and Python
interfaces. L0Learn can address problems with millions of features, achieving
competitive run times and statistical performance with state-of-the-art sparse
learning packages. L0Learn is available on both CRAN and GitHub
(https://cran.r-project.org/package=L0Learn and
https://github.com/hazimehh/L0Learn).
","['\nHussein Hazimeh\n', '\nRahul Mazumder\n', '\nTim Nonet\n']",Accepted to JMLR (MLOSS),,http://arxiv.org/abs/2202.04820v2,cs.LG,"['cs.LG', 'cs.MS', 'stat.CO', 'stat.ML']",,,[]
"Faster Gröbner Bases via Domain-Specific Ordering in Parameter
  Identifiability of ODE Models",http://arxiv.org/abs/2202.06297v2,2022-02-13T12:40:11Z,2023-02-02T17:01:39Z,"  We consider a specific class of polynomial systems that arise in parameter
identifiability problems of models of ordinary differential equations (ODE) and
discover a method for speeding up the Gr\""obner basis computation by using
specific variable ordering and weights coming from the structure of the ODE
model. We provide empirical results that show improvement across different
symbolic computing frameworks.
","['\nMariya Bessonov\n', '\nIlia Ilmer\n', '\nTatiana Konstantinova\n', '\nAlexey Ovchinnikov\n', '\nGleb Pogudin\n', '\nPedro Soto\n']",,,http://arxiv.org/abs/2202.06297v2,cs.SC,"['cs.SC', 'cs.MS', 'q-bio.QM']",,,[]
Phase Vocoder Done Right,http://arxiv.org/abs/2202.07382v1,2022-02-15T13:20:14Z,2022-02-15T13:20:14Z,"  The phase vocoder (PV) is a widely spread technique for processing audio
signals. It employs a short-time Fourier transform (STFT)
analysis-modify-synthesis loop and is typically used for time-scaling of
signals by means of using different time steps for STFT analysis and synthesis.
The main challenge of PV used for that purpose is the correction of the STFT
phase. In this paper, we introduce a novel method for phase correction based on
phase gradient estimation and its integration. The method does not require
explicit peak picking and tracking nor does it require detection of transients
and their separate treatment. Yet, the method does not suffer from the typical
phase vocoder artifacts even for extreme time stretching factors.
","['\nZdenek Prusa\n', '\nNicki Holighaus\n']",,,http://arxiv.org/abs/2202.07382v1,cs.SD,"['cs.SD', 'cs.MS', 'eess.AS']",,,[]
Non-iterative Filter Bank Phase (Re)Construction,http://arxiv.org/abs/2202.07498v1,2022-02-15T15:11:54Z,2022-02-15T15:11:54Z,"  Signal reconstruction from magnitude-only measurements presents a
long-standing problem in signal processing. In this contribution, we propose a
phase (re)construction method for filter banks with uniform decimation and
controlled frequency variation. The suggested procedure extends the recently
introduced phase-gradient heap integration and relies on a phase-magnitude
relationship for filter bank coefficients obtained from Gaussian filters.
Admissible filter banks are modeled as the discretization of certain
generalized translation-invariant systems, for which we derive the
phase-magnitude relationship explicitly. The implementation for discrete
signals is described and the performance of the algorithm is evaluated on a
range of real and synthetic signals.
","['\nZdeněk Průša\n', '\nNicki Holighaus\n']",,,http://dx.doi.org/10.23919/EUSIPCO.2017.8081342,cs.SD,"['cs.SD', 'cs.MS', 'eess.AS', 'eess.SP']",10.23919/EUSIPCO.2017.8081342,,[]
"Extending FEniCS to Work in Higher Dimensions Using Tensor Product
  Finite Elements",http://arxiv.org/abs/2202.00762v2,2022-02-01T21:14:28Z,2022-05-25T20:12:54Z,"  We present a method to extend the finite element library FEniCS to solve
problems with domains in dimensions above three by constructing tensor product
finite elements. This methodology only requires that the high dimensional
domain is structured as a Cartesian product of two lower dimensional
subdomains. In this study we consider Dirichlet problems for scalar linear
partial differential equations, though the methodology can be extended to
non-linear problems. The utilization of tensor product finite elements allows
us to construct a global system of linear algebraic equations that only relies
on the finite element infrastructure of the lower dimensional subdomains
contained in FEniCS. We demonstrate the effectiveness of our methodology in
four distinctive test cases. The first test case is a Poisson equation posed in
a four dimensional domain which is a Cartesian product of two unit squares
solved using the classical Galerkin finite element method. The second test case
is the wave equation in space-time, where the computational domain is a
Cartesian product of a two dimensional space grid and a one dimensional time
interval. In this second case we also employ the Galerkin method. The third
test case is an advection dominated advection-diffusion equation where the
global domain is a Cartesian product of two one dimensional intervals in which
the streamline upwind Petrov-Galerkin method is applied to ensure discrete
stability. The final test case uses the Galerkin approach to solve a Poisson
problem on a Cartesian product of two intervals with a spatially varying,
non-separable diffusivity term. In all cases, a p=1 basis is used and optimal
L^2 convergence rates of order h^{p+1} of the errors are achieved with respect
to h refinement
","['\nMark Loveland\n', '\nEirik Valseth\n', '\nMatt Lukac\n', '\nClint Dawson\n']",,,http://dx.doi.org/10.1016/j.jocs.2022.101831,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1016/j.jocs.2022.101831,,[]
Giga-scale Kernel Matrix Vector Multiplication on GPU,http://arxiv.org/abs/2202.01085v3,2022-02-02T15:28:15Z,2022-10-12T22:01:20Z,"  Kernel matrix-vector multiplication (KMVM) is a foundational operation in
machine learning and scientific computing. However, as KMVM tends to scale
quadratically in both memory and time, applications are often limited by these
computational constraints. In this paper, we propose a novel approximation
procedure coined \textit{Faster-Fast and Free Memory Method} ($\fthreem$) to
address these scaling issues of KMVM for tall~($10^8\sim 10^9$) and
skinny~($D\leq7$) data. Extensive experiments demonstrate that $\fthreem$ has
empirical \emph{linear time and memory} complexity with a relative error of
order $10^{-3}$ and can compute a full KMVM for a billion points \emph{in under
a minute} on a high-end GPU, leading to a significant speed-up in comparison to
existing CPU methods. We demonstrate the utility of our procedure by applying
it as a drop-in for the state-of-the-art GPU-based linear solver FALKON,
\emph{improving speed 1.5-5.5 times} at the cost of $<1\%$ drop in accuracy. We
further demonstrate competitive results on \emph{Gaussian Process regression}
coupled with significant speedups on a variety of real-world datasets.
","['\nRobert Hu\n', '\nSiu Lun Chau\n', '\nDino Sejdinovic\n', '\nJoan Alexis Glaunès\n']",,,http://arxiv.org/abs/2202.01085v3,math.NA,"['math.NA', 'cs.LG', 'cs.MS', 'cs.NA', 'stat.CO']",,,[]
"MUPen2DTool: a Matlab Tool for 2D Nuclear Magnetic Resonance relaxation
  data inversion",http://arxiv.org/abs/2201.06504v1,2022-01-17T16:29:28Z,2022-01-17T16:29:28Z,"  Accurate and efficient analysis of materials properties from Nuclear Magnetic
Resonance (NMR) relaxation data requires robust and efficient inversion
procedures. Despite the great variety of applications requiring to process
two-dimensional NMR data (2DNMR), a few software tools are freely available.
The aim of this paper is to present MUPen2DTool, an open-source MATLAB based
software tool for 2DNMR data inversion. The user can choose among several types
of NMR experiments, and the software provides codes that can be used and
extended easily. Furthermore, a MATLAB interface makes it easier to include
users own data. The practical use is demonstrated in the reported examples of
both synthetic and real NMR data.
","['\nVilliam Bortolotti\n', '\nLeonardo Brizi\n', '\nGermana Landi\n', '\nAnastasiia Nagmutdinova\n', '\nFabiana Zama\n']",,,http://arxiv.org/abs/2201.06504v1,cs.MS,"['cs.MS', '65Z05, 68V35', 'D.0; G.1; I.6']",,,[]
"An Analysis of Approximation Algorithms for Iterated Stochastic
  Integrals and a Julia and MATLAB Simulation Toolbox",http://arxiv.org/abs/2201.08424v2,2022-01-20T19:41:46Z,2023-01-23T11:02:07Z,"  For the approximation and simulation of twofold iterated stochastic integrals
and the corresponding L\'{e}vy areas w.r.t. a multi-dimensional Wiener process,
we review four algorithms based on a Fourier series approach. Especially, the
very efficient algorithm due to Wiktorsson and a newly proposed algorithm due
to Mrongowius and R\""ossler are considered. To put recent advances into
context, we analyse the four Fourier-based algorithms in a unified framework to
highlight differences and similarities in their derivation. A comparison of
theoretical properties is complemented by a numerical simulation that reveals
the order of convergence for each algorithm. Further, concrete instructions for
the choice of the optimal algorithm and parameters for the simulation of
solutions for stochastic (partial) differential equations are given.
Additionally, we provide advice for an efficient implementation of the
considered algorithms and incorporated these insights into an open source
toolbox that is freely available for both Julia and MATLAB programming
languages. The performance of this toolbox is analysed by comparing it to some
existing implementations, where we observe a significant speed-up.
","['\nFelix Kastner\n', '\nAndreas Rößler\n']",,Numer. Algor. (2022),http://dx.doi.org/10.1007/s11075-022-01401-z,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.PR', '60H05, 60H10, 65C30']",10.1007/s11075-022-01401-z,,[]
Fast Differentiable Matrix Square Root,http://arxiv.org/abs/2201.08663v1,2022-01-21T12:18:06Z,2022-01-21T12:18:06Z,"  Computing the matrix square root or its inverse in a differentiable manner is
important in a variety of computer vision tasks. Previous methods either adopt
the Singular Value Decomposition (SVD) to explicitly factorize the matrix or
use the Newton-Schulz iteration (NS iteration) to derive the approximate
solution. However, both methods are not computationally efficient enough in
either the forward pass or in the backward pass. In this paper, we propose two
more efficient variants to compute the differentiable matrix square root. For
the forward propagation, one method is to use Matrix Taylor Polynomial (MTP),
and the other method is to use Matrix Pad\'e Approximants (MPA). The backward
gradient is computed by iteratively solving the continuous-time Lyapunov
equation using the matrix sign function. Both methods yield considerable
speed-up compared with the SVD or the Newton-Schulz iteration. Experimental
results on the de-correlated batch normalization and second-order vision
transformer demonstrate that our methods can also achieve competitive and even
slightly better performances. The code is available at
\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.
","['\nYue Song\n', '\nNicu Sebe\n', '\nWei Wang\n']",Accpeted by ICLR 2022,,http://arxiv.org/abs/2201.08663v1,cs.CV,"['cs.CV', 'cs.LG', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
Parallel Metric-Based Mesh Adaptation in PETSc using ParMmg,http://arxiv.org/abs/2201.02806v3,2022-01-08T11:14:28Z,2022-07-27T16:36:32Z,"  This research note documents the integration of the MPI-parallel metric-based
mesh adaptation toolkit ParMmg into the solver library PETSc. This coupling
brings robust, scalable anisotropic mesh adaptation to a wide community of
PETSc users, as well as users of downstream packages. We demonstrate the new
functionality via the solution of Poisson problems in three dimensions, with
both uniform and spatially-varying right-hand sides.
","['\nJoseph G. Wallwork\n', '\nMatthew G. Knepley\n', '\nNicolas Barral\n', '\nMatthew D. Piggott\n']","5 pages, 2 figures. Appeared as a research note in the 30th
  International Meshing Roundtable",,http://arxiv.org/abs/2201.02806v3,cs.MS,"['cs.MS', 'cs.GR', '35-04', 'G.4']",,,[]
"Comparison of methods for the calculation of the real dilogarithm
  regarding instruction-level parallelism",http://arxiv.org/abs/2201.01678v1,2022-01-05T16:06:49Z,2022-01-05T16:06:49Z,"  We compare different methods for the computation of the real dilogarithm
regarding their ability for using instruction-level parallelism when executed
on appropriate CPUs. As a result we present an instruction-level-aware method
and compare it to existing implementations.
",['\nAlexander Voigt\n'],5 pages,,http://arxiv.org/abs/2201.01678v1,hep-ph,"['hep-ph', 'cs.MS', 'cs.NA', 'math.NA', '33-04, 33E20, 33F05, 65D20']",,,[]
"An open tool based on lifex for myofibers generation in cardiac
  computational models",http://arxiv.org/abs/2201.03303v4,2022-01-10T12:08:57Z,2022-10-07T10:31:18Z,"  Modeling the whole cardiac function involves the solution of several complex
multi-physics and multi-scale models that are highly computationally demanding,
which call for simpler yet accurate, high-performance computational tools.
Despite the efforts made by several research groups, no software for
whole-heart fully-coupled cardiac simulations in the scientific community has
reached full maturity yet. In this work we present the first publicly released
package of lifex, a high-performance Finite Element solver for multi-physics
and multi-scale problems developed in the framework of the iHEART project. The
goal of lifex is twofold. On the one side, it aims at making in silico
experiments easily reproducible and accessible to a wide community of users,
including those with a background in medicine or bio-engineering. On the other
hand, as an academic research library lifex can be exploited by scientific
computing experts to explore new mathematical models and numerical methods
within a robust development framework. lifex has been developed with a modular
structure and will be released bundled in different modules. The tool presented
here proposes an innovative generator for myocardial fibers based on
Laplace-Dirichlet Rule-Based Methods, which are the essential building blocks
for modeling the electrophysiological, mechanical and electromechanical cardiac
function, from single-chamber to whole-heart simulations. This report comes
with an extensive technical and mathematical documentation to welcome new users
to the core structure of a prototypical lifex application and to provide them
with a possible approach to include the generated cardiac fibers into more
sophisticated computational pipelines.
","['\nPasquale C. Africa\n', '\nRoberto Piersanti\n', '\nMarco Fedele\n', ""\nLuca Dede'\n"", '\nAlfio Quarteroni\n']",,,http://arxiv.org/abs/2201.03303v4,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', '68-04, 68N30 (Primary), 35-04, 65-04, 65M60, 65N30, 65Y05, 92-04,\n  92C50 (Secondary)', 'G.4; G.1; J.3']",,,[]
pymdp: A Python library for active inference in discrete state spaces,http://arxiv.org/abs/2201.03904v2,2022-01-11T12:18:44Z,2022-05-04T22:13:22Z,"  Active inference is an account of cognition and behavior in complex systems
which brings together action, perception, and learning under the theoretical
mantle of Bayesian inference. Active inference has seen growing applications in
academic research, especially in fields that seek to model human or animal
behavior. While in recent years, some of the code arising from the active
inference literature has been written in open source languages like Python and
Julia, to-date, the most popular software for simulating active inference
agents is the DEM toolbox of SPM, a MATLAB library originally developed for the
statistical analysis and modelling of neuroimaging data. Increasing interest in
active inference, manifested both in terms of sheer number as well as
diversifying applications across scientific disciplines, has thus created a
need for generic, widely-available, and user-friendly code for simulating
active inference in open-source scientific computing languages like Python. The
Python package we present here, pymdp (see
https://github.com/infer-actively/pymdp), represents a significant step in this
direction: namely, we provide the first open-source package for simulating
active inference with partially-observable Markov Decision Processes or POMDPs.
We review the package's structure and explain its advantages like modular
design and customizability, while providing in-text code blocks along the way
to demonstrate how it can be used to build and run active inference processes
with ease. We developed pymdp to increase the accessibility and exposure of the
active inference framework to researchers, engineers, and developers with
diverse disciplinary backgrounds. In the spirit of open-source software, we
also hope that it spurs new innovation, development, and collaboration in the
growing active inference community.
","['\nConor Heins\n', '\nBeren Millidge\n', '\nDaphne Demekas\n', '\nBrennan Klein\n', '\nKarl Friston\n', '\nIain Couzin\n', '\nAlexander Tschantz\n']",,"Journal of Open Source Software, 7(73), 4098 (2022)",http://dx.doi.org/10.21105/joss.04098,cs.AI,"['cs.AI', 'cs.MS', 'q-bio.NC']",10.21105/joss.04098,,[]
PyHHMM: A Python Library for Heterogeneous Hidden Markov Models,http://arxiv.org/abs/2201.06968v1,2022-01-12T07:32:36Z,2022-01-12T07:32:36Z,"  We introduce PyHHMM, an object-oriented open-source Python implementation of
Heterogeneous-Hidden Markov Models (HHMMs). In addition to HMM's basic core
functionalities, such as different initialization algorithms and classical
observations models, i.e., continuous and multinoulli, PyHHMM distinctively
emphasizes features not supported in similar available frameworks: a
heterogeneous observation model, missing data inference, different model order
selection criterias, and semi-supervised training. These characteristics result
in a feature-rich implementation for researchers working with sequential data.
PyHHMM relies on the numpy, scipy, scikit-learn, and seaborn Python packages,
and is distributed under the Apache-2.0 License. PyHHMM's source code is
publicly available on Github (https://github.com/fmorenopino/HeterogeneousHMM)
to facilitate adoptions and future contributions. A detailed documentation
(https://pyhhmm.readthedocs.io/en/latest), which covers examples of use and
models' theoretical explanation, is available. The package can be installed
through the Python Package Index (PyPI), via 'pip install pyhhmm'.
","['\nFernando Moreno-Pino\n', '\nEmese Sükei\n', '\nPablo M. Olmos\n', '\nAntonio Artés-Rodríguez\n']",,,http://arxiv.org/abs/2201.06968v1,cs.MS,"['cs.MS', 'cs.LG', 'stat.ML']",,,[]
"Solving the Cauchy problem for a three-dimensional difference equation
  in a parallelepiped",http://arxiv.org/abs/2201.13308v1,2022-01-09T23:44:14Z,2022-01-09T23:44:14Z,"  The aim of this article is further development of the theory of linear
difference equations with constant coefficients. We present a new algorithm for
calculating the solution to the Cauchy problem for a three-dimensional
difference equation with constant coefficients in a parallelepiped at the point
using the coefficients of the difference equation and Cauchy data. The
implemented algorithm is the next significant achievement in a series of
articles justifying the Apanovich and Leinartas' theorems about the solvability
and well-posedness of the Cauchy problem. We also use methods of computer
algebra since the three-dimensional case usually demands extended calculations.
","['\nMarina S. Apanovich\n', '\nAlexander P. Lyapin\n', '\nKonstantin V. Shadrin\n']",,,http://arxiv.org/abs/2201.13308v1,math.CA,"['math.CA', 'cs.MS', 'cs.NA', 'math.NA', '05A15, 37H10, 39A05, 39A70']",,,[]
"PEPit: computer-assisted worst-case analyses of first-order optimization
  methods in Python",http://arxiv.org/abs/2201.04040v1,2022-01-11T16:35:22Z,2022-01-11T16:35:22Z,"  PEPit is a Python package aiming at simplifying the access to worst-case
analyses of a large family of first-order optimization methods possibly
involving gradient, projection, proximal, or linear optimization oracles, along
with their approximate, or Bregman variants.
  In short, PEPit is a package enabling computer-assisted worst-case analyses
of first-order optimization methods. The key underlying idea is to cast the
problem of performing a worst-case analysis, often referred to as a performance
estimation problem (PEP), as a semidefinite program (SDP) which can be solved
numerically. For doing that, the package users are only required to write
first-order methods nearly as they would have implemented them. The package
then takes care of the SDP modelling parts, and the worst-case analysis is
performed numerically via a standard solver.
","['\nBaptiste Goujaud\n', '\nCéline Moucer\n', '\nFrançois Glineur\n', '\nJulien Hendrickx\n', '\nAdrien Taylor\n', '\nAymeric Dieuleveut\n']","Reference work for the PEPit package (available at
  https://github.com/bgoujaud/PEPit)",,http://arxiv.org/abs/2201.04040v1,math.OC,"['math.OC', 'cs.LG', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
Batched Second-Order Adjoint Sensitivity for Reduced Space Methods,http://arxiv.org/abs/2201.00241v1,2022-01-01T20:53:09Z,2022-01-01T20:53:09Z,"  This paper presents an efficient method for extracting the second-order
sensitivities from a system of implicit nonlinear equations on upcoming
graphical processing units (GPU) dominated computer systems. We design a custom
automatic differentiation (AutoDiff) backend that targets highly parallel
architectures by extracting the second-order information in batch. When the
nonlinear equations are associated to a reduced space optimization problem, we
leverage the parallel reverse-mode accumulation in a batched adjoint-adjoint
algorithm to compute efficiently the reduced Hessian of the problem. We apply
the method to extract the reduced Hessian associated to the balance equations
of a power network, and show on the largest instances that a parallel GPU
implementation is 30 times faster than a sequential CPU reference based on
UMFPACK.
","['\nFrançois Pacaud\n', '\nMichel Schanen\n', '\nDaniel Adrian Maldonado\n', '\nAlexis Montoison\n', '\nValentin Churavy\n', '\nJulian Samaroo\n', '\nMihai Anitescu\n']",SIAM-PP22,,http://dx.doi.org/10.1137/1.9781611977141.6,cs.MS,"['cs.MS', 'cs.CE']",10.1137/1.9781611977141.6,,[]
"Variational symplectic diagonally implicit Runge-Kutta methods for
  isospectral systems",http://arxiv.org/abs/2112.13721v1,2021-12-27T15:04:55Z,2021-12-27T15:04:55Z,"  Isospectral flows appear in a variety of applications, e.g. the Toda lattice
in solid state physics or in discrete models for two-dimensional hydrodynamics,
with the isospectral property often corresponding to mathematically or
physically important conservation laws. Their most prominent feature, i.e. the
conservation of the eigenvalues of the matrix state variable, should therefore
be retained when discretizing these systems. Recently, it was shown how
isospectral Runge-Kutta methods can, in the Lie-Poisson case also considered in
our work, be obtained through Hamiltonian reduction of symplectic Runge-Kutta
methods on the cotangent bundle of a Lie group. We provide the Lagrangian
analogue and, in the case of symplectic diagonal implicit Runge-Kutta methods,
derive the methods through a discrete Euler-Poincare reduction. Our derivation
relies on a formulation of diagonally implicit isospectral Runge-Kutta methods
in terms of the Cayley transform, generalizing earlier work that showed this
for the implicit midpoint rule. Our work is also a generalization of earlier
variational Lie group integrators that, interestingly, appear when these are
interpreted as update equations for intermediate time points. From a practical
point of view, our results allow for a simple implementation of higher order
isospectral methods and we demonstrate this with numerical experiments where
both the isospectral property and energy are conserved to high accuracy.
","['\nClauson Carvalho da Silva\n', '\nChristian Lessig\n']",,,http://arxiv.org/abs/2112.13721v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65L06, 65P10']",,,[]
Neumann Series in GMRES and Algebraic Multigrid Smoothers,http://arxiv.org/abs/2112.14681v1,2021-12-29T17:57:07Z,2021-12-29T17:57:07Z,"  Neumann series underlie both Krylov methods and algebraic multigrid
smoothers. A low-synch modified Gram-Schmidt (MGS)-GMRES algorithm is described
that employs a Neumann series to accelerate the projection step. A corollary to
the backward stability result of Paige et al. (2006) demonstrates that the
truncated Neumann series approximation is sufficient for convergence of GMRES.
The lower triangular solver associated with the correction matrix $T_m = (\: I
+ L_m \:)^{-1}$ may then be replaced by a matrix-vector product with $T_m = I -
L_m$. Next, Neumann series are applied to accelerate the classical
R\""uge-Stuben algebraic multigrid preconditioner using both a polynomial
Gauss-Seidel or incomplete ILU smoother. The sparse triangular solver employed
in these smoothers is replaced by an inner iteration based upon matrix-vector
products. Henrici's departure from normality of the associated iteration
matrices leads to a better understanding of these series. Connections are made
between the (non)normality of the $L$ and $U$ factors and nonlinear stability
analysis, as well as the pseudospectra of the coefficient matrix. Furthermore,
re-orderings that preserve structural symmetry also reduce the departure from
normality of the upper triangular factor and improve the relative residual of
the triangular solves. To demonstrate the effectiveness of this approach on
many-core architectures, the proposed solver and preconditioner are applied to
the pressure continuity equation for the incompressible Navier-Stokes equations
of fluid motion. The pressure solve time is reduced considerably with no change
in the convergence rate and the polynomial Gauss-Seidel smoother is compared
with a Jacobi smoother. Numerical and timing results are presented for
Nalu-Wind and the PeleLM combustion codes, where ILU with iterative triangular
solvers is shown to be much more effective than polynomial Gauss-Seidel.
","['\nStephen Thomas\n', '\nArielle Carr\n', '\nPaul Mullowney\n', '\nRuipeng Li\n', '\nKasia Świrydowicz\n']",,,http://arxiv.org/abs/2112.14681v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Proceedings of the 13th International Conference on Automated Deduction
  in Geometry",http://arxiv.org/abs/2112.14770v1,2021-12-28T21:56:13Z,2021-12-28T21:56:13Z,"  Automated Deduction in Geometry (ADG) is a forum to exchange ideas and views,
to present research results and progress, and to demonstrate software tools at
the intersection between geometry and automated deduction. Relevant topics
include (but are not limited to): polynomial algebra, invariant and
coordinate-free methods; probabilistic, synthetic, and logic approaches,
techniques for automated geometric reasoning from discrete mathematics,
combinatorics, and numerics; interactive theorem proving in geometry; symbolic
and numeric methods for geometric computation, geometric constraint solving,
automated generation/reasoning and manipulation with diagrams; design and
implementation of geometry software, automated theorem provers, special-purpose
tools, experimental studies; applications of ADG in mechanics, geometric
modelling, CAGD/CAD, computer vision, robotics and education.
  Traditionally, the ADG conference is held every two years. The previous
editions of ADG were held in Nanning in 2018, Strasbourg in 2016, Coimbra in
2014, Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,
Gainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and
Toulouse in 1996. The 13th edition of ADG was supposed to be held in 2020 in
Hagenberg, Austria, but due to the COVID-19 pandemic, it was postponed for
2021, and held online (still hosted by RISC Institute, Hagenberg, Austria),
September 15-17, 2021 (https://www.risc.jku.at/conferences/adg2021).
","['\nPredrag Janičić\n', '\nZoltán Kovács\n']",,"EPTCS 352, 2021",http://dx.doi.org/10.4204/EPTCS.352,cs.AI,"['cs.AI', 'cs.LO', 'cs.MS', 'cs.SC']",10.4204/EPTCS.352,,[]
"Olsson.wl : a Mathematica package for the computation of linear
  transformations of multivariable hypergeometric functions",http://arxiv.org/abs/2201.01189v1,2021-12-31T17:08:08Z,2021-12-31T17:08:08Z,"  We present the Olsson.wl Mathematica package which aims to find linear
transformations for some classes of multivariable hypergeometric functions. It
is based on a well-known method developed by P. O. M. Olsson in J. Math. Phys.
5, 420 (1964) in order to derive the analytic continuations of the Appell $F_1$
double hypergeometric series from the linear transformations of the Gauss
$_2F_1$ hypergeometric function. We provide a brief description of Olsson's
method and demonstrate the commands of the package, along with examples. We
also provide a companion package, called ROC2.wl and dedicated to the
derivation of the regions of convergence of double hypergeometric series. This
package can be used independently of Olsson.wl.
","['\nB. Ananthanarayan\n', '\nSouvik Bera\n', '\nS. Friot\n', '\nTanay Pathak\n']","16 pages, 1 figure and 2 ancillary files",,http://arxiv.org/abs/2201.01189v1,cs.MS,"['cs.MS', 'cs.NA', 'hep-ph', 'hep-th', 'math.NA']",,,[]
"Matrix-free approaches for GPU acceleration of a high-order finite
  element hydrodynamics application using MFEM, Umpire, and RAJA",http://arxiv.org/abs/2112.07075v1,2021-12-14T00:25:12Z,2021-12-14T00:25:12Z,"  With the introduction of advanced heterogeneous computing architectures based
on GPU accelerators, large-scale production codes have had to rethink their
numerical algorithms and incorporate new programming models and memory
management strategies in order to run efficiently on the latest supercomputers.
In this work we discuss our co-design strategy to address these challenges and
achieve performance and portability with MARBL, a next-generation multi-physics
code in development at Lawrence Livermore National Laboratory. We present a
two-fold approach, wherein new hardware is used to motivate both new algorithms
and new abstraction layers, resulting in a single source application code
suitable for a variety of platforms. Focusing on MARBL's ALE hydrodynamics
package, we demonstrate scalability on different platforms and highlight that
many of our innovations have been contributed back to open-source software
libraries, such as MFEM (finite element algorithms) and RAJA (kernel
abstractions).
","['\nArturo Vargas\n', '\nThomas M. Stitt\n', '\nKenneth Weiss\n', '\nVladimir Z. Tomov\n', '\nJean-Sylvain Camier\n', '\nTzanio Kolev\n', '\nRobert N. Rieben\n']","Submitted to The International Journal of High Performance Computing
  Applications",,http://arxiv.org/abs/2112.07075v1,cs.MS,"['cs.MS', '35-04', 'D.0; F.2; G.4; I.6']",,,[]
"An eXtended Finite Element Method Implementation in COMSOL Multiphysics:
  Thermo-Hydro-Mechanical Modeling of Fluid Flow in Discontinuous Porous Media",http://arxiv.org/abs/2112.11918v1,2021-12-17T06:36:58Z,2021-12-17T06:36:58Z,"  This paper presents the implementation of the eXtended Finite Element Method
(XFEM) in the general-purpose commercial software package COMSOL Multiphysics
for multi-field thermo-hydro-mechanical problems in discontinuous porous media.
To this end, an exclusive enrichment strategy is proposed in compliance with
the COMSOL modeling structure. COMSOL modules and physics interfaces are
adopted to take account of the relevant physical processes involved in
thermo-hydro-mechanical coupling analysis, namely: the mechanical deformation,
fluid flow in porous media and heat transfer. Essential changes are made to the
internal variables of the physics interfaces to ensure consistency in the
evaluation of enriched solution fields. The model preprocessing, level-set
updates, coupling of the relevant physics and postprocessing procedures are
performed adopting a coherent utilization of the COMSOL built-in features along
with the COMSOL LiveLink for MATLAB functions. The implementation process,
remedies for the treatment of the enriched zones, XFEM framework setup,
multiphysics coupling, numerical integration and numerical solution strategy
are described in detail. The capabilities and performance of the proposed
approach are investigated by examining several multi-field
thermo-hydro-mechanical simulations involving single/multiple discontinuities
in 2D/3D porous rock settings.
","['\nAhmad Jafari\n', '\nMohammad Vahab\n', '\nPooyan Broumand\n', '\nNasser Khalili\n']",,,http://arxiv.org/abs/2112.11918v1,cs.MS,"['cs.MS', 'cs.CE']",,,[]
"Efficient implementation of modern entropy stable and kinetic energy
  preserving discontinuous Galerkin methods for conservation laws",http://arxiv.org/abs/2112.10517v2,2021-12-20T13:25:37Z,2023-09-19T06:55:12Z,"  Many modern discontinuous Galerkin (DG) methods for conservation laws make
use of summation by parts operators and flux differencing to achieve kinetic
energy preservation or entropy stability. While these techniques increase the
robustness of DG methods significantly, they are also computationally more
demanding than standard weak form nodal DG methods. We present several
implementation techniques to improve the efficiency of flux differencing DG
methods that use tensor product quadrilateral or hexahedral elements, in 2D or
3D respectively. Focus is mostly given to CPUs and DG methods for the
compressible Euler equations, although these techniques are generally also
useful for other physical systems including the compressible Navier-Stokes and
magnetohydrodynamics equations. We present results using two open source codes,
Trixi.jl written in Julia and FLUXO written in Fortran, to demonstrate that our
proposed implementation techniques are applicable to different code bases and
programming languages.
","['\nHendrik Ranocha\n', '\nMichael Schlottke-Lakemper\n', '\nJesse Chan\n', '\nAndrés M. Rueda-Ramírez\n', '\nAndrew R. Winters\n', '\nFlorian Hindenlang\n', '\nGregor J. Gassner\n']",,"ACM Transactions on Mathematical Software, 2023",http://dx.doi.org/10.1145/3625559,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'physics.comp-ph']",10.1145/3625559,,[]
NetKet 3: Machine Learning Toolbox for Many-Body Quantum Systems,http://arxiv.org/abs/2112.10526v2,2021-12-20T13:41:46Z,2022-08-18T16:28:36Z,"  We introduce version 3 of NetKet, the machine learning toolbox for many-body
quantum physics. NetKet is built around neural-network quantum states and
provides efficient algorithms for their evaluation and optimization. This new
version is built on top of JAX, a differentiable programming and accelerated
linear algebra framework for the Python programming language. The most
significant new feature is the possibility to define arbitrary neural network
ans\""atze in pure Python code using the concise notation of machine-learning
frameworks, which allows for just-in-time compilation as well as the implicit
generation of gradients thanks to automatic differentiation. NetKet 3 also
comes with support for GPU and TPU accelerators, advanced support for discrete
symmetry groups, chunking to scale up to thousands of degrees of freedom,
drivers for quantum dynamics applications, and improved modularity, allowing
users to use only parts of the toolbox as a foundation for their own code.
","['\nFilippo Vicentini\n', '\nDamian Hofmann\n', '\nAttila Szabó\n', '\nDian Wu\n', '\nChristopher Roth\n', '\nClemens Giuliani\n', '\nGabriel Pescia\n', '\nJannes Nys\n', '\nVladimir Vargas-Calderon\n', '\nNikita Astrakhantsev\n', '\nGiuseppe Carleo\n']","55 pages, 5 figures. Accompanying code at
  https://github.com/netket/netket",SciPost Phys. Codebases 7 (2022),http://dx.doi.org/10.21468/SciPostPhysCodeb.7,quant-ph,"['quant-ph', 'cs.LG', 'cs.MS', 'physics.comp-ph']",10.21468/SciPostPhysCodeb.7,,[]
"PyChEst: a Python package for the consistent retrospective estimation of
  distributional changes in piece-wise stationary time series",http://arxiv.org/abs/2112.10565v1,2021-12-20T14:39:39Z,2021-12-20T14:39:39Z,"  We introduce PyChEst, a Python package which provides tools for the
simultaneous estimation of multiple changepoints in the distribution of
piece-wise stationary time series. The nonparametric algorithms implemented are
provably consistent in a general framework: when the samples are generated by
unknown piece-wise stationary processes. In this setting, samples may have
long-range dependencies of arbitrary form and the finite-dimensional marginals
of any (unknown) fixed size before and after the changepoints may be the same.
The strength of the algorithms included in the package is in their ability to
consistently detect the changes without imposing any assumptions beyond
stationarity on the underlying process distributions. We illustrate this
distinguishing feature by comparing the performance of the package against
state-of-the-art models designed for a setting where the samples are
independently and identically distributed.
","['\nAzadeh Khaleghi\n', '\nLukas Zierahn\n']",,,http://arxiv.org/abs/2112.10565v1,stat.CO,"['stat.CO', 'cs.MS', 'stat.AP', 'stat.ML']",,,[]
"Latte: Cross-framework Python Package for Evaluation of Latent-Based
  Generative Models",http://arxiv.org/abs/2112.10638v3,2021-12-20T16:00:28Z,2022-01-22T11:54:21Z,"  Latte (for LATent Tensor Evaluation) is a Python library for evaluation of
latent-based generative models in the fields of disentanglement learning and
controllable generation. Latte is compatible with both PyTorch and
TensorFlow/Keras, and provides both functional and modular APIs that can be
easily extended to support other deep learning frameworks. Using NumPy-based
and framework-agnostic implementation, Latte ensures reproducible, consistent,
and deterministic metric calculations regardless of the deep learning framework
of choice.
","['\nKarn N. Watcharasupat\n', '\nJunyoung Lee\n', '\nAlexander Lerch\n']",To appear in Software Impacts,"Software Impacts, Volume 11, 2022, 100222, ISSN 2665-9638",http://dx.doi.org/10.1016/j.simpa.2022.100222,cs.LG,"['cs.LG', 'cs.AI', 'cs.IR', 'cs.MS']",10.1016/j.simpa.2022.100222,,[]
PyTracer: Automatically profiling numerical instabilities in Python,http://arxiv.org/abs/2112.11508v2,2021-12-21T20:22:34Z,2022-02-08T15:21:40Z,"  Numerical stability is a crucial requirement of reliable scientific
computing. However, despite the pervasiveness of Python in data science,
analyzing large Python programs remains challenging due to the lack of scalable
numerical analysis tools available for this language. To fill this gap, we
developed PyTracer, a profiler to quantify numerical instability in Python
applications. PyTracer transparently instruments Python code to produce
numerical traces and visualize them interactively in a Plotly dashboard. We
designed PyTracer to be agnostic to numerical noise model, allowing for tool
evaluation through Monte-Carlo Arithmetic, random rounding, random data
perturbation, or structured noise for a particular application. We illustrate
PyTracer's capabilities by testing the numerical stability of key functions in
both SciPy and Scikit-learn, two dominant Python libraries for mathematical
modeling. Through these evaluations, we demonstrate PyTracer as a scalable,
automatic, and generic framework for numerical profiling in Python.
","['\nYohan Chatelain\n', '\nNigel Yong\n', '\nGregory Kiar\n', '\nTristan Glatard\n']","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,http://arxiv.org/abs/2112.11508v2,cs.MS,"['cs.MS', 'cs.NA', 'cs.SE', 'math.NA']",,,[]
"Iterative Krylov Methods for Acoustic Problems on Graphics Processing
  Unit",http://arxiv.org/abs/2112.11880v1,2021-12-22T14:04:53Z,2021-12-22T14:04:53Z,"  This paper deals with linear algebra operations on Graphics Processing Unit
(GPU) with complex number arithmetic using double precision. An analysis of
their uses within iterative Krylov methods is presented to solve acoustic
problems. Numerical experiments performed on a set of acoustic matrices arising
from the modelisation of acoustic phenomena inside a car compartment are
collected, and outline the performance, robustness and effectiveness of our
algorithms, with a speed-up up to 28x for dot product, 9.8x for sparse
matrix-vector product and solvers.
","['\nAbal-Kassim Cheik Ahamed\n', '\nFrederic Magoules\n']",,,http://arxiv.org/abs/2112.11880v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA']",,,[]
Differentiable Scripting,http://arxiv.org/abs/2112.03036v1,2021-12-03T12:33:56Z,2021-12-03T12:33:56Z,"  In Computational Science, Engineering and Finance (CSEF) scripts typically
serve as the ""glue"" between potentially highly complex and computationally
expensive external subprograms. Differentiability of the resulting programs
turns out to be essential in the context of derivative-based methods for error
analysis, uncertainty quantification, optimization or training of surrogates.
We argue that it should be enforced by the scripting language itself through
exclusive support of differentiable (smoothed) external subprograms and
differentiable intrinsics combined with prohibition of nondifferentiable
branches in the data flow. Illustration is provided by a prototype adjoint code
compiler for a simple Python-like scripting language.
",['\nUwe Naumann\n'],7 pages,,http://arxiv.org/abs/2112.03036v1,cs.MS,['cs.MS'],,,[]
Dynamic Sparse Tensor Algebra Compilation,http://arxiv.org/abs/2112.01394v1,2021-12-02T16:28:34Z,2021-12-02T16:28:34Z,"  This paper shows how to generate efficient tensor algebra code that compute
on dynamic sparse tensors, which have sparsity structures that evolve over
time. We propose a language for precisely specifying recursive, pointer-based
data structures, and we show how this language can express a wide range of
dynamic data structures that support efficient modification, such as linked
lists, binary search trees, and B-trees. We then describe how, given high-level
specifications of such data structures, a compiler can generate code to
efficiently iterate over and compute with dynamic sparse tensors that are
stored in the aforementioned data structures. Furthermore, we define an
abstract interface that captures how nonzeros can be inserted into dynamic data
structures, and we show how this abstraction guides a compiler to emit
efficient code that store the results of sparse tensor algebra computations in
dynamic data structures.
  We evaluate our technique and find that it generates efficient dynamic sparse
tensor algebra kernels. Code that our technique emits to compute the main
kernel of the PageRank algorithm is 1.05$\times$ as fast as Aspen, a
state-of-the-art dynamic graph processing framework. Furthermore, our technique
outperforms PAM, a parallel ordered (key-value) maps library, by 7.40$\times$
when used to implement element-wise addition of a dynamic sparse matrix to a
static sparse matrix.
","['\nStephen Chou\n', '\nSaman Amarasinghe\n']","15 pages, 16 figures",,http://arxiv.org/abs/2112.01394v1,cs.MS,"['cs.MS', 'cs.PL']",,,[]
"Bayesian supervised predictive classification and hypothesis testing
  toolkit for partition exchangeability",http://arxiv.org/abs/2112.01618v1,2021-12-02T21:50:42Z,2021-12-02T21:50:42Z,"  Bayesian supervised predictive classifiers, hypothesis testing, and
parametric estimation under Partition Exchangeability are implemented. The two
classifiers presented are the marginal classifier (that assumes test data is
i.i.d.) next to a more computationally costly but accurate simultaneous
classifier (that finds a labelling for the entire test dataset at once based on
simultanous use of all the test data to predict each label). We also provide
the Maximum Likelihood Estimation (MLE) of the only underlying parameter of the
partition exchangeability generative model as well as hypothesis testing
statistics for equality of this parameter with a single value, alternative, or
multiple samples. We present functions to simulate the sequences from Ewens
Sampling Formula as the realisation of the Poisson-Dirichlet distribution and
their respective probabilities.
","['\nVille Kinnula\n', '\nJing Tang\n', '\nAli Amiryousefi\n']",,,http://arxiv.org/abs/2112.01618v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
ProbNum: Probabilistic Numerics in Python,http://arxiv.org/abs/2112.02100v1,2021-12-03T07:20:50Z,2021-12-03T07:20:50Z,"  Probabilistic numerical methods (PNMs) solve numerical problems via
probabilistic inference. They have been developed for linear algebra,
optimization, integration and differential equation simulation. PNMs naturally
incorporate prior information about a problem and quantify uncertainty due to
finite computational resources as well as stochastic input. In this paper, we
present ProbNum: a Python library providing state-of-the-art probabilistic
numerical solvers. ProbNum enables custom composition of PNMs for specific
problem classes via a modular design as well as wrappers for off-the-shelf use.
Tutorials, documentation, developer guides and benchmarks are available online
at www.probnum.org.
","['\nJonathan Wenger\n', '\nNicholas Krämer\n', '\nMarvin Pförtner\n', '\nJonathan Schmidt\n', '\nNathanael Bosch\n', '\nNina Effenberger\n', '\nJohannes Zenn\n', '\nAlexandra Gessner\n', '\nToni Karvonen\n', '\nFrançois-Xavier Briol\n', '\nMaren Mahsereci\n', '\nPhilipp Hennig\n']",,,http://arxiv.org/abs/2112.02100v1,cs.MS,"['cs.MS', 'cs.LG', 'cs.NA', 'math.NA']",,,[]
"AIMpy: A Python code to solve Schrödinger-like equations with the
  asymptotic iteration method",http://arxiv.org/abs/2112.02934v1,2021-12-06T11:13:47Z,2021-12-06T11:13:47Z,"  This paper is dedicated to present an open-source program so-called
\emph{AIMpy} built on Python language. \emph{AIMpy} is a solver for
Schr\""{o}dinger-like differential equations using Asymptotic Iteration Method
(AIM). To confirm the code works seamlessly, it has been shown through the
paper with recalculation of some previously studied eigenvalue examples that
the code can reproduce their results very well.
",['\nMesut Karakoç\n'],,"International Journal of Modern Physics C Vol. 32, No. 02, 2150017
  (2021)",http://dx.doi.org/10.1142/S0129183121500170,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'quant-ph']",10.1142/S0129183121500170,,[]
Simulation Intelligence: Towards a New Generation of Scientific Methods,http://arxiv.org/abs/2112.03235v2,2021-12-06T18:45:31Z,2022-11-27T07:20:27Z,"  The original ""Seven Motifs"" set forth a roadmap of essential methods for the
field of scientific computing, where a motif is an algorithmic method that
captures a pattern of computation and data movement. We present the ""Nine
Motifs of Simulation Intelligence"", a roadmap for the development and
integration of the essential algorithms necessary for a merger of scientific
computing, scientific simulation, and artificial intelligence. We call this
merger simulation intelligence (SI), for short. We argue the motifs of
simulation intelligence are interconnected and interdependent, much like the
components within the layers of an operating system. Using this metaphor, we
explore the nature of each layer of the simulation intelligence operating
system stack (SI-stack) and the motifs therein: (1) Multi-physics and
multi-scale modeling; (2) Surrogate modeling and emulation; (3)
Simulation-based inference; (4) Causal modeling and inference; (5) Agent-based
modeling; (6) Probabilistic programming; (7) Differentiable programming; (8)
Open-ended optimization; (9) Machine programming. We believe coordinated
efforts between motifs offers immense opportunity to accelerate scientific
discovery, from solving inverse problems in synthetic biology and climate
science, to directing nuclear energy experiments and predicting emergent
behavior in socioeconomic settings. We elaborate on each layer of the SI-stack,
detailing the state-of-art methods, presenting examples to highlight challenges
and opportunities, and advocating for specific ways to advance the motifs and
the synergies from their combinations. Advancing and integrating these
technologies can enable a robust and efficient hypothesis-simulation-analysis
type of scientific method, which we introduce with several use-cases for
human-machine teaming and automated science.
","['\nAlexander Lavin\n', '\nDavid Krakauer\n', '\nHector Zenil\n', '\nJustin Gottschlich\n', '\nTim Mattson\n', '\nJohann Brehmer\n', '\nAnima Anandkumar\n', '\nSanjay Choudry\n', '\nKamil Rocki\n', '\nAtılım Güneş Baydin\n', '\nCarina Prunkl\n', '\nBrooks Paige\n', '\nOlexandr Isayev\n', '\nErik Peterson\n', '\nPeter L. McMahon\n', '\nJakob Macke\n', '\nKyle Cranmer\n', '\nJiaxin Zhang\n', '\nHaruko Wainwright\n', '\nAdi Hanuka\n', '\nManuela Veloso\n', '\nSamuel Assefa\n', '\nStephan Zheng\n', '\nAvi Pfeffer\n']",,,http://arxiv.org/abs/2112.03235v2,cs.AI,"['cs.AI', 'cs.CE', 'cs.LG', 'cs.MS']",,,[]
"Accelerating jackknife resampling for the Canonical Polyadic
  Decomposition",http://arxiv.org/abs/2112.03985v1,2021-12-07T20:58:30Z,2021-12-07T20:58:30Z,"  The Canonical Polyadic (CP) tensor decomposition is frequently used as a
model in applications in a variety of different fields. Using jackknife
resampling to estimate parameter uncertainties is often desirable but results
in an increase of the already high computational cost. Upon observation that
the resampled tensors, though different, are nearly identical, we show that it
is possible to extend the recently proposed Concurrent ALS (CALS) technique to
a jackknife resampling scenario. This extension gives access to the
computational efficiency advantage of CALS for the price of a modest increase
(typically a few percent) in the number of floating point operations. Numerical
experiments on both synthetic and real-world datasets demonstrate that the new
workflow based on a CALS extension can be several times faster than a
straightforward workflow where the jackknife submodels are processed
individually.
","['\nChristos Psarras\n', '\nLars Karlsson\n', '\nRasmus Bro\n', '\nPaolo Bientinesi\n']",,,http://dx.doi.org/10.3389/fams.2022.830270,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.3389/fams.2022.830270,,[]
(R)SE challenges in HPC,http://arxiv.org/abs/2112.06617v1,2021-12-10T14:24:28Z,2021-12-10T14:24:28Z,"  We discuss some specific software engineering challenges in the field of
high-performance computing, and argue that the slow adoption of SE tools and
techniques is at least in part caused by the fact that these do not address the
HPC challenges `out-of-the-box'. By giving some examples of solutions for
designing, testing and benchmarking HPC software, we intend to bring software
engineering and HPC closer together.
","['\nJonas Thies\n', '\nMelven Röhrig-Zöllner\n', '\nAchim Basermann\n']","2 pages, whitepaper for the RSE-HPC-2021 workshop on the SC'21,
  https://us-rse.org/rse-hpc-2021/",,http://arxiv.org/abs/2112.06617v1,cs.SE,"['cs.SE', 'cs.DC', 'cs.MS', 'cs.PF', '65Y05', 'G.4; D.2.2']",,,[]
"RLIBM-PROG: Progressive Polynomial Approximations for Fast Correctly
  Rounded Math Libraries",http://arxiv.org/abs/2111.12852v2,2021-11-25T00:19:27Z,2022-03-17T04:01:21Z,"  This paper presents a novel method for generating a single polynomial
approximation that produces correctly rounded results for all inputs of an
elementary function for multiple representations. The generated polynomial
approximation has the nice property that the first few lower degree terms
produce correctly rounded results for specific representations of smaller
bitwidths, which we call progressive performance. To generate such progressive
polynomial approximations, we approximate the correctly rounded result and
formulate the computation of correctly rounded polynomial approximations as a
linear program similar to our prior work on the RLibm project. To enable the
use of resulting polynomial approximations in mainstream libraries, we want to
avoid piecewise polynomials with large lookup tables. We observe that the
problem of computing polynomial approximations for elementary functions is a
linear programming problem in low dimensions, i.e., with a small number of
unknowns. We design a fast randomized algorithm for computing polynomial
approximations with progressive performance. Our method produces correct and
fast polynomials that require a small amount of storage. A few polynomial
approximations from our prototype have already been incorporated into LLVM's
math library.
","['\nMridul Aanjaneya\n', '\nJay P. Lim\n', '\nSantosh Nagarakatte\n']",14 pages,,http://arxiv.org/abs/2111.12852v2,cs.MS,['cs.MS'],,,[]
cliquematch: Finding correspondence via cliques in large graphs,http://arxiv.org/abs/2112.00004v1,2021-11-30T06:15:26Z,2021-11-30T06:15:26Z,"  The maximum clique problem finds applications in computer vision,
bioinformatics, and network analysis, many of which involve the construction of
correspondence graphs to find similarities between two given objects.
cliquematch is a Python package designed for this purpose: it provides a simple
framework to construct correspondence graphs, and implements an algorithm to
find and enumerate maximum cliques in C++, that can process graphs of a few
million edges on consumer hardware, with comparable performance to publicly
available methods.
",['\nGautham Venkatasubramanian\n'],"11 pages, 3 figures, 1 table; Code available at
  https://github.com/ahgamut/cliquematch",,http://dx.doi.org/10.5281/zenodo.4277288,cs.MS,"['cs.MS', 'cs.DS', 'F.2.2; G.2.2; G.2.4; G.4; I.4.7']",10.5281/zenodo.4277288,,[]
"A Massively Parallel Implementation of Multilevel Monte Carlo for Finite
  Element Models",http://arxiv.org/abs/2111.11788v2,2021-11-23T11:04:12Z,2023-05-23T15:46:23Z,"  The Multilevel Monte Carlo (MLMC) method has proven to be an effective
variance-reduction statistical method for Uncertainty Quantification (UQ) in
Partial Differential Equation (PDE) models, combining model computations at
different levels to create an accurate estimate. Still, the computational
complexity of the resulting method is extremely high, particularly for 3D
models, which requires advanced algorithms for the efficient exploitation of
High Performance Computing (HPC). In this article we present a new
implementation of the MLMC in massively parallel computer architectures,
exploiting parallelism within and between each level of the hierarchy. The
numerical approximation of the PDE is performed using the finite element method
but the algorithm is quite general and could be applied to other discretization
methods as well, although the focus is on parallel sampling. The two key
ingredients of an efficient parallel implementation are a good processor
partition scheme together with a good scheduling algorithm to assign work to
different processors. We introduce a multiple partition of the set of
processors that permits the simultaneous execution of different levels and we
develop a dynamic scheduling algorithm to exploit it. The problem of finding
the optimal scheduling of distributed tasks in a parallel computer is an
NP-complete problem. We propose and analyze a new greedy scheduling algorithm
to assign samples and we show that it is a 2-approximation, which is the best
that may be expected under general assumptions. On top of this result we design
a distributed memory implementation using the Message Passing Interface (MPI)
standard. Finally we present a set of numerical experiments illustrating its
scalability properties.
","['\nSantiago Badia\n', '\nJerrad Hampton\n', '\nJavier Principe\n']","21 pages, 13 figures",,http://arxiv.org/abs/2111.11788v2,cs.MS,"['cs.MS', 'cs.CE']",,,[]
"FCMpy: A Python Module for Constructing and Analyzing Fuzzy Cognitive
  Maps",http://arxiv.org/abs/2111.12749v1,2021-11-24T19:21:14Z,2021-11-24T19:21:14Z,"  FCMpy is an open source package in Python for building and analyzing Fuzzy
Cognitive Maps. More specifically, the package allows 1) deriving fuzzy causal
weights from qualitative data, 2) simulating the system behavior, 3) applying
machine learning algorithms (e.g., Nonlinear Hebbian Learning, Active Hebbian
Learning, Genetic Algorithms and Deterministic Learning) to adjust the FCM
causal weight matrix and to solve classification problems, and 4) implementing
scenario analysis by simulating hypothetical interventions (i.e., analyzing
what-if scenarios).
","['\nSamvel Mkhitaryan\n', '\nPhilippe J. Giabbanelli\n', '\nMaciej K. Wozniak\n', '\nGonzalo Napoles\n', '\nNanne K. de Vries\n', '\nRik Crutzen\n']","22 pages, 9 Figures","PeerJ Computer Science 8:e1078, 2022",http://dx.doi.org/10.7717/peerj-cs.1078,cs.MS,"['cs.MS', 'cs.LG']",10.7717/peerj-cs.1078,,[]
An Asymptotic Cost Model for Autoscheduling Sparse Tensor Programs,http://arxiv.org/abs/2111.14947v1,2021-11-29T20:50:33Z,2021-11-29T20:50:33Z,"  While loop reordering and fusion can make big impacts on the constant-factor
performance of dense tensor programs, the effects on sparse tensor programs are
asymptotic, often leading to orders of magnitude performance differences in
practice. Sparse tensors also introduce a choice of compressed storage formats
that can have asymptotic effects. Research into sparse tensor compilers has led
to simplified languages that express these tradeoffs, but the user is expected
to provide a schedule that makes the decisions. This is challenging because
schedulers must anticipate the interaction between sparse formats, loop
structure, potential sparsity patterns, and the compiler itself. Automating
this decision making process stands to finally make sparse tensor compilers
accessible to end users.
  We present, to the best of our knowledge, the first automatic asymptotic
scheduler for sparse tensor programs. We provide an approach to abstractly
represent the asymptotic cost of schedules and to choose between them. We
narrow down the search space to a manageably small ""Pareto frontier"" of
asymptotically undominated kernels. We test our approach by compiling these
kernels with the TACO sparse tensor compiler and comparing them with those
generated with the default TACO schedules. Our results show that our approach
reduces the scheduling space by orders of magnitude and that the generated
kernels perform asymptotically better than those generated using the default
schedules.
","['\nWillow Ahrens\n', '\nFredrik Kjolstad\n', '\nSaman Amarasinghe\n']","14 pages, 7 figures",,http://arxiv.org/abs/2111.14947v1,cs.MS,"['cs.MS', 'cs.PL']",,,[]
HOTTBOX: Higher Order Tensor ToolBOX,http://arxiv.org/abs/2111.15662v1,2021-11-30T18:53:54Z,2021-11-30T18:53:54Z,"  HOTTBOX is a Python library for exploratory analysis and visualisation of
multi-dimensional arrays of data, also known as tensors. The library includes
methods ranging from standard multi-way operations and data manipulation
through to multi-linear algebra based tensor decompositions. HOTTBOX also
comprises sophisticated algorithms for generalised multi-linear classification
and data fusion, such as Support Tensor Machine (STM) and Tensor Ensemble
Learning (TEL). For user convenience, HOTTBOX offers a unifying API which
establishes a self-sufficient ecosystem for various forms of efficient
representation of multi-way data and the corresponding decomposition and
association algorithms. Particular emphasis is placed on scalability and
interactive visualisation, to support multidisciplinary data analysis
communities working on big data and tensors. HOTTBOX also provides means for
integration with other popular data science libraries for visualisation and
data manipulation. The source code, examples and documentation ca be found at
https://github.com/hottbox/hottbox.
","['\nIlya Kisil\n', '\nGiuseppe G. Calvi\n', '\nBruno S. Dees\n', '\nDanilo P. Mandic\n']",,,http://arxiv.org/abs/2111.15662v1,cs.MS,"['cs.MS', 'eess.SP']",,,[]
"RawArray: A Simple, Fast, and Extensible Archival Format for Numeric
  Data",http://arxiv.org/abs/2112.01273v1,2021-11-30T03:51:24Z,2021-11-30T03:51:24Z,"  Raw data sizes are growing and proliferating in scientific research, driven
by the success of data-hungry computational methods, such as machine learning.
The preponderance of proprietary and shoehorned data formats make computations
slower and make it harder to reproduce research and to port methods to new
platforms. Here we present the RawArray format: a simple, fast, and extensible
format for archival storage of multidimensional numeric arrays on disk.
  The RawArray file format is a simple concatenation of a header array and a
data array. The header comprises seven or more 64-bit unsigned integers. The
array data can be anything. Arbitrary user metadata can be appended to an
RawArray file if desired, for example to store measurement details, color
palettes, or geolocation data.
  We present benchmarks showing a factor of 2--3$\times$ speedup over HDF5 for
a range of array sizes and a speedup of up to 20$\times$ in reading the common
deep learning datasets MNIST and CIFAR10.
",['\nDavid S. Smith\n'],"8 pages, 3 figures",,http://arxiv.org/abs/2112.01273v1,cs.DB,"['cs.DB', 'cs.LG', 'cs.MS']",,,[]
"On the very accurate evaluation of the Voigt/complex error function with
  small imaginary argument",http://arxiv.org/abs/2112.02078v1,2021-11-30T02:18:03Z,2021-11-30T02:18:03Z,"  A rapidly convergent series, based on Taylor expansion of the imaginary part
of the complex error function, is presented for highly accurate approximation
of the Voigt/complex error function with small imaginary argument (Y less than
0.1). Error analysis and run-time tests in double-precision computing platform
reveals that in the real and imaginary parts the proposed algorithm provides
average accuracy exceeding 10^-15 and 10^-16, respectively, and the calculation
speed is as fast as that of reported in recent publications. An optimized
MATLAB code providing rapid computation with high accuracy is presented.
",['\nYihong Wang\n'],"11 pages, 7 figures",,http://arxiv.org/abs/2112.02078v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Computing with B-series,http://arxiv.org/abs/2111.11680v2,2021-11-23T06:55:29Z,2022-11-15T11:45:27Z,"  We present BSeries.jl, a Julia package for the computation and manipulation
of B-series, which are a versatile theoretical tool for understanding and
designing discretizations of differential equations. We give a short
introduction to the theory of B-series and associated concepts and provide
examples of their use, including method composition and backward error
analysis. The associated software is highly performant and makes it possible to
work with B-series of high order.
","['\nDavid I. Ketcheson\n', '\nHendrik Ranocha\n']",,"ACM Transactions on Mathematical Software, 2022",http://dx.doi.org/10.1145/3573384,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'cs.SC']",10.1145/3573384,,[]
"Polynomial spline collocation method for solving weakly regular Volterra
  integral equations of the first kind",http://arxiv.org/abs/2111.11706v1,2021-11-23T07:58:14Z,2021-11-23T07:58:14Z,"  The polynomial spline collocation method is proposed for solution of Volterra
integral equations of the first kind with special piecewise continuous kernels.
The Gauss-type quadrature formula is used to approximate integrals during the
discretisation of the proposed projection method. The estimate of accuracy of
approximate solution is obtained. Stochastic arithmetics is also used based on
the Contr\^{o}le et Estimation Stochastique des Arrondis de Calculs (CESTAC)
method and the Control of Accuracy and Debugging for Numerical Applications
(CADNA) library. Applying this approach it is possible to find optimal
parameters of the projective method. The numerical examples are included to
illustrate the efficiency of proposed novel collocation method.
","['\nA. Tynda\n', '\nS. Noeiaghdam\n', '\nD. Sidorov\n']","19 pages, 2 fig., 35 ref. Submitted to {\guillemotleft}The Bulletin
  of Irkutsk State University{\guillemotright}. Series
  {\guillemotleft}Mathematics{\guillemotright}",,http://arxiv.org/abs/2111.11706v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.DS', '45H05, 65R20']",,,[]
"NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in
  Machine Learning",http://arxiv.org/abs/2111.13984v2,2021-11-27T21:02:20Z,2022-01-01T18:32:07Z,"  Optimizing nonconvex (NCVX) problems, especially nonsmooth and constrained
ones, is an essential part of machine learning. However, it can be hard to
reliably solve such problems without optimization expertise. Existing
general-purpose NCVX optimization packages are powerful but typically cannot
handle nonsmoothness. GRANSO is among the first optimization solvers targeting
general nonsmooth NCVX problems with nonsmooth constraints, but, as it is
implemented in MATLAB and requires the user to provide analytical gradients,
GRANSO is often not a convenient choice in machine learning (especially deep
learning) applications. To greatly lower the technical barrier, we introduce a
new software package called NCVX, whose initial release contains the solver
PyGRANSO, a PyTorch-enabled port of GRANSO incorporating auto-differentiation,
GPU acceleration, tensor input, and support for new QP solvers. NCVX is built
on freely available and widely used open-source frameworks, and as a highlight,
can solve general constrained deep learning problems, the first of its kind.
NCVX is available at https://ncvx.org, with detailed documentation and numerous
examples from machine learning and other fields.
","['\nBuyun Liang\n', '\nTim Mitchell\n', '\nJu Sun\n']",NCVX is available at https://ncvx.org,,http://arxiv.org/abs/2111.13984v2,cs.LG,"['cs.LG', 'cs.CV', 'cs.MS', 'eess.SP', 'math.OC']",,,[]
"Method for representing an exponent in a fifth-dimensional hypercomplex
  number systems using a hypercomplex computing software",http://arxiv.org/abs/2111.09841v1,2021-11-18T18:07:32Z,2021-11-18T18:07:32Z,"  The structure of method for constructing a representation of an exponential
function in hypercomplex number systems(HNS) by the method of solving an
associated system of linear differential equations is considered. Brief
information about the hypercomplex computing software (HCS) is given. With the
use of HCS, the necessary cumbersome operations on symbolic expressions were
performed when constructing the representation of the exponent in the
fifth-dimensional HNS. Fragments of programs in the environment of HCS and
results of symbolic calculations are resulted
","['\nY. Boiarinova\n', '\nY. Kalinovskiy\n']",,,http://arxiv.org/abs/2111.09841v1,cs.SE,"['cs.SE', 'cs.MS']",,,[]
Implicit SVD for Graph Representation Learning,http://arxiv.org/abs/2111.06312v1,2021-11-11T16:58:17Z,2021-11-11T16:58:17Z,"  Recent improvements in the performance of state-of-the-art (SOTA) methods for
Graph Representational Learning (GRL) have come at the cost of significant
computational resource requirements for training, e.g., for calculating
gradients via backprop over many data epochs. Meanwhile, Singular Value
Decomposition (SVD) can find closed-form solutions to convex problems, using
merely a handful of epochs. In this paper, we make GRL more computationally
tractable for those with modest hardware. We design a framework that computes
SVD of \textit{implicitly} defined matrices, and apply this framework to
several GRL tasks. For each task, we derive linear approximation of a SOTA
model, where we design (expensive-to-store) matrix $\mathbf{M}$ and train the
model, in closed-form, via SVD of $\mathbf{M}$, without calculating entries of
$\mathbf{M}$. By converging to a unique point in one step, and without
calculating gradients, our models show competitive empirical test performance
over various graphs such as article citation and biological interaction
networks. More importantly, SVD can initialize a deeper model, that is
architected to be non-linear almost everywhere, though behaves linearly when
its parameters reside on a hyperplane, onto which SVD initializes. The deeper
model can then be fine-tuned within only a few epochs. Overall, our procedure
trains hundreds of times faster than state-of-the-art methods, while competing
on empirical test performance. We open-source our implementation at:
https://github.com/samihaija/isvd
","['\nSami Abu-El-Haija\n', '\nHesham Mostafa\n', '\nMarcel Nassar\n', '\nValentino Crespi\n', '\nGreg Ver Steeg\n', '\nAram Galstyan\n']",,Advances in Neural Information Processing Systems (NeurIPS) 2021,http://arxiv.org/abs/2111.06312v1,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS', 'cs.SI']",,,[]
Enhanced Formulation for Guillotine 2D Cutting Problems,http://arxiv.org/abs/2111.06348v1,2021-11-11T17:59:35Z,2021-11-11T17:59:35Z,"  We advance the state of the art in Mixed-Integer Linear Programming (MILP)
formulations for Guillotine 2D Cutting Problems by (i) adapting a previously
known reduction to our preprocessing phase and by (ii) enhancing a previous
formulation by cutting down its size and symmetries. Our focus is the
Guillotine 2D Knapsack Problem with orthogonal and unrestricted cuts,
constrained demand, unlimited stages, and no rotation -- however, the
formulation may be adapted to many related problems. The code is available.
Concerning the set of 59 instances used to benchmark the original formulation,
and summing the statistics for all models generated, the enhanced formulation
has only a small fraction of the variables and constraints of the original
model (respectively, 3.07% and 8.35%). The enhanced formulation also takes
about 4 hours to solve all instances while the original formulation takes 12
hours to solve 53 of them (the other six runs hit a three-hour time limit
each). We integrate, to both formulations, a pricing framework proposed for the
original formulation; the enhanced formulation keeps a significant advantage in
this situation. Finally, in a recently proposed set of 80 harder instances, the
enhanced formulation (with and without the pricing framework) found: 22 optimal
solutions for the unrestricted problem (5 already known, 17 new); 22 optimal
solutions for the restricted problem (all are new and they are not the same 22
of the optimal unrestricted solutions); better lower bounds for 25 instances;
better upper bounds for 58 instances.
","['\nHenrique Becker\n', '\nOlinto Araujo\n', '\nLuciana S. Buriol\n']","22 pages, 6 tables",,http://arxiv.org/abs/2111.06348v1,math.OC,"['math.OC', 'cs.DM', 'cs.DS', 'cs.MS', '68R05 (Primary), 68U99, 05D99, 52B99']",,,[]
Verified Optimization,http://arxiv.org/abs/2111.06807v1,2021-11-12T16:38:49Z,2021-11-12T16:38:49Z,"  Optimization is used extensively in engineering, industry, and finance, and
various methods are used to transform problems to the point where they are
amenable to solution by numerical methods. We describe progress towards
developing a framework, based on the Lean interactive proof assistant, for
designing and applying such reductions in reliable and flexible ways.
","['\nAlexander Bentkamp\n', '\nJeremy Avigad\n']",,,http://arxiv.org/abs/2111.06807v1,math.OC,"['math.OC', 'cs.LO', 'cs.MS']",,,[]
ILU Smoothers for Low Mach Navier-Stokes Pressure Solvers,http://arxiv.org/abs/2111.09512v7,2021-11-18T04:12:23Z,2023-11-27T23:11:01Z,"  Incomplete LU (ILU) smoothers are effective in the algebraic multigrid (AMG)
$V$-cycle for reducing high-frequency components of the error. However, the
requisite direct triangular solves are comparatively slow on GPUs. Previous
work has demonstrated the advantages of Jacobi iteration as an alternative to
direct solution of these systems. Depending on the threshold and fill-level
parameters chosen, the factors can be highly non-normal and Jacobi is unlikely
to converge in a low number of iterations. We demonstrate that row scaling can
reduce the departure from normality, allowing us to replace the inherently
sequential solve with a rapidly converging Richardson iteration. There are
several advantages beyond the lower compute time. Scaling is performed locally
for a diagonal block of the global matrix because it is applied directly to the
factor. Further, an ILUT Schur complement smoother maintains a constant GMRES
iteration count as the number of MPI ranks increases, and thus parallel
strong-scaling is improved. Our algorithms have been incorporated into hypre,
and we demonstrate improved time to solution for linear systems arising in the
Nalu-Wind and PeleLM pressure solvers. For large problem sizes, GMRES$+$AMG
executes at least five times faster when using iterative triangular solves
compared with direct solves on massively-parallel GPUs.
","['\nStephen Thomas\n', '\nArielle Carr\n', '\nPaul Mullowney\n', '\nKasia Świrydowicz\n', '\nMarc Day\n']","v2 updated citation information; v3 updated results; v4 abstract
  updated, new results added; v5 new experimental analysis and results added;
  v6 shortened theory, improved discussion of applications; v7 final version",,http://arxiv.org/abs/2111.09512v7,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Parallel Algorithms for Masked Sparse Matrix-Matrix Products,http://arxiv.org/abs/2111.09947v1,2021-11-18T21:03:00Z,2021-11-18T21:03:00Z,"  Computing the product of two sparse matrices (SpGEMM) is a fundamental
operation in various combinatorial and graph algorithms as well as various
bioinformatics and data analytics applications for computing inner-product
similarities. For an important class of algorithms, only a subset of the output
entries are needed, and the resulting operation is known as Masked SpGEMM since
a subset of the output entries is considered to be ""masked out"". Existing
algorithms for Masked SpGEMM usually do not consider mask as part of
multiplication and either first compute a regular SpGEMM followed by masking,
or perform a sparse inner product only for output elements that are not masked
out. In this work, we investigate various novel algorithms and data structures
for this rather challenging and important computation, and provide guidelines
on how to design a fast Masked-SpGEMM for shared-memory architectures. Our
evaluations show that factors such as matrix and mask density, mask structure
and cache behavior play a vital role in attaining high performance for Masked
SpGEMM. We evaluate our algorithms on a large number of matrices using several
real-world benchmarks and show that our algorithms in most cases significantly
outperform the state of the art for Masked SpGEMM implementations.
","['\nSrđan Milaković\n', '\nOguz Selvitopi\n', '\nIsrat Nisa\n', '\nZoran Budimlić\n', '\nAydin Buluc\n']",,,http://arxiv.org/abs/2111.09947v1,cs.DC,"['cs.DC', 'cs.DS', 'cs.MS']",,,[]
"SimpleTensor -- a user-friendly Mathematica package for elementary
  tensor and differential-geometric calculations",http://arxiv.org/abs/2111.06718v1,2021-11-12T13:37:49Z,2021-11-12T13:37:49Z,"  In this paper we present a short overview of the new Wolfram Mathematica
package intended for elementary ""in-basis"" tensor and differential-geometric
calculations. In contrast to alternatives our package is designed to be
easy-to-use, short, all-purpose, and hackable. It supports tensor contractions
using Einstein notation, transformations between different bases, tensor
derivative operator, expansion in basis vectors and forms, exterior derivative,
and interior product.
",['\nD. O. Rybalka\n'],13 pages,,http://arxiv.org/abs/2111.06718v1,nucl-th,"['nucl-th', 'cs.MS', 'cs.SC', 'hep-th', 'physics.comp-ph']",,,[]
"Locally Feasibly Projected Sequential Quadratic Programming for
  Nonlinear Programming on Arbitrary Smooth Constraint Manifolds",http://arxiv.org/abs/2111.03236v1,2021-11-05T03:10:24Z,2021-11-05T03:10:24Z,"  High-dimensional nonlinear optimization problems subject to nonlinear
constraints can appear in several contexts including constrained physical and
dynamical systems, statistical estimation, and other numerical models. Feasible
optimization routines can sometimes be valuable if the objective function is
only defined on the feasible set or if numerical difficulties associated with
merit functions or infeasible termination arise during the use of infeasible
optimization routines. Drawing on the Riemannian optimization and sequential
quadratic programming literature, a practical algorithm is constructed to
conduct feasible optimization on arbitrary implicitly defined constraint
manifolds. Specifically, with $n$ (potentially bound-constrained) variables and
$m < n$ nonlinear constraints, each outer optimization loop iteration involves
a single $O(nm^2)$-flop factorization, and computationally efficient
retractions are constructed that involve $O(nm)$-flop inner loop iterations. A
package, LFPSQP.jl, is created using the Julia language that takes advantage of
automatic differentiation and projected conjugate gradient methods for use in
inexact/truncated Newton steps.
","['\nKevin S. Silmore\n', '\nJames W. Swan\n']","Associated Julia package can be found at
  https://github.com/ksil/LFPSQP.jl",,http://arxiv.org/abs/2111.03236v1,math.OC,"['math.OC', 'cs.MS']",,,[]
"Escaping the abstraction: a foreign function interface for the Unified
  Form Language [UFL]",http://arxiv.org/abs/2111.00945v1,2021-11-01T13:38:38Z,2021-11-01T13:38:38Z,"  High level domain specific languages for the finite element method underpin
high productivity programming environments for simulations based on partial
differential equations (PDE) while employing automatic code generation to
achieve high performance. However, a limitation of this approach is that it
does not support operators that are not directly expressible in the vector
calculus. This is critical in applications where PDEs are not enough to
accurately describe the physical problem of interest. The use of deep learning
techniques have become increasingly popular in filling this knowledge gap, for
example to include features not represented in the differential equations, or
closures for unresolved spatiotemporal scales. We introduce an interface within
the Firedrake finite element system that enables a seamless interface with deep
learning models. This new feature composes with the automatic differentiation
capabilities of Firedrake, enabling the automated solution of inverse problems.
Our implementation interfaces with PyTorch and can be extended to other machine
learning libraries. The resulting framework supports complex models coupling
PDEs and deep learning whilst maintaining separation of concerns between
application scientists and software experts.
","['\nNacime Bouziani\n', '\nDavid A. Ham\n']",First Workshop on Differentiable Programming (NeurIPS 2021),,http://arxiv.org/abs/2111.00945v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Source-to-Source Automatic Differentiation of OpenMP Parallel Loops,http://arxiv.org/abs/2111.01861v1,2021-11-02T19:40:59Z,2021-11-02T19:40:59Z,"  This paper presents our work toward correct and efficient automatic
differentiation of OpenMP parallel worksharing loops in forward and reverse
mode. Automatic differentiation is a method to obtain gradients of numerical
programs, which are crucial in optimization, uncertainty quantification, and
machine learning. The computational cost to compute gradients is a common
bottleneck in practice. For applications that are parallelized for multicore
CPUs or GPUs using OpenMP, one also wishes to compute the gradients in
parallel. We propose a framework to reason about the correctness of the
generated derivative code, from which we justify our OpenMP extension to the
differentiation model. We implement this model in the automatic differentiation
tool Tapenade and present test cases that are differentiated following our
extended differentiation procedure. Performance of the generated derivative
programs in forward and reverse mode is better than sequential, although our
reverse mode often scales worse than the input programs.
","['\nJan Hückelheim\n', '\nLaurent Hascoët\n']",To appear in ACM TOMS,,http://arxiv.org/abs/2111.01861v1,cs.MS,"['cs.MS', 'cs.LG', 'cs.PF']",,,[]
Symbolic spectral decomposition of 3x3 matrices,http://arxiv.org/abs/2111.02117v1,2021-11-03T10:24:22Z,2021-11-03T10:24:22Z,"  Spectral decomposition of matrices is a recurring and important task in
applied mathematics, physics and engineering. Many application problems require
the consideration of matrices of size three with spectral decomposition over
the real numbers. If the functional dependence of the spectral decomposition on
the matrix elements has to be preserved, then closed-form solution approaches
must be considered. Existing closed-form expressions are based on the use of
principal matrix invariants which suffer from a number of deficiencies when
evaluated in the framework of finite precision arithmetic. This paper
introduces an alternative form for the computation of the involved matrix
invariants (in particular the discriminant) in terms of sum-of-products
expressions as function of the matrix elements. We prove and demonstrate by
numerical examples that this alternative approach leads to increased floating
point accuracy, especially in all important limit cases (e.g. eigenvalue
multiplicity). It is believed that the combination of symbolic algorithms with
the accuracy improvements presented in this paper can serve as a powerful
building block for many engineering tasks.
","['\nMichal Habera\n', '\nAndreas Zilian\n']",,,http://arxiv.org/abs/2111.02117v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
MetaFEM: A Generic FEM Solver By Meta-expressions,http://arxiv.org/abs/2111.03541v2,2021-11-05T15:01:56Z,2021-11-11T22:57:45Z,"  Current multi-physics Finite Element Method (FEM) solvers are complex systems
in terms of both their mathematical complexity and lines of code. This paper
proposes a skeleton generic FEM solver, named MetaFEM, in total about 5,000
lines of Julia code, which translates generic input Partial Differential
Equation (PDE) weak forms into corresponding GPU-accelerated simulations with a
grammar similar to FEniCS or FreeFEM. Two novel approaches differentiate
MetaFEM from the common solvers: (1) the FEM kernel is based on an original
theory/algorithm which explicitly processes meta-expressions, as the name
suggests, and (2) the symbolic engine is a rule-based Computer Algebra System
(CAS), i.e., the equations are rewritten/derived according to a set of
rewriting rules instead of going through completely fixed routines, supporting
easy customization by developers. Example cases in thermal conduction, linear
elasticity and incompressible flow are presented to demonstrate utility.
","['\nJiaxi Xie\n', '\nKornel Ehmann\n', '\nJian Cao\n']",,,http://dx.doi.org/10.1016/j.cma.2022.114907,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1016/j.cma.2022.114907,,[]
A set of R packages to estimate population counts from mobile phone data,http://arxiv.org/abs/2111.05269v1,2021-11-04T04:02:44Z,2021-11-04T04:02:44Z,"  In this paper, we describe the software implementation of the methodological
framework designed to incorporate mobile phone data into the current production
chain of official statistics during the ESSnet Big Data II project. We present
an overview of the architecture of the software stack, its components, the
interfaces between them, and show how they can be used. Our software
implementation consists in four R packages: destim for estimation of the
spatial distribution of the mobile devices, deduplication for classification of
the devices as being in 1:1 or 2:1 correspondence with its owner, aggregation
for estimation of the number of individuals detected by the network starting
from the geolocation probabilities and the duplicity probabilities and
inference which combines the number of individuals provided by the previous
package with other information like the population counts from an official
register and the mobile operator penetration rates to provide an estimation of
the target population counts.
","['\nBogdan Oancea\n', '\nDavid Salgado\n', '\nLuis Sanguiao Sande\n', '\nSandra Barragan\n']","16 pages, 4 figures","ROMANIAN STATISTICAL REVIEW, Issue 1, Page 17-38, 2021",http://arxiv.org/abs/2111.05269v1,cs.MS,"['cs.MS', 'cs.SI', 'stat.AP']",,,[]
"The Creation of Puffin, the Automatic Uncertainty Compiler",http://arxiv.org/abs/2110.10153v2,2021-10-19T10:28:35Z,2021-10-25T09:40:02Z,"  An uncertainty compiler is a tool that automatically translates original
computer source code lacking explicit uncertainty analysis into code containing
appropriate uncertainty representations and uncertainty propagation algorithms.
We have developed an prototype uncertainty compiler along with an associated
object-oriented uncertainty language in the form of a stand-alone Python
library. It handles the specifications of input uncertainties and inserts calls
to intrusive uncertainty quantification algorithms in the library. The
uncertainty compiler can apply intrusive uncertainty propagation methods to
codes or parts of codes and therefore more comprehensively and flexibly address
both epistemic and aleatory uncertainties.
","['\nNicholas Gray\n', '\nMarco De Angelis\n', '\nScott Ferson\n']","21 Pages, 10 Figures",,http://dx.doi.org/10.1016/j.ijar.2023.108951,cs.MS,"['cs.MS', 'stat.CO']",10.1016/j.ijar.2023.108951,,[]
Streaming Generalized Canonical Polyadic Tensor Decompositions,http://arxiv.org/abs/2110.14514v1,2021-10-27T15:26:24Z,2021-10-27T15:26:24Z,"  In this paper, we develop a method which we call OnlineGCP for computing the
Generalized Canonical Polyadic (GCP) tensor decomposition of streaming data.
GCP differs from traditional canonical polyadic (CP) tensor decompositions as
it allows for arbitrary objective functions which the CP model attempts to
minimize. This approach can provide better fits and more interpretable models
when the observed tensor data is strongly non-Gaussian. In the streaming case,
tensor data is gradually observed over time and the algorithm must
incrementally update a GCP factorization with limited access to prior data. In
this work, we extend the GCP formalism to the streaming context by deriving a
GCP optimization problem to be solved as new tensor data is observed, formulate
a tunable history term to balance reconstruction of recently observed data with
data observed in the past, develop a scalable solution strategy based on
segregated solves using stochastic gradient descent methods, describe a
software implementation that provides performance and portability to
contemporary CPU and GPU architectures and integrates with Matlab for enhanced
useability, and demonstrate the utility and performance of the approach and
software on several synthetic and real tensor data sets.
","['\nEric Phipps\n', '\nNick Johnson\n', '\nTamara G. Kolda\n']",,,http://arxiv.org/abs/2110.14514v1,math.NA,"['math.NA', 'cs.LG', 'cs.MS', 'cs.NA']",,,[]
Accelerating quantum many-body configuration interaction with directives,http://arxiv.org/abs/2110.10765v1,2021-10-20T20:17:18Z,2021-10-20T20:17:18Z,"  Many-Fermion Dynamics-nuclear, or MFDn, is a configuration interaction (CI)
code for nuclear structure calculations. It is a platform-independent Fortran
90 code using a hybrid MPI+X programming model. For CPU platforms the
application has a robust and optimized OpenMP implementation for shared memory
parallelism. As part of the NESAP application readiness program for NERSC's
latest Perlmutter system, MFDn has been updated to take advantage of
accelerators. The current mainline GPU port is based on OpenACC. In this work
we describe some of the key challenges of creating an efficient GPU
implementation. Additionally, we compare the support of OpenMP and OpenACC on
AMD and NVIDIA GPUs.
","['\nBrandon Cook\n', '\nPatrick J. Fasano\n', '\nPieter Maris\n', '\nChao Yang\n', '\nDossay Oryspayev\n']","22 pages, 7 figures, 11 code listings, WACCPD@SC21",,http://dx.doi.org/10.1007/978-3-030-97759-7_6,cs.DC,"['cs.DC', 'cs.CE', 'cs.MS', 'cs.PF', 'nucl-th']",10.1007/978-3-030-97759-7_6,,[]
LightSeq2: Accelerated Training for Transformer-based Models on GPUs,http://arxiv.org/abs/2110.05722v3,2021-10-12T03:17:03Z,2022-06-16T11:29:37Z,"  Transformer-based neural models are used in many AI applications. Training
these models is expensive, as it takes huge GPU resources and long duration. It
is challenging because typical data like sentences have variable lengths, and
Transformer's computation patterns are more complex than convolutional neural
networks. Existing systems either only focus on model inference or optimization
for only BERT-like encoder models. In this paper, we present LightSeq2, a
system to accelerate training for a general family of Transformer models on
GPUs. We propose a series of GPU optimization techniques tailored to the
specific computation flow and memory access patterns of Transformer models.
LightSeq2 supports many model architectures, including BERT (encoder-only), GPT
(decoder-only), Transformer (encoder-decoder), and vision Transformer. Our
experiments for a variety of models and benchmarks show that LightSeq2 is
consistently faster (1.4-3.5x) than previous systems on different GPUs. In
particular, it gains 308% training speedup compared with existing systems on a
large public machine translation benchmark (WMT14 English-German).
","['\nXiaohui Wang\n', '\nYang Wei\n', '\nYing Xiong\n', '\nGuyue Huang\n', '\nXian Qian\n', '\nYufei Ding\n', '\nMingxuan Wang\n', '\nLei Li\n']","13 pages, 22 figures, accepted by SC 22",,http://arxiv.org/abs/2110.05722v3,cs.CL,"['cs.CL', 'cs.MS']",,,[]
A Cross-Platform Benchmark for Interval Computation Libraries,http://arxiv.org/abs/2110.06215v1,2021-10-12T16:24:39Z,2021-10-12T16:24:39Z,"  Interval computation is widely used to certify computations that use floating
point operations to avoid pitfalls related to rounding error introduced by
inaccurate operations. Despite its popularity and practical benefits, support
for interval arithmetic is not standardized nor available in mainstream
programming languages. We propose the first benchmark for interval
computations, coupled with reference solutions computed with exact arithmetic,
and compare popular C and C++ libraries over different architectures, operating
systems, and compilers. The benchmark allows identifying limitations in
existing implementations, and provides a reliable guide on which library to use
on each system. We believe that our benchmark will be useful for developers of
future interval libraries, as a way to test the correctness and performance of
their algorithms.
","['\nXuan Tang\n', '\nZachary Ferguson\n', '\nTeseo Schneider\n', '\nDenis Zorin\n', '\nShoaib Kamil\n', '\nDaniele Panozzo\n']","11 pages, 33 figures, 2 tables","In Parallel Processing and Applied Mathematics. PPAM 2022. Lecture
  Notes in Computer Science, vol 13827. Springer, Cham",http://dx.doi.org/10.1007/978-3-031-30445-3_35,cs.MS,"['cs.MS', 'cs.CG']",10.1007/978-3-031-30445-3_35,,[]
"Two-dimensional mesh generator in generalized coordinates implemented in
  Python",http://arxiv.org/abs/2110.12875v1,2021-10-17T20:42:18Z,2021-10-17T20:42:18Z,"  Through mathematical models, it is possible to turn a problem of the physical
domain into the computational domain. In this context, the paper presents a
two-dimensional mesh generator in generalized coordinates, which uses the
Parametric Linear Spline method and partial differential equations. The
generator is automated and able to treat real complex domains. The code was
implemented in Python, applying the Numpy and Matplotlib libraries to matrix
manipulations and graphical plots, respectively. Applications are made for
monoblock meshes (two-dimensional shape of a bottle) and multi-block meshes
(geometry of Igap\'o I lake, Londrina, Paran\'a, Brazil).
","['\nGustavo Taiji Naozuka\n', '\nSaulo Martiello Mastelini\n', '\nEliandro Rodrigues Cirilo\n', '\nNeyva Maria Lopes Romeiro\n', '\nPaulo Laerte Natti\n']","14 pages, 7 figures","Semina: Exact and Technological Sciences, v.42, n.1, p.29-44,
  Jan./June2021",http://dx.doi.org/10.5433/1679-0375.2021v42n1p29,cs.MS,"['cs.MS', 'cs.CY']",10.5433/1679-0375.2021v42n1p29,,[]
"Fast Block Linear System Solver Using Q-Learning Schduling for Unified
  Dynamic Power System Simulations",http://arxiv.org/abs/2110.05843v1,2021-10-12T09:10:27Z,2021-10-12T09:10:27Z,"  We present a fast block direct solver for the unified dynamic simulations of
power systems. This solver uses a novel Q-learning based method for task
scheduling. Unified dynamic simulations of power systems represent a method in
which the electric-mechanical transient, medium-term and long-term dynamic
phenomena are organically united. Due to the high rank and large numbers in
solving, fast solution of these equations is the key to speeding up the
simulation. The sparse systems of simulation contain complex nested block
structure, which could be used by the solver to speed up. For the scheduling of
blocks and frontals in the solver, we use a learning based task-tree scheduling
technique in the framework of Markov Decision Process. That is, we could learn
optimal scheduling strategies by offline training on many sample matrices. Then
for any systems, the solver would get optimal task partition and scheduling on
the learned model. Our learning-based algorithm could help improve the
performance of sparse solver, which has been verified in some numerical
experiments. The simulation on some large power systems shows that our solver
is 2-6 times faster than KLU, which is the state-of-the-art sparse solver for
circuit simulation problems.
","['\nYingshi Chen\n', '\nXinli Song\n', '\nHanYang Dai\n', '\nTao Liu\n', '\nWuzhi Zhong\n', '\nGuoyang Wu\n']","8 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:2109.14929",,http://arxiv.org/abs/2110.05843v1,cs.LG,"['cs.LG', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
A Brief Introduction to Automatic Differentiation for Machine Learning,http://arxiv.org/abs/2110.06209v2,2021-10-12T00:10:28Z,2021-10-14T19:18:07Z,"  Machine learning and neural network models in particular have been improving
the state of the art performance on many artificial intelligence related tasks.
Neural network models are typically implemented using frameworks that perform
gradient based optimization methods to fit a model to a dataset. These
frameworks use a technique of calculating derivatives called automatic
differentiation (AD) which removes the burden of performing derivative
calculations from the model designer. In this report we describe AD, its
motivations, and different implementation approaches. We briefly describe
dataflow programming as it relates to AD. Lastly, we present example programs
that are implemented with Tensorflow and PyTorch, which are two commonly used
AD frameworks.
",['\nDavan Harrison\n'],8 pages,,http://arxiv.org/abs/2110.06209v2,cs.LG,"['cs.LG', 'cs.CL', 'cs.MS', 'cs.PL']",,,[]
Least Squares on GPUs in Multiple Double Precision,http://arxiv.org/abs/2110.08375v2,2021-10-15T21:25:14Z,2022-03-20T23:53:20Z,"  This paper describes the application of the code generated by the CAMPARY
software to accelerate the solving of linear systems in the least squares sense
on Graphics Processing Units (GPUs), in double double, quad double, and octo
double precision. The goal is to use accelerators to offset the cost overhead
caused by multiple double precision arithmetic. For the blocked Householder QR
and the back substitution, of interest are those dimensions at which teraflop
performance is attained. The other interesting question is the cost overhead
factor that appears each time the precision is doubled.
  Experimental results are reported on five different NVIDIA GPUs, with a
particular focus on the P100 and the V100, both capable of teraflop
performance. Thanks to the high Compute to Global Memory Access (CGMA) ratios
of multiple double arithmetic, teraflop performance is already attained running
the double double QR on 1,024-by-1,024 matrices, both on the P100 and the V100.
For the back substitution, the dimension of the upper triangular system must be
as high as 17,920 to reach one teraflops on the V100, in quad double precision,
and then taking only the times spent by the kernels into account. The lower
performance of the back substitution in small dimensions does not prevent
teraflop performance of the solver at dimension 1,024, as the time for the QR
decomposition dominates.
  In doubling the precision from double double to quad double and from quad
double to octo double, the observed cost overhead factors are lower than the
factors predicted by the arithmetical operation counts. This observation
correlates with the increased performance for increased precision, which can
again be explained by the high CGMA ratios.
",['\nJan Verschelde\n'],"24 pages, 11 tables, 5 figures, added plot of the roofline model.
  Accepted for publication in the 2022 IEEE International Parallel and
  Distributed Processing Symposium Workshops (IPDPSW)",,http://arxiv.org/abs/2110.08375v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",,,[]
"libdlr: Efficient imaginary time calculations using the discrete Lehmann
  representation",http://arxiv.org/abs/2110.06765v3,2021-10-13T15:02:27Z,2022-06-21T16:45:35Z,"  We introduce libdlr, a library implementing the recently introduced discrete
Lehmann representation (DLR) of imaginary time Green's functions. The DLR basis
consists of a collection of exponentials chosen by the interpolative
decomposition to ensure stable and efficient recovery of Green's functions from
imaginary time or Matsbuara frequency samples. The library provides subroutines
to build the DLR basis and grids, and to carry out various standard operations.
The simplicity of the DLR makes it straightforward to incorporate into existing
codes as a replacement for less efficient representations of imaginary time
Green's functions, and libdlr is intended to facilitate this process. libdlr is
written in Fortran, provides a C header interface, and contains a Python module
pydlr. We also introduce a stand-alone Julia implementation, Lehmann.jl.
","['\nJason Kaye\n', '\nKun Chen\n', '\nHugo U. R. Strand\n']",,,http://dx.doi.org/10.1016/j.cpc.2022.108458,physics.comp-ph,"['physics.comp-ph', 'cond-mat.str-el', 'cs.MS', 'cs.NA', 'math.NA', '81-04, 65D15', 'G.4; J.2; G.1.2']",10.1016/j.cpc.2022.108458,,[]
"The software design of Gridap: a Finite Element package based on the
  Julia JIT compiler",http://arxiv.org/abs/2109.12818v1,2021-09-27T06:27:37Z,2021-09-27T06:27:37Z,"  We present the software design of Gridap, a novel finite element library
written exclusively in the Julia programming language, which is being used by
several research groups world-wide to simulate complex physical phenomena such
as magnetohydrodynamics, photonics, weather modeling, non-linear solid
mechanics, and fluid-structure interaction problems. The library provides a
feature-rich set of discretization techniques for the numerical approximation
of a wide range of PDEs, including linear, nonlinear, single-field, and
multi-field equations. An expressive API allows users to define PDEs in weak
form by a syntax close to the mathematical notation. While this is also
available in previous codes, the main novelty of Gridap is that it implements
this API without introducing a DSL plus a compiler of variational forms.
Instead, it leverages the Julia just-in-time compiler to build efficient code,
specialized for the concrete problem at hand. As a result, there is no need to
use different languages for the computational back-end and the user front-end
anymore, thus eliminating the so-called two-language problem. Gridap also
provides a low-level API that is modular and extensible via the
multiple-dispatch paradigm of Julia and provides easy access to the main
building blocks of the library. The main contribution of this paper is the
detailed presentation of the novel software abstractions behind the Gridap
design that leverages the new software possibilities provided by the Julia
language. The second main contribution of the article is a performance
comparison against FEniCS. We measure CPU times needed to assemble discrete
systems of linear equations for different problem types and show that the
performance of Gridap is comparable to FEniCS, demonstrating that the new
software design does not compromise performance. Gridap is freely available at
Github and distributed under an MIT license.
","['\nFrancesc Verdugo\n', '\nSantiago Badia\n']",,,http://dx.doi.org/10.1016/j.cpc.2022.108341,cs.MS,['cs.MS'],10.1016/j.cpc.2022.108341,,[]
MPLAPACK version 2.0.1 user manual,http://arxiv.org/abs/2109.13406v2,2021-09-28T00:10:44Z,2022-09-12T10:07:56Z,"  The MPLAPACK (formerly MPACK) is a multiple-precision version of LAPACK
(https://www.netlib.org/lapack/). MPLAPACK version 2.0.1 is based on LAPACK
version 3.9.1 and translated from Fortran 90 to C++ using FABLE, a Fortran to
C++ source-to-source conversion tool
(https://github.com/cctbx/cctbx_project/tree/master/fable/). MPLAPACK version
2.0.1 provides the real and complex version of MPBLAS, and the real and complex
versions of MPLAPACK support all LAPACK features: solvers for systems of
simultaneous linear equations, least-squares solutions of linear systems of
equations, eigenvalue problems, and singular value problems, and related matrix
factorizations except for mixed-precision routines. The MPLAPACK defines an API
for numerical linear algebra, similar to LAPACK. It is easy to port legacy
C/C++ numerical codes using MPLAPACK. MPLAPACK supports binary64, binary128,
FP80 (extended double), MPFR, GMP, and QD libraries (double-double and
quad-double). Users can choose MPFR or GMP for arbitrary accurate calculations,
double-double or quad-double for fast 32 or 64-decimal calculations. We can
consider the binary64 version as the C++ version of LAPACK. Moreover, it comes
with an OpenMP accelerated version of MPBLAS for some routines and CUDA (A100
and V100 support) for double-double versions of Rgemm and Rsyrk. The peak
performances of the OpenMP version are almost proportional to the number of
cores, and the performances of the CUDA version are impressive, and
approximately 400-600 GFlops. MPLAPACK is available at GitHub
(https://github.com/nakatamaho/mplapack/) under the 2-clause BSD license.
",['\nMaho Nakata\n'],,,http://arxiv.org/abs/2109.13406v2,cs.MS,['cs.MS'],,,[]
preCICE v2: A Sustainable and User-Friendly Coupling Library,http://arxiv.org/abs/2109.14470v2,2021-09-29T15:01:34Z,2021-09-30T09:42:19Z,"  preCICE is a free/open-source coupling library. It enables creating
partitioned multi-physics simulations by gluing together separate software
packages. This paper summarizes the development efforts in preCICE of the past
five years. During this time span, we have turned the software from a working
prototype -- sophisticated numerical coupling methods and scalability on ten
thousands of compute cores -- to a sustainable and user-friendly software
project with a steadily-growing community. Today, we know through forum
discussions, conferences, workshops, and publications of more than 100 research
groups using preCICE. We cover the fundamentals of the software alongside a
performance and accuracy analysis of different data mapping methods.
Afterwards, we describe ready-to-use integration with widely-used external
simulation software packages, tests and continuous integration from unit to
system level, and community building measures, drawing an overview of the
current preCICE ecosystem.
","['\nGerasimos Chourdakis\n', '\nKyle Davis\n', '\nBenjamin Rodenberg\n', '\nMiriam Schulte\n', '\nFrédéric Simonis\n', '\nBenjamin Uekermann\n', '\nGeorg Abrams\n', '\nHans-Joachim Bungartz\n', '\nLucia Cheung Yau\n', '\nIshaan Desai\n', '\nKonrad Eder\n', '\nRichard Hertrich\n', '\nFlorian Lindner\n', '\nAlexander Rusch\n', '\nDmytro Sashko\n', '\nDavid Schneider\n', '\nAmin Totounferoush\n', '\nDominik Volland\n', '\nPeter Vollmer\n', '\nOguz Ziya Koseomur\n']","added missing author, added author contributions, changed license",,http://dx.doi.org/10.12688/openreseurope.14445.1,cs.MS,['cs.MS'],10.12688/openreseurope.14445.1,,[]
An Attempt to Generate Code for Symmetric Tensor Computations,http://arxiv.org/abs/2110.00186v1,2021-10-01T03:07:26Z,2021-10-01T03:07:26Z,"  This document describes an attempt to develop a compiler-based approach for
computations with symmetric tensors. Given a computation and the symmetries of
its input tensors, we derive formulas for random access under a storage scheme
that eliminates redundancies; construct intermediate representations to
describe the loop structure; and translate this information, using the taco
tensor algebra compiler, into code. While we achieve a framework for reasoning
about a fairly general class of symmetric computations, the resulting code is
not performant when the symmetries are misaligned.
","['\nJessica Shi\n', '\nStephen Chou\n', '\nFredrik Kjolstad\n', '\nSaman Amarasinghe\n']",,,http://arxiv.org/abs/2110.00186v1,cs.MS,"['cs.MS', 'cs.PL']",,,[]
"pyFFS: A Python Library for Fast Fourier Series Computation and
  Interpolation with GPU Acceleration",http://arxiv.org/abs/2110.00262v3,2021-10-01T08:38:17Z,2022-09-26T11:48:08Z,"  Fourier transforms are an often necessary component in many computational
tasks, and can be computed efficiently through the fast Fourier transform (FFT)
algorithm. However, many applications involve an underlying continuous signal,
and a more natural choice would be to work with e.g. the Fourier series (FS)
coefficients in order to avoid the additional overhead of translating between
the analog and discrete domains. Unfortunately, there exists very little
literature and tools for the manipulation of FS coefficients from discrete
samples. This paper introduces a Python library called pyFFS for efficient FS
coefficient computation, convolution, and interpolation. While the libraries
SciPy and NumPy provide efficient functionality for discrete Fourier transform
coefficients via the FFT algorithm, pyFFS addresses the computation of FS
coefficients through what we call the fast Fourier series (FFS). Moreover,
pyFFS includes an FS interpolation method based on the chirp Z-transform that
can make it more than an order of magnitude faster than the SciPy equivalent
when one wishes to perform interpolation. GPU support through the CuPy library
allows for further acceleration, e.g. an order of magnitude faster for
computing the 2-D FS coefficients of 1000 x 1000 samples and nearly two orders
of magnitude faster for 2-D interpolation. As an application, we discuss the
use of pyFFS in Fourier optics. pyFFS is available as an open source package at
https://github.com/imagingofthings/pyFFS, with documentation at
https://pyffs.readthedocs.io.
","['\nEric Bezzam\n', '\nSepand Kashani\n', '\nPaul Hurley\n', '\nMartin Vetterli\n', '\nMatthieu Simeoni\n']","SIAM Journal on Scientific Computing, Volume 44, Issue 4 (2022)",,http://arxiv.org/abs/2110.00262v3,cs.MS,"['cs.MS', 'eess.SP']",,,[]
Learning the Markov Decision Process in the Sparse Gaussian Elimination,http://arxiv.org/abs/2109.14929v1,2021-09-30T08:56:39Z,2021-09-30T08:56:39Z,"  We propose a learning-based approach for the sparse Gaussian Elimination.
There are many hard combinatorial optimization problems in modern sparse
solver. These NP-hard problems could be handled in the framework of Markov
Decision Process, especially the Q-Learning technique. We proposed some
Q-Learning algorithms for the main modules of sparse solver: minimum degree
ordering, task scheduling and adaptive pivoting. Finally, we recast the sparse
solver into the framework of Q-Learning.
  Our study is the first step to connect these two classical mathematical
models: Gaussian Elimination and Markov Decision Process. Our learning-based
algorithm could help improve the performance of sparse solver, which has been
verified in some numerical experiments.
",['\nYingshi Chen\n'],"13 pages,2 figures",,http://arxiv.org/abs/2109.14929v1,math.NA,"['math.NA', 'cs.LG', 'cs.MS', 'cs.NA']",,,[]
LazySets.jl: Scalable Symbolic-Numeric Set Computations,http://arxiv.org/abs/2110.01711v2,2021-10-04T20:50:47Z,2021-12-21T17:45:01Z,"  LazySets.jl is a Julia library that provides ways to symbolically represent
sets of points as geometric shapes, with a special focus on convex sets and
polyhedral approximations. LazySets provides methods to apply common set
operations, convert between different set representations, and efficiently
compute with sets in high dimensions using specialized algorithms based on the
set types. LazySets is the core library of JuliaReach, a cutting-edge software
addressing the fundamental problem of reachability analysis: computing the set
of states that are reachable by a dynamical system from all initial states and
for all admissible inputs and parameters. While the library was originally
designed for reachability and formal verification, its scope goes beyond such
topics. LazySets is an easy-to-use, general-purpose and scalable library for
computations that mix symbolics and numerics. In this article we showcase the
basic functionality, highlighting some of the key design choices.
","['\nMarcelo Forets\n', '\nChristian Schilling\n']",published in the Proceedings of the JuliaCon Conferences 2021,JuliaCon Proceedings (2021),http://dx.doi.org/10.21105/jcon.00097,cs.MS,"['cs.MS', 'cs.CG', 'cs.NA', 'math.NA']",10.21105/jcon.00097,,[]
Power Consumption Analysis of Parallel Algorithms on GPUs,http://arxiv.org/abs/2110.01414v1,2021-09-28T14:17:39Z,2021-09-28T14:17:39Z,"  Due to their highly parallel multi-cores architecture, GPUs are being
increasingly used in a wide range of computationally intensive applications.
Compared to CPUs, GPUs can achieve higher performances at accelerating the
programs' execution in an energy-efficient way. Therefore GPGPU computing is
useful for high performance computing applications and in many scientific
research fields. In order to bring further performance improvements, GPU
clusters are increasingly adopted. The energy consumed by GPUs cannot be
neglected. Therefore, an energy-efficient time scheduling of the programs that
are going to be executed by the parallel GPUs based on their deadline as well
as the assigned priorities could be deployed to face their energetic avidity.
For this reason, we present in this paper a model enabling the measure of the
power consumption and the time execution of some elementary operations running
on a single GPU using a new developed energy measurement protocol.
Consequently, using our methodology, energy needs of a program could be
predicted, allowing a better task scheduling.
","['\nFrédéric Magoulès\n', '\nAbal-Kassim Cheik Ahamed\n', '\nAlban Desmaison\n', '\nJean-Christophe Léchenet\n', '\nFrançois Mayer\n', '\nHaifa Ben Salem\n', '\nThomas Zhu\n']",,,http://dx.doi.org/10.1109/HPCC.2014.54,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'cs.PF', 'math.NA', '14Q65, 15A60, 65E10, 65F10, 68W10, 65Y05, 68M20', 'G.1.3; G.1.6; I.3.1; D.3.4']",10.1109/HPCC.2014.54,,[]
Arbitrary-precision computation of the gamma function,http://arxiv.org/abs/2109.08392v1,2021-09-17T07:58:43Z,2021-09-17T07:58:43Z,"  We discuss the best methods available for computing the gamma function
$\Gamma(z)$ in arbitrary-precision arithmetic with rigorous error bounds. We
address different cases: rational, algebraic, real or complex arguments; large
or small arguments; low or high precision; with or without precomputation. The
methods also cover the log-gamma function $\log \Gamma(z)$, the digamma
function $\psi(z)$, and derivatives $\Gamma^{(n)}(z)$ and $\psi^{(n)}(z)$.
Besides attempting to summarize the existing state of the art, we present some
new formulas, estimates, bounds and algorithmic improvements and discuss
implementation results.
",['\nFredrik Johansson\nLFANT\n'],,,http://arxiv.org/abs/2109.08392v1,cs.MS,"['cs.MS', 'math.CA']",,,['LFANT']
Merlion: A Machine Learning Library for Time Series,http://arxiv.org/abs/2109.09265v1,2021-09-20T02:03:43Z,2021-09-20T02:03:43Z,"  We introduce Merlion, an open-source machine learning library for time
series. It features a unified interface for many commonly used models and
datasets for anomaly detection and forecasting on both univariate and
multivariate time series, along with standard pre/post-processing layers. It
has several modules to improve ease-of-use, including visualization, anomaly
score calibration to improve interpetability, AutoML for hyperparameter tuning
and model selection, and model ensembling. Merlion also provides a unique
evaluation framework that simulates the live deployment and re-training of a
model in production. This library aims to provide engineers and researchers a
one-stop solution to rapidly develop models for their specific time series
needs and benchmark them across multiple time series datasets. In this
technical report, we highlight Merlion's architecture and major
functionalities, and we report benchmark numbers across different baseline
models and ensembles.
","['\nAadyot Bhatnagar\n', '\nPaul Kassianik\n', '\nChenghao Liu\n', '\nTian Lan\n', '\nWenzhuo Yang\n', '\nRowan Cassius\n', '\nDoyen Sahoo\n', '\nDevansh Arpit\n', '\nSri Subramanian\n', '\nGerald Woo\n', '\nAmrita Saha\n', '\nArun Kumar Jagota\n', '\nGokulakrishnan Gopalakrishnan\n', '\nManpreet Singh\n', '\nK C Krithika\n', '\nSukumar Maddineni\n', '\nDaeki Cho\n', '\nBo Zong\n', '\nYingbo Zhou\n', '\nCaiming Xiong\n', '\nSilvio Savarese\n', '\nSteven Hoi\n', '\nHuan Wang\n']","22 pages, 1 figure, 14 tables",,http://arxiv.org/abs/2109.09265v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
"AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming
  in Julia",http://arxiv.org/abs/2109.12449v2,2021-09-25T22:19:12Z,2022-02-04T22:28:20Z,"  No single Automatic Differentiation (AD) system is the optimal choice for all
problems. This means informed selection of an AD system and combinations can be
a problem-specific variable that can greatly impact performance. In the Julia
programming language, the major AD systems target the same input and thus in
theory can compose. Hitherto, switching between AD packages in the Julia
Language required end-users to familiarize themselves with the user-facing API
of the respective packages. Furthermore, implementing a new, usable AD package
required AD package developers to write boilerplate code to define convenience
API functions for end-users. As a response to these issues, we present
AbstractDifferentiation.jl for the automatized generation of an extensive,
unified, user-facing API for any AD package. By splitting the complexity
between AD users and AD developers, AD package developers only need to
implement one or two primitive definitions to support various utilities for AD
users like Jacobians, Hessians and lazy product operators from native
primitives such as pullbacks or pushforwards, thus removing tedious -- but so
far inevitable -- boilerplate code, and enabling the easy switching and
composing between AD implementations for end-users.
","['\nFrank Schäfer\n', '\nMohamed Tarek\n', '\nLyndon White\n', '\nChris Rackauckas\n']","3 figures, 2 tables 15 pages",,http://arxiv.org/abs/2109.12449v2,cs.MS,"['cs.MS', 'cs.LG', 'cs.SE']",,,[]
"H2Opus: A distributed-memory multi-GPU software package for non-local
  operators",http://arxiv.org/abs/2109.05451v1,2021-09-12T07:32:41Z,2021-09-12T07:32:41Z,"  Hierarchical $\mathcal{H}^2$-matrices are asymptotically optimal
representations for the discretizations of non-local operators such as those
arising in integral equations or from kernel functions. Their $O(N)$ complexity
in both memory and operator application makes them particularly suited for
large-scale problems. As a result, there is a need for software that provides
support for distributed operations on these matrices to allow large-scale
problems to be represented. In this paper, we present high-performance,
distributed-memory GPU-accelerated algorithms and implementations for
matrix-vector multiplication and matrix recompression of hierarchical matrices
in the $\mathcal{H}^2$ format.
  The algorithms are a new module of H2Opus, a performance-oriented package
that supports a broad variety of $\mathcal{H}^2$-matrix operations on CPUs and
GPUs. Performance in the distributed GPU setting is achieved by marshaling the
tree data of the hierarchical matrix representation to allow batched kernels to
be executed on the individual GPUs. MPI is used for inter-process
communication. We optimize the communication data volume and hide much of the
communication cost with local compute phases of the algorithms. Results show
near-ideal scalability up to 1024 NVIDIA V100 GPUs on Summit, with performance
exceeding 2.3 Tflop/s/GPU for the matrix-vector multiplication, and 670
Gflops/s/GPU for matrix compression, which involves batched QR and SVD
operations.
  We illustrate the flexibility and efficiency of the library by solving a 2D
variable diffusivity integral fractional diffusion problem with an algebraic
multigrid-preconditioned Krylov solver and demonstrate scalability up to 16M
degrees of freedom problems on 64 GPUs.
","['\nStefano Zampini\n', '\nWajih Boukaram\n', '\nGeorge Turkiyyah\n', '\nOmar Knio\n', '\nDavid E. Keyes\n']",,,http://arxiv.org/abs/2109.05451v1,cs.DC,"['cs.DC', 'cs.MS', '65Y05, 65F55, 65R20, 65-04', 'G.4; G.1.9']",,,[]
OGRe: An Object-Oriented General Relativity Package for Mathematica,http://arxiv.org/abs/2109.04193v1,2021-09-06T00:31:23Z,2021-09-06T00:31:23Z,"  We present OGRe, a modern Mathematica package for tensor calculus, designed
to be both powerful and user-friendly. The package can be used in a variety of
contexts where tensor calculations are needed, in both mathematics and physics,
but it is especially suitable for general relativity. By implementing an
object-oriented design paradigm, OGRe allows calculating arbitrarily
complicated tensor formulas easily, and automatically transforms between index
configurations and coordinate systems behind the scenes as needed, eliminating
user errors by making it impossible for the user to combine tensors in
inconsistent ways. Other features include displaying tensors in various forms,
automatic calculation of curvature tensors and geodesic equations, easy
importing and exporting of tensors between sessions, optimized algorithms and
parallelization for improved performance, and more.
",['\nBarak Shoshany\n'],"92 pages, source code available at https://github.com/bshoshany/OGRe","Journal of Open Source Software, 6(65), 3416 (2021)",http://dx.doi.org/10.21105/joss.03416,cs.MS,"['cs.MS', 'cs.SC', 'gr-qc', 'math.DG']",10.21105/joss.03416,,[]
Efficient Exascale Discretizations: High-Order Finite Element Methods,http://arxiv.org/abs/2109.04996v1,2021-09-10T17:07:48Z,2021-09-10T17:07:48Z,"  Efficient exploitation of exascale architectures requires rethinking of the
numerical algorithms used in many large-scale applications. These architectures
favor algorithms that expose ultra fine-grain parallelism and maximize the
ratio of floating point operations to energy intensive data movement. One of
the few viable approaches to achieve high efficiency in the area of PDE
discretizations on unstructured grids is to use matrix-free/partially-assembled
high-order finite element methods, since these methods can increase the
accuracy and/or lower the computational time due to reduced data motion. In
this paper we provide an overview of the research and development activities in
the Center for Efficient Exascale Discretizations (CEED), a co-design center in
the Exascale Computing Project that is focused on the development of
next-generation discretization software and algorithms to enable a wide range
of finite element applications to run efficiently on future hardware. CEED is a
research partnership involving more than 30 computational scientists from two
US national labs and five universities, including members of the Nek5000, MFEM,
MAGMA and PETSc projects. We discuss the CEED co-design activities based on
targeted benchmarks, miniapps and discretization libraries and our work on
performance optimizations for large-scale GPU architectures. We also provide a
broad overview of research and development activities in areas such as
unstructured adaptive mesh refinement algorithms, matrix-free linear solvers,
high-order data visualization, and list examples of collaborations with several
ECP and external applications.
","['\nTzanio Kolev\n', '\nPaul Fischer\n', '\nMisun Min\n', '\nJack Dongarra\n', '\nJed Brown\n', '\nVeselin Dobrev\n', '\nTim Warburton\n', '\nStanimire Tomov\n', '\nMark S. Shephard\n', '\nAhmad Abdelfattah\n', '\nValeria Barra\n', '\nNatalie Beams\n', '\nJean-Sylvain Camier\n', '\nNoel Chalmers\n', '\nYohann Dudouit\n', '\nAli Karakus\n', '\nIan Karlin\n', '\nStefan Kerkemeier\n', '\nYu-Hsiang Lan\n', '\nDavid Medina\n', '\nElia Merzari\n', '\nAleksandr Obabko\n', '\nWill Pazner\n', '\nThilina Rathnayake\n', '\nCameron W. Smith\n', '\nLukas Spies\n', '\nKasia Swirydowicz\n', '\nJeremy Thompson\n', '\nAnanias Tomboulides\n', '\nVladimir Tomov\n']","22 pages, 18 figures",,http://dx.doi.org/10.1177/10943420211020803,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",10.1177/10943420211020803,,[]
GPU Algorithms for Efficient Exascale Discretizations,http://arxiv.org/abs/2109.05072v1,2021-09-10T19:17:02Z,2021-09-10T19:17:02Z,"  In this paper we describe the research and development activities in the
Center for Efficient Exascale Discretization within the US Exascale Computing
Project, targeting state-of-the-art high-order finite-element algorithms for
high-order applications on GPU-accelerated platforms. We discuss the GPU
developments in several components of the CEED software stack, including the
libCEED, MAGMA, MFEM, libParanumal, and Nek projects. We report performance and
capability improvements in several CEED-enabled applications on both NVIDIA and
AMD GPU systems.
","['\nAhmad Abdelfattah\n', '\nValeria Barra\n', '\nNatalie Beams\n', '\nRyan Bleile\n', '\nJed Brown\n', '\nJean-Sylvain Camier\n', '\nRobert Carson\n', '\nNoel Chalmers\n', '\nVeselin Dobrev\n', '\nYohann Dudouit\n', '\nPaul Fischer\n', '\nAli Karakus\n', '\nStefan Kerkemeier\n', '\nTzanio Kolev\n', '\nYu-Hsiang Lan\n', '\nElia Merzari\n', '\nMisun Min\n', '\nMalachi Phillips\n', '\nThilina Rathnayake\n', '\nRobert Rieben\n', '\nThomas Stitt\n', '\nAnanias Tomboulides\n', '\nStanimire Tomov\n', '\nVladimir Tomov\n', '\nArturo Vargas\n', '\nTim Warburton\n', '\nKenneth Weiss\n']",,,http://arxiv.org/abs/2109.05072v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"H2OPUS-TLR: High Performance Tile Low Rank Symmetric Factorizations
  using Adaptive Randomized Approximation",http://arxiv.org/abs/2108.11932v1,2021-08-26T17:43:37Z,2021-08-26T17:43:37Z,"  Tile low rank representations of dense matrices partition them into blocks of
roughly uniform size, where each off-diagonal tile is compressed and stored as
its own low rank factorization. They offer an attractive representation for
many data-sparse dense operators that appear in practical applications, where
substantial compression and a much smaller memory footprint can be achieved.
TLR matrices are a compromise between the simplicity of a regular
perfectly-strided data structure and the optimal complexity of the unbalanced
trees of hierarchically low rank matrices, and provide a convenient
performance-tuning parameter through their tile size that can be proportioned
to take into account the cache size where the tiles reside in the memory
hierarchy.
  There are currently no high-performance algorithms that can generate Cholesky
and $LDL^T$ factorizations, particularly on GPUs. The difficulties in achieving
high performance when factoring TLR matrices come from the expensive
compression operations that must be performed during the factorization process
and the adaptive rank distribution of the tiles that causes an irregular work
pattern for the processing cores. In this work, we develop a dynamic batching
operation and combine it with batched adaptive randomized approximations to
achieve high performance both on GPUs and CPUs.
  Our implementation attains over 1.2 TFLOP/s in double precision on the V100
GPU, and is limited by the performance of batched GEMM operations. The Cholesky
factorization of covariance matrix of size $N = 131K$ arising in spatial
statistics can be factored to an accuracy $\epsilon=10^{-2}$ in just a few
seconds. We believe the proposed GEMM-centric algorithm allows it to be readily
ported to newer hardware such as the tensor cores that are optimized for small
GEMM operations.
","['\nWajih Boukaram\n', '\nStefano Zampini\n', '\nGeorge Turkiyyah\n', '\nDavid Keyes\n']",,,http://arxiv.org/abs/2108.11932v1,cs.DC,"['cs.DC', 'cs.MS', '65F05, 65F08, 65F55', 'G.4']",,,[]
A New Test for Hamming-Weight Dependencies,http://arxiv.org/abs/2108.13061v2,2021-08-30T08:43:23Z,2022-03-28T14:55:32Z,"  We describe a new statistical test for pseudorandom number generators
(PRNGs). Our test can find bias induced by dependencies among the Hamming
weights of the outputs of a PRNG, even for PRNGs that pass state-of-the-art
tests of the same kind from the literature, and in particular for generators
based on $\mathbf F_2$-linear transformations such as the dSFMT,
xoroshiro1024+, and WELL512.
","['\nDavid Blackman\n', '\nSebastiano Vigna\n']",arXiv admin note: substantial text overlap with arXiv:1805.01407,,http://arxiv.org/abs/2108.13061v2,cs.DS,"['cs.DS', 'cs.MS']",,,[]
RIFLE: Imputation and Robust Inference from Low Order Marginals,http://arxiv.org/abs/2109.00644v3,2021-09-01T23:17:30Z,2023-09-13T00:17:41Z,"  The ubiquity of missing values in real-world datasets poses a challenge for
statistical inference and can prevent similar datasets from being analyzed in
the same study, precluding many existing datasets from being used for new
analyses. While an extensive collection of packages and algorithms have been
developed for data imputation, the overwhelming majority perform poorly if
there are many missing values and low sample sizes, which are unfortunately
common characteristics in empirical data. Such low-accuracy estimations
adversely affect the performance of downstream statistical models. We develop a
statistical inference framework for regression and classification in the
presence of missing data without imputation. Our framework, RIFLE (Robust
InFerence via Low-order moment Estimations), estimates low-order moments of the
underlying data distribution with corresponding confidence intervals to learn a
distributionally robust model. We specialize our framework to linear regression
and normal discriminant analysis, and we provide convergence and performance
guarantees. This framework can also be adapted to impute missing data. In
numerical experiments, we compare RIFLE to several state-of-the-art approaches
(including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) for
imputation and inference in the presence of missing values. Our experiments
demonstrate that RIFLE outperforms other benchmark algorithms when the
percentage of missing values is high and/or when the number of data points is
relatively small. RIFLE is publicly available at
https://github.com/optimization-for-data-driven-science/RIFLE.
","['\nSina Baharlouei\n', '\nKelechi Ogudu\n', '\nSze-chuan Suen\n', '\nMeisam Razaviyayn\n']","36 pages, 11 figures","Transaction on Machine Learning Research (TMLR), 09/2023",http://arxiv.org/abs/2109.00644v3,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"dbcsp: User-friendly R package for Distance-Based Common Spacial
  Patterns",http://arxiv.org/abs/2109.00740v1,2021-09-02T06:42:56Z,2021-09-02T06:42:56Z,"  Common Spacial Patterns (CSP) is a widely used method to analyse
electroencephalography (EEG) data, concerning the supervised classification of
brain's activity. More generally, it can be useful to distinguish between
multivariate signals recorded during a time span for two different classes. CSP
is based on the simultaneous diagonalization of the average covariance matrices
of signals from both classes and it allows to project the data into a
low-dimensional subspace. Once data are represented in a low-dimensional
subspace, a classification step must be carried out. The original CSP method is
based on the Euclidean distance between signals and here, we extend it so that
it can be applied on any appropriate distance for data at hand. Both, the
classical CSP and the new Distance-Based CSP (DB-CSP) are implemented in an R
package, called dbcsp.
","['\nItsaso Rodriguez\n', '\nItziar Irigoien\n', '\nBasilio Sierra\n', '\nConcepcion Arenas\n']",,,http://arxiv.org/abs/2109.00740v1,cs.MS,"['cs.MS', 'eess.SP']",,,[]
The ensmallen library for flexible numerical optimization,http://arxiv.org/abs/2108.12981v2,2021-08-30T03:49:21Z,2024-02-09T13:07:00Z,"  We overview the ensmallen numerical optimization library, which provides a
flexible C++ framework for mathematical optimization of user-supplied objective
functions. Many types of objective functions are supported, including general,
differentiable, separable, constrained, and categorical. A diverse set of
pre-built optimizers is provided, including Quasi-Newton optimizers and many
variants of Stochastic Gradient Descent. The underlying framework facilitates
the implementation of new optimizers. Optimization of an objective function
typically requires supplying only one or two C++ functions. Custom behavior can
be easily specified via callback functions. Empirical comparisons show that
ensmallen outperforms other frameworks while providing more functionality. The
library is available at https://ensmallen.org and is distributed under the
permissive BSD license.
","['\nRyan R. Curtin\n', '\nMarcus Edel\n', '\nRahul Ganesh Prabhu\n', '\nSuryoday Basak\n', '\nZhihao Lou\n', '\nConrad Sanderson\n']",,"Journal of Machine Learning Research, Vol. 22, No. 166, 2021",http://arxiv.org/abs/2108.12981v2,cs.MS,"['cs.MS', 'cs.SE', 'math.OC', '65K10, 68N99', 'G.4; G.1.3; G.1.6']",,,[]
A Study of Mixed Precision Strategies for GMRES on GPUs,http://arxiv.org/abs/2109.01232v1,2021-09-02T22:27:18Z,2021-09-02T22:27:18Z,"  Support for lower precision computation is becoming more common in
accelerator hardware due to lower power usage, reduced data movement and
increased computational performance. However, computational science and
engineering (CSE) problems require double precision accuracy in several
domains. This conflict between hardware trends and application needs has
resulted in a need for mixed precision strategies at the linear algebra
algorithms level if we want to exploit the hardware to its full potential while
meeting the accuracy requirements. In this paper, we focus on preconditioned
sparse iterative linear solvers, a key kernel in several CSE applications. We
present a study of mixed precision strategies for accelerating this kernel on
an NVIDIA V$100$ GPU with a Power 9 CPU. We seek the best methods for
incorporating multiple precisions into the GMRES linear solver; these include
iterative refinement and parallelizable preconditioners. Our work presents
strategies to determine when mixed precision GMRES will be effective and to
choose parameters for a mixed precision iterative refinement solver to achieve
better performance. We use an implementation that is based on the Trilinos
library and employs Kokkos Kernels for performance portability of linear
algebra kernels. Performance results demonstrate the promise of mixed precision
approaches and demonstrate even further improvements are possible by optimizing
low-level kernels.
","['\nJennifer A. Loe\n', '\nChristian A. Glusa\n', '\nIchitaro Yamazaki\n', '\nErik G. Boman\n', '\nSivasankaran Rajamanickam\n']",arXiv admin note: substantial text overlap with arXiv:2105.07544,,http://arxiv.org/abs/2109.01232v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"Achieving near native runtime performance and cross-platform performance
  portability for random number generation through SYCL interoperability",http://arxiv.org/abs/2109.01329v2,2021-09-03T06:14:30Z,2021-10-18T21:23:19Z,"  High-performance computing (HPC) is a major driver accelerating scientific
research and discovery, from quantum simulations to medical therapeutics. While
the increasing availability of HPC resources is in many cases pivotal to
successful science, even the largest collaborations lack the computational
expertise required for maximal exploitation of current hardware capabilities.
The need to maintain multiple platform-specific codebases further complicates
matters, potentially adding constraints on machines that can be utilized.
Fortunately, numerous programming models are under development that aim to
facilitate portable codes for heterogeneous computing. One in particular is
SYCL, an open standard, C++-based single-source programming paradigm. Among
SYCL's features is interoperability, a mechanism through which applications and
third-party libraries coordinate sharing data and execute collaboratively. In
this paper, we leverage the SYCL programming model to demonstrate
cross-platform performance portability across heterogeneous resources. We
detail our NVIDIA and AMD random number generator extensions to the oneMKL
open-source interfaces library. Performance portability is measured relative to
platform-specific baseline applications executed on four major hardware
platforms using two different compilers supporting SYCL. The utility of our
extensions are exemplified in a real-world setting via a high-energy physics
simulation application. We show the performance of implementations that
capitalize on SYCL interoperability are at par with native implementations,
attesting to the cross-platform performance portability of a SYCL-based
approach to scientific codes.
","['\nVincent R. Pascuzzi\n', '\nMehdi Goli\n']","24 pages, 5 figures, conference",,http://dx.doi.org/10.1007/978-3-030-97759-7_2,cs.DC,"['cs.DC', 'cs.MS', 'hep-ex']",10.1007/978-3-030-97759-7_2,,[]
"Accelerating an Iterative Eigensolver for Nuclear Structure
  Configuration Interaction Calculations on GPUs using OpenACC",http://arxiv.org/abs/2109.00485v1,2021-09-01T16:55:31Z,2021-09-01T16:55:31Z,"  To accelerate the solution of large eigenvalue problems arising from
many-body calculations in nuclear physics on distributed-memory parallel
systems equipped with general-purpose Graphic Processing Units (GPUs), we
modified a previously developed hybrid MPI/OpenMP implementation of an
eigensolver written in FORTRAN 90 by using an OpenACC directives based
programming model. Such an approach requires making minimal changes to the
original code and enables a smooth migration of large-scale nuclear structure
simulations from a distributed-memory many-core CPU system to a distributed GPU
system. However, in order to make the OpenACC based eigensolver run efficiently
on GPUs, we need to take into account the architectural differences between a
many-core CPU and a GPU device. Consequently, the optimal way to insert OpenACC
directives may be different from the original way of inserting OpenMP
directives. We point out these differences in the implementation of sparse
matrix-matrix multiplications (SpMM), which constitutes the main cost of the
eigensolver, as well as other differences in the preconditioning step and dense
linear algebra operations. We compare the performance of the OpenACC based
implementation executed on multiple GPUs with the performance on
distributed-memory many-core CPUs, and demonstrate significant speedup achieved
on GPUs compared to the on-node performance of a many-core CPU. We also show
that the overall performance improvement of the eigensolver on multiple GPUs is
more modest due to the communication overhead among different MPI ranks.
","['\nPieter Maris\n', '\nChao Yang\n', '\nDossay Oryspayev\n', '\nBrandon Cook\n']","26 pages, 13 figures",,http://arxiv.org/abs/2109.00485v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA', 'nucl-th']",,,[]
The full Low-carbon Expansion Generation Optimization (LEGO) model,http://arxiv.org/abs/2109.01368v2,2021-09-03T08:32:58Z,2022-01-19T16:22:18Z,"  This paper introduces the full Low-carbon Expansion Generation Optimization
(LEGO) model available on Github (https://github.com/wogrin/LEGO). LEGO is a
mixed-integer quadratically constrained optimization problem and has been
designed to be a multi-purpose tool, like a Swiss army knife, that can be
employed to study many different aspects of the energy sector. Ranging from
short-term unit commitment to long-term generation and transmission expansion
planning. The underlying modeling philosophies are: modularity and flexibility.
Its unique temporal structure allows LEGO to function with either chronological
hourly data, or all kinds of representative periods. LEGO is also composed of
thematic modules that can be added or removed from the model easily via data
options depending on the scope of the study. Those modules include: unit
commitment constraints; DC- or AC-OPF formulations; battery degradation; rate
of change of frequency inertia constraints; demand-side management; or the
hydrogen sector. LEGO also provides a plethora of model outputs (both primal
and dual), which is the basis for both technical but also economic analyses. To
our knowledge, there is no model that combines all of these capabilities, which
we hereby make freely available to the scientific community.
","['\nSonja Wogrin\n', '\nDiego A. Tejada-Arango\n', '\nUdo Bachhiesl\n', '\nBenjamin F. Hobbs\n']",out of date,,http://arxiv.org/abs/2109.01368v2,math.OC,"['math.OC', 'cs.CE', 'cs.MS', 'cs.SY', 'eess.SY']",,,[]
"RLIBM-ALL: A Novel Polynomial Approximation Method to Produce Correctly
  Rounded Results for Multiple Representations and Rounding Modes",http://arxiv.org/abs/2108.06756v2,2021-08-15T14:44:50Z,2021-11-30T02:44:14Z,"  Mainstream math libraries for floating point (FP) do not produce correctly
rounded results for all inputs. In contrast, CR-LIBM and RLIBM provide
correctly rounded implementations for a specific FP representation with one
rounding mode. Using such libraries for a representation with a new rounding
mode or with different precision will result in wrong results due to double
rounding. This paper proposes a novel method to generate a single polynomial
approximation that produces correctly rounded results for all inputs for
multiple rounding modes and multiple precision configurations. To generate a
correctly rounded library for $n$-bits, our key idea is to generate such a
polynomial approximation for a representation with $n+2$-bits using the
\emph{round-to-odd} mode. We prove that the resulting polynomial approximation
will produce correctly rounded results for all five rounding modes in the
standard and for multiple representations with $k$-bits such that $|E| +1 < k
\leq n$, where $|E|$ is the number of exponent bits in the representation.
Building on our prior work in the RLIBM project, we also approximate the
correctly rounded result when we generate the library with $n+2$-bits using the
round-to-odd mode. We also generate polynomial approximations by structuring it
as a linear programming problem but propose enhancements to polynomial
generation to handle the round-to-odd mode. Our prototype is the first 32-bit
float library that produces correctly rounded results with all rounding modes
in the IEEE standard for all inputs with a single polynomial approximation. It
also produces correctly rounded results for any FP configuration ranging from
10-bits to 32-bits while also being faster than mainstream libraries.
","['\nJay P. Lim\n', '\nSantosh Nagarakatte\n']",28 pages,,http://arxiv.org/abs/2108.06756v2,cs.MS,['cs.MS'],,,[]
"Fast MATLAB evaluation of nonlinear energies using FEM in 2D and 3D:
  nodal elements",http://arxiv.org/abs/2109.01158v2,2021-08-22T21:00:21Z,2022-05-10T11:07:48Z,"  Nonlinear energy functionals appearing in the calculus of variations can be
discretized by the finite element (FE) method and formulated as a sum of energy
contributions from local elements. A fast evaluation of energy functionals
containing the first order gradient terms is a central part of this
contribution. We describe a vectorized implementation using the simplest linear
nodal (P1) elements in which all energy contributions are evaluated all at once
without the loop over triangular or tetrahedral elements. Furthermore, in
connection to the first-order optimization methods, the discrete gradient of
energy functional is assembled in a way that the gradient components are
evaluated over all degrees of freedom all at once. The key ingredient is the
vectorization of exact or approximate energy gradients over nodal patches. It
leads to a time-efficient implementation at higher memory-cost. Provided codes
in MATLAB related to 2D/3D hyperelasticity and 2D p-Laplacian problem are
available for download and structured in a way it can be easily extended to
other types of vector or scalar forms of energies.
","['\nAlexej Moskovka\n', '\nJan Valdman\n']","24 pages, 9 figures Before the article was published, some minor
  changes were applied based on the reviewers' comments","Applied Mathematics and Computation, Volume 424, 2022",http://dx.doi.org/10.1016/j.amc.2022.127048,cs.MS,['cs.MS'],10.1016/j.amc.2022.127048,,[]
"Adaptive numerical simulations with Trixi.jl: A case study of Julia for
  scientific computing",http://arxiv.org/abs/2108.06476v2,2021-08-14T06:20:32Z,2022-01-15T09:13:02Z,"  We present Trixi.jl, a Julia package for adaptive high-order numerical
simulations of hyperbolic partial differential equations. Utilizing Julia's
strengths, Trixi.jl is extensible, easy to use, and fast. We describe the main
design choices that enable these features and compare Trixi.jl with a mature
open source Fortran code that uses the same numerical methods. We conclude with
an assessment of Julia for simulation-focused scientific computing, an area
that is still dominated by traditional high-performance computing languages
such as C, C++, and Fortran.
","['\nHendrik Ranocha\n', '\nMichael Schlottke-Lakemper\n', '\nAndrew R. Winters\n', '\nErik Faulhaber\n', '\nJesse Chan\n', '\nGregor J. Gassner\n']",,"Proceedings of the JuliaCon Conferences, 2022",http://dx.doi.org/10.21105/jcon.00077,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'physics.comp-ph']",10.21105/jcon.00077,,[]
"PyParSVD: A streaming, distributed and randomized
  singular-value-decomposition library",http://arxiv.org/abs/2108.08845v1,2021-08-19T05:25:47Z,2021-08-19T05:25:47Z,"  We introduce PyParSVD\footnote{https://github.com/Romit-Maulik/PyParSVD}, a
Python library that implements a streaming, distributed and randomized
algorithm for the singular value decomposition. To demonstrate its
effectiveness, we extract coherent structures from scientific data. Futhermore,
we show weak scaling assessments on up to 256 nodes of the Theta machine at
Argonne Leadership Computing Facility, demonstrating potential for large-scale
data analyses of practical data sets.
","['\nRomit Maulik\n', '\nGianmarco Mengaldo\n']",arXiv admin note: text overlap with arXiv:2103.09389,,http://arxiv.org/abs/2108.08845v1,cs.MS,"['cs.MS', 'cs.DC', 'physics.ao-ph', 'physics.flu-dyn']",,,[]
"Vertical, Temporal, and Horizontal Scaling of Hierarchical Hypersparse
  GraphBLAS Matrices",http://arxiv.org/abs/2108.06650v1,2021-08-15T03:02:21Z,2021-08-15T03:02:21Z,"  Hypersparse matrices are a powerful enabler for a variety of network, health,
finance, and social applications. Hierarchical hypersparse GraphBLAS matrices
enable rapid streaming updates while preserving algebraic analytic power and
convenience. In many contexts, the rate of these updates sets the bounds on
performance. This paper explores hierarchical hypersparse update performance on
a variety of hardware with identical software configurations. The high-level
language bindings of the GraphBLAS readily enable performance experiments on
simultaneous diverse hardware. The best single process performance measured was
4,000,000 updates per second. The best single node performance measured was
170,000,000 updates per second. The hardware used spans nearly a decade and
allows a direct comparison of hardware improvements for this computation over
this time range; showing a 2x increase in single-core performance, a 3x
increase in single process performance, and a 5x increase in single node
performance. Running on nearly 2,000 MIT SuperCloud nodes simultaneously
achieved a sustained update rate of over 200,000,000,000 updates per second.
Hierarchical hypersparse GraphBLAS allows the MIT SuperCloud to analyze
extremely large streaming network data sets.
","['\nJeremy Kepner\n', '\nTim Davis\n', '\nChansup Byun\n', '\nWilliam Arcand\n', '\nDavid Bestor\n', '\nWilliam Bergeron\n', '\nVijay Gadepally\n', '\nMatthew Hubbell\n', '\nMichael Houle\n', '\nMichael Jones\n', '\nAnna Klein\n', '\nLauren Milechin\n', '\nJulie Mullen\n', '\nAndrew Prout\n', '\nAlbert Reuther\n', '\nAntonio Rosa\n', '\nSiddharth Samsi\n', '\nCharles Yee\n', '\nPeter Michaleas\n']","6 pages, 5 figures, 32 references, accepted to IEEE HPEC 2021. arXiv
  admin note: text overlap with arXiv:2001.06935",,http://dx.doi.org/10.1109/HPEC49654.2021.9622802,cs.DC,"['cs.DC', 'cs.DM', 'cs.MS', 'cs.NI', 'cs.PF']",10.1109/HPEC49654.2021.9622802,,[]
"Parallel time integration using Batched BLAS (Basic Linear Algebra
  Subprograms) routines",http://arxiv.org/abs/2108.07126v1,2021-08-16T14:49:04Z,2021-08-16T14:49:04Z,"  We present an approach for integrating the time evolution of quantum systems.
We leverage the computation power of graphics processing units (GPUs) to
perform the integration of all time steps in parallel. The performance boost is
especially prominent for small to medium-sized quantum systems. The devised
algorithm can largely be implemented using the recently-specified batched
versions of the BLAS routines, and can therefore be easily ported to a variety
of platforms. Our PARAllelized Matrix Exponentiation for Numerical Time
evolution (PARAMENT) implementation runs on CUDA-enabled graphics processing
units.
","['\nKonstantin Herb\n', '\nPol Welter\n']",8 pages including source of the integration core in pseudo C code,"Computer Physics Communications 270, 108181 (2022)",http://dx.doi.org/10.1016/j.cpc.2021.108181,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'physics.comp-ph', 'quant-ph']",10.1016/j.cpc.2021.108181,,[]
Reachability of weakly nonlinear systems using Carleman linearization,http://arxiv.org/abs/2108.10390v2,2021-08-23T20:19:43Z,2021-11-01T15:00:58Z,"  In this article we introduce a solution method for a special class of
nonlinear initial-value problems using set-based propagation techniques. The
novelty of the approach is that we employ a particular embedding (Carleman
linearization) to leverage recent advances of high-dimensional reachability
solvers for linear ordinary differential equations based on the support
function. Using a global error bound for the Carleman linearization
abstraction, we are able to describe the full set of behaviors of the system
for sets of initial conditions and in dense time.
","['\nMarcelo Forets\n', '\nChristian Schilling\n']",,"International Conference on Reachability Problems (pp. 85-99),
  2021. Springer, Cham",http://dx.doi.org/10.1007/978-3-030-89716-1_6,math.OC,"['math.OC', 'cs.MS', 'cs.SY', 'eess.SY', 'math.DS']",10.1007/978-3-030-89716-1_6,,[]
"Partial Reuse AMG Setup Cost Amortization Strategy for the Solution of
  Non-Steady State Problems",http://arxiv.org/abs/2108.02054v1,2021-08-04T13:32:17Z,2021-08-04T13:32:17Z,"  The partial reuse algebraic multigrid (AMG) setup cost amortization strategy
is presented for the solution of non-steady state problems. The transfer
operators are reused from the previous time steps, and the system matrices and
the smoother operators are rebuilt on each of the AMG hierarchy levels. It is
shown on the example of modelling a two-fluid dam break scenario that the
strategy may decrease the AMG preconditioner setup cost by 40% to 200%. The
total compute time is decreased by up to 20%, but the specific outcome depends
on the fraction of time that the setup step initially takes.
",['\nD. E. Demidov\n'],,,http://arxiv.org/abs/2108.02054v1,cs.MS,"['cs.MS', '35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80']",,,[]
"Grassland: A Rapid Algebraic Modeling System for Million-variable
  Optimization",http://arxiv.org/abs/2108.04586v1,2021-08-10T11:02:54Z,2021-08-10T11:02:54Z,"  An algebraic modeling system (AMS) is a type of mathematical software for
optimization problems, which allows users to define symbolic mathematical
models in a specific language, instantiate them with given source of data, and
solve them with the aid of external solver engines. With the bursting scale of
business models and increasing need for timeliness, traditional AMSs are not
sufficient to meet the following industry needs: 1) million-variable models
need to be instantiated from raw data very efficiently; 2) Strictly feasible
solution of million-variable models need to be delivered in a rapid manner to
make up-to-date decisions against highly dynamic environments. Grassland is a
rapid AMS that provides an end-to-end solution to tackle these emerged new
challenges. It integrates a parallelized instantiation scheme for large-scale
linear constraints, and a sequential decomposition method that accelerates
model solving exponentially with an acceptable loss of optimality. Extensive
benchmarks on both classical models and real enterprise scenario demonstrate 6
~ 10x speedup of Grassland over state-of-the-art solutions on model
instantiation. Our proposed system has been deployed in the large-scale real
production planning scenario of Huawei. With the aid of our decomposition
method, Grassland successfully accelerated Huawei's million-variable production
planning simulation pipeline from hours to 3 ~ 5 minutes, supporting
near-real-time production plan decision making against highly dynamic
supply-demand environment.
","['\nXihan Li\n', '\nXiongwei Han\n', '\nZhishuo Zhou\n', '\nMingxuan Yuan\n', '\nJia Zeng\n', '\nJun Wang\n']",Accepted by CIKM 2021,,http://arxiv.org/abs/2108.04586v1,cs.MS,['cs.MS'],,,[]
High-Performance Level-1 and Level-2 BLAS,http://arxiv.org/abs/2108.02025v1,2021-08-04T12:51:12Z,2021-08-04T12:51:12Z,"  The introduction of the Basic Linear Algebra Subroutine (BLAS) in the 1970s
paved the way for different libraries to solve the same problem with an
improved approach and hardware. The new BLAS implementation led to
High-Performance Computing (HPC) innovation. All the love went to the level 3
BLAS due to its humongous application in different fields, not bounded by
computer science. However, level 1 and level 2 got neglected; we tried to solve
the problem by introducing the new algorithm for the Vector-Vector dot product,
Vector-Vector outer product and Matrix-Vector product, which improves the
performance of these operations in a significant way. We are not introducing
any library but algorithms, which improves upon the current state of art
algorithms. Also, we rely on the FMA instruction, OpenMP, and the compiler to
optimize the code rather than implementing the algorithm in assembly.
Therefore, our current implementation is machine oblivious and depends on the
compilers ability to optimize the code.
","['\nAmit Singh\n', '\nCem Bassoy\n']","11 pages, 5 figures",,http://arxiv.org/abs/2108.02025v1,cs.MS,"['cs.MS', 'cs.CC', '68Q17(Primary), 15A99(Secondary)']",,,[]
"Improving MATLAB's isprime performance without arbitrary-precision
  arithmetic",http://arxiv.org/abs/2108.04791v1,2021-08-08T17:26:14Z,2021-08-08T17:26:14Z,"  MATLAB is a numerical computing platform used by scientists, engineers,
mathematicians, and students which contains many mathematical functions,
including isprime. MATLAB's isprime function determines which elements of an
input array are prime. This research details modular arithmetic techniques, the
Miller-Rabin primality test, vectorized operations, and division-minimizing
strategies which harness the power of MATLAB's capabilities to improve
isprime's performance. The results are typically 5 to 10 times faster for small
integers and many hundreds of times faster for large integers and long arrays.
",['\nTravis Near\n'],"13 pages, 7 tables, 2 figures",,http://arxiv.org/abs/2108.04791v1,cs.MS,"['cs.MS', 'cs.CR', 'cs.PF']",,,[]
"Parallel Sub-Structuring Methods for solving Sparse Linear Systems on a
  cluster of GPU",http://arxiv.org/abs/2108.13162v1,2021-08-08T19:41:11Z,2021-08-08T19:41:11Z,"  The main objective of this work consists in analyzing sub-structuring method
for the parallel solution of sparse linear systems with matrices arising from
the discretization of partial differential equations such as finite element,
finite volume and finite difference. With the success encountered by the
general-purpose processing on graphics processing units (GPGPU), we develop an
hybrid multiGPUs and CPUs sub-structuring algorithm. GPU computing, with CUDA,
is used to accelerate the operations performed on each processor. Numerical
experiments have been performed on a set of matrices arising from engineering
problems. We compare C+MPI implementation on classical CPU cluster with
C+MPI+CUDA on a cluster of GPU. The performance comparison shows a speed-up for
the sub-structuring method up to 19 times in double precision by using CUDA.
","['\nAbal-Kassim Cheik Ahamed\n', '\nFrédéric Magoulès\n']",,"2014 IEEE Intl Conf on High Performance Computing and
  Communications, 2014, pp. 121-128",http://dx.doi.org/10.1109/HPCC.2014.24,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA', '14Q65, 15A60, 65E10, 65F10, 68W10, 65Y05', 'G.1.3; G.1.6; I.3.1; D.3.4']",10.1109/HPCC.2014.24,,[]
"Optimisation of an FPGA Credit Default Swap engine by embracing dataflow
  techniques",http://arxiv.org/abs/2108.03982v1,2021-07-28T17:10:50Z,2021-07-28T17:10:50Z,"  Quantitative finance is the use of mathematical models to analyse financial
markets and securities. Typically requiring significant amounts of computation,
an important question is the role that novel architectures can play in
accelerating these models in the future on HPC machines. In this paper we
explore the optimisation of an existing, open source, FPGA based Credit Default
Swap (CDS) engine using High Level Synthesis (HLS). Developed by Xilinx, and
part of their open source Vitis libraries, the implementation of this engine
currently favours flexibility and ease of integration over performance.
  We explore redesigning the engine to fully embrace the dataflow approach,
ultimately resulting in an engine which is around eight times faster on an
Alveo U280 FPGA than the original Xilinx library version. We then compare five
of our engines on the U280 against a 24-core Xeon Platinum Cascade Lake CPU,
outperforming the CPU by around 1.55 times, with the FPGA consuming 4.7 times
less power and delivering around seven times the power efficiency of the CPU.
","['\nNick Brown\n', '\nMark Klaisoongnoen\n', '\nOliver Thomson Brown\n']","Preprint of article in the IEEE Cluster FPGA for HPC Workshop 2021
  (HPC FPGA 2021)",,http://arxiv.org/abs/2108.03982v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Accelerating advection for atmospheric modelling on Xilinx and Intel
  FPGAs",http://arxiv.org/abs/2107.13500v1,2021-07-28T17:14:01Z,2021-07-28T17:14:01Z,"  Reconfigurable architectures, such as FPGAs, enable the execution of code at
the electronics level, avoiding the assumptions imposed by the general purpose
black-box micro-architectures of CPUs and GPUs. Such tailored execution can
result in increased performance and power efficiency, and as the HPC community
moves towards exascale an important question is the role such hardware
technologies can play in future supercomputers.
  In this paper we explore the porting of the PW advection kernel, an important
code component used in a variety of atmospheric simulations and accounting for
around 40\% of the runtime of the popular Met Office NERC Cloud model (MONC).
Building upon previous work which ported this kernel to an older generation of
Xilinx FPGA, we target latest generation Xilinx Alveo U280 and Intel Stratix 10
FPGAs. Exploring the development of a dataflow design which is performance
portable between vendors, we then describe implementation differences between
the tool chains and compare kernel performance between FPGA hardware. This is
followed by a more general performance comparison, scaling up the number of
kernels on the Xilinx Alveo and Intel Stratix 10, against a 24 core Xeon
Platinum Cascade Lake CPU and NVIDIA Tesla V100 GPU. When overlapping the
transfer of data to and from the boards with compute, the FPGA solutions
considerably outperform the CPU and, whilst falling short of the GPU in terms
of performance, demonstrate power usage benefits, with the Alveo being
especially power efficient. The result of this work is a comparison and set of
design techniques that apply both to this specific atmospheric advection kernel
on Xilinx and Intel FPGAs, and that are also of interest more widely when
looking to accelerate HPC codes on a variety of reconfigurable architectures.
",['\nNick Brown\n'],"Preprint of article in the IEEE Cluster FPGA for HPC Workshop 2021
  (HPC FPGA 2021)",,http://arxiv.org/abs/2107.13500v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
MLDev: Data Science Experiment Automation and Reproducibility Software,http://arxiv.org/abs/2107.12322v1,2021-07-26T16:51:44Z,2021-07-26T16:51:44Z,"  In this paper we explore the challenges of automating experiments in data
science. We propose an extensible experiment model as a foundation for
integration of different open source tools for running research experiments. We
implement our approach in a prototype open source MLDev software package and
evaluate it in a series of experiments yielding promising results. Comparison
with other state-of-the-art tools signifies novelty of our approach.
","['\nAnton Khritankov\n', '\nNikita Pershin\n', '\nNikita Ukhov\n', '\nArtem Ukhov\n']","11 pages, 2 figures","DAMDID/RCDL-2021, CCIS vol. 1620 (2022), Springer Cham, 3-18",http://dx.doi.org/10.1007/978-3-031-12285-9_1,cs.LG,"['cs.LG', 'cs.MS', 'cs.SE', 'I.2.m']",10.1007/978-3-031-12285-9_1,,[]
"Accelerated Multiple Precision Direct Method and Mixed Precision
  Iterative Refinement on Python Programming Environment",http://arxiv.org/abs/2107.12550v1,2021-07-27T01:57:03Z,2021-07-27T01:57:03Z,"  Current Python programming environment does not have any reliable and
efficient multiple precision floating-point (MPF) arithmetic except ``mpmath""
and ``gmpy2"" packages based on GNU MP(GMP) and MPFR libraries. Although it is
well known that multi-component-type MPF library can be utilized for middle
length precision arithmetic under 200 bits, they are not widely used on Python
environment. In this paper, we describe our accelerated MPF direct method with
AVX2 techniques and its application to mixed precision iterative refinement
combined with mpmath, and demonstrate their efficiency on x86\_64 computational
environments.
",['\nTomonori Kouya\n'],,,http://arxiv.org/abs/2107.12550v1,cs.MS,"['cs.MS', 'cs.NA', 'cs.PF', 'math.NA']",,,[]
"High Performance Uncertainty Quantification with Parallelized Multilevel
  Markov Chain Monte Carlo",http://arxiv.org/abs/2107.14552v1,2021-07-30T11:09:23Z,2021-07-30T11:09:23Z,"  Numerical models of complex real-world phenomena often necessitate High
Performance Computing (HPC). Uncertainties increase problem dimensionality
further and pose even greater challenges.
  We present a parallelization strategy for multilevel Markov chain Monte
Carlo, a state-of-the-art, algorithmically scalable Uncertainty Quantification
(UQ) algorithm for Bayesian inverse problems, and a new software framework
allowing for large-scale parallelism across forward model evaluations and the
UQ algorithms themselves. The main scalability challenge presents itself in the
form of strong data dependencies introduced by the MLMCMC method, prohibiting
trivial parallelization.
  Our software is released as part of the modular and open-source MIT UQ
Library (MUQ), and can easily be coupled with arbitrary user codes. We
demonstrate it using the DUNE and the ExaHyPE Engine. The latter provides a
realistic, large-scale tsunami model in which identify the source of a tsunami
from buoy-elevation data.
","['\nLinus Seelinger\n', '\nAnne Reinarz\n', '\nLeonhard Rannabauer\n', '\nMichael Bader\n', '\nPeter Bastian\n', '\nRobert Scheichl\n']",,,http://arxiv.org/abs/2107.14552v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Comparing OpenMP Implementations With Applications Across A64FX
  Platforms",http://arxiv.org/abs/2107.10346v1,2021-07-21T20:28:38Z,2021-07-21T20:28:38Z,"  The development of the A64FX processor by Fujitsu has created a massive
innovation in High-Performance Computing and the birth of Fugaku: the current
world's fastest supercomputer. A variety of tools are used to analyze the
run-times and performances of several applications, and in particular, how
these applications scale on the A64FX processor. We examine the performance and
behavior of applications through OpenMP scaling and how their performance
differs across different compilers on the new Ookami cluster at Stony Brook
University as well as the Fugaku supercomputer at RIKEN in Japan.
","['\nBenjamin Michalowicz\n', '\nEric Raut\n', '\nYan Kang\n', '\nTony Curtis\n', '\nBarbara Chapman\n', '\nDossay Oryspayev\n']",,,http://arxiv.org/abs/2107.10346v1,cs.MS,['cs.MS'],,,[]
"giotto-ph: A Python Library for High-Performance Computation of
  Persistent Homology of Vietoris-Rips Filtrations",http://arxiv.org/abs/2107.05412v2,2021-07-12T13:30:45Z,2021-08-02T19:04:35Z,"  We introduce giotto-ph, a high-performance, open-source software package for
the computation of Vietoris-Rips barcodes. giotto-ph is based on Morozov and
Nigmetov's lockfree (multicore) implementation of Ulrich Bauer's Ripser
package. It also contains a re-working of the GUDHI library's implementation of
Boissonnat and Pritam's Edge Collapser, which can be used as a pre-processing
step to dramatically reduce overall run-times in certain scenarios. Our
contribution is twofold: on the one hand, we integrate existing
state-of-the-art ideas coherently in a single library and provide Python
bindings to the C++ code. On the other hand, we increase parallelization
opportunities and improve overall performance by adopting more efficient data
structures. Our persistent homology backend establishes a new state of the art,
surpassing even GPU-accelerated implementations such as Ripser++ when using as
few as 5-10 CPU cores. Furthermore, our implementation of Edge Collapser has
fewer software dependencies and improved run-times relative to GUDHI's original
implementation.
","['\nJulián Burella Pérez\n', '\nSydney Hauke\n', '\nUmberto Lupo\n', '\nMatteo Caorsi\n', '\nAlberto Dassatti\n']","18 pages, 7 figures",,http://arxiv.org/abs/2107.05412v2,cs.CG,"['cs.CG', 'cs.MS', '68R99', 'G.4; G.2.2']",,,[]
"Faster Math Functions, Soundly",http://arxiv.org/abs/2107.05761v1,2021-07-12T22:12:33Z,2021-07-12T22:12:33Z,"  Standard library implementations of functions like sin and exp optimize for
accuracy, not speed, because they are intended for general-purpose use. But
applications tolerate inaccuracy from cancellation, rounding error, and
singularities-sometimes even very high error-and many application could
tolerate error in function implementations as well. This raises an intriguing
possibility: speeding up numerical code by tuning standard function
implementations. This paper thus introduces OpTuner, an automatic method for
selecting the best implementation of mathematical functions at each use site.
OpTuner assembles dozens of implementations for the standard mathematical
functions from across the speed-accuracy spectrum. OpTuner then uses error
Taylor series and integer linear programming to compute optimal assignments of
function implementation to use site and presents the user with a speed-accuracy
Pareto curve they can use to speed up their code. In a case study on the
POV-Ray ray tracer, OpTuner speeds up a critical computation, leading to a
whole program speedup of 9% with no change in the program output (whereas human
efforts result in slower code and lower-quality output). On a broader study of
37 standard benchmarks, OpTuner matches 216 implementations to 89 use sites and
demonstrates speed-ups of 107% for negligible decreases in accuracy and of up
to 438% for error-tolerant applications.
","['\nIan Briggs\n', '\nPavel Panchekha\n']",,,http://arxiv.org/abs/2107.05761v1,cs.MS,"['cs.MS', 'cs.SE']",,,[]
"Topology optimization using the unsmooth variational topology
  optimization (UNVARTOP) method. An educational implementation in Matlab",http://arxiv.org/abs/2107.07763v1,2021-07-16T08:39:47Z,2021-07-16T08:39:47Z,"  This paper presents an efficient and comprehensive MATLAB code to solve
two-dimensional structural topology optimization problems, including minimum
mean compliance, compliant mechanism synthesis and multi-load compliance
problems. The Unsmooth Variational Topology Optimization (UNVARTOP) method,
developed by the authors in a previous work, is used in the topology
optimization code, based on the finite element method (FEM), to compute the
sensitivity and update the topology. The paper also includes instructions to
improve the bisection algorithm, modify the computation of the Lagrangian
multiplier by using an Augmented Lagrangian to impose the constraint, implement
heat conduction problems and extend the code to three-dimensional topology
optimization problems. The code, intended for students and newcomers in
topology optimization, is included as an appendix (Appendix A) and it can be
downloaded from https://github.com/DanielYago together with supplementary
material.
","['\nDaniel Yago\n', '\nJuan Cante\n', '\nOriol Lloberas-Valls\n', '\nJavier Oliver\n']",,"Structural and Multidisciplinary Optimization, 2021",http://dx.doi.org/10.1007/s00158-020-02722-0,cs.CE,"['cs.CE', 'cs.MS']",10.1007/s00158-020-02722-0,,[]
"NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with
  Error Approximations",http://arxiv.org/abs/2107.09443v1,2021-07-19T12:38:31Z,2021-07-19T12:38:31Z,"  Physics-informed neural networks (PINNs) are an increasingly powerful way to
solve partial differential equations, generate digital twins, and create neural
surrogates of physical models. In this manuscript we detail the inner workings
of NeuralPDE.jl and show how a formulation structured around numerical
quadrature gives rise to new loss functions which allow for adaptivity towards
bounded error tolerances. We describe the various ways one can use the tool,
detailing mathematical techniques like using extended loss functions for
parameter estimation and operator discovery, to help potential users adopt
these PINN-based techniques into their workflow. We showcase how NeuralPDE uses
a purely symbolic formulation so that all of the underlying training code is
generated from an abstract formulation, and show how to make use of GPUs and
solve systems of PDEs. Afterwards we give a detailed performance analysis which
showcases the trade-off between training techniques on a large set of PDEs. We
end by focusing on a complex multiphysics example, the Doyle-Fuller-Newman
(DFN) Model, and showcase how this PDE can be formulated and solved with
NeuralPDE. Together this manuscript is meant to be a detailed and approachable
technical report to help potential users of the technique quickly get a sense
of the real-world performance trade-offs and use cases of the PINN techniques.
","['\nKirill Zubov\n', '\nZoe McCarthy\n', '\nYingbo Ma\n', '\nFrancesco Calisto\n', '\nValerio Pagliarino\n', '\nSimone Azeglio\n', '\nLuca Bottero\n', '\nEmmanuel Luján\n', '\nValentin Sulzer\n', '\nAshutosh Bharambe\n', '\nNand Vinchhi\n', '\nKaushik Balakrishnan\n', '\nDevesh Upadhyay\n', '\nChris Rackauckas\n']","74 pages, 20+ figures, 20+ tables",,http://arxiv.org/abs/2107.09443v1,cs.MS,"['cs.MS', 'cs.SC']",,,[]
"Parallel Element-based Algebraic Multigrid for H(curl) and H(div)
  Problems Using the ParELAG Library",http://arxiv.org/abs/2107.05613v2,2021-07-12T17:48:29Z,2022-12-17T03:35:44Z,"  This paper presents the use of element-based algebraic multigrid (AMGe)
hierarchies, implemented in the ParELAG (Parallel Element Agglomeration
Algebraic Multigrid Upscaling and Solvers) library, to produce multilevel
preconditioners and solvers for H(curl) and H(div) formulations. ParELAG
constructs hierarchies of compatible nested spaces, forming an exact de Rham
sequence on each level. This allows the application of hybrid smoothers on all
levels and AMS (Auxiliary-space Maxwell Solver) or ADS (Auxiliary-space
Divergence Solver) on the coarsest levels, obtaining complete multigrid cycles.
Numerical results are presented, showing the parallel performance of the
proposed methods. As a part of the exposition, this paper demonstrates some of
the capabilities of ParELAG and outlines some of the components and procedures
within the library.
","['\nDelyan Z. Kalchev\n', '\nPanayot S. Vassilevski\n', '\nUmberto Villa\n']",,"SIAM Journal on Scientific Computing 2023, 45(3), S371-S400",http://dx.doi.org/10.1137/21M1433253,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1137/21M1433253,,[]
"3D Acoustic-Elastic Coupling with Gravity: The Dynamics of the 2018
  Palu, Sulawesi Earthquake and Tsunami",http://arxiv.org/abs/2107.06640v3,2021-07-13T11:09:04Z,2021-11-22T10:28:45Z,"  We present a highly scalable 3D fully-coupled Earth & ocean model of
earthquake rupture and tsunami generation. We model seismic, acoustic and
surface gravity wave propagation in elastic (Earth) and acoustic (ocean)
materials sourced by physics-based non-linear earthquake dynamic rupture.
Complicated geometries, including high-resolution bathymetry, coastlines and
segmented earthquake faults are discretized by adaptive unstructured
tetrahedral meshes. A Discontinuous Galerkin discretization with ADER local
time-stepping (ADER-DG) yields petascale computational efficiency and
high-order accuracy in time and space.
  We compare the 3D fully-coupled approach to a benchmark problem for 3D-2D
linked models that use 2D shallow-water modeling. We present a large-scale
fully-coupled model of the 2018 Sulawesi events that links the dynamics from
supershear earthquake faulting to elastic and acoustic waves in Earth and ocean
to tsunami gravity wave propagation in the narrow Palu Bay. And we demonstrate
scalability and performance of the MPI+OpenMP parallelization on three
petascale supercomputers.
","['\nLukas Krenz\n', '\nCarsten Uphoff\n', '\nThomas Ulrich\n', '\nAlice-Agnes Gabriel\n', '\nLauren S. Abrahams\n', '\nEric M. Dunham\n', '\nMichael Bader\n']","13 pages, 6 figures; European Commission Project: ChEESE - Centre of
  Excellence for Exascale in Solid Earth (EC-H2020-823844)","SC '21: Proceedings of the International Conference for High
  Performance Computing, Networking, Storage and AnalysisNovember 2021 Article
  No.: 63",http://dx.doi.org/10.1145/3458817.3476173,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS', 'physics.geo-ph']",10.1145/3458817.3476173,,[]
Using a template engine as a computer algebra tool,http://arxiv.org/abs/2107.07461v1,2021-07-15T17:04:02Z,2021-07-15T17:04:02Z,"  In research problems that involve the use of numerical methods for solving
systems of ordinary differential equations (ODEs), it is often required to
select the most efficient method for a particular problem. To solve a Cauchy
problem for a system of ODEs, Runge-Kutta methods (explicit or implicit ones,
with or without step-size control, etc.) are employed. In that case, it is
required to search through many implementations of the numerical method and
select coefficients or other parameters of its numerical scheme. This paper
proposes a library and scripts for automated generation of routine functions in
the Julia programming language for a set of numerical schemes of Runge-Kutta
methods. For symbolic manipulations, we use a template substitution tool. The
proposed approach to automated generation of program code allows us to use a
single template for editing, instead of modifying each individual function to
be compared. On the one hand, this provides universality in the implementation
of a numerical scheme and, on the other hand, makes it possible to minimize the
number of errors in the process of modifying the compared implementations of
the numerical method. We consider Runge-Kutta methods without step-size
control, embedded methods with step-size control, and Rosenbrock methods with
step-size control. The program codes for the numerical schemes, which are
generated automatically using the proposed library, are tested by numerical
solution of several well-known problems.
","['\nMigran N. Gevorkyan\n', '\nAnna V. Korolkova\n', '\nDmitry S. Kulyabov\n']",in English; in Russian,,http://dx.doi.org/10.1134/S0361768821010047,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'cs.SC']",10.1134/S0361768821010047,,[]
"Refactoring the MPS/University of Chicago Radiative MHD(MURaM) Model for
  GPU/CPU Performance Portability Using OpenACC Directives",http://arxiv.org/abs/2107.08145v1,2021-07-16T23:35:14Z,2021-07-16T23:35:14Z,"  The MURaM (Max Planck University of Chicago Radiative MHD) code is a solar
atmosphere radiative MHD model that has been broadly applied to solar phenomena
ranging from quiet to active sun, including eruptive events such as flares and
coronal mass ejections. The treatment of physics is sufficiently realistic to
allow for the synthesis of emission from visible light to extreme UV and
X-rays, which is critical for a detailed comparison with available and future
multi-wavelength observations. This component relies critically on the
radiation transport solver (RTS) of MURaM; the most computationally intensive
component of the code. The benefits of accelerating RTS are multiple fold: A
faster RTS allows for the regular use of the more expensive multi-band
radiation transport needed for comparison with observations, and this will pave
the way for the acceleration of ongoing improvements in RTS that are critical
for simulations of the solar chromosphere. We present challenges and strategies
to accelerate a multi-physics, multi-band MURaM using a directive-based
programming model, OpenACC in order to maintain a single source code across
CPUs and GPUs. Results for a $288^3$ test problem show that MURaM with the
optimized RTS routine achieves 1.73x speedup using a single NVIDIA V100 GPU
over a fully subscribed 40-core Intel Skylake CPU node and with respect to the
number of simulation points (in millions) per second, a single NVIDIA V100 GPU
is equivalent to 69 Skylake cores. We also measure parallel performance on up
to 96 GPUs and present weak and strong scaling results.
","['\nEric Wright\n', '\nDamien Przybylski\n', '\nMatthias Rempel\n', '\nCena Miller\n', '\nSupreeth Suresh\n', '\nShiquan Su\n', '\nRichard Loft\n', '\nSunita Chandrasekaran\n']",,,http://arxiv.org/abs/2107.08145v1,physics.space-ph,"['physics.space-ph', 'cs.CE', 'cs.MS']",,,[]
"Neko: A Modern, Portable, and Scalable Framework for High-Fidelity
  Computational Fluid Dynamics",http://arxiv.org/abs/2107.01243v1,2021-07-02T19:28:27Z,2021-07-02T19:28:27Z,"  Recent trends and advancement in including more diverse and heterogeneous
hardware in High-Performance Computing is challenging software developers in
their pursuit for good performance and numerical stability. The well-known
maxim ""software outlives hardware"" may no longer necessarily hold true, and
developers are today forced to re-factor their codebases to leverage these
powerful new systems. CFD is one of the many application domains affected. In
this paper, we present Neko, a portable framework for high-order spectral
element flow simulations. Unlike prior works, Neko adopts a modern
object-oriented approach, allowing multi-tier abstractions of the solver stack
and facilitating hardware backends ranging from general-purpose processors down
to exotic vector processors and FPGAs. We show that Neko's performance and
accuracy are comparable to NekRS, and thus on-par with Nek5000's successor on
modern CPU machines. Furthermore, we develop a performance model, which we use
to discuss challenges and opportunities for high-order solvers on emerging
hardware.
","['\nNiclas Jansson\n', '\nMartin Karp\n', '\nArtur Podobas\n', '\nStefano Markidis\n', '\nPhilipp Schlatter\n']",,,http://arxiv.org/abs/2107.01243v1,cs.MS,['cs.MS'],,,[]
ATC: an Advanced Tucker Compression library for multidimensional data,http://arxiv.org/abs/2107.01384v4,2021-07-03T08:58:42Z,2023-02-09T13:56:09Z,"  We present ATC, a C++ library for advanced Tucker-based lossy compression of
dense multidimensional numerical data in a shared-memory parallel setting,
based on the sequentially truncated higher-order singular value decomposition
(ST-HOSVD) and bit plane truncation. Several techniques are proposed to improve
speed, memory usage, error control and compression rate. First, a hybrid
truncation scheme is described which combines Tucker rank truncation and
TTHRESH quantization [Ballester-Ripoll et al., IEEE Trans. Visual. Comput.
Graph., 2020]. We derive a novel expression to approximate the error of
truncated Tucker decompositions in the case of core and factor perturbations.
Furthermore, we parallelize the quantization and encoding scheme and adjust
this phase to improve error control. Moreover, implementation aspects are
described, such as an ST-HOSVD procedure using only a single transposition. We
also discuss several usability features of ATC, including the presence of
multiple interfaces, extensive data type support and integrated downsampling of
the decompressed data. Numerical results show that ATC maintains
state-of-the-art Tucker compression rates, while providing average speed-up
factors of 2.2-3.5 and halving memory usage. Furthermore, our compressor
provides precise error control, only deviating 1.4% from the requested error on
average. Finally, ATC often achieves higher compression than non-Tucker-based
compressors in the high-error domain.
","['\nWouter Baert\n', '\nNick Vannieuwenhoven\n']","The ATC software is publicly available at the following repository:
  https://gitlab.kuleuven.be/numa/software/atc",,http://arxiv.org/abs/2107.01384v4,cs.MS,['cs.MS'],,,[]
"DIRECTGO: A new DIRECT-type MATLAB toolbox for derivative-free global
  optimization",http://arxiv.org/abs/2107.02205v2,2021-07-05T18:13:21Z,2022-04-28T13:45:08Z,"  In this work, we introduce DIRECTGO, a new MATLAB toolbox for derivative-free
global optimization. DIRECTGO collects various deterministic derivative-free
DIRECT-type algorithms for box-constrained, generally-constrained, and problems
with hidden constraints. Each sequential algorithm is implemented in two ways:
using static and dynamic data structures for more efficient information storage
and organization. Furthermore, parallel schemes are applied to some promising
algorithms within DIRECTGO. The toolbox is equipped with a graphical user
interface (GUI), ensuring the user-friendly use of all functionalities
available in DIRECTGO. Available features are demonstrated in detailed
computational studies using a comprehensive DIRECTGOLib v1.0 library of global
optimization test problems. Additionally, eleven classical engineering design
problems illustrate the potential of DIRECTGO to solve challenging real-world
problems. Finally, the appendix gives examples of accompanying MATLAB programs
and provides a synopsis of its use on the test problems with box and general
constraints.
","['\nLinas Stripinis\n', '\nRemigijus Paulavičius\n']",Revised version of the paper,,http://arxiv.org/abs/2107.02205v2,math.OC,"['math.OC', 'cs.DS', 'cs.MS', '68U99, 90C26 (Primary) 68W10 (Secondary)', 'C.1.4; D.2; G.1.6; G.4']",,,[]
Decomposition algorithms for tensors and polynomials,http://arxiv.org/abs/2107.04097v1,2021-07-08T20:31:05Z,2021-07-08T20:31:05Z,"  We give algorithms to compute decompositions of a given polynomial, or more
generally mixed tensor, as sum of rank one tensors, and to establish whether
such a decomposition is unique. In particular, we present methods to compute
the decomposition of a general plane quintic in seven powers, and of a general
space cubic in five powers; the two decompositions of a general plane sextic of
rank nine, and the five decompositions of a general plane septic. Furthermore,
we give Magma implementations of all our algorithms.
","['\nAntonio Laface\n', '\nAlex Massarenti\n', '\nRick Rischter\n']",19 pages,,http://arxiv.org/abs/2107.04097v1,math.AG,"['math.AG', 'cs.MS', 'cs.SC', 'Primary 14N07, Secondary 14N05, 51N35, 14Q15, 14N15']",,,[]
"Fast Evaluation of Finite Element Weak Forms Using Python Tensor
  Contraction Packages",http://arxiv.org/abs/2107.04121v1,2021-07-07T15:08:24Z,2021-07-07T15:08:24Z,"  In finite element calculations, the integral forms are usually evaluated
using nested loops over elements, and over quadrature points. Many such forms
(e.g. linear or multi-linear) can be expressed in a compact way, without the
explicit loops, using a single tensor contraction expression by employing the
Einstein summation convention. To automate this process and leverage existing
high performance codes, we first introduce a notation allowing trivial
differentiation of multi-linear finite element forms. Based on that we propose
and describe a new transpiler from Einstein summation based expressions,
augmented to allow defining multi-linear finite element weak forms, to regular
tensor contraction expressions. The resulting expressions are compatible with a
number of Python scientific computing packages, that implement, optimize and in
some cases parallelize the general tensor contractions. We assess the
performance of those packages, as well as the influence of operand memory
layouts and tensor contraction paths optimizations on the elapsed time and
memory requirements of the finite element form evaluations. We also compare the
efficiency of the transpiled weak form implementations to the C-based functions
available in the finite element package SfePy.
",['\nRobert Cimrman\n'],,,http://dx.doi.org/10.1016/j.advengsoft.2021.103033,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65-04', 'F.2.1; G.1.8; G.4']",10.1016/j.advengsoft.2021.103033,,[]
Algorithmic Causal Effect Identification with causaleffect,http://arxiv.org/abs/2107.04632v1,2021-07-09T19:00:33Z,2021-07-09T19:00:33Z,"  Our evolution as a species made a huge step forward when we understood the
relationships between causes and effects. These associations may be trivial for
some events, but they are not in complex scenarios. To rigorously prove that
some occurrences are caused by others, causal theory and causal inference were
formalized, introducing the $do$-operator and its associated rules. The main
goal of this report is to review and implement in Python some algorithms to
compute conditional and non-conditional causal queries from observational data.
To this end, we first present some basic background knowledge on probability
and graph theory, before introducing important results on causal theory, used
in the construction of the algorithms. We then thoroughly study the
identification algorithms presented by Shpitser and Pearl in 2006, explaining
our implementation in Python alongside. The main identification algorithm can
be seen as a repeated application of the rules of $do$-calculus, and it
eventually either returns an expression for the causal query from experimental
probabilities or fails to identify the causal effect, in which case the effect
is non-identifiable. We introduce our newly developed Python library and give
some usage examples.
","['\nMartí Pedemonte\nUniversitat de Barcelona\n', '\nJordi Vitrià\nUniversitat de Barcelona\n', '\nÁlvaro Parafita\nUniversitat de Barcelona\n']","40 pages, 27 figures",,http://arxiv.org/abs/2107.04632v1,cs.MS,"['cs.MS', 'cs.AI', 'math.ST', 'stat.TH', '62D20 (Primary), 62H22 (Secondary)', 'G.3; G.4']",,,"['Universitat de Barcelona', 'Universitat de Barcelona', 'Universitat de Barcelona']"
"A Batched GPU Methodology for Numerical Solutions of Partial
  Differential Equations",http://arxiv.org/abs/2107.05395v1,2021-07-08T14:41:05Z,2021-07-08T14:41:05Z,"  In this paper we present a methodology for data accesses when solving batches
of Tridiagonal and Pentadiagonal matrices that all share the same
left-hand-side (LHS) matrix. The intended application is to the numerical
solution of Partial Differential Equations via the finite-difference method,
although the methodology is applicable more broadly. By only storing one copy
of this matrix, a significant reduction in storage overheads is obtained,
together with a corresponding decrease in compute time. Taken together, these
two performance enhancements lead to an overall more efficient implementation
over the current state of the art algorithms cuThomasBatch and cuPentBatch,
allowing for a greater number of systems to be solved on a single GPU. We
demonstrate the methodology in the case of the Diffusion Equation,
Hyperdiffusion Equation, and the Cahn--Hilliard Equation, all in one spatial
dimension. In this last example, we demonstrate how the method can be used to
perform $2^{20}$ independent simulations of phase separation in one dimension.
In this way, we build up a robust statistical description of the coarsening
phenomenon which is the defining behavior of phase separation. We anticipate
that the method will be of further use in other similar contexts requiring
statistical simulation of physical systems.
","['\nEnda Carroll\n', '\nAndrew Gloster\n', '\nMiguel D. Bustamante\n', ""\nLennon Ó' Náraigh\n""]",arXiv admin note: substantial text overlap with arXiv:1909.04539,,http://arxiv.org/abs/2107.05395v1,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS']",,,[]
Efficient recursive least squares solver for rank-deficient matrices,http://arxiv.org/abs/2106.11594v1,2021-06-22T07:59:35Z,2021-06-22T07:59:35Z,"  Updating a linear least squares solution can be critical for near real-time
signalprocessing applications. The Greville algorithm proposes a simple formula
for updating the pseudoinverse of a matrix A $\in$ R nxm with rank r. In this
paper, we explicitly derive a similar formula by maintaining a general rank
factorization, which we call rank-Greville. Based on this formula, we
implemented a recursive least squares algorithm exploiting the rank-deficiency
of A, achieving the update of the minimum-norm least-squares solution in O(mr)
operations and, therefore, solving the linear least-squares problem from
scratch in O(nmr) operations. We empirically confirmed that this algorithm
displays a better asymptotic time complexity than LAPACK solvers for
rank-deficient matrices. The numerical stability of rank-Greville was found to
be comparable to Cholesky-based solvers. Nonetheless, our implementation
supports exact numerical representations of rationals, due to its remarkable
algebraic simplicity.
","['\nRuben Staub\nLC\n', '\nStephan N. Steinmann\nLC\n']",,"Applied Mathematics and Computation, Elsevier, 2021, 399,
  pp.125996",http://dx.doi.org/10.1016/j.amc.2021.125996,cs.MS,['cs.MS'],10.1016/j.amc.2021.125996,,"['LC', 'LC']"
Optimal Checkpointing for Adjoint Multistage Time-Stepping Schemes,http://arxiv.org/abs/2106.13879v2,2021-06-25T20:41:50Z,2022-04-28T16:01:59Z,"  We consider checkpointing strategies that minimize the number of
recomputations needed when performing discrete adjoint computations using
multistage time-stepping schemes, which requires computing several substeps
within one complete time step. In this case we propose two algorithms that can
generate optimal checkpointing schedules under weak assumptions. The first is
an extension of the seminal Revolve algorithm adapted to multistage schemes.
The second algorithm, named CAMS, is developed based on dynamic programming,
and it requires the least number of recomputations when compared with other
algorithms. The CAMS algorithm is made publicly available in a library with
bindings to C and Python. Numerical results illustrate that the proposed
algorithms can deliver up to two times the speedup compared with that of
classical Revolve. Moreover, we discuss a tailored implementation of an adjoint
computation that is arguably better suited for mature scientific computing
libraries by avoiding the central control assumed by the original checkpointing
strategy. The proposed algorithms have been adopted by the PETSc TSAdjoint
library. Their performance has been demonstrated with a large-scale
PDE-constrained optimization problem on a leadership-class supercomputer.
","['\nHong Zhang\n', '\nEmil Constantinescu\n']",,,http://arxiv.org/abs/2106.13879v2,cs.MS,['cs.MS'],,,[]
"Efficient algorithms for computing rank-revealing factorizations on a
  GPU",http://arxiv.org/abs/2106.13402v2,2021-06-25T03:19:58Z,2023-05-21T19:47:27Z,"  Standard rank-revealing factorizations such as the singular value
decomposition and column pivoted QR factorization are challenging to implement
efficiently on a GPU. A major difficulty in this regard is the inability of
standard algorithms to cast most operations in terms of the Level-3 BLAS. This
paper presents two alternative algorithms for computing a rank-revealing
factorization of the form $A = U T V^*$, where $U$ and $V$ are orthogonal and
$T$ is triangular. Both algorithms use randomized projection techniques to cast
most of the flops in terms of matrix-matrix multiplication, which is
exceptionally efficient on the GPU. Numerical experiments illustrate that these
algorithms achieve an order of magnitude acceleration over finely tuned GPU
implementations of the SVD while providing low-rank approximation errors close
to that of the SVD.
","['\nNathan Heavner\n', '\nChao Chen\n', '\nAbinand Gopal\n', '\nPer-Gunnar Martinsson\n']",,,http://arxiv.org/abs/2106.13402v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Linear solvers for power grid optimization problems: a review of
  GPU-accelerated linear solvers",http://arxiv.org/abs/2106.13909v2,2021-06-25T23:12:06Z,2021-08-13T21:32:58Z,"  The linear equations that arise in interior methods for constrained
optimization are sparse symmetric indefinite and become extremely
ill-conditioned as the interior method converges. These linear systems present
a challenge for existing solver frameworks based on sparse LU or LDL^T
decompositions. We benchmark five well known direct linear solver packages
using matrices extracted from power grid optimization problems. The achieved
solution accuracy varies greatly among the packages. None of the tested
packages delivers significant GPU acceleration for our test cases.
","['\nKasia Swirydowicz\n', '\nEric Darve\n', '\nWesley Jones\n', '\nJonathan Maack\n', '\nShaked Regev\n', '\nMichael A. Saunders\n', '\nStephen J. Thomas\n', '\nSlaven Peles\n']",,,http://dx.doi.org/10.1016/j.parco.2021.102870,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1016/j.parco.2021.102870,,[]
"Leveraging GPU batching for scalable nonlinear programming through
  massive Lagrangian decomposition",http://arxiv.org/abs/2106.14995v1,2021-06-28T21:39:38Z,2021-06-28T21:39:38Z,"  We present the implementation of a trust-region Newton algorithm ExaTron for
bound-constrained nonlinear programming problems, fully running on multiple
GPUs. Without data transfers between CPU and GPU, our implementation has
achieved the elimination of a major performance bottleneck under a memory-bound
situation, particularly when solving many small problems in batch. We discuss
the design principles and implementation details for our kernel function and
core operations. Different design choices are justified by numerical
experiments. By using the application of distributed control of alternating
current optimal power flow, where a large problem is decomposed into many
smaller nonlinear programs using a Lagrangian approach, we demonstrate
computational performance of ExaTron on the Summit supercomputer at Oak
RidgeNational Laboratory. Our numerical results show the linear scaling with
respect to the batch size and the number of GPUs and more than 35 times speedup
on 6 GPUs than on 40 CPUs available on a single node.
","['\nYoungdae Kim\n', '\nFrançois Pacaud\n', '\nKibaek Kim\n', '\nMihai Anitescu\n']",,,http://arxiv.org/abs/2106.14995v1,math.OC,"['math.OC', 'cs.DC', 'cs.MS', '65K05, 90C06, 90C30, 90-04, 90-08']",,,[]
"The mbsts package: Multivariate Bayesian Structural Time Series Models
  in R",http://arxiv.org/abs/2106.14045v3,2021-06-26T15:28:38Z,2023-02-06T18:42:06Z,"  The multivariate Bayesian structural time series (MBSTS) model is a general
machine learning model that deals with inference and prediction for multiple
correlated time series, where one also has the choice of using a different
candidate pool of contemporaneous predictors for each target series. The MBSTS
model has wide applications and is ideal for feature selection, time series
forecasting, nowcasting, inferring causal impact, and others. This paper
demonstrates how to use the R package mbsts for MBSTS modeling, establishing a
bridge between user-friendly and developer-friendly functions in the package
and the corresponding methodology. Object-oriented functions in the package are
explained in the way that enables users to flexibly add or deduct some
components, as well as to simplify or complicate some settings.
","['\nNing Ning\n', '\nJinwen Qiu\n']",,,http://arxiv.org/abs/2106.14045v3,stat.ME,"['stat.ME', 'cs.LG', 'cs.MS', 'stat.AP', 'stat.CO']",,,[]
Web-based Structural Identifiability Analyzer,http://arxiv.org/abs/2106.15066v1,2021-06-29T02:57:34Z,2021-06-29T02:57:34Z,"  Parameter identifiability describes whether, for a given differential model,
one can determine parameter values from model equations. Knowing global or
local identifiability properties allows construction of better practical
experiments to identify parameters from experimental data. In this work, we
present a web-based software tool that allows to answer specific
identifiability queries. Concretely, our toolbox can determine identifiability
of individual parameters of the model and also provide all functions of
parameters that are identifiable (also called identifiable combinations) from
single or multiple experiments. The program is freely available at
https://maple.cloud/app/6509768948056064.
","['\nIlia Ilmer\n', '\nAlexey Ovchinnikov\n', '\nGleb Pogudin\n']",,,http://arxiv.org/abs/2106.15066v1,cs.MS,"['cs.MS', 'cs.SC', 'cs.SY', 'eess.SY', 'q-bio.QM']",,,[]
"Automatic Differentiation With Higher Infinitesimals, or Computational
  Smooth Infinitesimal Analysis in Weil Algebra",http://arxiv.org/abs/2106.14153v2,2021-06-27T06:17:26Z,2021-07-05T03:22:50Z,"  We propose an algorithm to compute the $C^\infty$-ring structure of arbitrary
Weil algebra. It allows us to do some analysis with higher infinitesimals
numerically and symbolically. To that end, we first give a brief description of
the (Forward-mode) automatic differentiation (AD) in terms of $C^\infty$-rings.
The notion of a $C^\infty$-ring was introduced by Lawvere and used as the
fundamental building block of smooth infinitesimal analysis and synthetic
differential geometry. We argue that interpreting AD in terms of
$C^\infty$-rings gives us a unifying theoretical framework and modular ways to
express multivariate partial derivatives. In particular, we can ""package""
higher-order Forward-mode AD as a Weil algebra, and take tensor products to
compose them to achieve multivariate higher-order AD. The algorithms in the
present paper can also be used for a pedagogical purpose in learning and
studying smooth infinitesimal analysis as well.
",['\nHiromi Ishii\n'],to appear in Computer Algebra in Scientific Computing 2021,"Computer Algebra in Scientific Computing, pp. 174-191. CASC 2021.
  Lecture Notes in Computer Science, vol 12865. Springer, Cham",http://dx.doi.org/10.1007/978-3-030-85165-1_11,cs.SC,"['cs.SC', 'cs.MS', 'cs.NA', 'math.CT', 'math.DG', 'math.NA']",10.1007/978-3-030-85165-1_11,,[]
"Manifolds.jl: An Extensible Julia Framework for Data Analysis on
  Manifolds",http://arxiv.org/abs/2106.08777v3,2021-06-16T13:36:17Z,2023-06-12T07:55:16Z,"  We present the Julia package Manifolds.jl, providing a fast and easy-to-use
library of Riemannian manifolds and Lie groups. This package enables working
with data defined on a Riemannian manifold, such as the circle, the sphere,
symmetric positive definite matrices, or one of the models for hyperbolic
spaces. We introduce a common interface, available in ManifoldsBase.jl, with
which new manifolds, applications, and algorithms can be implemented. We
demonstrate the utility of Manifolds.jl using B\'ezier splines, an optimization
task on manifolds, and principal component analysis on nonlinear data. In a
benchmark, Manifolds.jl outperforms all comparable packages for low-dimensional
manifolds in speed; over Python and Matlab packages, the improvement is often
several orders of magnitude, while over C/C++ packages, the improvement is
two-fold. For high-dimensional manifolds, it outperforms all packages except
for Tensorflow-Riemopt, which is specifically tailored for high-dimensional
manifolds.
","['\nSeth D. Axen\n', '\nMateusz Baran\n', '\nRonny Bergmann\n', '\nKrzysztof Rzecki\n']",,,http://dx.doi.org/10.1145/3618296,cs.MS,['cs.MS'],10.1145/3618296,,[]
"HIFIR: Hybrid Incomplete Factorization with Iterative Refinement for
  Preconditioning Ill-conditioned and Singular Systems",http://arxiv.org/abs/2106.09877v2,2021-06-18T02:30:39Z,2021-12-01T16:17:05Z,"  We introduce a software package called HIFIR for preconditioning sparse,
unsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes
a hybrid incomplete factorization, which combines multilevel incomplete LU
factorization with a truncated, rank-revealing QR factorization on the final
Schur complement. This novel hybridization is based on the new theory of
approximate generalized inverse and $\epsilon$-accuracy. It enables
near-optimal preconditioners for consistent systems and enables flexible GMRES
to solve inconsistent systems when coupled with iterative refinement. In this
paper, we focus on some practical algorithmic and software issues of HIFIR. In
particular, we introduce a new inverse-based rook pivoting into ILU, which
improves the robustness and the overall efficiency for some ill-conditioned
systems by significantly reducing the size of the final Schur complement for
some systems. We also describe the software design of HIFIR in terms of its
efficient data structures for supporting rook pivoting in a multilevel setting,
its template-based generic programming interfaces for mixed-precision real and
complex values in C++, and its user-friendly high-level interfaces in MATLAB
and Python. We demonstrate the effectiveness of HIFIR for ill-conditioned or
singular systems arising from several applications, including the Helmholtz
equation, linear elasticity, stationary incompressible Navier--Stokes
equations, and time-dependent advection-diffusion equation.
","['\nQiao Chen\n', '\nXiangmin Jiao\n']",Submitted to ACM Transactions on Mathematical Software (TOMS),,http://arxiv.org/abs/2106.09877v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained
  SDPs",http://arxiv.org/abs/2106.08775v2,2021-06-16T13:35:40Z,2021-07-03T00:13:34Z,"  We present a novel, practical, and provable approach for solving diagonally
constrained semi-definite programming (SDP) problems at scale using accelerated
non-convex programming. Our algorithm non-trivially combines acceleration
motions from convex optimization with coordinate power iteration and matrix
factorization techniques. The algorithm is extremely simple to implement, and
adds only a single extra hyperparameter -- momentum. We prove that our method
admits local linear convergence in the neighborhood of the optimum and always
converges to a first-order critical point. Experimentally, we showcase the
merits of our method on three major application domains: MaxCut, MaxSAT, and
MIMO signal detection. In all cases, our methodology provides significant
speedups over non-convex and convex SDP solvers -- 5X faster than
state-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP
solvers -- with comparable or improved solution quality.
","['\nJunhyung Lyle Kim\n', '\nJA Lara Benitez\n', '\nMohammad Taha Toghani\n', '\nCameron Wolfe\n', '\nZhiwei Zhang\n', '\nAnastasios Kyrillidis\n']","10 pages, 8 figures, preprint under review",,http://arxiv.org/abs/2106.08775v2,math.OC,"['math.OC', 'cs.IT', 'cs.LG', 'cs.MS', 'math.IT', 'stat.ML', '49-02', 'F.2.1; G.4']",,,[]
"semopy 2: A Structural Equation Modeling Package with Random Effects in
  Python",http://arxiv.org/abs/2106.01140v3,2021-06-02T13:18:03Z,2021-06-09T17:35:07Z,"  Structural Equation Modeling (SEM) is an umbrella term that includes numerous
multivariate statistical techniques that are employed throughout a plethora of
research areas, ranging from social to natural sciences. Until recently, SEM
software was either commercial or restricted to niche languages, and the lack
of SEM packages compatible with more mainstream programming languages was dire.
To combat that, we introduced a Python package semopy 1 that surpassed other
state-of-the-art software in terms of performance and estimation accuracy. Yet,
it was lacking in functionality and its usage was burdened with unnecessary
boilerplate code. Here, we introduce a complete overhaul of semopy that
improves upon the previous results and comes with lots of new capabilities.
Furthermore, we propose a novel SEM model that combines in itself a notion of
random effects from linear mixed models (LMMs) to model numerous phenomena,
such as spatial data, time series or population stratification in genetics.
","['\nGeorgy Meshcheryakov\n', '\nAnna A. Igolkina\n', '\nMaria G. Samsonova\n']",,,http://arxiv.org/abs/2106.01140v3,stat.AP,"['stat.AP', 'cs.MS']",,,[]
"A multiresolution Discrete Element Method for triangulated objects with
  implicit timestepping",http://arxiv.org/abs/2105.12415v2,2021-05-26T09:11:33Z,2022-03-09T09:28:32Z,"  Simulations of many rigid bodies colliding with each other sometimes yield
particularly interesting results if the colliding objects differ significantly
in size and are non-spherical. The most expensive part within such a simulation
code is the collision detection. We propose a family of novel multiscale
collision detection algorithms that can be applied to triangulated objects
within explicit and implicit time stepping methods. They are well-suited to
handle objects that cannot be represented by analytical shapes or assemblies of
analytical objects. Inspired by multigrid methods and adaptive mesh refinement,
we determine collision points iteratively over a resolution hierarchy, and
combine a functional minimisation plus penalty parameters with the actual
comparision-based geometric distance calculation. Coarse surrogate geometry
representations identify ""no collision"" scenarios early on and otherwise yield
an educated guess which triangle subsets of the next finer level potentially
yield collisions. They prune the search tree, and furthermore feed conservative
contact force estimates into the iterative solve behind an implicit time
stepping. Implicit time stepping and non-analytical shapes often yield
prohibitive high compute cost for rigid body simulations. Our approach reduces
these cost algorithmically by one to two orders of magnitude. It also exhibits
high vectorisation efficiency due to its iterative nature.
","['\nPeter J. Noble\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1137/21M1421842,cs.CG,"['cs.CG', 'cs.MS', '70E55, 70F35, 68U05, 51P05, 37N15']",10.1137/21M1421842,,[]
Task inefficiency patterns for a wave equation solver,http://arxiv.org/abs/2105.12739v2,2021-05-26T18:00:01Z,2021-07-12T12:40:58Z,"  The orchestration of complex algorithms demands high levels of automation to
use modern hardware efficiently. Task-based programming with OpenMP 5.0 is a
prominent candidate to accomplish this goal. We study OpenMP 5.0's tasking in
the context of a wave equation solver (ExaHyPE) using three different
architectures and runtimes. We describe several task-scheduling flaws present
in currently available runtimes, demonstrate how they impact performance and
show how to work around them. Finally, we propose extensions to the OpenMP
standard.
","['\nHolger Schulz\n', '\nGonzalo Brito Gadeschi\n', '\nOleksandr Rudyy\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1007/978-3-030-85262-7_8,cs.DC,"['cs.DC', 'cs.MS']",10.1007/978-3-030-85262-7_8,,[]
"Mill.jl and JsonGrinder.jl: automated differentiable feature extraction
  for learning from raw JSON data",http://arxiv.org/abs/2105.09107v1,2021-05-19T13:02:10Z,2021-05-19T13:02:10Z,"  Learning from raw data input, thus limiting the need for manual feature
engineering, is one of the key components of many successful applications of
machine learning methods. While machine learning problems are often formulated
on data that naturally translate into a vector representation suitable for
classifiers, there are data sources, for example in cybersecurity, that are
naturally represented in diverse files with a unifying hierarchical structure,
such as XML, JSON, and Protocol Buffers. Converting this data to vector
(tensor) representation is generally done by manual feature engineering, which
is laborious, lossy, and prone to human bias about the importance of particular
features.
  Mill and JsonGrinder is a tandem of libraries, which fully automates the
conversion. Starting with an arbitrary set of JSON samples, they create a
differentiable machine learning model capable of infer from further JSON
samples in their raw form.
","['\nSimon Mandlik\n', '\nMatej Racinsky\n', '\nViliam Lisy\n', '\nTomas Pevny\n']","5 pages, 2 figures, 1 table, submitted to section on one-source
  software of Journal of Machine Learning Research",,http://arxiv.org/abs/2105.09107v1,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS']",,,[]
"Uncertainty quantification through Monte Carlo method in a cloud
  computing setting",http://arxiv.org/abs/2105.09512v1,2021-05-20T04:52:40Z,2021-05-20T04:52:40Z,"  The Monte Carlo (MC) method is the most common technique used for uncertainty
quantification, due to its simplicity and good statistical results. However,
its computational cost is extremely high, and, in many cases, prohibitive.
Fortunately, the MC algorithm is easily parallelizable, which allows its use in
simulations where the computation of a single realization is very costly. This
work presents a methodology for the parallelization of the MC method, in the
context of cloud computing. This strategy is based on the MapReduce paradigm,
and allows an efficient distribution of tasks in the cloud. This methodology is
illustrated on a problem of structural dynamics that is subject to
uncertainties. The results show that the technique is capable of producing good
results concerning statistical moments of low order. It is shown that even a
simple problem may require many realizations for convergence of histograms,
which makes the cloud computing strategy very attractive (due to its high
scalability capacity and low-cost). Additionally, the results regarding the
time of processing and storage space usage allow one to qualify this new
methodology as a solution for simulations that require a number of MC
realizations beyond the standard.
","['\nA. Cunha Jr\n', '\nR. Nasser\n', '\nR. Sampaio\n', '\nH. Lopes\n', '\nK. Breitman\n']",,"Computer Physics Communications, vol. 185, pp. 1355-1363, 2014",http://dx.doi.org/10.1016/j.cpc.2014.01.006,stat.CO,"['stat.CO', 'cs.MS', 'math.PR', 'stat.AP', '62D05', 'G.3']",10.1016/j.cpc.2014.01.006,,[]
"FRaGenLP: A Generator of Random Linear Programming Problems for Cluster
  Computing Systems",http://arxiv.org/abs/2105.10384v1,2021-05-18T14:55:24Z,2021-05-18T14:55:24Z,"  The article presents and evaluates a scalable FRaGenLP algorithm for
generating random linear programming problems of large dimension $n$ on cluster
computing systems. To ensure the consistency of the problem and the boundedness
of the feasible region, the constraint system includes $2n+1$ standard
inequalities, called support inequalities. New random inequalities are
generated and added to the system in a manner that ensures the consistency of
the constraints. Furthermore, the algorithm uses two likeness metrics to
prevent the addition of a new random inequality that is similar to one already
present in the constraint system. The algorithm also rejects random
inequalities that cannot affect the solution of the linear programming problem
bounded by the support inequalities. The parallel implementation of the
FRaGenLP algorithm is performed in C++ through the parallel BSF-skeleton, which
encapsulates all aspects related to the MPI-based parallelization of the
program. We provide the results of large-scale computational experiments on a
cluster computing system to study the scalability of the FRaGenLP algorithm.
","['\nLeonid B. Sokolinsky\n', '\nIrina M. Sokolinskaya\n']","Submitted to ""Communications in Computer and Information Science""","Communications in Computer and Information Science. 2021, vol.
  1437. 164-177",http://dx.doi.org/10.1007/978-3-030-81691-9_12,cs.DC,"['cs.DC', 'cs.MS', 'math.OC']",10.1007/978-3-030-81691-9_12,,[]
"On the Complexity and Parallel Implementation of Hensel's Lemma and
  Weierstrass Preparation",http://arxiv.org/abs/2105.10798v2,2021-05-22T19:26:52Z,2021-07-02T18:50:05Z,"  Hensel's lemma, combined with repeated applications of Weierstrass
preparation theorem, allows for the factorization of polynomials with
multivariate power series coefficients. We present a complexity analysis for
this method and leverage those results to guide the load-balancing of a
parallel implementation to concurrently update all factors. In particular, the
factorization creates a pipeline where the terms of degree k of the first
factor are computed simultaneously with the terms of degree k-1 of the second
factor, etc. An implementation challenge is the inherent irregularity of
computational work between factors, as our complexity analysis reveals.
Additional resource utilization and load-balancing is achieved through the
parallelization of Weierstrass preparation. Experimental results show the
efficacy of this mixed parallel scheme, achieving up to 9x parallel speedup on
12 cores.
","['\nAlexander Brandt\n', '\nMarc Moreno Maza\n']","21 pages, 3 figures, submitted to Computer Algebra in Scientific
  Computing CASC 2021",,http://arxiv.org/abs/2105.10798v2,cs.SC,"['cs.SC', 'cs.DC', 'cs.MS']",,,[]
"kEDM: A Performance-portable Implementation of Empirical Dynamic
  Modeling using Kokkos",http://arxiv.org/abs/2105.12301v1,2021-05-26T02:21:55Z,2021-05-26T02:21:55Z,"  Empirical Dynamic Modeling (EDM) is a state-of-the-art non-linear time-series
analysis framework. Despite its wide applicability, EDM was not scalable to
large datasets due to its expensive computational cost. To overcome this
obstacle, researchers have attempted and succeeded in accelerating EDM from
both algorithmic and implementational aspects. In previous work, we developed a
massively parallel implementation of EDM targeting HPC systems (mpEDM).
However, mpEDM maintains different backends for different architectures. This
design becomes a burden in the increasingly diversifying HPC systems, when
porting to new hardware. In this paper, we design and develop a
performance-portable implementation of EDM based on the Kokkos performance
portability framework (kEDM), which runs on both CPUs and GPUs while based on a
single codebase. Furthermore, we optimize individual kernels specifically for
EDM computation, and use real-world datasets to demonstrate up to $5.5\times$
speedup compared to mpEDM in convergent cross mapping computation.
","['\nKeichi Takahashi\nNara Institute of Science and Technology\n', '\nWassapon Watanakeesuntorn\nNara Institute of Science and Technology\n', '\nKohei Ichikawa\nNara Institute of Science and Technology\n', '\nJoseph Park\nU.S. Department of the Interior\n', '\nRyousei Takano\nNational Institute of Advanced Industrial Science and Technology\n', '\nJason Haga\nNational Institute of Advanced Industrial Science and Technology\n', '\nGeorge Sugihara\nUniversity of California San Diego\n', '\nGerald M. Pao\nSalk Institute for Biological Studies\n']","8 pages, 9 figures, accepted at Practice & Experience in Advanced
  Research Computing (PEARC'21), corresponding authors: Keichi Takahashi,
  Gerald M. Pao",,http://dx.doi.org/10.1145/3437359.3465571,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",10.1145/3437359.3465571,,"['Nara Institute of Science and Technology', 'Nara Institute of Science and Technology', 'Nara Institute of Science and Technology', 'U.S. Department of the Interior', 'National Institute of Advanced Industrial Science and Technology', 'National Institute of Advanced Industrial Science and Technology', 'University of California San Diego', 'Salk Institute for Biological Studies']"
TensorFlow RiemOpt: a library for optimization on Riemannian manifolds,http://arxiv.org/abs/2105.13921v2,2021-05-27T10:42:09Z,2021-07-07T18:50:43Z,"  The adoption of neural networks and deep learning in non-Euclidean domains
has been hindered until recently by the lack of scalable and efficient learning
frameworks. Existing toolboxes in this space were mainly motivated by research
and education use cases, whereas practical aspects, such as deploying and
maintaining machine learning models, were often overlooked.
  We attempt to bridge this gap by proposing TensorFlow RiemOpt, a Python
library for optimization on Riemannian manifolds in TensorFlow. The library is
designed with the aim for a seamless integration with the TensorFlow ecosystem,
targeting not only research, but also streamlining production machine learning
pipelines.
",['\nOleg Smirnov\n'],"The library code is available at
  https://github.com/master/tensorflow-riemopt",,http://arxiv.org/abs/2105.13921v2,cs.MS,"['cs.MS', 'cs.CG', 'cs.LG']",,,[]
High-performance symbolic-numerics via multiple dispatch,http://arxiv.org/abs/2105.03949v3,2021-05-09T14:22:43Z,2022-02-05T07:46:51Z,"  As mathematical computing becomes more democratized in high-level languages,
high-performance symbolic-numeric systems are necessary for domain scientists
and engineers to get the best performance out of their machine without deep
knowledge of code optimization. Naturally, users need different term types
either to have different algebraic properties for them, or to use efficient
data structures. To this end, we developed Symbolics.jl, an extendable symbolic
system which uses dynamic multiple dispatch to change behavior depending on the
domain needs. In this work we detail an underlying abstract term interface
which allows for speed without sacrificing generality. We show that by
formalizing a generic API on actions independent of implementation, we can
retroactively add optimized data structures to our system without changing the
pre-existing term rewriters. We showcase how this can be used to optimize term
construction and give a 113x acceleration on general symbolic transformations.
Further, we show that such a generic API allows for complementary
term-rewriting implementations. We demonstrate the ability to swap between
classical term-rewriting simplifiers and e-graph-based term-rewriting
simplifiers. We showcase an e-graph ruleset which minimizes the number of CPU
cycles during expression evaluation, and demonstrate how it simplifies a
real-world reaction-network simulation to halve the runtime. Additionally, we
show a reaction-diffusion partial differential equation solver which is able to
be automatically converted into symbolic expressions via multiple dispatch
tracing, which is subsequently accelerated and parallelized to give a 157x
simulation speedup. Together, this presents Symbolics.jl as a next-generation
symbolic-numeric computing environment geared towards modeling and simulation.
","['\nShashi Gowda\n', '\nYingbo Ma\n', '\nAlessandro Cheli\n', '\nMaja Gwozdz\n', '\nViral B. Shah\n', '\nAlan Edelman\n', '\nChristopher Rackauckas\n']",,,http://arxiv.org/abs/2105.03949v3,cs.CL,"['cs.CL', 'cs.MS', 'cs.PL', 'cs.SC', 'D.3.3; I.1.1; I.1.3']",,,[]
SIRNN: A Math Library for Secure RNN Inference,http://arxiv.org/abs/2105.04236v1,2021-05-10T10:04:46Z,2021-05-10T10:04:46Z,"  Complex machine learning (ML) inference algorithms like recurrent neural
networks (RNNs) use standard functions from math libraries like exponentiation,
sigmoid, tanh, and reciprocal of square root. Although prior work on secure
2-party inference provides specialized protocols for convolutional neural
networks (CNNs), existing secure implementations of these math operators rely
on generic 2-party computation (2PC) protocols that suffer from high
communication. We provide new specialized 2PC protocols for math functions that
crucially rely on lookup-tables and mixed-bitwidths to address this performance
overhead; our protocols for math functions communicate up to 423x less data
than prior work. Some of the mixed bitwidth operations used by our math
implementations are (zero and signed) extensions, different forms of
truncations, multiplication of operands of mixed-bitwidths, and digit
decomposition (a generalization of bit decomposition to larger digits). For
each of these primitive operations, we construct specialized 2PC protocols that
are more communication efficient than generic 2PC, and can be of independent
interest. Furthermore, our math implementations are numerically precise, which
ensures that the secure implementations preserve model accuracy of cleartext.
We build on top of our novel protocols to build SIRNN, a library for end-to-end
secure 2-party DNN inference, that provides the first secure implementations of
an RNN operating on time series sensor data, an RNN operating on speech data,
and a state-of-the-art ML architecture that combines CNNs and RNNs for
identifying all heads present in images. Our evaluation shows that SIRNN
achieves up to three orders of magnitude of performance improvement when
compared to inference of these models using an existing state-of-the-art 2PC
framework.
","['\nDeevashwer Rathee\n', '\nMayank Rathee\n', '\nRahul Kranti Kiran Goli\n', '\nDivya Gupta\n', '\nRahul Sharma\n', '\nNishanth Chandran\n', '\nAseem Rastogi\n']",IEEE Security and Privacy 2021,,http://arxiv.org/abs/2105.04236v1,cs.CR,"['cs.CR', 'cs.LG', 'cs.MS']",,,[]
"Accelerating the SpMV kernel on standard CPUs by exploiting the
  partially diagonal structures",http://arxiv.org/abs/2105.04937v1,2021-05-11T11:04:01Z,2021-05-11T11:04:01Z,"  Sparse Matrix Vector multiplication (SpMV) is one of basic building blocks in
scientific computing, and acceleration of SpMV has been continuously required.
In this research, we aim for accelerating SpMV on recent CPUs for sparse
matrices that have a specific sparsity structure, namely a diagonally
structured sparsity pattern. We focus a hybrid storage format that combines the
DIA and CSR formats, so-called the HDC format. First, we recall the importance
of introducing cache blocking techniques into HDC-based SpMV kernels. Next,
based on the observation of the cache blocked kernel, we present a modified
version of the HDC formats, which we call the M-HDC format, in which partial
diagonal structures are expected to be more efficiently picked up. For these
SpMV kernels, we theoretically analyze the expected performance improvement
based on performance models. Then, we conduct comprehensive experiments on
state-of-the-art multi-core CPUs. By the experiments using typical matrices, we
clarify the detailed performance characteristics of each SpMV kernel. We also
evaluate the performance for matrices appearing in practical applications and
demonstrate that our approach can accelerate SpMV for some of them. Through the
present paper, we demonstrate the effectiveness of exploiting partial diagonal
structures by the M-HDC format as a promising approach to accelerating SpMV on
CPUs for a certain kind of practical sparse matrices.
","['\nTakeshi Fukaya\n', '\nKoki Ishida\n', '\nAkie Miura\n', '\nTakeshi Iwashita\n', '\nHiroshi Nakashima\n']",,,http://arxiv.org/abs/2105.04937v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"SPUX Framework: a Scalable Package for Bayesian Uncertainty
  Quantification and Propagation",http://arxiv.org/abs/2105.05969v1,2021-05-12T21:16:24Z,2021-05-12T21:16:24Z,"  We present SPUX - a modular framework for Bayesian inference enabling
uncertainty quantification and propagation in linear and nonlinear,
deterministic and stochastic models, and supporting Bayesian model selection.
SPUX can be coupled to any serial or parallel application written in any
programming language, (e.g. including Python, R, Julia, C/C++, Fortran, Java,
or a binary executable), scales effortlessly from serial runs on a personal
computer to parallel high performance computing clusters, and aims to provide a
platform particularly suited to support and foster reproducibility in
computational science. We illustrate SPUX capabilities for a simple yet
representative random walk model, describe how to couple different types of
user applications, and showcase several readily available examples from
environmental sciences. In addition to available state-of-the-art numerical
inference algorithms including EMCEE, PMCMC (PF) and SABC, the open source
nature of the SPUX framework and the explicit description of the hierarchical
parallel SPUX executors should also greatly simplify the implementation and
usage of other inference and optimization techniques.
","['\nJonas Šukys\n', '\nMarco Bacci\n']",Supplementary Material available as a PDF in submission package,,http://arxiv.org/abs/2105.05969v1,stat.CO,"['stat.CO', 'cs.CE', 'cs.MS']",,,[]
Experimental Evaluation of Multiprecision Strategies for GMRES on GPUs,http://arxiv.org/abs/2105.07544v1,2021-05-16T23:22:02Z,2021-05-16T23:22:02Z,"  Support for lower precision computation is becoming more common in
accelerator hardware due to lower power usage, reduced data movement and
increased computational performance. However, computational science and
engineering (CSE) problems require double precision accuracy in several
domains. This conflict between hardware trends and application needs has
resulted in a need for multiprecision strategies at the linear algebra
algorithms level if we want to exploit the hardware to its full potential while
meeting the accuracy requirements. In this paper, we focus on preconditioned
sparse iterative linear solvers, a key kernel in several CSE applications. We
present a study of multiprecision strategies for accelerating this kernel on
GPUs. We seek the best methods for incorporating multiple precisions into the
GMRES linear solver; these include iterative refinement and parallelizable
preconditioners. Our work presents strategies to determine when multiprecision
GMRES will be effective and to choose parameters for a multiprecision iterative
refinement solver to achieve better performance. We use an implementation that
is based on the Trilinos library and employs Kokkos Kernels for performance
portability of linear algebra kernels. Performance results demonstrate the
promise of multiprecision approaches and demonstrate even further improvements
are possible by optimizing low-level kernels.
","['\nJennifer A. Loe\n', '\nChristian A. Glusa\n', '\nIchitaro Yamazaki\n', '\nErik G. Boman\n', '\nSivasankaran Rajamanickam\n']","Accepted for publication in the IEEE IPDPS Accelerators and Hybrid
  Emerging Systems (AsHES) 11th Workshop, 2021",,http://arxiv.org/abs/2105.07544v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
ReLie: a Reduce program for Lie group analysis of differential equations,http://arxiv.org/abs/2105.11534v1,2021-05-07T11:22:13Z,2021-05-07T11:22:13Z,"  Lie symmetry analysis provides a general theoretical framework for
investigating ordinary and partial differential equations. The theory is
completely algorithmic even if it usually involves lengthy computations. For
this reason, many computer algebra packages have been developed along the years
to automate the computation. In this paper, we describe the program ReLie,
written in the Computer Algebra System Reduce, which since 2008 is an open
source program (http://www.reduce-algebra.com) and is available for all
platforms. \relie is able to perform almost automatically the needed
computations for Lie symmetry analysis of differential equations. Its source
code is freely available at the url http://mat521.unime.it/oliveri. The use of
the program is illustrated by means of some simple examples; nevertheless, it
is to be underlined that it provides effective also for more complex
computations where one has to deal with very large expressions.
",['\nFrancesco Oliveri\n'],,,http://arxiv.org/abs/2105.11534v1,cs.MS,"['cs.MS', 'cs.NA', 'math-ph', 'math.MP', 'math.NA', '34-04, 34A05, 35-04, 58J70, 58J72']",,,[]
"Paradiseo: From a Modular Framework for Evolutionary Computation to the
  Automated Design of Metaheuristics ---22 Years of Paradiseo---",http://arxiv.org/abs/2105.00420v1,2021-05-02T08:45:33Z,2021-05-02T08:45:33Z,"  The success of metaheuristic optimization methods has led to the development
of a large variety of algorithm paradigms. However, no algorithm clearly
dominates all its competitors on all problems. Instead, the underlying variety
of landscapes of optimization problems calls for a variety of algorithms to
solve them efficiently. It is thus of prior importance to have access to mature
and flexible software frameworks which allow for an efficient exploration of
the algorithm design space. Such frameworks should be flexible enough to
accommodate any kind of metaheuristics, and open enough to connect with
higher-level optimization, monitoring and evaluation softwares. This article
summarizes the features of the ParadisEO framework, a comprehensive C++ free
software which targets the development of modular metaheuristics. ParadisEO
provides a highly modular architecture, a large set of components, speed of
execution and automated algorithm design features, which are key to modern
approaches to metaheuristics development.
","['\nJohann Dreo\nSystems Biology Group, Department of Computational Biology, USR 3756, Institut Pasteur and CNRS, Paris, France\n', '\nArnaud Liefooghe\nUniv. Lille, CNRS, Inria, Centrale Lille, UMR 9189 CRIStAL, Lille, France\n', ""\nSébastien Verel\nUniv. Littoral Côte d'Opale, Calais, France\n"", '\nMarc Schoenauer\nTAU, Inria, CNRS and UPSaclay, LISN, Saclay, France\n', '\nJuan J. Merelo\nUniversity of Granada, Granada, Spain\n', '\nAlexandre Quemy\nPoznan University of Technology, Poznan, Poland\n', '\nBenjamin Bouvier\nInria, Lille, France\n', '\nJan Gmys\nInria, Lille, France\n']","12 pages, 6 figures, 3 listings, 1 table. To appear in 2021 Genetic
  and Evolutionary Computation Conference Companion (GECCO'21 Companion), July
  10--14, 2021, Lille, France. ACM, New York, NY, USA",,http://dx.doi.org/10.1145/3449726.3463276,cs.NE,"['cs.NE', 'cs.MS']",10.1145/3449726.3463276,,"['Systems Biology Group, Department of Computational Biology, USR 3756, Institut Pasteur and CNRS, Paris, France', 'Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 CRIStAL, Lille, France', ""Univ. Littoral Côte d'Opale, Calais, France"", 'TAU, Inria, CNRS and UPSaclay, LISN, Saclay, France', 'University of Granada, Granada, Spain', 'Poznan University of Technology, Poznan, Poland', 'Inria, Lille, France', 'Inria, Lille, France']"
tsrobprep - an R package for robust preprocessing of time series data,http://arxiv.org/abs/2104.12657v2,2021-04-26T15:35:11Z,2021-10-11T11:33:46Z,"  Data cleaning is a crucial part of every data analysis exercise. Yet, the
currently available R packages do not provide fast and robust methods for
cleaning and preparation of time series data. The open source package tsrobprep
introduces efficient methods for handling missing values and outliers using
model based approaches. For data imputation a probabilistic replacement model
is proposed, which may consist of autoregressive components and external
inputs. For outlier detection a clustering algorithm based on finite mixture
modelling is introduced, which considers time series properties in terms of the
gradient and the underlying seasonality as features. The procedure allows to
return a probability for each observation being outlying data as well as a
specific cause for an outlier assignment in terms of the provided feature
space. The methods work robust and are fully tunable. Moreover, by providing
the auto_data_cleaning function the data preprocessing can be carried out in
one cast, without comprehensive tuning and providing suitable results. The
primary motivation of the package is the preprocessing of energy system data.
We present application for electricity load, wind and solar power data.
","['\nMichał Narajewski\n', '\nJens Kley-Holsteg\n', '\nFlorian Ziel\n']",,SoftwareX 16 (2021) 100809,http://dx.doi.org/10.1016/j.softx.2021.100809,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS', 'stat.CO']",10.1016/j.softx.2021.100809,,[]
"Bringing Trimmed Serendipity Methods to Computational Practice in
  Firedrake",http://arxiv.org/abs/2104.12986v2,2021-04-27T05:25:02Z,2021-10-08T18:14:38Z,"  We present an implementation of the trimmed serendipity finite element
family, using the open source finite element package Firedrake. The new
elements can be used seamlessly within the software suite for problems
requiring $H^1$, \hcurl, or \hdiv-conforming elements on meshes of squares or
cubes. To test how well trimmed serendipity elements perform in comparison to
traditional tensor product elements, we perform a sequence of numerical
experiments including the primal Poisson, mixed Poisson, and Maxwell cavity
eigenvalue problems. Overall, we find that the trimmed serendipity elements
converge, as expected, at the same rate as the respective tensor product
elements while being able to offer significant savings in the time or memory
required to solve certain problems.
","['\nJustin Crum\n', '\nCyrus Cheng\n', '\nDavid A. Ham\n', '\nLawrence Mitchell\n', '\nRobert C. Kirby\n', '\nJoshua A. Levine\n', '\nAndrew Gillette\n']","19 pages, 7 figures, 3 tables, 2 listings",ACM Transactions on Mathematical Software 48(1):8:1-8:19 (2022),http://dx.doi.org/10.1145/3490485,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.AP']",10.1145/3490485,,[]
"High-Performance Partial Spectrum Computation for Symmetric eigenvalue
  problems and the SVD",http://arxiv.org/abs/2104.14186v1,2021-04-29T08:04:23Z,2021-04-29T08:04:23Z,"  Current dense symmetric eigenvalue (EIG) and singular value decomposition
(SVD) implementations may suffer from the lack of concurrency during the
tridiagonal and bidiagonal reductions, respectively. This performance
bottleneck is typical for the two-sided transformations due to the Level-2 BLAS
memory-bound calls. Therefore, the current state-of-the-art EIG and SVD
implementations may achieve only a small fraction of the system's sustained
peak performance. The QR-based Dynamically Weighted Halley (QDWH) algorithm may
be used as a pre-processing step toward the EIG and SVD solvers, while
mitigating the aforementioned bottleneck. QDWH-EIG and QDWH-SVD expose more
parallelism, while relying on compute-bound matrix operations. Both run closer
to the sustained peak performance of the system, but at the expense of
performing more FLOPS than the standard EIG and SVD algorithms. In this paper,
we introduce a new QDWH-based solver for computing the partial spectrum for EIG
(QDWHpartial-EIG) and SVD (QDWHpartial-SVD) problems. By optimizing the
rational function underlying the algorithms only in the desired part of the
spectrum, QDWHpartial-EIG and QDWHpartial-SVD algorithms efficiently compute a
fraction (say 1-20%) of the corresponding spectrum. We develop high-performance
implementations of QDWHpartial-EIG and QDWHpartial-SVD on distributed-memory
anymore systems and demonstrate their numerical robustness. Experimental
results using up to 36K MPI processes show performance speedups for
QDWHpartial-SVD up to 6X and 2X against PDGESVD from ScaLAPACK and KSVD,
respectively. QDWHpartial-EIG outperforms PDSYEVD from ScaLAPACK up to 3.5X but
remains slower compared to ELPA. QDWHpartial-EIG achieves, however, a better
occupancy of the underlying hardware by extracting higher sustained peak
performance than ELPA, which is critical moving forward with accelerator-based
supercomputers.
","['\nD. Keyes\n', '\nH. Ltaief\n', '\nY. Nakatsukasa\n', '\nD. Sukkari\n']",,,http://arxiv.org/abs/2104.14186v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA']",,,[]
"QDOT: Quantized Dot Product Kernel for Approximate High-Performance
  Computing",http://arxiv.org/abs/2105.00115v1,2021-04-30T22:41:17Z,2021-04-30T22:41:17Z,"  Approximate computing techniques have been successful in reducing computation
and power costs in several domains. However, error sensitive applications in
high-performance computing are unable to benefit from existing approximate
computing strategies that are not developed with guaranteed error bounds. While
approximate computing techniques can be developed for individual
high-performance computing applications by domain specialists, this often
requires additional theoretical analysis and potentially extensive software
modification. Hence, the development of low-level error-bounded approximate
computing strategies that can be introduced into any high-performance computing
application without requiring additional analysis or significant software
alterations is desirable. In this paper, we provide a contribution in this
direction by proposing a general framework for designing error-bounded
approximate computing strategies and apply it to the dot product kernel to
develop qdot -- an error-bounded approximate dot product kernel. Following the
introduction of qdot, we perform a theoretical analysis that yields a
deterministic bound on the relative approximation error introduced by qdot.
Empirical tests are performed to illustrate the tightness of the derived error
bound and to demonstrate the effectiveness of qdot on a synthetic dataset, as
well as two scientific benchmarks -- Conjugate Gradient (CG) and the Power
method. In particular, using qdot for the dot products in CG can result in a
majority of components being perforated or quantized to half precision without
increasing the iteration count required for convergence to the same solution as
CG using a double precision dot product.
","['\nJames Diffenderfer\n', '\nDaniel Osei-Kuffuor\n', '\nHarshitha Menon\n']",,,http://arxiv.org/abs/2105.00115v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models,http://arxiv.org/abs/2105.00385v2,2021-05-02T03:08:53Z,2021-05-29T04:20:30Z,"  Bayesian Knowledge Tracing, a model used for cognitive mastery estimation,
has been a hallmark of adaptive learning research and an integral component of
deployed intelligent tutoring systems (ITS). In this paper, we provide a brief
history of knowledge tracing model research and introduce pyBKT, an accessible
and computationally efficient library of model extensions from the literature.
The library provides data generation, fitting, prediction, and cross-validation
routines, as well as a simple to use data helper interface to ingest typical
tutor log dataset formats. We evaluate the runtime with various dataset sizes
and compare to past implementations. Additionally, we conduct sanity checks of
the model using experiments with simulated data to evaluate the accuracy of its
EM parameter learning and use real-world data to validate its predictions,
comparing pyBKT's supported model variants with results from the papers in
which they were originally introduced. The library is open source and open
license for the purpose of making knowledge tracing more accessible to
communities of research and practice and to facilitate progress in the field
through easier replication of past approaches.
","['\nAnirudhan Badrinath\n', '\nFrederic Wang\n', '\nZachary Pardos\n']",Accepted to the 2021 Conference on Educational Data Mining (EDM '21),,http://arxiv.org/abs/2105.00385v2,cs.MS,"['cs.MS', 'cs.AI', 'cs.CY', 'cs.LG']",,,[]
"Sphynx: a parallel multi-GPU graph partitioner for distributed-memory
  systems",http://arxiv.org/abs/2105.00578v1,2021-05-02T23:47:28Z,2021-05-02T23:47:28Z,"  Graph partitioning has been an important tool to partition the work among
several processors to minimize the communication cost and balance the workload.
While accelerator-based supercomputers are emerging to be the standard, the use
of graph partitioning becomes even more important as applications are rapidly
moving to these architectures. However, there is no distributed-memory
parallel, multi-GPU graph partitioner available for applications. We developed
a spectral graph partitioner, Sphynx, using the portable, accelerator-friendly
stack of the Trilinos framework. In Sphynx, we allow using different
preconditioners and exploit their unique advantages. We use Sphynx to
systematically evaluate the various algorithmic choices in spectral
partitioning with a focus on the GPU performance. We perform those evaluations
on two distinct classes of graphs: regular (such as meshes, matrices from
finite element methods) and irregular (such as social networks and web graphs),
and show that different settings and preconditioners are needed for these graph
classes. The experimental results on the Summit supercomputer show that Sphynx
is the fastest alternative on irregular graphs in an application-friendly
setting and obtains a partitioning quality close to ParMETIS on regular graphs.
When compared to nvGRAPH on a single GPU, Sphynx is faster and obtains better
balance and better quality partitions. Sphynx provides a good and robust
partitioning method across a wide range of graphs for applications looking for
a GPU-based partitioner.
","['\nSeher Acer\n', '\nErik G Boman\n', '\nChristian A Glusa\n', '\nSivasankaran Rajamanickam\n']",To appear in Parallel Computing,,http://arxiv.org/abs/2105.00578v1,cs.DC,"['cs.DC', 'cs.DM', 'cs.MS', '68W10']",,,[]
"Parallel implementation of a compatible high-order meshless method for
  the Stokes' equations",http://arxiv.org/abs/2104.14447v1,2021-04-29T16:06:13Z,2021-04-29T16:06:13Z,"  A parallel implementation of a compatible discretization scheme for
steady-state Stokes problems is presented in this work. The scheme uses
generalized moving least squares to generate differential operators and apply
boundary conditions. This meshless scheme allows a high-order convergence for
both the velocity and pressure, while also incorporates finite-difference-like
sparse discretization. Additionally, the method is inherently scalable: the
stencil generation process requires local inversion of matrices amenable to GPU
acceleration, and the divergence-free treatment of velocity replaces the
traditional saddle point structure of the global system with elliptic diagonal
blocks amenable to algebraic multigrid. The implementation in this work uses a
variety of Trilinos packages to exploit this local and global parallelism, and
benchmarks demonstrating high-order convergence and weak scalability are
provided.
","['\nQuang-Thinh Ha\n', '\nPaul A. Kuberry\n', '\nNathaniel A. Trask\n', '\nEmily M. Ryan\n']",,,http://arxiv.org/abs/2104.14447v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA', 'cs.PF', 'math.AP']",,,[]
A systematic review of Python packages for time series analysis,http://arxiv.org/abs/2104.07406v2,2021-04-15T12:09:54Z,2021-06-22T08:24:49Z,"  This paper presents a systematic review of Python packages with a focus on
time series analysis. The objective is to provide (1) an overview of the
different time series analysis tasks and preprocessing methods implemented, and
(2) an overview of the development characteristics of the packages (e.g.,
documentation, dependencies, and community size). This review is based on a
search of literature databases as well as GitHub repositories. Following the
filtering process, 40 packages were analyzed. We classified the packages
according to the analysis tasks implemented, the methods related to data
preparation, and the means for evaluating the results produced (methods and
access to evaluation data). We also reviewed documentation aspects, the
licenses, the size of the packages' community, and the dependencies used. Among
other things, our results show that forecasting is by far the most frequently
implemented task, that half of the packages provide access to real datasets or
allow generating synthetic data, and that many packages depend on a few
libraries (the most used ones being numpy, scipy and pandas). We hope that this
review can help practitioners and researchers navigate the space of Python
packages dedicated to time series analysis. We will provide an updated list of
the reviewed packages online at
https://siebert-julien.github.io/time-series-analysis-python/.
","['\nJulien Siebert\n', '\nJanek Groß\n', '\nChristof Schroth\n']","12 pages, 3 figures, 4 tables, accepted to ITISE2021",,http://arxiv.org/abs/2104.07406v2,cs.MS,"['cs.MS', '68-04', 'I.5.5']",,,[]
"Code generation for productive portable scalable finite element
  simulation in Firedrake",http://arxiv.org/abs/2104.08012v1,2021-04-16T10:14:54Z,2021-04-16T10:14:54Z,"  Creating scalable, high performance PDE-based simulations requires a suitable
combination of discretizations, differential operators, preconditioners and
solvers. The required combination changes with the application and with the
available hardware, yet software development time is a severely limited
resource for most scientists and engineers. Here we demonstrate that generating
simulation code from a high-level Python interface provides an effective
mechanism for creating high performance simulations from very few lines of user
code. We demonstrate that moving from one supercomputer to another can require
significant algorithmic changes to achieve scalable performance, but that the
code generation approach enables these algorithmic changes to be achieved with
minimal development effort.
","['\nJack D. Betteridge\n', '\nPatrick E. Farrell\n', '\nDavid A. Ham\n']",,,http://arxiv.org/abs/2104.08012v1,cs.MS,['cs.MS'],,,[]
PyArmadillo: a streamlined linear algebra library for Python,http://arxiv.org/abs/2104.11120v4,2021-04-22T15:13:33Z,2021-10-20T04:05:10Z,"  PyArmadillo is a linear algebra library for the Python language, with the aim
of closely mirroring the programming interface of the widely used Armadillo C++
library, which in turn is deliberately similar to Matlab. PyArmadillo hence
facilitates algorithm prototyping with Matlab-like syntax directly in Python,
and relatively straightforward conversion of PyArmadillo-based Python code into
performant Armadillo-based C++ code. The converted code can be used for
purposes such as speeding up Python-based programs in conjunction with
pybind11, or the integration of algorithms originally prototyped in Python into
larger C++ codebases. PyArmadillo provides objects for matrices and cubes, as
well as over 200 associated functions for manipulating data stored in the
objects. Integer, floating point and complex numbers are supported. Various
matrix factorisations are provided through integration with LAPACK, or one of
its high performance drop-in replacements such as Intel MKL or OpenBLAS.
PyArmadillo is open-source software, distributed under the Apache 2.0 license;
it can be obtained at https://pyarma.sourceforge.io or via the Python Package
Index in precompiled form.
","['\nJason Rumengan\n', '\nTerry Yue Zhuo\n', '\nConrad Sanderson\n']",,"Journal of Open Source Software, Vol. 66, No. 6, 2021",http://dx.doi.org/10.21105/joss.03051,cs.MS,"['cs.MS', '15-04, 62-04, 65-04, 68-04', 'G.4; D.3; D.2.3']",10.21105/joss.03051,,[]
NOMAD version 4: Nonlinear optimization with the MADS algorithm,http://arxiv.org/abs/2104.11627v2,2021-04-23T14:28:57Z,2021-05-04T01:13:51Z,"  NOMAD is software for optimizing blackbox problems. In continuous development
since 2001, it constantly evolved with the integration of new algorithmic
features published in scientific publications. These features are motivated by
real applications encountered by industrial partners. The latest major release
of NOMAD, version 3, dates from 2008. Minor releases are produced as new
features are incorporated. The present work describes NOMAD 4, a complete
redesign of the previous version, with a new architecture providing more
flexible code, added functionalities and reusable code. We introduce
algorithmic components, which are building blocks for more complex algorithms,
and can initiate other components, launch nested algorithms, or perform
specialized tasks. They facilitate the implementation of new ideas, including
the MegaSearchPoll component, warm and hot restarts, and a revised version of
the PSD-MADS algorithm. Another main improvement of NOMAD 4 is the usage of
parallelism, to simultaneously compute multiple blackbox evaluations, and to
maximize usage of available cores. Running different algorithms, tuning their
parameters, and comparing their performance for optimization is simpler than
before, while overall optimization performance is maintained between versions 3
and 4. NOMAD is freely available at www.gerad.ca/nomad and the whole project is
visible at github.com/bbopt/nomad.
","['\nCharles Audet\n', '\nSébastien Le Digabel\n', '\nViviane Rochon Montplaisir\n', '\nChristophe Tribes\n']",,,http://arxiv.org/abs/2104.11627v2,math.OC,"['math.OC', 'cs.MS']",,,[]
mlf-core: a framework for deterministic machine learning,http://arxiv.org/abs/2104.07651v2,2021-04-15T17:58:03Z,2022-06-16T09:09:55Z,"  Machine learning has shown extensive growth in recent years and is now
routinely applied to sensitive areas. To allow appropriate verification of
predictive models before deployment, models must be deterministic. However,
major machine learning libraries default to the usage of non-deterministic
algorithms based on atomic operations. Solely fixing all random seeds is not
sufficient for deterministic machine learning. To overcome this shortcoming,
various machine learning libraries released deterministic counterparts to the
non-deterministic algorithms. We evaluated the effect of these algorithms on
determinism and runtime. Based on these results, we formulated a set of
requirements for deterministic machine learning and developed a new software
solution, the mlf-core ecosystem, which aids machine learning projects to meet
and keep these requirements. We applied mlf-core to develop deterministic
models in various biomedical fields including a single cell autoencoder with
TensorFlow, a PyTorch-based U-Net model for liver-tumor segmentation in CT
scans, and a liver cancer classifier based on gene expression profiles with
XGBoost.
","['\nLukas Heumos\n', '\nPhilipp Ehmele\n', '\nLuis Kuhn Cuellar\n', '\nKevin Menden\n', '\nEdmund Miller\n', '\nSteffen Lemke\n', '\nGisela Gabernet\n', '\nSven Nahnsen\n']",https://mlf-core.com and https://github.com/mlf-core/mlf-core,,http://arxiv.org/abs/2104.07651v2,cs.MS,"['cs.MS', 'cs.LG', 'q-bio.QM', 'stat.ML']",,,[]
"Boosting Memory Access Locality of the Spectral Element Method with
  Hilbert Space-Filling Curves",http://arxiv.org/abs/2104.08416v1,2021-04-17T01:27:38Z,2021-04-17T01:27:38Z,"  We propose an algorithm based on Hilbert space-filling curves to reorder mesh
elements in memory for use with the Spectral Element Method, aiming to attain
fewer cache misses, better locality of data reference and faster execution. We
present a technique to numerically simulate acoustic wave propagation in 2D
domains using the Spectral Element Method, and discuss computational
performance aspects of this procedure. We reorder mesh-related data via Hilbert
curves to achieve sizable reductions in execution time under several mesh
configurations in shared-memory systems. Our experiments show that the Hilbert
curve approach works well with meshes of several granularities and also with
small and large variations in element sizes, achieving reductions between 9%
and 25% in execution time when compared to three other ordering schemes.
","['\nRoger R. F. Araújo\n', '\nLutz Gross\n', '\nSamuel Xavier-de-Souza\n']","23 pages, 12 figures",,http://dx.doi.org/10.1016/j.cageo.2021.104938,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF', '86-08 (Primary), 35Q68, 35Q86 (Secondary)', 'G.4; D.1.3']",10.1016/j.cageo.2021.104938,,[]
"RLIBM-32: High Performance Correctly Rounded Math Libraries for 32-bit
  Floating Point Representations",http://arxiv.org/abs/2104.04043v1,2021-04-08T20:37:17Z,2021-04-08T20:37:17Z,"  This paper proposes a set of techniques to develop correctly rounded math
libraries for 32-bit float and posit types. It enhances our RLibm approach that
frames the problem of generating correctly rounded libraries as a linear
programming problem in the context of 16-bit types to scale to 32-bit types.
Specifically, this paper proposes new algorithms to (1) generate polynomials
that produce correctly rounded outputs for all inputs using counterexample
guided polynomial generation, (2) generate efficient piecewise polynomials with
bit-pattern based domain splitting, and (3) deduce the amount of freedom
available to produce correct results when range reduction involves multiple
elementary functions. The resultant math library for the 32-bit float type is
faster than state-of-the-art math libraries while producing the correct output
for all inputs. We have also developed a set of correctly rounded elementary
functions for 32-bit posits.
","['\nJay P. Lim\n', '\nSantosh Nagarakatte\n']",23 pages,,http://arxiv.org/abs/2104.04043v1,cs.MS,['cs.MS'],,,[]
MIPROT: A Medical Image Processing Toolbox for MATLAB,http://arxiv.org/abs/2104.04771v1,2021-04-10T13:56:39Z,2021-04-10T13:56:39Z,"  This paper presents a Matlab toolbox to perform basic image processing and
visualization tasks, particularly designed for medical image processing. The
functionalities available are similar to basic functions found in other
non-Matlab widely used libraries such as the Insight Toolkit (ITK). The toolbox
is entirely written in native Matlab code, but is fast and flexible.
  Main use cases for the toolbox are illustrated here, including image
input/output, pre-processing, filtering, image registration and visualisation.
Both the code and sample data are made publicly available and open source.
",['\nAlberto Gomez\n'],,,http://arxiv.org/abs/2104.04771v1,cs.MS,"['cs.MS', '65-04']",,,[]
"Efficient algorithms for computing a rank-revealing UTV factorization on
  parallel computing architectures",http://arxiv.org/abs/2104.05782v1,2021-04-12T19:15:36Z,2021-04-12T19:15:36Z,"  The randomized singular value decomposition (RSVD) is by now a well
established technique for efficiently computing an approximate singular value
decomposition of a matrix. Building on the ideas that underpin the RSVD, the
recently proposed algorithm ""randUTV"" computes a FULL factorization of a given
matrix that provides low-rank approximations with near-optimal error. Because
the bulk of randUTV is cast in terms of communication-efficient operations like
matrix-matrix multiplication and unpivoted QR factorizations, it is faster than
competing rank-revealing factorization methods like column pivoted QR in most
high performance computational settings. In this article, optimized randUTV
implementations are presented for both shared memory and distributed memory
computing environments. For shared memory, randUTV is redesigned in terms of an
""algorithm-by-blocks"" that, together with a runtime task scheduler, eliminates
bottlenecks from data synchronization points to achieve acceleration over the
standard ""blocked algorithm"", based on a purely fork-join approach. The
distributed memory implementation is based on the ScaLAPACK library. The
performances of our new codes compare favorably with competing factorizations
available on both shared memory and distributed memory architectures.
","['\nN. Heavner\n', '\nF. D. Igual\n', '\nG. Quintana-Ortí\n', '\nP. G. Martinsson\n']",31 pages and 20 figures,,http://arxiv.org/abs/2104.05782v1,cs.MS,"['cs.MS', 'G.1.3; G.4; C.4; D.1.3; F.2.1']",,,[]
"LAGraph: Linear Algebra, Network Analysis Libraries, and the Study of
  Graph Algorithms",http://arxiv.org/abs/2104.01661v1,2021-04-04T18:49:58Z,2021-04-04T18:49:58Z,"  Graph algorithms can be expressed in terms of linear algebra. GraphBLAS is a
library of low-level building blocks for such algorithms that targets algorithm
developers. LAGraph builds on top of the GraphBLAS to target users of graph
algorithms with high-level algorithms common in network analysis. In this
paper, we describe the first release of the LAGraph library, the design
decisions behind the library, and performance using the GAP benchmark suite.
LAGraph, however, is much more than a library. It is also a project to document
and analyze the full range of algorithms enabled by the GraphBLAS. To that end,
we have developed a compact and intuitive notation for describing these
algorithms. In this paper, we present that notation with examples from the GAP
benchmark suite.
","['\nGábor Szárnyas\n', '\nDavid A. Bader\n', '\nTimothy A. Davis\n', '\nJames Kitchen\n', '\nTimothy G. Mattson\n', '\nScott McMillan\n', '\nErik Welch\n']",Accepted to GrAPL 2021,,http://arxiv.org/abs/2104.01661v1,cs.MS,"['cs.MS', 'cs.DS']",,,[]
"Parallelized Discrete Exterior Calculus for Three-Dimensional Elliptic
  Problems",http://arxiv.org/abs/2104.05999v1,2021-04-13T08:06:48Z,2021-04-13T08:06:48Z,"  A formulation of elliptic boundary value problems is used to develop the
first discrete exterior calculus (DEC) library for massively parallel
computations with 3D domains. This can be used for steady-state analysis of any
physical process driven by the gradient of a scalar quantity, e.g. temperature,
concentration, pressure or electric potential, and is easily extendable to
transient analysis. In addition to offering this library to the community, we
demonstrate one important benefit from the DEC formulation: effortless
introduction of strong heterogeneities and discontinuities. These are typical
for real materials, but challenging for widely used domain discretization
schemes, such as finite elements. Specifically, we demonstrate the efficiency
of the method for calculating the evolution of thermal conductivity of a solid
with a growing crack population. Future development of the library will deal
with transient problems, and more importantly with processes driven by
gradients of vector quantities.
","['\nPieter D. Boom\n', '\nAshley Seepujak\n', '\nOdysseas Kosmas\n', '\nLee Margetts\n', '\nAndrey Jivkov\n']",,,http://dx.doi.org/10.1016/j.cpc.2022.108456,cs.MS,"['cs.MS', 'physics.comp-ph']",10.1016/j.cpc.2022.108456,,[]
"Fitting Splines to Axonal Arbors Quantifies Relationship between Branch
  Order and Geometry",http://arxiv.org/abs/2104.01532v3,2021-04-04T03:38:42Z,2021-06-05T15:19:43Z,"  Neuromorphology is crucial to identifying neuronal subtypes and understanding
learning. It is also implicated in neurological disease. However, standard
morphological analysis focuses on macroscopic features such as branching
frequency and connectivity between regions, and often neglects the internal
geometry of neurons. In this work, we treat neuron trace points as a sampling
of differentiable curves and fit them with a set of branching B-splines. We
designed our representation with the Frenet-Serret formulas from differential
geometry in mind. The Frenet-Serret formulas completely characterize smooth
curves, and involve two parameters, curvature and torsion. Our representation
makes it possible to compute these parameters from neuron traces in closed
form. These parameters are defined continuously along the curve, in contrast to
other parameters like tortuosity which depend on start and end points. We
applied our method to a dataset of cortical projection neurons traced in two
mouse brains, and found that the parameters are distributed differently between
primary, collateral, and terminal axon branches, thus quantifying geometric
differences between different components of an axonal arbor. The results agreed
in both brains, further validating our representation. The code used in this
work can be readily applied to neuron traces in SWC format and is available in
our open-source Python package brainlit: http://brainlit.neurodata.io/.
","['\nThomas L. Athey\n', '\nJacopo Teneggi\n', '\nJoshua T. Vogelstein\n', '\nDaniel Tward\n', '\nUlrich Mueller\n', '\nMichael I. Miller\n']",,Front. Neuroinform. 15 (2021),http://dx.doi.org/10.3389/fninf.2021.704627,q-bio.NC,"['q-bio.NC', 'cs.MS', 'math.DG']",10.3389/fninf.2021.704627,,[]
AuTO: A Framework for Automatic differentiation in Topology Optimization,http://arxiv.org/abs/2104.01965v1,2021-04-05T15:36:17Z,2021-04-05T15:36:17Z,"  A critical step in topology optimization (TO) is finding sensitivities.
Manual derivation and implementation of the sensitivities can be quite
laborious and error-prone, especially for non-trivial objectives, constraints
and material models. An alternate approach is to utilize automatic
differentiation (AD). While AD has been around for decades, and has also been
applied in TO, wider adoption has largely been absent.
  In this educational paper, we aim to reintroduce AD for TO, and make it
easily accessible through illustrative codes. In particular, we employ JAX, a
high-performance Python library for automatically computing sensitivities from
a user defined TO problem. The resulting framework, referred to here as AuTO,
is illustrated through several examples in compliance minimization, compliant
mechanism design and microstructural design.
","['\nAaditya Chandrasekhar\n', '\nSaketh Sridhara\n', '\nKrishnan Suresh\n']",,,http://dx.doi.org/10.1007/s00158-021-03025-8,cs.MS,"['cs.MS', 'cs.CE', 'cs.NA', 'math.NA']",10.1007/s00158-021-03025-8,,[]
Hardware-Oriented Krylov Methods for High-Performance Computing,http://arxiv.org/abs/2104.02494v1,2021-04-06T13:25:22Z,2021-04-06T13:25:22Z,"  Krylov subspace methods are an essential building block in numerical
simulation software. The efficient utilization of modern hardware is a
challenging problem in the development of these methods. In this work, we
develop Krylov subspace methods to solve linear systems with multiple
right-hand sides, tailored to modern hardware in high-performance computing. To
this end, we analyze an innovative block Krylov subspace framework that allows
to balance the computational and data-transfer costs to the hardware. Based on
the framework, we formulate commonly used Krylov methods. For the CG and
BiCGStab methods, we introduce a novel stabilization approach as an alternative
to a deflation strategy. This helps us to retain the block size, thus leading
to a simpler and more efficient implementation. In addition, we optimize the
methods further for distributed memory systems and the communication overhead.
For the CG method, we analyze approaches to overlap the communication and
computation and present multiple variants of the CG method, which differ in
their communication properties. Furthermore, we present optimizations of the
orthogonalization procedure in the GMRes method. Beside introducing a pipelined
Gram-Schmidt variant that overlaps the global communication with the
computation of inner products, we present a novel orthonormalization method
based on the TSQR algorithm, which is communication-optimal and stable. For all
optimized method, we present tests that show their superiority in a distributed
setting.
",['\nNils-Arne Dreier\n'],PhD thesis (2020),,http://arxiv.org/abs/2104.02494v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA']",,,[]
The landscape of software for tensor computations,http://arxiv.org/abs/2103.13756v3,2021-03-25T11:13:27Z,2022-06-29T10:33:18Z,"  Tensors (also commonly seen as multi-linear operators or as multi-dimensional
arrays) are ubiquitous in scientific computing and in data science, and so are
the software efforts for tensor operations. Particularly in recent years, we
have observed an explosion in libraries, compilers, packages, and toolboxes;
unfortunately these efforts are very much scattered among the different
scientific domains, and inevitably suffer from replication, suboptimal
implementations, and in many cases, limited visibility. As a first step towards
countering these inefficiencies, here we survey and loosely classify software
packages related to tensor computations. Our aim is to assemble a comprehensive
and up-to-date snapshot of the tensor software landscape, with the intention of
helping both users and developers. Aware of the difficulties inherent in any
multi-discipline survey, we very much welcome the reader's help in amending and
expanding our software list, which currently features 80 projects.
","['\nChristos Psarras\nRWTH Aachen University\n', '\nLars Karlsson\nUmeå University\n', '\nJiajia Li\nPacific Northwest National Laboratory\nCollege of William and Mary\n', '\nPaolo Bientinesi\nUmeå University\n']",,,http://arxiv.org/abs/2103.13756v3,cs.MS,['cs.MS'],,,"['RWTH Aachen University', 'Umeå University', 'Pacific Northwest National Laboratory', 'College of William and Mary', 'Umeå University']"
"TensorDiffEq: Scalable Multi-GPU Forward and Inverse Solvers for Physics
  Informed Neural Networks",http://arxiv.org/abs/2103.16034v1,2021-03-30T02:41:40Z,2021-03-30T02:41:40Z,"  Physics-Informed Neural Networks promise to revolutionize science and
engineering practice, by introducing domain-aware deep machine learning models
into scientific computation. Several software suites have emerged to make the
implementation and usage of these architectures available to the research and
industry communities. Here we introduce\linebreak TensorDiffEq, built on
Tensorflow 2.x, which presents an intuitive Keras-like interface for problem
domain definition, model definition, and solution of forward and inverse
problems using physics-aware deep learning methods. TensorDiffEq takes full
advantage of Tensorflow 2.x infrastructure for deployment on multiple GPUs,
allowing the implementation of large high-dimensional and complex models.
Simultaneously, TensorDiffEq supports the Keras API for custom neural network
architecture definitions. In the case of smaller or simpler models, the package
allows for rapid deployment on smaller-scale CPU platforms with negligible
changes to the implementation scripts. We demonstrate the basic usage and
capabilities of TensorDiffEq in solving forward, inverse, and data assimilation
problems of varying sizes and levels of complexity. The source code is
available at https://github.com/tensordiffeq.
","['\nLevi D. McClenny\n', '\nMulugeta A. Haile\n', '\nUlisses M. Braga-Neto\n']","Source Code: https://github.com/tensordiffeq/TensorDiffEq,
  Documentation: https://docs.tensordiffeq.io",,http://arxiv.org/abs/2103.16034v1,cs.MS,"['cs.MS', 'physics.comp-ph']",,,[]
"Optimizer Fusion: Efficient Training with Better Locality and
  Parallelism",http://arxiv.org/abs/2104.00237v1,2021-04-01T03:44:13Z,2021-04-01T03:44:13Z,"  Machine learning frameworks adopt iterative optimizers to train neural
networks. Conventional eager execution separates the updating of trainable
parameters from forward and backward computations. However, this approach
introduces nontrivial training time overhead due to the lack of data locality
and computation parallelism. In this work, we propose to fuse the optimizer
with forward or backward computation to better leverage locality and
parallelism during training. By reordering the forward computation, gradient
calculation, and parameter updating, our proposed method improves the
efficiency of iterative optimizers. Experimental results demonstrate that we
can achieve an up to 20% training time reduction on various configurations.
Since our methods do not alter the optimizer algorithm, they can be used as a
general ""plug-in"" technique to the training process.
","['\nZixuan Jiang\n', '\nJiaqi Gu\n', '\nMingjie Liu\n', '\nKeren Zhu\n', '\nDavid Z. Pan\n']","It is published as a paper at the Hardware Aware Efficient Training
  (HAET) workshop of ICLR 2021. There are 4 pages excluding references and
  appendices",,http://arxiv.org/abs/2104.00237v1,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"fairmodels: A Flexible Tool For Bias Detection, Visualization, And
  Mitigation",http://arxiv.org/abs/2104.00507v2,2021-04-01T15:06:13Z,2022-02-11T20:36:16Z,"  Machine learning decision systems are getting omnipresent in our lives. From
dating apps to rating loan seekers, algorithms affect both our well-being and
future. Typically, however, these systems are not infallible. Moreover, complex
predictive models are really eager to learn social biases present in historical
data that can lead to increasing discrimination. If we want to create models
responsibly then we need tools for in-depth validation of models also from the
perspective of potential discrimination. This article introduces an R package
fairmodels that helps to validate fairness and eliminate bias in classification
models in an easy and flexible fashion. The fairmodels package offers a
model-agnostic approach to bias detection, visualization and mitigation. The
implemented set of functions and fairness metrics enables model fairness
validation from different perspectives. The package includes a series of
methods for bias mitigation that aim to diminish the discrimination in the
model. The package is designed not only to examine a single model, but also to
facilitate comparisons between multiple models.
","['\nJakub Wiśniewski\n', '\nPrzemysław Biecek\n']","15 pages, 9 figures",,http://arxiv.org/abs/2104.00507v2,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS', 'stat.AP']",,,[]
"Two-Stage Gauss--Seidel Preconditioners and Smoothers for Krylov Solvers
  on a GPU cluster",http://arxiv.org/abs/2104.01196v2,2021-04-02T18:49:32Z,2021-04-24T14:09:09Z,"  Gauss-Seidel (GS) relaxation is often employed as a preconditioner for a
Krylov solver or as a smoother for Algebraic Multigrid (AMG). However, the
requisite sparse triangular solve is difficult to parallelize on many-core
architectures such as graphics processing units (GPUs). In the present study,
the performance of the traditional GS relaxation based on a triangular solve is
compared with two-stage variants, replacing the direct triangular solve with a
fixed number of inner Jacobi-Richardson (JR) iterations. When a small number of
inner iterations is sufficient to maintain the Krylov convergence rate, the
two-stage GS (GS2) often outperforms the traditional algorithm on many-core
architectures. We also compare GS2 with JR. When they perform the same number
of flops for SpMV (e.g. three JR sweeps compared to two GS sweeps with one
inner JR sweep), the GS2 iterations, and the Krylov solver preconditioned with
GS2, may converge faster than the JR iterations. Moreover, for some problems
(e.g. elasticity), it was found that JR may diverge with a damping factor of
one, whereas two-stage GS may improve the convergence with more inner
iterations. Finally, to study the performance of the two-stage smoother and
preconditioner for a practical problem, %(e.g. using tuned damping factors),
these were applied to incompressible fluid flow simulations on GPUs.
","['\nLuc Berger-Vergiat\n', '\nBrian Kelley\n', '\nSivasankaran Rajamanickam\n', '\nJonathan Hu\n', '\nKatarzyna Swirydowicz\n', '\nPaul Mullowney\n', '\nStephen Thomas\n', '\nIchitaro Yamazaki\n']",,,http://arxiv.org/abs/2104.01196v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
The Two-Dimensional Swept Rule Applied on Heterogeneous Architectures,http://arxiv.org/abs/2105.10332v1,2021-04-01T20:06:09Z,2021-04-01T20:06:09Z,"  The partial differential equations describing compressible fluid flows can be
notoriously difficult to resolve on a pragmatic scale and often require the use
of high performance computing systems and/or accelerators. However, these
systems face scaling issues such as latency, the fixed cost of communicating
information between devices in the system. The swept rule is a technique
designed to minimize these costs by obtaining a solution to unsteady equations
at as many possible spatial locations and times prior to communicating. In this
study, we implemented and tested the swept rule for solving two-dimensional
problems on heterogeneous computing systems across two distinct systems. Our
solver showed a speedup range of 0.22-2.71 for the heat diffusion equation and
0.52-1.46 for the compressible Euler equations. We can conclude from this study
that the swept rule offers both potential for speedups and slowdowns and that
care should be taken when designing such a solver to maximize benefits. These
results can help make decisions to maximize these benefits and inform designs.
","['\nAnthony S. Walker\n', '\nKyle E. Niemeyer\n']","18 pages, 11 figures",,http://arxiv.org/abs/2105.10332v1,cs.DC,"['cs.DC', 'cs.MS', 'physics.comp-ph']",,,[]
"Automatic differentiation for Riemannian optimization on low-rank matrix
  and tensor-train manifolds",http://arxiv.org/abs/2103.14974v2,2021-03-27T19:56:00Z,2021-10-23T11:27:47Z,"  In scientific computing and machine learning applications, matrices and more
general multidimensional arrays (tensors) can often be approximated with the
help of low-rank decompositions. Since matrices and tensors of fixed rank form
smooth Riemannian manifolds, one of the popular tools for finding low-rank
approximations is to use Riemannian optimization. Nevertheless, efficient
implementation of Riemannian gradients and Hessians, required in Riemannian
optimization algorithms, can be a nontrivial task in practice. Moreover, in
some cases, analytic formulas are not even available. In this paper, we build
upon automatic differentiation and propose a method that, given an
implementation of the function to be minimized, efficiently computes Riemannian
gradients and matrix-by-vector products between an approximate Riemannian
Hessian and a given vector.
","['\nAlexander Novikov\n', '\nMaxim Rakhuba\n', '\nIvan Oseledets\n']",,,http://arxiv.org/abs/2103.14974v2,math.OC,"['math.OC', 'cs.LG', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
Mathematics of Digital Hyperspace,http://arxiv.org/abs/2103.15203v1,2021-03-28T19:11:28Z,2021-03-28T19:11:28Z,"  Social media, e-commerce, streaming video, e-mail, cloud documents, web
pages, traffic flows, and network packets fill vast digital lakes, rivers, and
oceans that we each navigate daily. This digital hyperspace is an amorphous
flow of data supported by continuous streams that stretch standard concepts of
type and dimension. The unstructured data of digital hyperspace can be
elegantly represented, traversed, and transformed via the mathematics of
hypergraphs, hypersparse matrices, and associative array algebra. This paper
explores a novel mathematical concept, the semilink, that combines pairs of
semirings to provide the essential operations for graph analytics, database
operations, and machine learning. The GraphBLAS standard currently supports
hypergraphs, hypersparse matrices, the mathematics required for semilinks, and
seamlessly performs graph, network, and matrix operations. With the addition of
key based indices (such as pointers to strings) and semilinks, GraphBLAS can
become a richer associative array algebra and be a plug-in replacement for
spreadsheets, database tables, and data centric operating systems, enhancing
the navigation of unstructured data found in digital hyperspace.
","['\nJeremy Kepner\n', '\nTimothy Davis\n', '\nVijay Gadepally\n', '\nHayden Jananthan\n', '\nLauren Milechin\n']","9 pages, 8 figures, 2 tables, accepted to GrAPL 2021. arXiv admin
  note: text overlap with arXiv:1807.03165, arXiv:2004.01181, arXiv:1909.05631,
  arXiv:1708.02937",,http://dx.doi.org/10.1109/IPDPSW52791.2021.00048,cs.MS,"['cs.MS', 'cs.DB', 'cs.DM', 'cs.NE', 'math.RA']",10.1109/IPDPSW52791.2021.00048,,[]
"An open-source ABAQUS implementation of the scaled boundary finite
  element method to study interfacial problems using polyhedral meshes",http://arxiv.org/abs/2103.09663v1,2021-03-16T03:19:41Z,2021-03-16T03:19:41Z,"  The scaled boundary finite element method (SBFEM) is capable of generating
polyhedral elements with an arbitrary number of surfaces. This salient feature
significantly alleviates the meshing burden being a bottleneck in the analysis
pipeline in the standard finite element method (FEM). In this paper, we
implement polyhedral elements based on the SBFEM into the commercial finite
element software ABAQUS. To this end, user elements are provided through the
user subroutine UEL. Detailed explanations regarding the data structures and
implementational aspects of the procedures are given. The focus of the current
implementation is on interfacial problems and therefore, element-based surfaces
are created on polyhedral user elements to establish interactions. This is
achieved by an overlay of standard finite elements with negligible stiffness,
provided in the ABAQUS element library, with polyhedral user elements. By means
of several numerical examples, the advantages of polyhedral elements regarding
the treatment of non-matching interfaces and automatic mesh generation are
clearly demonstrated. Thus, the performance of ABAQUS for problems involving
interfaces is augmented based on the availability of polyhedral meshes. Due to
the implementation of polyhedral user elements, ABAQUS can directly handle
complex geometries given in the form of digital images or stereolithography
(STL) files. In order to facilitate the use of the proposed approach, the code
of the UEL is published open-source and can be downloaded from
https://github.com/ShukaiYa/SBFEM-UEL.
","['\nShukai Ya\n', '\nSascha Eisenträger\n', '\nChongmin Song\n', '\nJianbo Li\n']","34 pages, 34 figures",,http://dx.doi.org/10.1016/j.cma.2021.113766,cs.MS,['cs.MS'],10.1016/j.cma.2021.113766,,[]
FEniCS-preCICE: Coupling FEniCS to other Simulation Software,http://arxiv.org/abs/2103.11191v2,2021-03-20T14:51:46Z,2021-03-23T10:58:39Z,"  The new software FEniCS-preCICE is a middle software layer, sitting in
between the existing finite-element library FEniCS and the coupling library
preCICE. The middle layer simplifies coupling (existing) FEniCS application
codes to other simulation software via preCICE. To this end, FEniCS-preCICE
converts between FEniCS and preCICE mesh and data structures, provides
easy-to-use coupling conditions, and manages data checkpointing for implicit
coupling. The new software is a library itself and follows a FEniCS-native
style. Only a few lines of additional code are necessary to prepare a FEniCS
application code for coupling. We illustrate the functionality of
FEniCS-preCICE by two examples: a FEniCS heat conduction code coupled to
OpenFOAM and a FEniCS linear elasticity code coupled to SU2. The results of
both scenarios are compared with other simulation software showing good
agreement.
","['\nBenjamin Rodenberg\n', '\nIshaan Desai\n', '\nRichard Hertrich\n', '\nAlexander Jaust\n', '\nBenjamin Uekermann\n']","submitted to SoftwareX, fixed layout of Fig. 3 & 4, updated reference
  to code examples to https://github.com/precice/tutorials/tree/a166efa",,http://arxiv.org/abs/2103.11191v2,cs.MS,['cs.MS'],,,[]
"Kokkos Kernels: Performance Portable Sparse/Dense Linear Algebra and
  Graph Kernels",http://arxiv.org/abs/2103.11991v1,2021-03-22T16:36:12Z,2021-03-22T16:36:12Z,"  As hardware architectures are evolving in the push towards exascale,
developing Computational Science and Engineering (CSE) applications depend on
performance portable approaches for sustainable software development. This
paper describes one aspect of performance portability with respect to
developing a portable library of kernels that serve the needs of several CSE
applications and software frameworks. We describe Kokkos Kernels, a library of
kernels for sparse linear algebra, dense linear algebra and graph kernels. We
describe the design principles of such a library and demonstrate portable
performance of the library using some selected kernels. Specifically, we
demonstrate the performance of four sparse kernels, three dense batched
kernels, two graph kernels and one team level algorithm.
","['\nSivasankaran Rajamanickam\n', '\nSeher Acer\n', '\nLuc Berger-Vergiat\n', '\nVinh Dang\n', '\nNathan Ellingwood\n', '\nEvan Harvey\n', '\nBrian Kelley\n', '\nChristian R. Trott\n', '\nJeremiah Wilke\n', '\nIchitaro Yamazaki\n']",,,http://arxiv.org/abs/2103.11991v1,cs.MS,['cs.MS'],,,[]
"Understanding performance variability in standard and pipelined parallel
  Krylov solvers",http://arxiv.org/abs/2103.12067v1,2021-03-21T16:27:51Z,2021-03-21T16:27:51Z,"  In this work, we collect data from runs of Krylov subspace methods and
pipelined Krylov algorithms in an effort to understand and model the impact of
machine noise and other sources of variability on performance. We find large
variability of Krylov iterations between compute nodes for standard methods
that is reduced in pipelined algorithms, directly supporting conjecture, as
well as large variation between statistical distributions of runtimes across
iterations. Based on these results, we improve upon a previously introduced
nondeterministic performance model by allowing iterations to fluctuate over
time. We present our data from runs of various Krylov algorithms across
multiple platforms as well as our updated non-stationary model that provides
good agreement with observations. We also suggest how it can be used as a
predictive tool.
","['\nHannah Morgan\n', '\nPatrick Sanan\n', '\nMatthew G. Knepley\n', '\nRichard Tran Mills\n']","18 pages, 12 figures","IJHPCA, 35(1), 2020",http://dx.doi.org/10.1177/1094342020966835,cs.MS,['cs.MS'],10.1177/1094342020966835,,[]
"SymPKF: a symbolic and computational toolbox for the design of
  parametric Kalman filter dynamics",http://arxiv.org/abs/2103.09226v2,2021-03-16T17:56:13Z,2021-03-21T07:27:44Z,"  Recent researches in data assimilation lead to the introduction of the
parametric Kalman filter (PKF): an implementation of the Kalman filter, where
the covariance matrices are approximated by a parameterized covariance model.
In the PKF, the dynamics of the covariance during the forecast step relies on
the prediction of the covariance parameters. Hence, the design of the parameter
dynamics is crucial while it can be tedious to do this by hand. This
contribution introduces a python package, SymPKF, able to compute PKF dynamics
for univariate statistics and when the covariance model is parameterized from
the variance and the local anisotropy of the correlations. The ability of
SymPKF to produce the PKF dynamics is shown on a non-linear diffusive advection
(Burgers equation) over a 1D domain and the linear advection over a 2D domain.
The computation of the PKF dynamics is performed at a symbolic level, but an
automatic code generator is also introduced to perform numerical simulations. A
final multivariate example illustrates the potential of SymPKF to go beyond the
univariate case.
","['\nOlivier Pannekoucke\n', '\nPhilippe Arbogast\n']",,,http://arxiv.org/abs/2103.09226v2,physics.data-an,"['physics.data-an', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
Hessian Chain Bracketing,http://arxiv.org/abs/2103.09480v2,2021-03-17T07:25:24Z,2021-10-26T07:54:41Z,"  Second derivatives of mathematical models for real-world phenomena are
fundamental ingredients of a wide range of numerical simulation methods
including parameter sensitivity analysis, uncertainty quantification, nonlinear
optimization and model calibration. The evaluation of such Hessians often
dominates the overall computational effort. The combinatorial {\sc Hessian
Accumulation} problem aiming to minimize the number of floating-point
operations required for the computation of a Hessian turns out to be
NP-complete. We propose a dynamic programming formulation for the solution of
{\sc Hessian Accumulation} over a sub-search space. This approach yields
improvements by factors of ten and higher over the state of the art based on
second-order tangent and adjoint algorithmic differentiation.
","['\nUwe Naumann\n', '\nShubhaditya Burela\n']",,,http://arxiv.org/abs/2103.09480v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Porting a sparse linear algebra math library to Intel GPUs,http://arxiv.org/abs/2103.10116v1,2021-03-18T09:44:17Z,2021-03-18T09:44:17Z,"  With the announcement that the Aurora Supercomputer will be composed of
general purpose Intel CPUs complemented by discrete high performance Intel
GPUs, and the deployment of the oneAPI ecosystem, Intel has committed to enter
the arena of discrete high performance GPUs. A central requirement for the
scientific computing community is the availability of production-ready software
stacks and a glimpse of the performance they can expect to see on Intel high
performance GPUs. In this paper, we present the first platform-portable open
source math library supporting Intel GPUs via the DPC++ programming
environment. We also benchmark some of the developed sparse linear algebra
functionality on different Intel GPUs to assess the efficiency of the DPC++
programming ecosystem to translate raw performance into application
performance. Aside from quantifying the efficiency within the hardware-specific
roofline model, we also compare against routines providing the same
functionality that ship with Intel's oneMKL vendor library.
","['\nYuhsiang M. Tsai\n', '\nTerry Cojean\n', '\nHartwig Anzt\n']","preprint, not submitted",,http://arxiv.org/abs/2103.10116v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
Non-invasive multigrid for semi-structured grids,http://arxiv.org/abs/2103.11962v1,2021-03-22T16:06:32Z,2021-03-22T16:06:32Z,"  Multigrid solvers for hierarchical hybrid grids (HHG) have been proposed to
promote the efficient utilization of high performance computer architectures.
These HHG meshes are constructed by uniformly refining a relatively coarse
fully unstructured mesh. While HHG meshes provide some flexibility for
unstructured applications, most multigrid calculations can be accomplished
using efficient structured grid ideas and kernels. This paper focuses on
generalizing the HHG idea so that it is applicable to a broader community of
computational scientists, and so that it is easier for existing applications to
leverage structured multigrid components. Specifically, we adapt the structured
multigrid methodology to significantly more complex semi-structured meshes.
Further, we illustrate how mature applications might adopt a semi-structured
solver in a relatively non-invasive fashion. To do this, we propose a formal
mathematical framework for describing the semi-structured solver. This
formalism allows us to precisely define the associated multigrid method and to
show its relationship to a more traditional multigrid solver. Additionally, the
mathematical framework clarifies the associated software design and
implementation. Numerical experiments highlight the relationship of the new
solver with classical multigrid. We also demonstrate the generality and
potential performance gains associated with this type of semi-structured
multigrid.
","['\nMatthias Mayr\n', '\nLuc Berger-Vergiat\n', '\nPeter Ohm\n', '\nRaymond S. Tuminaro\n']",,,http://dx.doi.org/10.1137/20M1375413,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1137/20M1375413,,[]
"A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra
  Computation",http://arxiv.org/abs/2103.11615v2,2021-03-22T06:54:32Z,2021-07-05T03:21:00Z,"  We propose a functional implementation of \emph{Multivariate Tower Automatic
Differentiation}. Our implementation is intended to be used in implementing
$C^\infty$-structure computation of an arbitrary Weil algebra, which we
discussed in the previous work.
",['\nHiromi Ishii\n'],,"Computer Algebra - Theory and its Applications,RIMS K\^oky\^uroku,
  No.2185 (2021). pp.104-112",http://arxiv.org/abs/2103.11615v2,cs.SC,"['cs.SC', 'cs.MS', 'cs.NA', 'math.DG', 'math.NA']",,,[]
"Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs
  -- A MAPLE Package",http://arxiv.org/abs/2103.03646v1,2021-03-05T13:20:47Z,2021-03-05T13:20:47Z,"  There exist several methods for computing exact solutions of algebraic
differential equations. Most of the methods, however, do not ensure existence
and uniqueness of the solutions and might fail after several steps, or are
restricted to linear equations. The authors have presented in previous works a
method to overcome this problem for autonomous first order algebraic ordinary
differential equations and formal Puiseux series solutions and algebraic
solutions. In the first case, all solutions can uniquely be represented by a
sufficiently large truncation and in the latter case by its minimal polynomial.
The main contribution of this paper is the implementation, in a MAPLE-package
named FirstOrderSolve, of the algorithmic ideas presented therein. More
precisely, all formal Puiseux series and algebraic solutions, including the
generic and singular solutions, are computed and described uniquely. The
computation strategy is to reduce the given differential equation to a simpler
one by using local parametrizations and the already known degree bounds.
","['\nFrancois Boulier\n', '\nJose Cano\n', '\nSebastian Falkensteiner\n', '\nRafael Sendra\n']",,,http://arxiv.org/abs/2103.03646v1,cs.MS,"['cs.MS', 'cs.SC', '34-04']",,,[]
Machine Learning using Stata/Python,http://arxiv.org/abs/2103.03122v1,2021-03-03T10:31:44Z,2021-03-03T10:31:44Z,"  We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting
popular Machine Learning (ML) methods both in regression and classification
settings. Using the recent Stata/Python integration platform (sfi) of Stata 16,
these commands provide hyper-parameters' optimal tuning via K-fold
cross-validation using greed search. More specifically, they make use of the
Python Scikit-learn API to carry out both cross-validation and outcome/label
prediction.
",['\nGiovanni Cerulli\n'],"Keywords: Machine Learning, Stata, Python, Optimal tuning",,http://arxiv.org/abs/2103.03122v1,stat.CO,"['stat.CO', 'cs.LG', 'cs.MS']",,,[]
"Quasi-structured quadrilateral meshing in Gmsh -- a robust pipeline for
  complex CAD models",http://arxiv.org/abs/2103.04652v1,2021-03-08T10:23:55Z,2021-03-08T10:23:55Z,"  We propose an end-to-end pipeline to robustly generate high-quality
quadrilateral meshes for complex CAD models. An initial quad-dominant mesh is
generated with frontal point insertion guided by a locally integrable cross
field and a scalar size map adapted to the small CAD features. After triangle
combination and midpoint-subdivision into an all-quadrilateral mesh, the
topology of the mesh is modified to reduce the number of irregular vertices.
The idea is to preserve the irregular vertices matching cross-field
singularities and to eliminate the others. The topological modifications are
either local and based on disk quadrangulations, or more global with the
remeshing of patches of quads according to predefined patterns. Validity of the
quad mesh is guaranteed by monitoring element quality during all operations and
reverting the changes when necessary. Advantages of our approach include
robustness, strict respect of the CAD features and support for user-prescribed
size constraints. The quad mesher, which is available in Gmsh, is validated and
illustrated on two datasets of CAD models.
","['\nMaxence Reberol\n', '\nChristos Georgiadis\n', '\nJean-François Remacle\n']","33 pages, 10 figures, supplemental at
  https://www.hextreme.eu/data/quadqs2021_supplemental.pdf",,http://arxiv.org/abs/2103.04652v1,cs.CE,"['cs.CE', 'cs.CG', 'cs.MS']",,,[]
"ModelingToolkit: A Composable Graph Transformation System For
  Equation-Based Modeling",http://arxiv.org/abs/2103.05244v3,2021-03-09T06:31:24Z,2022-02-09T10:49:22Z,"  Getting good performance out of numerical equation solvers requires that the
user has provided stable and efficient functions representing their model.
However, users should not be trusted to write good code. In this manuscript we
describe ModelingToolkit (MTK), a symbolic equation-based modeling system which
allows for composable transformations to generate stable, efficient, and
parallelized model implementations. MTK blurs the lines of traditional symbolic
computing by acting directly on a user's numerical code. We show the ability to
apply graph algorithms for automatically parallelizing and performing index
reduction on code written for differential-algebraic equation (DAE) solvers,
""fixing"" the performance and stability of the model without requiring any
changes to on the user's part. We demonstrate how composable model
transformations can be combined with automated data-driven surrogate generation
techniques, allowing machine learning methods to generate accelerated
approximate models within an acausal modeling framework. These reduced models
are shown to outperform the Dymola Modelica compiler on an HVAC model by 590x
at 3\% error. Together, this demonstrates MTK as a system for bringing the
latest research in graph transformations directly to modeling applications.
","['\nYingbo Ma\n', '\nShashi Gowda\n', '\nRanjan Anantharaman\n', '\nChris Laughman\n', '\nViral Shah\n', '\nChris Rackauckas\n']","10 pages, 3 figures, 1 table",,http://arxiv.org/abs/2103.05244v3,cs.MS,"['cs.MS', 'cs.SC', 'cs.SE']",,,[]
Exploiting Asynchronous Priority Scheduling in Parallel Eikonal Solvers,http://arxiv.org/abs/2103.05694v1,2021-03-09T19:58:10Z,2021-03-09T19:58:10Z,"  Numerical solutions to the Eikonal equation are computed using variants of
the fast marching method, the fast sweeping method, and the fast iterative
method. In this paper, we provide a unified view of these algorithms that
highlights their similarities and suggests a wider class of Eikonal solvers. We
then use this framework to justify applying concurrent priority scheduling
techniques to Eikonal solvers. We demonstrate that doing so results in good
parallel performance for a problem from seismology. We explain why existing
Eikonal solvers may produce different results despite using the same
differencing scheme and demonstrate techniques to address these discrepancies.
These techniques allow us to obtain deterministic output from our asynchronous
fine-grained parallel Eikonal solver.
","['\nIan Henriksen\n', '\nBozhi You\n', '\nKeshav Pingali\n']",,,http://arxiv.org/abs/2103.05694v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"GraphMineSuite: Enabling High-Performance and Programmable Graph Mining
  Algorithms with Set Algebra",http://arxiv.org/abs/2103.03653v1,2021-03-05T13:26:18Z,2021-03-05T13:26:18Z,"  We propose GraphMineSuite (GMS): the first benchmarking suite for graph
mining that facilitates evaluating and constructing high-performance graph
mining algorithms. First, GMS comes with a benchmark specification based on
extensive literature review, prescribing representative problems, algorithms,
and datasets. Second, GMS offers a carefully designed software platform for
seamless testing of different fine-grained elements of graph mining algorithms,
such as graph representations or algorithm subroutines. The platform includes
parallel implementations of more than 40 considered baselines, and it
facilitates developing complex and fast mining algorithms. High modularity is
possible by harnessing set algebra operations such as set intersection and
difference, which enables breaking complex graph mining algorithms into simple
building blocks that can be separately experimented with. GMS is supported with
a broad concurrency analysis for portability in performance insights, and a
novel performance metric to assess the throughput of graph mining algorithms,
enabling more insightful evaluation. As use cases, we harness GMS to rapidly
redesign and accelerate state-of-the-art baselines of core graph mining
problems: degeneracy reordering (by up to >2x), maximal clique listing (by up
to >9x), k-clique listing (by 1.1x), and subgraph isomorphism (by up to 2.5x),
also obtaining better theoretical performance bounds.
","['\nMaciej Besta\n', '\nZur Vonarburg-Shmaria\n', '\nYannick Schaffner\n', '\nLeonardo Schwarz\n', '\nGrzegorz Kwasniewski\n', '\nLukas Gianinazzi\n', '\nJakub Beranek\n', '\nKacper Janda\n', '\nTobias Holenstein\n', '\nSebastian Leisinger\n', '\nPeter Tatkowski\n', '\nEsref Ozdemir\n', '\nAdrian Balla\n', '\nMarcin Copik\n', '\nPhilipp Lindenberger\n', '\nPavel Kalvoda\n', '\nMarek Konieczny\n', '\nOnur Mutlu\n', '\nTorsten Hoefler\n']",,"International Conference on Very Large Data Bases (VLDB), 2021",http://arxiv.org/abs/2103.03653v1,cs.DC,"['cs.DC', 'cs.CV', 'cs.DS', 'cs.MS', 'cs.PF']",,,[]
Event-Based Automatic Differentiation of OpenMP with OpDiLib,http://arxiv.org/abs/2102.11572v3,2021-02-23T09:22:04Z,2022-06-30T15:32:11Z,"  We present the new software OpDiLib, a universal add-on for classical
operator overloading AD tools that enables the automatic differentiation (AD)
of OpenMP parallelized code. With it, we establish support for OpenMP features
in a reverse mode operator overloading AD tool to an extent that was previously
only reported on in source transformation tools. We achieve this with an
event-based implementation ansatz that is unprecedented in AD. Combined with
modern OpenMP features around OMPT, we demonstrate how it can be used to
achieve differentiation without any additional modifications of the source
code; neither do we impose a priori restrictions on the data access patterns,
which makes OpDiLib highly applicable. For further performance optimizations,
restrictions like atomic updates on adjoint variables can be lifted in a
fine-grained manner. OpDiLib can also be applied in a semi-automatic fashion
via a macro interface, which supports compilers that do not implement OMPT. We
demonstrate the applicability of OpDiLib for a pure operator overloading
approach in a hybrid parallel environment. We quantify the cost of atomic
updates on adjoint variables and showcase the speedup and scaling that can be
achieved with the different configurations of OpDiLib in both the forward and
the reverse pass.
","['\nJohannes Blühdorn\n', '\nMax Sagebaum\n', '\nNicolas R. Gauger\n']","31 pages, 13 figures, 3 tables, 13 listings; new layout, additional
  references, refocused Section 3 (former Section 4), extended performance
  tests, overall polishing and shortening",,http://dx.doi.org/10.1145/3570159,cs.MS,"['cs.MS', 'D.1.3; D.2.13; G.1.4; G.4']",10.1145/3570159,,[]
"Semi-analytic integration for a parallel space-time boundary element
  method modeling the heat equation",http://arxiv.org/abs/2102.09811v2,2021-02-19T08:54:43Z,2021-10-25T07:16:14Z,"  The presented paper concentrates on the boundary element method (BEM) for the
heat equation in three spatial dimensions. In particular, we deal with tensor
product space-time meshes allowing for quadrature schemes analytic in time and
numerical in space. The spatial integrals can be treated by standard BEM
techniques known from three dimensional stationary problems. The contribution
of the paper is twofold. First, we provide temporal antiderivatives of the heat
kernel necessary for the assembly of BEM matrices and the evaluation of the
representation formula. Secondly, the presented approach has been implemented
in a publicly available library besthea allowing researchers to reuse the
formulae and BEM routines straightaway. The results are validated by numerical
experiments in an HPC environment.
","['\nJan Zapletal\n', '\nRaphael Watschinger\n', '\nGünther Of\n', '\nMichal Merta\n']",,,http://dx.doi.org/10.1016/j.camwa.2021.10.025,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65N38, 35K05, 65Y05']",10.1016/j.camwa.2021.10.025,,[]
An Empirical Analysis of the R Package Ecosystem,http://arxiv.org/abs/2102.09904v1,2021-02-19T12:55:18Z,2021-02-19T12:55:18Z,"  In this research, we present a comprehensive, longitudinal empirical summary
of the R package ecosystem, including not just CRAN, but also Bioconductor and
GitHub. We analyze more than 25,000 packages, 150,000 releases, and 15 million
files across two decades, providing comprehensive counts and trends for common
metrics across packages, releases, authors, licenses, and other important
metadata. We find that the historical growth of the ecosystem has been robust
under all measures, with a compound annual growth rate of 29% for active
packages, 28% for new releases, and 26% for active maintainers. As with many
similar social systems, we find a number of highly right-skewed distributions
with practical implications, including the distribution of releases per
package, packages and releases per author or maintainer, package and maintainer
dependency in-degree, and size per package and release. For example, the top
five packages are imported by nearly 25% of all packages, and the top ten
maintainers support packages that are imported by over half of all packages. We
also highlight the dynamic nature of the ecosystem, recording both dramatic
acceleration and notable deceleration in the growth of R. From a licensing
perspective, we find a notable majority of packages are distributed under
copyleft licensing or omit licensing information entirely. The data, methods,
and calculations herein provide an anchor for public discourse and industry
decisions related to R and CRAN, serving as a foundation for future research on
the R software ecosystem and ""data science"" more broadly.
","['\nEthan Bommarito\n', '\nMichael J Bommarito II\n']","20 pages, 3 figures, 23 tables",,http://arxiv.org/abs/2102.09904v1,cs.MS,"['cs.MS', 'cs.CY', 'cs.SE', 'physics.soc-ph']",,,[]
"NonlinearSchrodinger: Higher-Order Algorithms and Darboux
  Transformations for Nonlinear Schrödinger Equations",http://arxiv.org/abs/2103.14469v1,2021-02-27T22:21:36Z,2021-02-27T22:21:36Z,"  NonlinearSchrodinger.jl is a Julia package with a simple interface for
studying solutions of nonlinear Schr\""odinger equations (NLSEs). In
approximately ten lines of code, one can perform a simulation of the cubic NLSE
using one of 32 algorithms, including symplectic and Runge-Kutta-Nystr\""om
integrators up to eighth order. Furthermore, it is possible to compute
analytical solutions via a numerical implementation of the Darboux
transformation for extended NLSEs up to fifth order, with an equally simple
interface. In what follows, we review the fundamentals of solving this class of
equations numerically and analytically, discuss the implementation, and provide
several examples.
",['\nOmar A. Ashour\n'],"43 pages, 15 figures. Submitted to Scipost Physics Codebases",,http://arxiv.org/abs/2103.14469v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'cs.NA', 'math.NA', 'nlin.SI']",,,[]
"Automatic Generation of Interpolants for Lattice Samplings: Part I --
  Theory and Analysis",http://arxiv.org/abs/2102.08514v1,2021-02-17T00:45:23Z,2021-02-17T00:45:23Z,"  Interpolation is a fundamental technique in scientific computing and is at
the heart of many scientific visualization techniques. There is usually a
trade-off between the approximation capabilities of an interpolation scheme and
its evaluation efficiency. For many applications, it is important for a user to
be able to navigate their data in real time. In practice, the evaluation
efficiency (or speed) outweighs any incremental improvements in reconstruction
fidelity. In this two-part work, we first analyze from a general standpoint the
use of compact piece-wise polynomial basis functions to efficiently interpolate
data that is sampled on a lattice. In the sequel, we detail how we generate
efficient implementations via automatic code generation on both CPU and GPU
architectures. Specifically, in this paper, we propose a general framework that
can produce a fast evaluation scheme by analyzing the algebro-geometric
structure of the convolution sum for a given lattice and basis function
combination. We demonstrate the utility and generality of our framework by
providing fast implementations of various box splines on the Body Centered and
Face Centered Cubic lattices, as well as some non-separable box splines on the
Cartesian lattice. We also provide fast implementations for certain Voronoi
splines that have not yet appeared in the literature. Finally, we demonstrate
that this framework may also be used for non-Cartesian lattices in 4D.
","['\nJoshua Horacsek\n', '\nUsman Alim\n']",,,http://arxiv.org/abs/2102.08514v1,cs.MS,['cs.MS'],,,[]
"Automatic Generation of Interpolants for Lattice Samplings: Part II --
  Implementation and Code Generation",http://arxiv.org/abs/2102.08518v1,2021-02-17T00:55:19Z,2021-02-17T00:55:19Z,"  In the prequel to this paper, we presented a systematic framework for
processing spline spaces. In this paper, we take the results of that framework
and provide a code generation pipeline that automatically generates efficient
implementations of spline spaces. We decompose the final algorithm from Part I
and translate the resulting components into LLVM-IR (a low level language that
can be compiled to various targets/architectures). Our design provides a
handful of parameters for a practitioner to tune - this is one of the avenues
that provides us with the flexibility to target many different computational
architectures and tune performance on those architectures. We also provide an
evaluation of the effect of the different parameters on performance.
","['\nJoshua Horacsek\n', '\nUsman Alim\n']",,,http://arxiv.org/abs/2102.08518v1,cs.MS,['cs.MS'],,,[]
"Core Imaging Library -- Part I: a versatile Python framework for
  tomographic imaging",http://arxiv.org/abs/2102.04560v2,2021-02-08T22:26:37Z,2021-05-27T21:00:21Z,"  We present the Core Imaging Library (CIL), an open-source Python framework
for tomographic imaging with particular emphasis on reconstruction of
challenging datasets. Conventional filtered back-projection reconstruction
tends to be insufficient for highly noisy, incomplete, non-standard or
multi-channel data arising for example in dynamic, spectral and in situ
tomography. CIL provides an extensive modular optimisation framework for
prototyping reconstruction methods including sparsity and total variation
regularisation, as well as tools for loading, preprocessing and visualising
tomographic data. The capabilities of CIL are demonstrated on a synchrotron
example dataset and three challenging cases spanning golden-ratio neutron
tomography, cone-beam X-ray laminography and positron emission tomography.
","['\nJakob S. Jørgensen\n', '\nEvelina Ametova\n', '\nGenoveva Burca\n', '\nGemma Fardell\n', '\nEvangelos Papoutsellis\n', '\nEdoardo Pasca\n', '\nKris Thielemans\n', '\nMartin Turner\n', '\nRyan Warr\n', '\nWilliam R. B. Lionheart\n', '\nPhilip J. Withers\n']","22 pages, 11 figures",,http://dx.doi.org/10.1098/rsta.2020.0192,math.OC,"['math.OC', 'cs.MS', '65K10, 65R32, 65F10']",10.1098/rsta.2020.0192,,[]
"On PyTorch Implementation of Density Estimators for von Mises-Fisher and
  Its Mixture",http://arxiv.org/abs/2102.05340v1,2021-02-10T09:26:56Z,2021-02-10T09:26:56Z,"  The von Mises-Fisher (vMF) is a well-known density model for directional
random variables. The recent surge of the deep embedding methodologies for
high-dimensional structured data such as images or texts, aimed at extracting
salient directional information, can make the vMF model even more popular. In
this article, we will review the vMF model and its mixture, provide detailed
recipes of how to train the models, focusing on the maximum likelihood
estimators, in Python/PyTorch. In particular, implementation of vMF typically
suffers from the notorious numerical issue of the Bessel function evaluation in
the density normalizer, especially when the dimensionality is high, and we
address the issue using the MPMath library that supports arbitrary precision.
For the mixture learning, we provide both minibatch-based large-scale SGD
learning, as well as the EM algorithm which is a full batch estimator. For each
estimator/methodology, we test our implementation on some synthetic data, while
we also demonstrate the use case in a more realistic scenario of image
clustering. Our code is publicly available in
https://github.com/minyoungkim21/vmf-lib.
",['\nMinyoung Kim\n'],,,http://arxiv.org/abs/2102.05340v1,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"User manual for bch, a program for the fast computation of the
  Baker-Campbell-Hausdorff and similar series",http://arxiv.org/abs/2102.06570v3,2021-02-12T15:10:39Z,2021-10-07T20:12:01Z,"  This manual describes bch, an efficient program written in the C programming
language for the fast computation of the Baker-Campbell-Hausdorff (BCH) and
similar Lie series. The Lie series can be represented in the Lyndon basis, in
the classical Hall basis, or in the right-normed basis of E.S. Chibrikov. In
the Lyndon basis, which proves to be particularly efficient for this purpose,
the computation of 111013 coefficients for the BCH series up to terms of degree
20 takes less than half a second on an ordinary personal computer and requires
negligible 11MB of memory. Up to terms of degree 30, which is the maximum
degree the program can handle, the computation of 74248451 coefficients takes
55 hours but still requires only a modest 5.5GB of memory.
",['\nHarald Hofstätter\n'],,,http://arxiv.org/abs/2102.06570v3,cs.MS,"['cs.MS', 'math.RA']",,,[]
"COMET: A Domain-Specific Compilation of High-Performance Computational
  Chemistry",http://arxiv.org/abs/2102.06827v1,2021-02-13T00:25:13Z,2021-02-13T00:25:13Z,"  The computational power increases over the past decades havegreatly enhanced
the ability to simulate chemical reactions andunderstand ever more complex
transformations. Tensor contractions are the fundamental computational building
block of these simulations. These simulations have often been tied to one
platform and restricted in generality by the interface provided to the user.
The expanding prevalence of accelerators and researcher demands necessitate a
more general approach which is not tied to specific hardware or requires
contortion of algorithms to specific hardware platforms. In this paper we
present COMET, a domain-specific programming language and compiler
infrastructure for tensor contractions targeting heterogeneous accelerators. We
present a system of progressive lowering through multiple layers of abstraction
and optimization that achieves up to 1.98X speedup for 30 tensor contractions
commonly used in computational chemistry and beyond.
","['\nErdal Mutlu\n', '\nRuiqin Tian\n', '\nBin Ren\n', '\nSriram Krishnamoorthy\n', '\nRoberto Gioiosa\n', '\nJacques Pienaar\n', '\nGokcen Kestor\n']","Proceeding of the 33rd the Workshop on Languages and Compilers for
  Parallel Computing (LCPC), October 2020",,http://arxiv.org/abs/2102.06827v1,cs.MS,"['cs.MS', 'physics.chem-ph']",,,[]
"A computer algebra system for the study of commutativity up-to-coherent
  homotopies",http://arxiv.org/abs/2102.07670v1,2021-02-15T16:58:19Z,2021-02-15T16:58:19Z,"  The Python package ComCH is a lightweight specialized computer algebra system
that provides models for well known objects, the surjection and Barratt-Eccles
operads, parameterizing the product structure of algebras that are commutative
in a derived sense. The primary examples of such algebras treated by ComCH are
the cochain complexes of spaces, for which it provides effective constructions
of Steenrod cohomology operations at all prime.
",['\nAnibal M. Medina-Mardones\n'],,,http://arxiv.org/abs/2102.07670v1,math.AT,"['math.AT', 'cs.MS', 'Primary 55-04, 18M60, Secondary 55S05, 18M70, 55N31']",,,[]
"Core Imaging Library -- Part II: Multichannel reconstruction for dynamic
  and spectral tomography",http://arxiv.org/abs/2102.06126v2,2021-02-10T12:21:34Z,2021-05-28T16:30:38Z,"  The newly developed Core Imaging Library (CIL) is a flexible plug and play
library for tomographic imaging with a specific focus on iterative
reconstruction. CIL provides building blocks for tailored regularised
reconstruction algorithms and explicitly supports multichannel tomographic
data. In the first part of this two-part publication, we introduced the
fundamentals of CIL. This paper focuses on applications of CIL for multichannel
data, e.g., dynamic and spectral. We formalise different optimisation problems
for colour processing, dynamic and hyperspectral tomography and demonstrate
CIL's capabilities for designing state of the art reconstruction methods
through case studies and code snapshots.
","['\nEvangelos Papoutsellis\n', '\nEvelina Ametova\n', '\nClaire Delplancke\n', '\nGemma Fardell\n', '\nJakob S. Jørgensen\n', '\nEdoardo Pasca\n', '\nMartin Turner\n', '\nRyan Warr\n', '\nWilliam R. B. Lionheart\n', '\nPhilip J. Withers\n']",,,http://dx.doi.org/10.1098/rsta.2020.0193,physics.med-ph,"['physics.med-ph', 'cs.MS', 'math.OC', '65K10, 65R32, 65F10']",10.1098/rsta.2020.0193,,[]
Quasi-Monte Carlo Software,http://arxiv.org/abs/2102.07833v3,2021-02-15T20:21:05Z,2021-10-14T17:44:05Z,"  Practitioners wishing to experience the efficiency gains from using low
discrepancy sequences need correct, robust, well-written software. This
article, based on our MCQMC 2020 tutorial, describes some of the better
quasi-Monte Carlo (QMC) software available. We highlight the key software
components required by QMC to approximate multivariate integrals or
expectations of functions of vector random variables. We have combined these
components in QMCPy, a Python open-source library, which we hope will draw the
support of the QMC community. Here we introduce QMCPy.
","['\nSou-Cheng T. Choi\n', '\nFred J. Hickernell\n', '\nR. Jagadeeswaran\n', '\nMichael J. McCourt\n', '\nAleksei G. Sorokin\n']","25 pages, 7 figures, to be published in the MCQMC2020 Proceedings",,http://arxiv.org/abs/2102.07833v3,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Fast Graph Learning with Unique Optimal Solutions,http://arxiv.org/abs/2102.08530v4,2021-02-17T02:00:07Z,2021-04-22T09:32:50Z,"  We consider two popular Graph Representation Learning (GRL) methods: message
passing for node classification and network embedding for link prediction. For
each, we pick a popular model that we: (i) linearize and (ii) and switch its
training objective to Frobenius norm error minimization. These simplifications
can cast the training into finding the optimal parameters in closed-form. We
program in TensorFlow a functional form of Truncated Singular Value
Decomposition (SVD), such that, we could decompose a dense matrix $\mathbf{M}$,
without explicitly computing $\mathbf{M}$. We achieve competitive performance
on popular GRL tasks while providing orders of magnitude speedup. We
open-source our code at http://github.com/samihaija/tf-fsvd
","['\nSami Abu-El-Haija\n', '\nValentino Crespi\n', '\nGreg Ver Steeg\n', '\nAram Galstyan\n']",,"ICLR 2021 Workshop on Geometrical and Topological Representation
  Learning",http://arxiv.org/abs/2102.08530v4,cs.LG,"['cs.LG', 'cs.MS', 'cs.SI']",,,[]
Optimizing Inference Performance of Transformers on CPUs,http://arxiv.org/abs/2102.06621v3,2021-02-12T17:01:35Z,2021-02-22T16:54:34Z,"  The Transformer architecture revolutionized the field of natural language
processing (NLP). Transformers-based models (e.g., BERT) power many important
Web services, such as search, translation, question-answering, etc. While
enormous research attention is paid to the training of those models, relatively
little efforts are made to improve their inference performance. This paper
comes to address this gap by presenting an empirical analysis of scalability
and performance of inferencing a Transformer-based model on CPUs. Focusing on
the highly popular BERT model, we identify key components of the Transformer
architecture where the bulk of the computation happens, and propose three
optimizations to speed them up. The optimizations are evaluated using the
inference benchmark from HuggingFace, and are shown to achieve the speedup of
up to x2.37. The considered optimizations do not require any changes to the
implementation of the models nor affect their accuracy.
","['\nDave Dice\n', '\nAlex Kogan\n']",,,http://arxiv.org/abs/2102.06621v3,cs.CL,"['cs.CL', 'cs.AI', 'cs.DC', 'cs.LG', 'cs.MS', 'I.2.0; D.4.8; G.4']",,,[]
"cuFINUFFT: a load-balanced GPU library for general-purpose nonuniform
  FFTs",http://arxiv.org/abs/2102.08463v2,2021-02-16T21:57:23Z,2021-03-25T23:18:05Z,"  Nonuniform fast Fourier transforms dominate the computational cost in many
applications including image reconstruction and signal processing. We thus
present a general-purpose GPU-based CUDA library for type 1 (nonuniform to
uniform) and type 2 (uniform to nonuniform) transforms in dimensions 2 and 3,
in single or double precision. It achieves high performance for a given
user-requested accuracy, regardless of the distribution of nonuniform points,
via cache-aware point reordering, and load-balanced blocked spreading in shared
memory. At low accuracies, this gives on-GPU throughputs around $10^9$
nonuniform points per second, and (even including host-device transfer) is
typically 4-10$\times$ faster than the latest parallel CPU code FINUFFT (at 28
threads). It is competitive with two established GPU codes, being up to
90$\times$ faster at high accuracy and/or type 1 clustered point distributions.
Finally we demonstrate a 5-12$\times$ speedup versus CPU in an X-ray
diffraction 3D iterative reconstruction task at $10^{-12}$ accuracy, observing
excellent multi-GPU weak scaling up to one rank per GPU.
","['\nYu-hsuan Shih\n', '\nGarrett Wright\n', '\nJoakim Andén\n', '\nJohannes Blaschke\n', '\nAlex H. Barnett\n']","10 pages, 9 figures",,http://arxiv.org/abs/2102.08463v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'eess.SP', 'math.NA']",,,[]
lrsarith: a small fixed/hybrid arithmetic C library,http://arxiv.org/abs/2101.12425v1,2021-01-29T06:40:53Z,2021-01-29T06:40:53Z,"  We describe lrsarith which is a small fixed precision and hybrid arithmetic C
library for integers and rationals that we developed for use in the lrslib
library for polyhedral computation. Using a generic set of operations, a
program can be compiled with either 64-bit or 128-bit (if available) fixed
precision, with an extended precision library such as GMP or the built-in MP
routines. A simple scheme checks for overflow and either terminates the program
or, in hybrid mode, changes to a higher precision arithmetic. Implementing
these arithmetics in lrslib resulted in only minimal changes to the original
code. We give computational results using lrs and mplrs, vertex/facet
enumeration codes in lrslib, using 64 and 128 bit fixed integer arithmetic with
and without overflow checking, GMP arithmetic, lrsarith hybrid arithmetic with
both GMP and MP, and FLINT hybrid arithmetic. We give a small self-contained
example C program using the lrsarith package in both fixed precision and hybrid
mode.
","['\nDavid Avis\n', '\nCharles Jordan\n']",,,http://arxiv.org/abs/2101.12425v1,cs.MS,"['cs.MS', '68-04', 'G.4; D.m']",,,[]
tf.data: A Machine Learning Data Processing Framework,http://arxiv.org/abs/2101.12127v2,2021-01-28T17:16:46Z,2021-02-23T22:56:12Z,"  Training machine learning models requires feeding input data for models to
ingest. Input pipelines for machine learning jobs are often challenging to
implement efficiently as they require reading large volumes of data, applying
complex transformations, and transferring data to hardware accelerators while
overlapping computation and communication to achieve optimal performance. We
present tf.data, a framework for building and executing efficient input
pipelines for machine learning jobs. The tf.data API provides operators which
can be parameterized with user-defined computation, composed, and reused across
different machine learning domains. These abstractions allow users to focus on
the application logic of data processing, while tf.data's runtime ensures that
pipelines run efficiently.
  We demonstrate that input pipeline performance is critical to the end-to-end
training time of state-of-the-art machine learning models. tf.data delivers the
high performance required, while avoiding the need for manual tuning of
performance knobs. We show that tf.data features, such as parallelism, caching,
static optimizations, and non-deterministic execution are essential for high
performance. Finally, we characterize machine learning input pipelines for
millions of jobs that ran in Google's fleet, showing that input data processing
is highly diverse and consumes a significant fraction of job resources. Our
analysis motivates future research directions, such as sharing computation
across jobs and pushing data projection to the storage layer.
","['\nDerek G. Murray\n', '\nJiri Simsa\n', '\nAna Klimovic\n', '\nIhor Indyk\n']",,,http://arxiv.org/abs/2101.12127v2,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"FastAD: Expression Template-Based C++ Library for Fast and
  Memory-Efficient Automatic Differentiation",http://arxiv.org/abs/2102.03681v1,2021-02-06T23:17:10Z,2021-02-06T23:17:10Z,"  Automatic differentiation is a set of techniques to efficiently and
accurately compute the derivative of a function represented by a computer
program. Existing C++ libraries for automatic differentiation (e.g. Adept, Stan
Math Library), however, exhibit large memory consumptions and runtime
performance issues. This paper introduces FastAD, a new C++ template library
for automatic differentiation, that overcomes all of these challenges in
existing libraries by using vectorization, simpler memory management using a
fully expression-template-based design, and other compile-time optimizations to
remove some run-time overhead. Benchmarks show that FastAD performs 2-10 times
faster than Adept and 2-19 times faster than Stan across various test cases
including a few real-world examples.
",['\nJames Yang\n'],,,http://arxiv.org/abs/2102.03681v1,cs.MS,"['cs.MS', 'stat.CO']",,,[]
"Performance of the low-rank tensor-train SVD (TT-SVD) for large dense
  tensors on modern multi-core CPUs",http://arxiv.org/abs/2102.00104v3,2021-01-29T22:56:55Z,2022-03-02T12:55:39Z,"  There are several factorizations of multi-dimensional tensors into
lower-dimensional components, known as `tensor networks'. We consider the
popular `tensor-train' (TT) format and ask: How efficiently can we compute a
low-rank approximation from a full tensor on current multi-core CPUs?
  Compared to sparse and dense linear algebra, kernel libraries for
multi-linear algebra are rare and typically not as well optimized. Linear
algebra libraries like BLAS and LAPACK may provide the required operations in
principle, but often at the cost of additional data movements for rearranging
memory layouts. Furthermore, these libraries are typically optimized for the
compute-bound case (e.g.\ square matrix operations) whereas low-rank tensor
decompositions lead to memory bandwidth limited operations.
  We propose a `tensor-train singular value decomposition' (TT-SVD) algorithm
based on two building blocks: a `Q-less tall-skinny QR' factorization, and a
fused tall-skinny matrix-matrix multiplication and reshape operation. We
analyze the performance of the resulting TT-SVD algorithm using the Roofline
performance model. In addition, we present performance results for different
algorithmic variants for shared-memory as well as distributed-memory
architectures. Our experiments show that commonly used TT-SVD implementations
suffer severe performance penalties. We conclude that a dedicated library for
tensor factorization kernels would benefit the community: Computing a low-rank
approximation can be as cheap as reading the data twice from main memory. As a
consequence, an implementation that achieves realistic performance will move
the limit at which one has to resort to randomized methods that only process
part of the data.
","['\nMelven Röhrig-Zöllner\n', '\nJonas Thies\n', '\nAchim Basermann\n']","26 pages, 16 figures, accepted by SISC",,http://dx.doi.org/10.1137/21M1395545,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '15A23, 15A69, 65F99, 65Y05, 65Y20', 'G.4; G.1.3']",10.1137/21M1395545,,[]
Brightening the Optical Flow through Posit Arithmetic,http://arxiv.org/abs/2101.06665v1,2021-01-17T13:19:10Z,2021-01-17T13:19:10Z,"  As new technologies are invented, their commercial viability needs to be
carefully examined along with their technical merits and demerits. The posit
data format, proposed as a drop-in replacement for IEEE 754 float format, is
one such invention that requires extensive theoretical and experimental study
to identify products that can benefit from the advantages of posits for
specific market segments. In this paper, we present an extensive empirical
study of posit-based arithmetic vis-\`a-vis IEEE 754 compliant arithmetic for
the optical flow estimation method called Lucas-Kanade (LuKa). First, we use
SoftPosit and SoftFloat format emulators to perform an empirical error analysis
of the LuKa method. Our study shows that the average error in LuKa with
SoftPosit is an order of magnitude lower than LuKa with SoftFloat. We then
present the integration of the hardware implementation of a posit adder and
multiplier in a RISC-V open-source platform. We make several recommendations,
along with the analysis of LuKa in the RISC-V context, for future generation
platforms incorporating posit arithmetic units.
","['\nVinay Saxena\n', '\nAnkitha Reddy\n', '\nJonathan Neudorfer\n', '\nJohn Gustafson\n', '\nSangeeth Nambiar\n', '\nRainer Leupers\n', '\nFarhad Merchant\n']",To appear in ISQED 2021,,http://arxiv.org/abs/2101.06665v1,cs.AR,"['cs.AR', 'cs.MS']",,,[]
A bi-directional extensible interface between Lean and Mathematica,http://arxiv.org/abs/2101.07758v1,2021-01-17T11:33:25Z,2021-01-17T11:33:25Z,"  We implement a user-extensible ad hoc connection between the Lean proof
assistant and the computer algebra system Mathematica. By reflecting the syntax
of each system in the other and providing a flexible interface for extending
translation, our connection allows for the exchange of arbitrary information
between the two systems.
  We show how to make use of the Lean metaprogramming framework to verify
certain Mathematica computations, so that the rigor of the proof assistant is
not compromised. We also use Mathematica as an untrusted oracle to guide proof
search in the proof assistant and interact with a Mathematica notebook from
within a Lean session. In the other direction, we import and process Lean
declarations from within Mathematica. The proof assistant library serves as a
database of mathematical knowledge that the CAS can display and explore.
","['\nRobert Y. Lewis\n', '\nMinchao Wu\n']",arXiv admin note: substantial text overlap with arXiv:1712.09288,,http://arxiv.org/abs/2101.07758v1,cs.LO,"['cs.LO', 'cs.MS']",,,[]
"Acceleration of multiple precision matrix multiplication based on
  multi-component floating-point arithmetic using AVX2",http://arxiv.org/abs/2101.06584v1,2021-01-17T04:05:13Z,2021-01-17T04:05:13Z,"  In this paper, we report the results obtained from the acceleration of
multi-binary64-type multiple precision matrix multiplication with AVX2. We
target double-double (DD), triple-double (TD), and quad-double (QD) precision
arithmetic designed by certain types of error-free transformation (EFT)
arithmetic. Furthermore, we implement SIMDized EFT functions, which
simultaneously compute with four binary64 numbers on x86_64 computing
environment, and by using help of them, we also develop SIMDized DD, TD, and QD
additions and multiplications. In addition, AVX2 load/store functions were
adopted to efficiently speed up reading and storing matrix elements from/to
memory. Owing to these combined techniques, our implemented multiple precision
matrix multiplications have been accelerated more than three times compared
with non-accelerated ones. Our accelerated matrix multiplication modifies the
performance of parallelization with OpenMP.
",['\nTomonori Kouya\n'],,,http://dx.doi.org/10.1007/978-3-030-86976-2_14,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'cs.PF']",10.1007/978-3-030-86976-2_14,,[]
"On the efficient parallel computing of long term reliable trajectories
  for the Lorenz system",http://arxiv.org/abs/2101.06682v1,2021-01-17T14:42:42Z,2021-01-17T14:42:42Z,"  In this work we propose an efficient parallelization of multiple-precision
Taylor series method with variable stepsize and fixed order. For given level of
accuracy the optimal variable stepsize determines higher order of the method
than in the case of optimal fixed stepsize. Although the used order of the
method is greater then that in the case of fixed stepsize, and hence the
computational work per step is greater, the reduced number of steps gives less
overall work. Also the greater order of the method is beneficial in the sense
that it increases the parallel efficiency. As a model problem we use the
paradigmatic Lorenz system. With 256 CPU cores in Nestum cluster, Sofia,
Bulgaria, we succeed to obtain a correct reference solution in the rather long
time interval - [0,11000]. To get this solution we performed two large
computations: one computation with 4566 decimal digits of precision and 5240-th
order method, and second computation for verification - with 4778 decimal
digits of precision and 5490-th order method.
","['\nI. Hristov\n', '\nR. Hristova\n', '\nS. Dimova\n', '\nP. Armyanov\n', '\nN. Shegunov\n', '\nI. Puzynin\n', '\nT. Puzynina\n', '\nZ. Sharipov\n', '\nZ. Tukhliev\n']","10 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:2010.14993","CEUR Workshop Proceedings, vol-2933, pp. 78-88 (2021)",http://arxiv.org/abs/2101.06682v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA', '65L05, 65Y05', 'G.1.7; G.1.0']",,,[]
FDApy: a Python package for functional data,http://arxiv.org/abs/2101.11003v1,2021-01-26T10:07:33Z,2021-01-26T10:07:33Z,"  We introduce the Python package, FDApy, as an implementation of functional
data. This package provide modules for the analysis of such data. It includes
classes for different dimensional data as well as irregularly sampled
functional data. A simulation toolbox is also provided. It might be used to
simulate different clusters of functional data. Some methodologies to handle
these data are implemented, such as dimension reduction and clustering. New
methods can be easily added. The package is publicly available on the Python
Package Index and Github.
",['\nSteven Golovkine\n'],,,http://arxiv.org/abs/2101.11003v1,cs.MS,"['cs.MS', 'cs.LG', 'stat.CO', 'stat.ML', '62R10 (Primary)']",,,[]
"Accelerated Polynomial Evaluation and Differentiation at Power Series in
  Multiple Double Precision",http://arxiv.org/abs/2101.10881v3,2021-01-22T19:42:43Z,2021-03-13T00:22:10Z,"  The problem is to evaluate a polynomial in several variables and its gradient
at a power series truncated to some finite degree with multiple double
precision arithmetic. To compensate for the cost overhead of multiple double
precision and power series arithmetic, data parallel algorithms for general
purpose graphics processing units are presented. The reverse mode of
algorithmic differentiation is organized into a massively parallel computation
of many convolutions and additions of truncated power series. Experimental
results demonstrate that teraflop performance is obtained in deca double
precision with power series truncated at degree 152. The algorithms scale well
for increasing precision and increasing degrees.
",['\nJan Verschelde\n'],"Improved the introduction, adding two citations to related work;
  fixed error, added table on the fluctuations of wall clock times. To appear
  in the Proceedings of the 2021 IEEE International Parallel and Distributed
  Processing Symposium Workshops (IPDPSW)",,http://arxiv.org/abs/2101.10881v3,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'cs.SC', 'math.AG', 'math.NA']",,,[]
Robust level-3 BLAS Inverse Iteration from the Hessenberg Matrix,http://arxiv.org/abs/2101.05063v1,2021-01-13T13:49:38Z,2021-01-13T13:49:38Z,"  Inverse iteration is known to be an effective method for computing
eigenvectors corresponding to simple and well-separated eigenvalues. In the
non-symmetric case, the solution of shifted Hessenberg systems is a central
step. Existing inverse iteration solvers approach the solution of the shifted
Hessenberg systems with either RQ or LU factorizations and, once factored,
solve the corresponding systems. This approach has limited level-3 BLAS
potential since distinct shifts have distinct factorizations. This paper
rearranges the RQ approach such that data shared between distinct shifts is
exposed. Thereby the backward substitution with the triangular R factor can be
expressed mostly with matrix-matrix multiplications (level-3 BLAS). The
resulting algorithm computes eigenvectors in a tiled, overflow-free, and
task-parallel fashion. The numerical experiments show that the new algorithm
outperforms existing inverse iteration solvers for the computation of both real
and complex eigenvectors.
",['\nAngelika Schwarz\n'],,,http://arxiv.org/abs/2101.05063v1,cs.MS,['cs.MS'],,,[]
"UFL Dual Spaces, a proposal",http://arxiv.org/abs/2101.05158v1,2021-01-13T15:55:51Z,2021-01-13T15:55:51Z,"  This white paper highlights current limitations in the algebraic closure
Unified Form Language (UFL). UFL currently represents forms over finite element
spaces, however finite element problems naturally result in objects in the dual
to a finite element space, and operators mapping between primal and dual finite
element spaces. This document sketches the relevant mathematical areas and
proposes changes to the UFL language to support dual spaces as first class
types in UFL.
",['\nDavid A. Ham\n'],,,http://arxiv.org/abs/2101.05158v1,cs.MS,['cs.MS'],,,[]
"dame-flame: A Python Library Providing Fast Interpretable Matching for
  Causal Inference",http://arxiv.org/abs/2101.01867v3,2021-01-06T04:38:57Z,2023-04-02T18:16:37Z,"  dame-flame is a Python package for performing matching for observational
causal inference on datasets containing discrete covariates. This package
implements the Dynamic Almost Matching Exactly (DAME) and Fast Large-Scale
Almost Matching Exactly (FLAME) algorithms, which match treatment and control
units on subsets of the covariates. The resulting matched groups are
interpretable, because the matches are made on covariates, and high-quality,
because machine learning is used to determine which covariates are important to
match on. DAME solves an optimization problem that matches units on as many
covariates as possible, prioritizing matches on important covariates. FLAME
approximates the solution found by DAME via a much faster backward feature
selection procedure. The package provides several adjustable parameters to
adapt the algorithms to specific applications, and can calculate treatment
effect estimates after matching. Descriptions of these parameters, details on
estimating treatment effects, and further examples, can be found in the
documentation at
https://almost-matching-exactly.github.io/DAME-FLAME-Python-Package/
","['\nNeha R. Gupta\nDuke University\n', '\nVittorio Orlandi\nDuke University\n', '\nChia-Rui Chang\nHarvard University\n', '\nTianyu Wang\nFudan University\n', '\nMarco Morucci\nNew York University\n', '\nPritam Dey\nDuke University\n', '\nThomas J. Howell\nDuke University\n', '\nXian Sun\nDuke University\n', '\nAngikar Ghosal\nDuke University\n', '\nSudeepa Roy\nDuke University\n', '\nCynthia Rudin\nDuke University\n', '\nAlexander Volfovsky\nDuke University\n']","26 pages, 2 figures",,http://arxiv.org/abs/2101.01867v3,cs.LG,"['cs.LG', 'cs.MS']",,,"['Duke University', 'Duke University', 'Harvard University', 'Fudan University', 'New York University', 'Duke University', 'Duke University', 'Duke University', 'Duke University', 'Duke University', 'Duke University', 'Duke University']"
Number Parsing at a Gigabyte per Second,http://arxiv.org/abs/2101.11408v9,2021-01-11T20:31:27Z,2022-11-03T18:40:26Z,"  With disks and networks providing gigabytes per second, parsing decimal
numbers from strings becomes a bottleneck. We consider the problem of parsing
decimal numbers to the nearest binary floating-point value. The general problem
requires variable-precision arithmetic. However, we need at most 17 digits to
represent 64-bit standard floating-point numbers (IEEE 754). Thus we can
represent the decimal significand with a single 64-bit word. By combining the
significand and precomputed tables, we can compute the nearest floating-point
number using as few as one or two 64-bit multiplications. Our implementation
can be several times faster than conventional functions present in standard C
libraries on modern 64-bit systems (Intel, AMD, ARM and POWER9). Our work is
available as open source software used by major systems such as Apache Arrow
and Yandex ClickHouse. The Go standard library has adopted a version of our
approach.
",['\nDaniel Lemire\n'],"Software at https://github.com/fastfloat/fast_float and
  https://github.com/lemire/simple_fastfloat_benchmark/","Software: Practice and Experience 51 (8), 2021",http://dx.doi.org/10.1002/spe.2984,cs.DS,"['cs.DS', 'cs.MS']",10.1002/spe.2984,,[]
A Julia implementation of Algorithm NCL for constrained optimization,http://arxiv.org/abs/2101.02164v1,2021-01-06T17:57:44Z,2021-01-06T17:57:44Z,"  Algorithm NCL is designed for general smooth optimization problems where
first and second derivatives are available, including problems whose
constraints may not be linearly independent at a solution (i.e., do not satisfy
the LICQ). It is equivalent to the LANCELOT augmented Lagrangian method,
reformulated as a short sequence of nonlinearly constrained subproblems that
can be solved efficiently by IPOPT and KNITRO, with warm starts on each
subproblem. We give numerical results from a Julia implementation of Algorithm
NCL on tax policy models that do not satisfy the LICQ, and on nonlinear
least-squares problems and general problems from the CUTEst test set.
","['\nDing Ma\n', '\nDominique Orban\n', '\nMichael A. Saunders\n']",,,http://dx.doi.org/10.13140/RG.2.2.29888.35841,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'math.NA']",10.13140/RG.2.2.29888.35841,,[]
"Frequency extraction for BEM-matrices arising from the 3D scalar
  Helmholtz equation",http://arxiv.org/abs/2012.14287v3,2020-12-28T15:32:34Z,2022-05-03T12:22:50Z,"  The discretisation of boundary integral equations for the scalar Helmholtz
equation leads to large dense linear systems. Efficient boundary element
methods (BEM), such as the fast multipole method (FMM) and $\Hmat$ based
methods, focus on structured low-rank approximations of subblocks in these
systems. It is known that the ranks of these subblocks increase linearly with
the wavenumber. We explore a data-sparse representation of BEM-matrices valid
for a range of frequencies, based on extracting the known phase of the Green's
function. Algebraically, this leads to a Hadamard product of a frequency matrix
with an $\Hmat$. We show that the frequency dependency of this $\Hmat$ can be
determined using a small number of frequency samples, even for geometrically
complex three-dimensional scattering obstacles. We describe an efficient
construction of the representation by combining adaptive cross approximation
with adaptive rational approximation in the continuous frequency dimension. We
show that our data-sparse representation allows to efficiently sample the full
BEM-matrix at any given frequency, and as such it may be useful as part of an
efficient sweeping routine.
","['\nSimon Dirckx\n', '\nDaan Huybrechs\n', '\nKarl Meerbergen\n']",,,http://arxiv.org/abs/2012.14287v3,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
calculus: High Dimensional Numerical and Symbolic Calculus in R,http://arxiv.org/abs/2101.00086v1,2020-12-31T21:52:19Z,2020-12-31T21:52:19Z,"  The R package calculus implements C++ optimized functions for numerical and
symbolic calculus, such as the Einstein summing convention, fast computation of
the Levi-Civita symbol and generalized Kronecker delta, Taylor series
expansion, multivariate Hermite polynomials, high-order derivatives, ordinary
differential equations, differential operators and numerical integration in
arbitrary orthogonal coordinate systems. The library applies numerical methods
when working with R functions or symbolic programming when working with
characters or expressions. The package handles multivariate numerical calculus
in arbitrary dimensions and coordinates and implements the symbolic counterpart
of the numerical methods whenever possible, without depending on external
computer algebra systems. Except for Rcpp, the package has no strict
dependencies in order to provide a stable self-contained toolbox that invites
re-use.
",['\nEmanuele Guidotti\n'],,"Journal of Statistical Software (2022), 104(5), 1-37",http://dx.doi.org/10.18637/jss.v104.i05,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '68-04', 'G.4']",10.18637/jss.v104.i05,,[]
"Universal Numbers Library: design and implementation of a
  high-performance reproducible number systems library",http://arxiv.org/abs/2012.11011v1,2020-12-20T20:07:57Z,2020-12-20T20:07:57Z,"  With the proliferation of embedded systems requiring intelligent behavior,
custom number systems to optimize performance per Watt of the entire system
become essential components for successful commercial products. We present the
Universal Number Library, a high-performance number systems library that
includes arbitrary integer, decimal, fixed-point, floating-point, and
introduces two tapered floating-point types, posit and valid, that support
reproducible arithmetic computation in arbitrary concurrency environments. We
discuss the design of the Universal library as a run-time for application
development, and as a platform for application-driven hardware validation. The
library implementation is described, and examples are provided to show
educational examples to elucidate the number system properties, and how
specialization is used to yield very high-performance emulation on existing
x86, ARM, and POWER processors. We will highlight the integration of the
library in larger application environments in computational science and
engineering to enable multi-precision and adaptive precision algorithms to
improve performance and efficiency of large scale and real-time applications.
We will demonstrate the integration of the Universal library into a
high-performance reproducible linear algebra run-time. We will conclude with
the roadmap of additional functionality of the library as we are targeting new
application domains, such as Software Defined Radio, instrumentation, sensor
fusion, and model-predictive control.
","['\nE. Theodore L. Omtzigt\n', '\nPeter Gottschling\n', '\nMark Seligman\n', '\nWilliam Zorn\n']","7 pages, 4 figures",,http://arxiv.org/abs/2012.11011v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
"Digital Annealer for quadratic unconstrained binary optimization: a
  comparative performance analysis",http://arxiv.org/abs/2012.12264v1,2020-12-22T09:12:27Z,2020-12-22T09:12:27Z,"  Digital Annealer (DA) is a computer architecture designed for tackling
combinatorial optimization problems formulated as quadratic unconstrained
binary optimization (QUBO) models. In this paper, we present the results of an
extensive computational study to evaluate the performance of DA in a systematic
way in comparison to multiple state-of-the-art solvers for different problem
classes. We examine pure QUBO models, as well as QUBO reformulations of three
constrained problems, namely quadratic assignment, quadratic cycle partition,
and selective graph coloring, with the last two being new applications for DA.
For the selective graph coloring problem, we also present a size reduction
heuristic that significantly increases the number of eligible instances for DA.
Our experimental results show that despite being in its development stage, DA
can provide high-quality solutions quickly and in that regard rivals the state
of the art, particularly for large instances. Moreover, as opposed to
established solvers, within its limit on the number of decision variables, DA's
solution times are not affected by the increase in instance size. These
findings illustrate that DA has the potential to become a successful technology
in tackling combinatorial optimization problems.
","['\nOylum Şeker\n', '\nNeda Tanoumand\n', '\nMerve Bodur\n']",,,http://arxiv.org/abs/2012.12264v1,math.OC,"['math.OC', 'cs.MS']",,,[]
NetworkDynamics.jl -- Composing and simulating complex networks in Julia,http://arxiv.org/abs/2012.12696v3,2020-12-22T11:41:24Z,2021-07-01T08:21:31Z,"  NetworkDynamics.jl is an easy-to-use and computationally efficient package
for working with heterogeneous dynamical systems on complex networks, written
in Julia, a high-level, high-performance, dynamic programming language. By
combining state of the art solver algorithms from DifferentialEquations.jl with
efficient data structures, NetworkDynamics.jl achieves top performance while
supporting advanced features like events, algebraic constraints, time-delays,
noise terms and automatic differentiation.
","['\nMichael Lindner\n', '\nLucas Lincoln\n', '\nFenja Drauschke\n', '\nJulia Monika Koulen\n', '\nHans Würfel\n', '\nAnton Plietzsch\n', '\nFrank Hellmann\n']","This article may be downloaded for personal use only. Any other use
  requires prior permission of the author and AIP Publishing. This article
  appeared in Chaos 31, 063133 (2021) and may be found at
  https://aip.scitation.org/doi/10.1063/5.0051387","Chaos 31, 063133 (2021)",http://dx.doi.org/10.1063/5.0051387,cs.MS,"['cs.MS', 'physics.soc-ph', 'G.4']",10.1063/5.0051387,,[]
"A 55-line code for large-scale parallel topology optimization in 2D and
  3D",http://arxiv.org/abs/2012.08208v1,2020-12-15T10:57:16Z,2020-12-15T10:57:16Z,"  This paper presents a 55-line code written in python for 2D and 3D topology
optimization (TO) based on the open-source finite element computing software
(FEniCS), equipped with various finite element tools and solvers. PETSc is used
as the linear algebra back-end, which results in significantly less
computational time than standard python libraries. The code is designed based
on the popular solid isotropic material with penalization (SIMP) methodology.
Extensions to multiple load cases, different boundary conditions, and
incorporation of passive elements are also presented. Thus, this implementation
is the most compact implementation of SIMP based topology optimization for 3D
as well as 2D problems.
  Utilizing the concept of Euclidean distance matrix to vectorize the
computation of the weight matrix for the filter, we have achieved a substantial
reduction in the computational time and have also made it possible for the code
to work with complex ground structure configurations. We have also presented
the code's extension to large-scale topology optimization problems with support
for parallel computations on complex structural configuration, which could help
students and researchers explore novel insights into the TO problem with dense
meshes. Appendix-A contains the complete code, and the website:
\url{https://github.com/iitrabhi/topo-fenics} also contains the complete code.
","['\nAbhinav Gupta\n', '\nRajib Chowdhury\n', '\nAnupam Chakrabarti\n', '\nTimon Rabczuk\n']",,,http://arxiv.org/abs/2012.08208v1,cs.MS,"['cs.MS', 'cs.CE', 'math.OC']",,,[]
What the new RooFit can do for your analysis,http://arxiv.org/abs/2012.02746v2,2020-12-04T17:55:30Z,2021-02-22T13:55:25Z,"  RooFit is a toolkit for statistical modelling and fitting, and together with
RooStats it is used for measurements and statistical tests by most experiments
in particle physics. Since one year, RooFit is being modernised. In this talk,
improvements already released with ROOT will be discussed, such as faster data
loading, vectorised computations and more standard-like interfaces. These allow
for speeding up unbinned fits by several factors, and make RooFit easier to use
from both C++ and Python.
",['\nStephan Hageboeck\n'],"6 pages, 4 figures, submitted to Proceedings of Science (ICHEP 2020)
  v2: Minor rephrasing to address comments by reviewers",,http://dx.doi.org/10.22323/1.390.0910,physics.data-an,"['physics.data-an', 'cs.MS', 'hep-ex']",10.22323/1.390.0910,,[]
"MFST: A Python OpenFST Wrapper With Support for Custom Semirings and
  Jupyter Notebooks",http://arxiv.org/abs/2012.03437v1,2020-12-07T03:36:54Z,2020-12-07T03:36:54Z,"  This paper introduces mFST, a new Python library for working with
Finite-State Machines based on OpenFST. mFST is a thin wrapper for OpenFST and
exposes all of OpenFST's methods for manipulating FSTs. Additionally, mFST is
the only Python wrapper for OpenFST that exposes OpenFST's ability to define a
custom semirings. This makes mFST ideal for developing models that involve
learning the weights on a FST or creating neuralized FSTs. mFST has been
designed to be easy to get started with and has been previously used in
homework assignments for a NLP class as well in projects for integrating FSTs
and neural networks. In this paper, we exhibit mFST API and how to use mFST to
build a simple neuralized FST with PyTorch.
",['\nMatthew Francis-Landau\n'],,,http://arxiv.org/abs/2012.03437v1,cs.LG,"['cs.LG', 'cs.CL', 'cs.MS']",,,[]
River: machine learning for streaming data in Python,http://arxiv.org/abs/2012.04740v1,2020-12-08T21:04:44Z,2020-12-08T21:04:44Z,"  River is a machine learning library for dynamic data streams and continual
learning. It provides multiple state-of-the-art learning methods, data
generators/transformers, performance metrics and evaluators for different
stream learning problems. It is the result from the merger of the two most
popular packages for stream learning in Python: Creme and scikit-multiflow.
River introduces a revamped architecture based on the lessons learnt from the
seminal packages. River's ambition is to be the go-to library for doing machine
learning on streaming data. Additionally, this open source package brings under
the same umbrella a large community of practitioners and researchers. The
source code is available at https://github.com/online-ml/river.
","['\nJacob Montiel\n', '\nMax Halford\n', '\nSaulo Martiello Mastelini\n', '\nGeoffrey Bolmier\n', '\nRaphael Sourty\n', '\nRobin Vaysse\n', '\nAdil Zouitine\n', '\nHeitor Murilo Gomes\n', '\nJesse Read\n', '\nTalel Abdessalem\n', '\nAlbert Bifet\n']",Submitted to JMLR MLOSS,,http://arxiv.org/abs/2012.04740v1,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS', '68-04', 'I.2; I.2.5']",,,[]
"Highly Efficient Lattice-Boltzmann Multiphase Simulations of Immiscible
  Fluids at High-Density Ratios on CPUs and GPUs through Code Generation",http://arxiv.org/abs/2012.06144v1,2020-12-11T06:07:58Z,2020-12-11T06:07:58Z,"  A high-performance implementation of a multiphase lattice Boltzmann method
based on the conservative Allen-Cahn model supporting high-density ratios and
high Reynolds numbers is presented. Metaprogramming techniques are used to
generate optimized code for CPUs and GPUs automatically. The coupled model is
specified in a high-level symbolic description and optimized through automatic
transformations. The memory footprint of the resulting algorithm is reduced
through the fusion of compute kernels. A roofline analysis demonstrates the
excellent efficiency of the generated code on a single GPU. The resulting
single GPU code has been integrated into the multiphysics framework waLBerla to
run massively parallel simulations on large domains. Communication hiding and
GPUDirect-enabled MPI yield near-perfect scaling behaviour. Scaling experiments
are conducted on the Piz Daint supercomputer with up to 2048 GPUs, simulating
several hundred fully resolved bubbles. Further, validation of the
implementation is shown in a physically relevant scenario-a three-dimensional
rising air bubble in water.
","['\nMarkus Holzer\n', '\nMartin Bauer\n', '\nUlrich Rüde\n']","17 pages, 9 figures",,http://arxiv.org/abs/2012.06144v1,physics.flu-dyn,"['physics.flu-dyn', 'cs.MS', 'cs.PF']",,,[]
Parallel Software to Offset the Cost of Higher Precision,http://arxiv.org/abs/2012.06607v1,2020-12-11T19:23:55Z,2020-12-11T19:23:55Z,"  Hardware double precision is often insufficient to solve large scientific
problems accurately. Computing in higher precision defined by software causes
significant computational overhead. The application of parallel algorithms
compensates for this overhead. Newton's method to develop power series
expansions of algebraic space curves is the use case for this application.
",['\nJan Verschelde\n'],"The paper corresponds to a talk given by the author at the HILT 2020
  Workshop on Safe Languages and Technologies for Structured and Efficient
  Parallel and Distributed/Cloud Computing, 16-17 November 2020",,http://arxiv.org/abs/2012.06607v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'cs.SC', 'math.AG', 'math.NA']",,,[]
The Chunks and Tasks Matrix Library 2.0,http://arxiv.org/abs/2011.11762v1,2020-11-23T22:04:50Z,2020-11-23T22:04:50Z,"  We present a C++ header-only parallel sparse matrix library, based on sparse
quadtree representation of matrices using the Chunks and Tasks programming
model. The library implements a number of sparse matrix algorithms for
distributed memory parallelization that are able to dynamically exploit data
locality to avoid movement of data. This is demonstrated for the example of
block-sparse matrix-matrix multiplication applied to three sequences of
matrices with different nonzero structure, using the CHT-MPI 2.0 runtime
library implementation of the Chunks and Tasks model. The runtime library
succeeds to dynamically load balance the calculation regardless of the sparsity
structure.
","['\nEmanuel H. Rubensson\n', '\nElias Rudberg\n', '\nAnastasia Kruchinina\n', '\nAnton G. Artemov\n']",,,http://arxiv.org/abs/2011.11762v1,cs.DC,"['cs.DC', 'cs.MS', '65F50', 'D.1.3; G.1.3; G.4']",,,[]
"Enabling GPU Accelerated Computing in the SUNDIALS Time Integration
  Library",http://arxiv.org/abs/2011.12984v2,2020-11-25T19:09:12Z,2021-12-08T19:34:40Z,"  As part of the Exascale Computing Project (ECP), a recent focus of
development efforts for the SUite of Nonlinear and DIfferential/ALgebraic
equation Solvers (SUNDIALS) has been to enable GPU-accelerated time integration
in scientific applications at extreme scales. This effort has resulted in
several new GPU-enabled implementations of core SUNDIALS data structures,
support for programming paradigms which are aware of the heterogeneous
architectures, and the introduction of utilities to provide new points of
flexibility. In this paper, we discuss our considerations, both internal and
external, when designing these new features and present the features
themselves. We also present performance results for several of the features on
the Summit supercomputer and early access hardware for the Frontier
supercomputer, which demonstrate negligible performance overhead resulting from
the additional infrastructure and significant speedups when using both NVIDIA
and AMD GPUs.
","['\nCody J. Balos\n', '\nDavid J. Gardner\n', '\nCarol S. Woodward\n', '\nDaniel R. Reynolds\n']",,"Parallel Computing, Volume 108, 2021, 102836, ISSN 0167-8191",http://dx.doi.org/10.1016/j.parco.2021.102836,cs.DC,"['cs.DC', 'cs.MS']",10.1016/j.parco.2021.102836,,[]
"Automatic Mathematical Information Retrieval to Perform Translations up
  to Computer Algebra Systems",http://arxiv.org/abs/2011.14616v1,2020-11-30T08:36:58Z,2020-11-30T08:36:58Z,"  In mathematics, LaTeX is the de facto standard to prepare documents, e.g.,
scientific publications. While some formulae are still developed using pen and
paper, more complicated mathematical expressions used more and more often with
computer algebra systems. Mathematical expressions are often manually
transcribed to computer algebra systems. The goal of my doctoral thesis is to
improve the efficiency of this workflow. My envisioned method will
automatically semantically enrich mathematical expressions so that they can be
imported to computer algebra systems and other systems that can take advantage
of the semantics, such as search engines or automatic plagiarism detection
systems. These imports should preserve the essential semantic features of the
expression.
",['\nAndré Greiner-Petter\n'],"Doctoral Consortium Paper at the Joint Conference on Digital
  Libraries (JCDL), Fort Worth, TX, USA, June 03-07, 2018","Bulletin of IEEE Technical Committee on Digital Libraries 15.1
  (Jan. 2019)",http://arxiv.org/abs/2011.14616v1,cs.IR,"['cs.IR', 'cs.MS']",,,[]
Automatically Building Diagrams for Olympiad Geometry Problems,http://arxiv.org/abs/2012.02590v2,2020-12-01T05:56:25Z,2021-05-01T00:41:22Z,"  We present a method for automatically building diagrams for olympiad-level
geometry problems and implement our approach in a new open-source software
tool, the Geometry Model Builder (GMB). Central to our method is a new
domain-specific language, the Geometry Model-Building Language (GMBL), for
specifying geometry problems along with additional metadata useful for building
diagrams. A GMBL program specifies (1) how to parameterize geometric objects
(or sets of geometric objects) and initialize these parameterized quantities,
(2) which quantities to compute directly from other quantities, and (3)
additional constraints to accumulate into a (differentiable) loss function. A
GMBL program induces a (usually) tractable numerical optimization problem whose
solutions correspond to diagrams of the original problem statement, and that we
can solve reliably using gradient descent. Of the 39 geometry problems since
2000 appearing in the International Mathematical Olympiad, 36 can be expressed
in our logic and our system can produce diagrams for 94% of them on average. To
the best of our knowledge, our method is the first in automated geometry
diagram construction to generate models for such complex problems.
","['\nRyan Krueger\n', '\nJesse Michael Han\n', '\nDaniel Selsam\n']",,,http://arxiv.org/abs/2012.02590v2,cs.CG,"['cs.CG', 'cs.MS']",,,[]
Combined Sieve Algorithm for Prime Gaps,http://arxiv.org/abs/2012.03771v1,2020-11-30T10:25:20Z,2020-11-30T10:25:20Z,"  A new Combined Sieve algorithm is presented with cost proportional to the
number of enumerated factors over a series of intervals. This algorithm
achieves a significant speedup, over a traditional sieve, when handling many
([10^4, 10^7]) intervals concurrently. The speedup comes from a space-time
tradeoff and a novel solution to a modular equation. In real world tests, this
new algorithm regularly runs 10,000x faster. This faster sieve paired with
higher sieving limits eliminates more composites and accelerates the search for
large prime gaps by 30-70%. During the development and testing of this new
algorithm, two top-10 record merit prime gaps were discovered.
",['\nSeth Troisi\n'],"10 pages, 4 figures, Open source code (GitHub), active development",,http://arxiv.org/abs/2012.03771v1,math.NT,"['math.NT', 'cs.MS', '11N05 (Primary) 11N35']",,,[]
"Automatic differentiation of Sylvester, Lyapunov, and algebraic Riccati
  equations",http://arxiv.org/abs/2011.11430v2,2020-11-23T14:33:31Z,2020-11-24T10:53:43Z,"  Sylvester, Lyapunov, and algebraic Riccati equations are the bread and butter
of control theorists. They are used to compute infinite-horizon Gramians, solve
optimal control problems in continuous or discrete time, and design observers.
While popular numerical computing frameworks (e.g., scipy) provide efficient
solvers for these equations, these solvers are still largely missing from most
automatic differentiation libraries. Here, we derive the forward and
reverse-mode derivatives of the solutions to all three types of equations, and
showcase their application on an inverse control problem.
","['\nTa-Chu Kao\n', '\nGuillaume Hennequin\n']",,,http://arxiv.org/abs/2011.11430v2,math.OC,"['math.OC', 'cs.LG', 'cs.MS']",,,[]
"A robust and scalable unfitted adaptive finite element framework for
  nonlinear solid mechanics",http://arxiv.org/abs/2012.00280v3,2020-12-01T05:37:24Z,2021-07-25T07:20:36Z,"  In this work, we bridge standard adaptive mesh refinement and coarsening on
scalable octree background meshes and robust unfitted finite element
formulations for the automatic and efficient solution of large-scale nonlinear
solid mechanics problems posed on complex geometries, as an alternative to
standard body-fitted formulations, unstructured mesh generation and graph
partitioning strategies. We pay special attention to those aspects requiring a
specialized treatment in the extension of the unfitted h-adaptive aggregated
finite element method on parallel tree-based adaptive meshes, recently
developed for linear scalar elliptic problems, to handle nonlinear problems in
solid mechanics. In order to accurately and efficiently capture localized
phenomena that frequently occur in nonlinear solid mechanics problems, we
perform pseudo time-stepping in combination with h-adaptive dynamic mesh
refinement and rebalancing driven by a-posteriori error estimators. The method
is implemented considering both irreducible and mixed (u/p) formulations and
thus it is able to robustly face problems involving incompressible materials.
In the numerical experiments, both formulations are used to model the inelastic
behavior of a wide range of compressible and incompressible materials. First, a
selected set of benchmarks are reproduced as a verification step. Second, a set
of experiments is presented with problems involving complex geometries. Among
them, we model a cantilever beam problem with spherical hollows distributed in
a Simple Cubic array. This test involves a discrete domain with up to 11.7M
Degrees Of Freedom solved in less than two hours on 3072 cores of a parallel
supercomputer.
","['\nSantiago Badia\n', '\nManuel Caicedo\n', '\nAlberto F. Martín\n', '\nJavier Principe\n']",,,http://dx.doi.org/10.1016/j.cma.2021.114093,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1016/j.cma.2021.114093,,[]
"A Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue
  Problems with No Tridiagonalization",http://arxiv.org/abs/2012.00506v3,2020-12-01T14:21:18Z,2022-03-18T21:46:39Z,"  In this paper, a Parallel Direct Eigensolver for Sequences of Hermitian
Eigenvalue Problems with no tridiagonalization is proposed, denoted by
\texttt{PDESHEP}, and it combines direct methods with iterative methods.
\texttt{PDESHEP} first reduces a Hermitian matrix to its banded form, then
applies a spectrum slicing algorithm to the banded matrix, and finally computes
the eigenvectors of the original matrix via backtransform. Therefore, compared
with conventional direct eigensolvers, \texttt{PDESHEP} avoids
tridiagonalization, which consists of many memory-bounded operations. In this
work, the iterative method in \texttt{PDESHEP} is based on the contour integral
method implemented in FEAST. The combination of direct methods with iterative
methods for banded matrices requires some efficient data redistribution
algorithms both from 2D to 1D and from 1D to 2D data structures. Hence, some
two-step data redistribution algorithms are proposed, which can be $10\times$
faster than ScaLAPACK routine \texttt{PXGEMR2D}. For the symmetric
self-consistent field (SCF) eigenvalue problems, \texttt{PDESHEP} can be on
average $1.25\times$ faster than the state-of-the-art direct solver in ELPA
when using $4096$ processes. Numerical results are obtained for dense Hermitian
matrices from real applications and large real sparse matrices from the
SuiteSparse collection.
","['\nShengguo Li\n', '\nXinzhe Wu\n', '\nJose E. Roman\n', '\nZiyang Yuan\n', '\nRuibo Wang\n', '\nLizhi Cheng\n']",19 pages and 9 figures,,http://arxiv.org/abs/2012.00506v3,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"Parameter Sensitivity Analysis of the SparTen High Performance Sparse
  Tensor Decomposition Software: Extended Analysis",http://arxiv.org/abs/2012.01520v1,2020-12-02T20:47:29Z,2020-12-02T20:47:29Z,"  Tensor decomposition models play an increasingly important role in modern
data science applications. One problem of particular interest is fitting a
low-rank Canonical Polyadic (CP) tensor decomposition model when the tensor has
sparse structure and the tensor elements are nonnegative count data. SparTen is
a high-performance C++ library which computes a low-rank decomposition using
different solvers: a first-order quasi-Newton or a second-order damped Newton
method, along with the appropriate choice of runtime parameters. Since default
parameters in SparTen are tuned to experimental results in prior published work
on a single real-world dataset conducted using MATLAB implementations of these
methods, it remains unclear if the parameter defaults in SparTen are
appropriate for general tensor data. Furthermore, it is unknown how sensitive
algorithm convergence is to changes in the input parameter values. This report
addresses these unresolved issues with large-scale experimentation on three
benchmark tensor data sets. Experiments were conducted on several different CPU
architectures and replicated with many initial states to establish generalized
profiles of algorithm convergence behavior.
","['\nJeremy M. Myers\n', '\nDaniel M. Dunlavy\n', '\nKeita Teranishi\n', '\nD. S. Hollman\n']","33 pages, 13 figures",,http://arxiv.org/abs/2012.01520v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'cs.PF', 'stat.CO']",,,[]
"Enabling New Flexibility in the SUNDIALS Suite of Nonlinear and
  Differential/Algebraic Equation Solvers",http://arxiv.org/abs/2011.10073v2,2020-11-19T19:13:38Z,2021-09-23T03:35:54Z,"  In recent years, the SUite of Nonlinear and DIfferential/ALgebraic equation
Solvers (SUNDIALS) has been redesigned to better enable the use of
application-specific and third-party algebraic solvers and data structures.
Throughout this work, we have adhered to specific guiding principles that
minimized the impact to current users while providing maximum flexibility for
later evolution of solvers and data structures. The redesign was done through
the addition of new linear and nonlinear solvers classes, enhancements to the
vector class, and the creation of modern Fortran interfaces. The vast majority
of this work has been performed ""behind-the-scenes,"" with minimal changes to
the user interface and no reduction in solver capabilities or performance.
These changes allow SUNDIALS users to more easily utilize external solver
libraries and create highly customized solvers, enabling greater flexibility on
extreme-scale, heterogeneous computational architectures.
","['\nDavid J. Gardner\n', '\nDaniel R. Reynolds\n', '\nCarol S. Woodward\n', '\nCody J. Balos\n']",,"ACM Transactions on Mathematical Software, Volume 48, Issue 3,
  September 2022, Article No.: 31",http://dx.doi.org/10.1145/3539801,cs.MS,['cs.MS'],10.1145/3539801,,[]
Scalable Local Timestepping on Octree Grids,http://arxiv.org/abs/2011.10570v1,2020-11-19T21:44:23Z,2020-11-19T21:44:23Z,"  Numerical solutions of hyperbolic partial differential equations(PDEs) are
ubiquitous in science and engineering. Method of lines is a popular approach to
discretize PDEs defined in spacetime, where space and time are discretized
independently. When using explicit timesteppers on adaptive grids, the use of a
global timestep-size dictated by the finest grid-spacing leads to
inefficiencies in the coarser regions. Even though adaptive space
discretizations are widely used in computational sciences, temporal adaptivity
is less common due to its sophisticated nature. In this paper, we present
highly scalable algorithms to enable local timestepping (LTS) for explicit
timestepping schemes on fully adaptive octrees. We demonstrate the accuracy of
our methods as well as the scalability of our framework across 16K cores in
TACC's Frontera. We also present a speed up estimation model for LTS, which
predicts the speedup compared to global timestepping (GTS) with an average of
0.1 relative error.
","['\nMilinda Fernando\n', '\nHari Sundar\n']",,,http://arxiv.org/abs/2011.10570v1,cs.MS,['cs.MS'],,,[]
Threaded Gröbner Bases: a Macaulay2 package,http://arxiv.org/abs/2011.08126v2,2020-11-16T17:46:50Z,2021-01-13T20:54:38Z,"  The complexity of Gr\""{o}bner computations has inspired many improvements to
Buchberger's algorithm over the years. Looking for further insights into the
algorithm's performance, we offer a threaded implementation of classical
Buchberger's algorithm in {\it Macaulay2}. The output of the main function of
the package includes information about {\it lineages} of non-zero remainders
that are added to the basis during the computation. This information can be
used for further algorithm improvements and optimization.
","['\nSonja Petrović\n', '\nShahrzad Jamshidi Zelenberg\n']","5 pages, package in revision",J. Softw. Alg. Geom. 11 (2021) 123-127,http://dx.doi.org/10.2140/jsag.2021.11.123,math.AC,"['math.AC', 'cs.MS', '13P10']",10.2140/jsag.2021.11.123,,[]
Deep Learning Framework From Scratch Using Numpy,http://arxiv.org/abs/2011.08461v1,2020-11-17T06:28:05Z,2020-11-17T06:28:05Z,"  This work is a rigorous development of a complete and general-purpose deep
learning framework from the ground up. The fundamental components of deep
learning - automatic differentiation and gradient methods of optimizing
multivariable scalar functions - are developed from elementary calculus and
implemented in a sensible object-oriented approach using only Python and the
Numpy library. Demonstrations of solved problems using the framework, named
ArrayFlow, include a computer vision classification task, solving for the shape
of a catenary, and a 2nd order differential equation.
",['\nAndrei Nicolae\n'],"11 pages, 5 figures",,http://arxiv.org/abs/2011.08461v1,cs.MS,"['cs.MS', 'cs.LG']",,,[]
"PIFE-PIC: Parallel Immersed-Finite-Element Particle-In-Cell For 3-D
  Kinetic Simulations of Plasma-Material Interactions",http://arxiv.org/abs/2011.10214v1,2020-11-20T04:53:16Z,2020-11-20T04:53:16Z,"  This paper presents a recently developed particle simulation code package
PIFE-PIC, which is a novel three-dimensional (3-D) Parallel
Immersed-Finite-Element (IFE) Particle-in-Cell (PIC) simulation model for
particle simulations of plasma-material interactions. This framework is based
on the recently developed non-homogeneous electrostatic IFE-PIC algorithm,
which is designed to handle complex plasma-material interface conditions
associated with irregular geometries using a Cartesian-mesh-based PIC.
Three-dimensional domain decomposition is utilized for both the electrostatic
field solver with IFE and the particle operations in PIC to distribute the
computation among multiple processors. A simulation of the
orbital-motion-limited (OML) sheath of a dielectric sphere immersed in a
stationary plasma is carried out to validate PIFE-PIC and profile the parallel
performance of the code package. Furthermore, a large-scale simulation of
plasma charging at a lunar crater containing 2 million PIC cells (10 million
FE/IFE cells) and about 520 million particles, running for 20,000 PIC steps in
about 109 wall-clock hours, is presented to demonstrate the high-performance
computing capability of PIFE-PIC.
","['\nDaoru Han\n', '\nXiaoming He\n', '\nDavid Lund\n', '\nXu Zhang\n']",,,http://arxiv.org/abs/2011.10214v1,cs.MS,"['cs.MS', 'cs.CE']",,,[]
tvopt: A Python Framework for Time-Varying Optimization,http://arxiv.org/abs/2011.07119v2,2020-11-12T16:14:09Z,2021-09-08T13:42:27Z,"  This paper introduces tvopt, a Python framework for prototyping and
benchmarking time-varying (or online) optimization algorithms. The paper first
describes the theoretical approach that informed the development of tvopt. Then
it discusses the different components of the framework and their use for
modeling and solving time-varying optimization problems. In particular, tvopt
provides functionalities for defining both centralized and distributed online
problems, and a collection of built-in algorithms to solve them, for example
gradient-based methods, ADMM and other splitting methods. Moreover, the
framework implements prediction strategies to improve the accuracy of the
online solvers. The paper then proposes some numerical results on a benchmark
problem and discusses their implementation using tvopt. The code for tvopt is
available at https://github.com/nicola-bastianello/tvopt.
",['\nNicola Bastianello\n'],"Code available here: https://github.com/nicola-bastianello/tvopt --
  IEEE CDC'21 paper",,http://arxiv.org/abs/2011.07119v2,cs.MS,"['cs.MS', 'cs.LG', 'math.OC']",,,[]
RCHOL: Randomized Cholesky Factorization for Solving SDD Linear Systems,http://arxiv.org/abs/2011.07769v4,2020-11-16T08:08:05Z,2021-09-02T19:44:25Z,"  We introduce a randomized algorithm, namely RCHOL, to construct an
approximate Cholesky factorization for a given Laplacian matrix (a.k.a., graph
Laplacian). From a graph perspective, the exact Cholesky factorization
introduces a clique in the underlying graph after eliminating a row/column. By
randomization, RCHOL only retains a sparse subset of the edges in the clique
using a random sampling developed by Spielman and Kyng. We prove RCHOL is
breakdown-free and apply it to solving large sparse linear systems with
symmetric diagonally dominant matrices. In addition, we parallelize RCHOL based
on the nested dissection ordering for shared-memory machines. We report
numerical experiments that demonstrate the robustness and the scalability of
RCHOL. For example, our parallel code scaled up to 64 threads on a single node
for solving the 3D Poisson equation, discretized with the 7-point stencil on a
$1024\times 1024 \times 1024$ grid, a problem that has one billion unknowns.
","['\nChao Chen\n', '\nTianyu Liang\n', '\nGeorge Biros\n']",,,http://arxiv.org/abs/2011.07769v4,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"A simple technique for unstructured mesh generation via adaptive finite
  elements",http://arxiv.org/abs/2011.07919v2,2020-11-16T13:12:33Z,2021-02-01T13:59:46Z,"  This work describes a concise algorithm for the generation of triangular
meshes with the help of standard adaptive finite element methods. We
demonstrate that a generic adaptive finite element solver can be repurposed
into a triangular mesh generator if a robust mesh smoothing algorithm is
applied between the mesh refinement steps. We present an implementation of the
mesh generator and demonstrate the resulting meshes via examples.
",['\nTom Gustafsson\n'],,,http://arxiv.org/abs/2011.07919v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Ginkgo -- A Math Library designed for Platform Portability,http://arxiv.org/abs/2011.08879v1,2020-11-17T19:10:12Z,2020-11-17T19:10:12Z,"  The first associations to software sustainability might be the existence of a
continuous integration (CI) framework; the existence of a testing framework
composed of unit tests, integration tests, and end-to-end tests; and also the
existence of software documentation. However, when asking what is a common
deathblow for a scientific software product, it is often the lack of platform
and performance portability. Against this background, we designed the Ginkgo
library with the primary focus on platform portability and the ability to not
only port to new hardware architectures, but also achieve good performance. In
this paper we present the Ginkgo library design, radically separating
algorithms from hardware-specific kernels forming the distinct hardware
executors, and report our experience when adding execution backends for NVIDIA,
AMD, and Intel GPUs. We also comment on the different levels of performance
portability, and the performance we achieved on the distinct hardware backends.
","['\nTerry Cojean\n', '\nYu-Hsiang ""Mike"" Tsai\n', '\nHartwig Anzt\n']",Submitted to Parallel Computing Journal (PARCO),,http://arxiv.org/abs/2011.08879v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF', 'cs.SE']",,,[]
"Efficient space-time reduced order model for linear dynamical systems in
  Python using less than 120 lines of code",http://arxiv.org/abs/2011.10648v1,2020-11-20T21:31:58Z,2020-11-20T21:31:58Z,"  A classical reduced order model (ROM) for dynamical problems typically
involves only the spatial reduction of a given problem. Recently, a novel
space-time ROM for linear dynamical problems has been developed, which further
reduces the problem size by introducing a temporal reduction in addition to a
spatial reduction without much loss in accuracy. The authors show an order of a
thousand speed-up with a relative error of less than 0.00001 for a large-scale
Boltzmann transport problem. In this work, we present for the first time the
derivation of the space-time Petrov-Galerkin projection for linear dynamical
systems and its corresponding block structures. Utilizing these block
structures, we demonstrate the ease of construction of the space-time ROM
method with two model problems: 2D diffusion and 2D convection diffusion, with
and without a linear source term. For each problem, we demonstrate the entire
process of generating the full order model (FOM) data, constructing the
space-time ROM, and predicting the reduced-order solutions, all in less than
120 lines of Python code. We compare our Petrov-Galerkin method with the
traditional Galerkin method and show that the space-time ROMs can achieve
O(100) speed-ups with O(0.001) to O(0.0001) relative errors for these problems.
Finally, we present an error analysis for the space-time Petrov-Galerkin
projection and derive an error bound, which shows an improvement compared to
traditional spatial Galerkin ROM methods.
","['\nYoungkyu Kim\n', '\nKaren May Wang\n', '\nYoungsoo Choi\n']","24 pages, 18 figures",,http://dx.doi.org/10.3390/math9141690,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.3390/math9141690,,[]
Toward Performance-Portable PETSc for GPU-based Exascale Systems,http://arxiv.org/abs/2011.00715v2,2020-11-02T04:05:29Z,2021-09-29T18:39:39Z,"  The Portable Extensible Toolkit for Scientific computation (PETSc) library
delivers scalable solvers for nonlinear time-dependent differential and
algebraic equations and for numerical optimization.The PETSc design for
performance portability addresses fundamental GPU accelerator challenges and
stresses flexibility and extensibility by separating the programming model used
by the application from that used by the library, and it enables application
developers to use their preferred programming model, such as Kokkos, RAJA,
SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using
GPUs from PETSc-based codes is provided, and case studies emphasize the
flexibility and high performance achieved on current GPU-based systems.
","['\nRichard Tran Mills\n', '\nMark F. Adams\n', '\nSatish Balay\n', '\nJed Brown\n', '\nAlp Dener\n', '\nMatthew Knepley\n', '\nScott E. Kruger\n', '\nHannah Morgan\n', '\nTodd Munson\n', '\nKarl Rupp\n', '\nBarry F. Smith\n', '\nStefano Zampini\n', '\nHong Zhang\n', '\nJunchao Zhang\n']","15 pages, 10 figures, 2 tables",,http://arxiv.org/abs/2011.00715v2,cs.MS,"['cs.MS', 'cs.DC', '65F10, 65F50, 68N99, 68W10', 'G.4']",,,[]
Calcium: computing in exact real and complex fields,http://arxiv.org/abs/2011.01728v1,2020-11-03T14:22:18Z,2020-11-03T14:22:18Z,"  Calcium is a C library for real and complex numbers in a form suitable for
exact algebraic and symbolic computation. Numbers are represented as elements
of fields $\mathbb{Q}(a_1,\ldots,a_n)$ where the extensions numbers $a_k$ may
be algebraic or transcendental. The system combines efficient field operations
with automatic discovery and certification of algebraic relations, resulting in
a practical computational model of $\mathbb{R}$ and $\mathbb{C}$ in which
equality is rigorously decidable for a large class of numbers.
",['\nFredrik Johansson\nLFANT\n'],,,http://arxiv.org/abs/2011.01728v1,cs.MS,"['cs.MS', 'cs.SC']",,,['LFANT']
"Extending the statistical software package Engine for Likelihood-Free
  Inference",http://arxiv.org/abs/2011.03977v1,2020-11-08T13:22:37Z,2020-11-08T13:22:37Z,"  Bayesian inference is a principled framework for dealing with uncertainty.
The practitioner can perform an initial assumption for the physical phenomenon
they want to model (prior belief), collect some data and then adjust the
initial assumption in the light of the new evidence (posterior belief).
Approximate Bayesian Computation (ABC) methods, also known as likelihood-free
inference techniques, are a class of models used for performing inference when
the likelihood is intractable. The unique requirement of these models is a
black-box sampling machine. Due to the modelling-freedom they provide these
approaches are particularly captivating. Robust Optimisation Monte Carlo (ROMC)
is one of the most recent techniques of the specific domain. It approximates
the posterior distribution by solving independent optimisation problems. This
dissertation focuses on the implementation of the ROMC method in the software
package Engine for Likelihood-Free Inference (ELFI). In the first chapters, we
provide the mathematical formulation and the algorithmic description of the
ROMC approach. In the following chapters, we describe our implementation; (a)
we present all the functionalities provided to the user and (b) we demonstrate
how to perform inference on some real examples. Our implementation provides a
robust and efficient solution to a practitioner who wants to perform inference
on a simulator-based model. Furthermore, it exploits parallel processing for
accelerating the inference wherever it is possible. Finally, it has been
designed to serve extensibility; the user can easily replace specific subparts
of the method without significant overhead on the development side. Therefore,
it can be used by a researcher for further experimentation.
","['\nVasileios Gkolemis\n', '\nMichael Gutmann\n']",,,http://arxiv.org/abs/2011.03977v1,cs.LG,"['cs.LG', 'cs.MS']",,,[]
"c-lasso -- a Python package for constrained sparse and robust regression
  and classification",http://arxiv.org/abs/2011.00898v1,2020-11-02T11:16:27Z,2020-11-02T11:16:27Z,"  We introduce c-lasso, a Python package that enables sparse and robust linear
regression and classification with linear equality constraints. The underlying
statistical forward model is assumed to be of the following form: \[ y = X
\beta + \sigma \epsilon \qquad \textrm{subject to} \qquad C\beta=0 \] Here, $X
\in \mathbb{R}^{n\times d}$is a given design matrix and the vector $y \in
\mathbb{R}^{n}$ is a continuous or binary response vector. The matrix $C$ is a
general constraint matrix. The vector $\beta \in \mathbb{R}^{d}$ contains the
unknown coefficients and $\sigma$ an unknown scale. Prominent use cases are
(sparse) log-contrast regression with compositional data $X$, requiring the
constraint $1_d^T \beta = 0$ (Aitchion and Bacon-Shone 1984) and the
Generalized Lasso which is a special case of the described problem (see, e.g,
(James, Paulson, and Rusmevichientong 2020), Example 3). The c-lasso package
provides estimators for inferring unknown coefficients and scale (i.e.,
perspective M-estimators (Combettes and M\""uller 2020a)) of the form \[
\min_{\beta \in \mathbb{R}^d, \sigma \in \mathbb{R}_{0}} f\left(X\beta -
y,{\sigma} \right) + \lambda \left\lVert \beta\right\rVert_1 \qquad
\textrm{subject to} \qquad C\beta = 0 \] for several convex loss functions
$f(\cdot,\cdot)$. This includes the constrained Lasso, the constrained scaled
Lasso, and sparse Huber M-estimators with linear equality constraints.
","['\nLéo Simpson\n', '\nPatrick L. Combettes\n', '\nChristian L. Müller\n']",,,http://arxiv.org/abs/2011.00898v1,stat.CO,"['stat.CO', 'cs.MS', 'math.OC', 'stat.ML']",,,[]
"Tinker-HP : Accelerating Molecular Dynamics Simulations of Large Complex
  Systems with Advanced Point Dipole Polarizable Force Fields using GPUs and
  Multi-GPUs systems",http://arxiv.org/abs/2011.01207v4,2020-11-02T18:50:39Z,2021-03-03T20:01:20Z,"  We present the extension of the Tinker-HP package (Lagard\`ere et al., Chem.
Sci., 2018,9, 956-972) to the use of Graphics Processing Unit (GPU) cards to
accelerate molecular dynamics simulations using polarizable many-body force
fields. The new high-performance module allows for an efficient use of single-
and multi-GPU architectures ranging from research laboratories to modern
supercomputer centers. After detailing an analysis of our general scalable
strategy that relies on OpenACC and CUDA, we discuss the various capabilities
of the package. Among them, the multi-precision possibilities of the code are
discussed. If an efficient double precision implementation is provided to
preserve the possibility of fast reference computations, we show that a lower
precision arithmetic is preferred providing a similar accuracy for molecular
dynamics while exhibiting superior performances. As Tinker-HP is mainly
dedicated to accelerate simulations using new generation point dipole
polarizable force field, we focus our study on the implementation of the AMOEBA
model. Testing various NVIDIA platforms including 2080Ti, 3090, V100 and A100
cards, we provide illustrative benchmarks of the code for single- and
multi-cards simulations on large biosystems encompassing up to millions of
atoms. The new code strongly reduces time to solution and offers the best
performances to date obtained using the AMOEBA polarizable force field.
Perspectives toward the strong-scaling performance of our multi-node massive
parallelization strategy, unsupervised adaptive sampling and large scale
applicability of the Tinker-HP code in biophysics are discussed. The present
software has been released in phase advance on GitHub in link with the High
Performance Computing community COVID-19 research efforts and is free for
Academics (see https://github.com/TinkerTools/tinker-hp).
","['\nOlivier Adjoua\n', '\nLouis Lagardère\n', '\nLuc-Henri Jolly\n', '\nArnaud Durocher\n', '\nThibaut Very\n', '\nIsabelle Dupays\n', '\nZhi Wang\n', '\nThéo Jaffrelot Inizan\n', '\nFrédéric Célerse\n', '\nPengyu Ren\n', '\nJay W. Ponder\n', '\nJean-Philip Piquemal\n']",,"Journal of Chemical Theory and Computation, 2021, 17, 4, 2034-2053",http://dx.doi.org/10.1021/acs.jctc.0c01164,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS', 'physics.chem-ph']",10.1021/acs.jctc.0c01164,,[]
"Improving the Performance of the GMRES Method using Mixed-Precision
  Techniques",http://arxiv.org/abs/2011.01850v1,2020-11-03T17:12:35Z,2020-11-03T17:12:35Z,"  The GMRES method is used to solve sparse, non-symmetric systems of linear
equations arising from many scientific applications. The solver performance
within a single node is memory bound, due to the low arithmetic intensity of
its computational kernels. To reduce the amount of data movement, and thus, to
improve performance, we investigated the effect of using a mix of single and
double precision while retaining double-precision accuracy. Previous efforts
have explored reduced precision in the preconditioner, but the use of reduced
precision in the solver itself has received limited attention. We found that
GMRES only needs double precision in computing the residual and updating the
approximate solution to achieve double-precision accuracy, although it must
restart after each improvement of single-precision accuracy. This finding holds
for the tested orthogonalization schemes: Modified Gram-Schmidt (MGS) and
Classical Gram-Schmidt with Re-orthogonalization (CGSR). Furthermore, our
mixed-precision GMRES, when restarted at least once, performed 19% and 24%
faster on average than double-precision GMRES for MGS and CGSR, respectively.
Our implementation uses generic programming techniques to ease the burden of
coding implementations for different data types. Our use of the Kokkos library
allowed us to exploit parallelism and optimize data management. Additionally,
KokkosKernels was used when producing performance results. In conclusion, using
a mix of single and double precision in GMRES can improve performance while
retaining double-precision accuracy.
","['\nNeil Lindquist\n', '\nPiotr Luszczek\n', '\nJack Dongarra\n']","16 pages. In the 17th Smoky Mountains Computational Sciences and
  Engineering Conference",,http://arxiv.org/abs/2011.01850v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
DoWhy: An End-to-End Library for Causal Inference,http://arxiv.org/abs/2011.04216v1,2020-11-09T06:22:11Z,2020-11-09T06:22:11Z,"  In addition to efficient statistical estimators of a treatment's effect,
successful application of causal inference requires specifying assumptions
about the mechanisms underlying observed data and testing whether they are
valid, and to what extent. However, most libraries for causal inference focus
only on the task of providing powerful statistical estimators. We describe
DoWhy, an open-source Python library that is built with causal assumptions as
its first-class citizens, based on the formal framework of causal graphs to
specify and test causal assumptions. DoWhy presents an API for the four steps
common to any causal analysis---1) modeling the data using a causal graph and
structural assumptions, 2) identifying whether the desired effect is estimable
under the causal model, 3) estimating the effect using statistical estimators,
and finally 4) refuting the obtained estimate through robustness checks and
sensitivity analyses. In particular, DoWhy implements a number of robustness
checks including placebo tests, bootstrap tests, and tests for unoberved
confounding. DoWhy is an extensible library that supports interoperability with
other implementations, such as EconML and CausalML for the the estimation step.
The library is available at https://github.com/microsoft/dowhy
","['\nAmit Sharma\n', '\nEmre Kiciman\n']",5 pages,,http://arxiv.org/abs/2011.04216v1,stat.ME,"['stat.ME', 'cs.AI', 'cs.MS', 'econ.EM']",,,[]
"Solving large number of non-stiff, low-dimensional ordinary differential
  equation systems on GPUs and CPUs: performance comparisons of MPGOS, ODEINT
  and DifferentialEquations.jl",http://arxiv.org/abs/2011.01740v1,2020-11-02T09:40:24Z,2020-11-02T09:40:24Z,"  In this paper, the performance characteristics of different solution
techniques and program packages to solve a large number of independent ordinary
differential equation systems is examined. The employed hardware are an Intel
Core i7-4820K CPU with 30.4 GFLOPS peak double-precision performance per cores
and an Nvidia GeForce Titan Black GPU that has a total of 1707 GFLOPS peak
double-precision performance. The tested systems (Lorenz equation,
Keller--Miksis equation and a pressure relief valve model) are non-stiff and
have low dimension. Thus, the performance of the codes are not limited by
memory bandwidth, and Runge--Kutta type solvers are efficient and suitable
choices. The tested program packages are MPGOS written in C++ and specialised
only for GPUs; ODEINT implemented in C++, which supports execution on both CPUs
and GPUs; finally, DifferentialEquations.jl written in Julia that also supports
execution on both CPUs and GPUs. Using GPUs, the program package MPGOS is
superior. For CPU computations, the ODEINT program package has the best
performance.
","['\nDániel Nagy\n', '\nLambert Plavecz\n', '\nFerenc Hegedűs\n']",,,http://arxiv.org/abs/2011.01740v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'cs.PF', 'math.NA']",,,[]
LightSeq: A High Performance Inference Library for Transformers,http://arxiv.org/abs/2010.13887v4,2020-10-23T13:45:26Z,2021-04-22T09:37:37Z,"  Transformer, BERT and their variants have achieved great success in natural
language processing. Since Transformer models are huge in size, serving these
models is a challenge for real industrial applications. In this paper, we
propose LightSeq, a highly efficient inference library for models in the
Transformer family. LightSeq includes a series of GPU optimization techniques
to to streamline the computation of neural layers and to reduce memory
footprint. LightSeq can easily import models trained using PyTorch and
Tensorflow. Experimental results on machine translation benchmarks show that
LightSeq achieves up to 14x speedup compared with TensorFlow and 1.4x compared
with FasterTransformer, a concurrent CUDA implementation. The code is available
at https://github.com/bytedance/lightseq.
","['\nXiaohui Wang\n', '\nYing Xiong\n', '\nYang Wei\n', '\nMingxuan Wang\n', '\nLei Li\n']","8 pages, 6 figures, accepted by NAACL 2021 Industry Track",,http://arxiv.org/abs/2010.13887v4,cs.MS,"['cs.MS', 'cs.LG']",,,[]
A comparison of techniques for solving the Poisson equation in CFD,http://arxiv.org/abs/2010.14132v1,2020-10-27T08:43:53Z,2020-10-27T08:43:53Z,"  CFD is a ubiquitous technique central to much of computational simulation
such as that required by aircraft design. Solving of the Poisson equation
occurs frequently in CFD and there are a number of possible approaches one may
leverage. The dynamical core of the MONC atmospheric model is one example of
CFD which requires the solving of the Poisson equation to determine pressure
terms. Traditionally this aspect of the model has been very time consuming
and-so it is important to consider how we might reduce the runtime cost.
  In this paper we survey the different approaches implemented in MONC to
perform the pressure solve. Designed to take advantage of large scale, modern,
HPC machines, we are concerned with the computation and communication behaviour
of the available techniques and in this text we focus on direct FFT and
indirect iterative methods. In addition to describing the implementation of
these techniques we illustrate on up to 32768 processor cores of a Cray XC30
both the performance and scalability of our approaches. Raw runtime is not the
only measure so we also make some comments around the stability and accuracy of
solution. The result of this work are a number of techniques, optimised for
large scale HPC systems, and an understanding of which is most appropriate in
different situations.
",['\nNick Brown\n'],"Pre-print of paper in the Journal of Civil Aircraft Design and
  Research 2017-03",Journal of Civil Aircraft Design and Research pages 85-94 2017-03,http://arxiv.org/abs/2010.14132v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"DistStat.jl: Towards Unified Programming for High-Performance
  Statistical Computing Environments in Julia",http://arxiv.org/abs/2010.16114v1,2020-10-30T08:16:47Z,2020-10-30T08:16:47Z,"  The demand for high-performance computing (HPC) is ever-increasing for
everyday statistical computing purposes. The downside is that we need to write
specialized code for each HPC environment. CPU-level parallelization needs to
be explicitly coded for effective use of multiple nodes in cluster
supercomputing environments. Acceleration via graphics processing units (GPUs)
requires to write kernel code. The Julia software package DistStat.jl
implements a data structure for distributed arrays that work on both multi-node
CPU clusters and multi-GPU environments transparently. This package paves a way
to developing high-performance statistical software in various HPC environments
simultaneously. As a demonstration of the transparency and scalability of the
package, we provide applications to large-scale nonnegative matrix
factorization, multidimensional scaling, and $\ell_1$-regularized Cox
proportional hazards model on an 8-GPU workstation and a 720-CPU-core virtual
cluster in Amazon Web Services (AWS) cloud. As a case in point, we analyze the
on-set of type-2 diabetes from the UK Biobank with 400,000 subjects and 500,000
single nucleotide polymorphisms using the $\ell_1$-regularized Cox proportional
hazards model. Fitting a half-million-variate regression model took less than
50 minutes on AWS.
","['\nSeyoon Ko\n', '\nHua Zhou\n', '\nJin Zhou\n', '\nJoong-Ho Won\n']",,,http://arxiv.org/abs/2010.16114v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
"Textbook efficiency: massively parallel matrix-free multigrid for the
  Stokes system",http://arxiv.org/abs/2010.13513v1,2020-10-26T12:11:55Z,2020-10-26T12:11:55Z,"  We employ textbook multigrid efficiency (TME), as introduced by Achi Brandt,
to construct an asymptotically optimal monolithic multigrid solver for the
Stokes system. The geometric multigrid solver builds upon the concept of
hierarchical hybrid grids (HHG), which is extended to higher-order
finite-element discretizations, and a corresponding matrix-free implementation.
The computational cost of the full multigrid (FMG) iteration is quantified, and
the solver is applied to multiple benchmark problems. Through a parameter
study, we suggest configurations that achieve TME for both, stabilized
equal-order, and Taylor-Hood discretizations. The excellent node-level
performance of the relevant compute kernels is presented via a roofline
analysis. Finally, we demonstrate the weak and strong scalability to up to
$147,456$ parallel processes and solve Stokes systems with more than $3.6
\times 10^{12}$ (trillion) unknowns.
","['\nNils Kohl\n', '\nUlrich Rüde\n']","22 pages, 7 figures",,http://arxiv.org/abs/2010.13513v1,cs.CE,"['cs.CE', 'cs.MS', 'cs.NA', 'math.NA', '65F10, 65N30, 65N55']",,,[]
"Generalized eigen, singular value, and partial least squares
  decompositions: The GSVD package",http://arxiv.org/abs/2010.14734v3,2020-10-28T03:57:27Z,2020-11-17T23:59:48Z,"  The generalized singular value decomposition (GSVD, a.k.a. ""SVD triplet"",
""duality diagram"" approach) provides a unified strategy and basis to perform
nearly all of the most common multivariate analyses (e.g., principal
components, correspondence analysis, multidimensional scaling, canonical
correlation, partial least squares). Though the GSVD is ubiquitous, powerful,
and flexible, it has very few implementations. Here I introduce the GSVD
package for R. The general goal of GSVD is to provide a small set of accessible
functions to perform the GSVD and two other related decompositions (generalized
eigenvalue decomposition, generalized partial least squares-singular value
decomposition). Furthermore, GSVD helps provide a more unified conceptual
approach and nomenclature to many techniques. I first introduce the concept of
the GSVD, followed by a formal definition of the generalized decompositions.
Next I provide some key decisions made during development, and then a number of
examples of how to use GSVD to implement various statistical techniques. These
examples also illustrate one of the goals of GSVD: how others can (or should)
build analysis packages that depend on GSVD. Finally, I discuss the possible
future of GSVD.
","['\nDerek Beaton\nRotman Research Institute, Baycrest Health Sciences\n']","38 pages, 9 figures, 3 tables",,http://arxiv.org/abs/2010.14734v3,cs.MS,"['cs.MS', 'cs.LG', 'stat.CO', 'stat.ME']",,,"['Rotman Research Institute, Baycrest Health Sciences']"
"Parallelizing multiple precision Taylor series method for integrating
  the Lorenz system",http://arxiv.org/abs/2010.14993v3,2020-10-26T09:28:08Z,2020-11-27T17:42:38Z,"  A hybrid MPI+OpenMP strategy for parallelizing multiple precision Taylor
series method is proposed, realized and tested. To parallelize the algorithm we
combine MPI and OpenMP parallel technologies together with GMP library (GNU
miltiple precision libary) and the tiny MPIGMP library. The details of the
parallelization are explained on the paradigmatic model of the Lorenz system.
We succeed to obtain a correct reference solution in the rather long time
interval - [0,7000]. The solution is verified by comparing the results for
2700-th order Taylor series method and precision of ~ 3374 decimal digits, and
those with 2800-th order and precision of ~ 3510 decimal digits. With 192 CPU
cores in Nestum cluster, Sofia, Bulgaria, the 2800-th order computation was ~
145 hours with speedup ~ 105.
","['\nI. Hristov\n', '\nR. Hristova\n', '\nS. Dimova\n', '\nP. Armyanov\n', '\nN. Shegunov\n', '\nI. Puzynin\n', '\nT. Puzynina\n', '\nZ. Sharipov\n', '\nZ. Tukhliev\n']",arXiv admin note: text overlap with arXiv:1908.09301,"Advanced Computing in Industrial Mathematics. BGSIAM 2020. Studies
  in Computational Intelligence, vol 1076. Springer, Cham",http://dx.doi.org/10.1007/978-3-031-20951-2_6,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.DS', 'math.NA', '65L05, 65Y05', 'G.1.7; G.1.0']",10.1007/978-3-031-20951-2_6,,[]
Temporal Vectorization for Stencils,http://arxiv.org/abs/2010.04868v1,2020-10-10T01:47:34Z,2020-10-10T01:47:34Z,"  Stencil computations represent a very common class of nested loops in
scientific and engineering applications. Exploiting vector units in modern CPUs
is crucial to achieving peak performance. Previous vectorization approaches
often consider the data space, in particular the innermost unit-strided loop.
It leads to the well-known data alignment conflict problem that vector loads
are overlapped due to the data sharing between continuous stencil computations.
This paper proposes a novel temporal vectorization scheme for stencils. It
vectorizes the stencil computation in the iteration space and assembles points
with different time coordinates in one vector. The temporal vectorization leads
to a small fixed number of vector reorganizations that is irrelevant to the
vector length, stencil order, and dimension. Furthermore, it is also applicable
to Gauss-Seidel stencils, whose vectorization is not well-studied. The
effectiveness of the temporal vectorization is demonstrated by various Jacobi
and Gauss-Seidel stencils.
","['\nLiang Yuan\n', '\nHang Cao\n', '\nYunquan Zhang\n', '\nKun Li\n', '\nPengqi Lu\n', '\nYue Yue\n']",,,http://arxiv.org/abs/2010.04868v1,cs.MS,"['cs.MS', 'cs.PF']",,,[]
DSLib: An open source library for the dominant set clustering method,http://arxiv.org/abs/2010.07906v1,2020-10-15T17:36:48Z,2020-10-15T17:36:48Z,"  DSLib is an open-source implementation of the Dominant Set (DS) clustering
algorithm written entirely in Matlab. The DS method is a graph-based clustering
technique rooted in the evolutionary game theory that starts gaining lots of
interest in the computer science community. Thanks to its duality with game
theory and its strict relation to the notion of maximal clique, has been
explored in several directions not only related to clustering problems.
Applications in graph matching, segmentation, classification and medical
imaging are common in literature. This package provides an implementation of
the original DS clustering algorithm since no code has been officially released
yet, together with a still growing collection of methods and variants related
to it. Our library is integrable into a Matlab pipeline without dependencies,
it is simple to use and easily extendable for upcoming works. The latest source
code, the documentation and some examples can be downloaded from
https://xwasco.github.io/DominantSetLibrary.
","['\nSebastiano Vascon\n', '\nSamuel Rota Bulò\n', '\nVittorio Murino\n', '\nMarcello Pelillo\n']",,,http://arxiv.org/abs/2010.07906v1,cs.MS,"['cs.MS', 'cs.LG']",,,[]
"CAPD::DynSys: a flexible C++ toolbox for rigorous numerical analysis of
  dynamical systems",http://arxiv.org/abs/2010.07097v1,2020-10-14T13:53:54Z,2020-10-14T13:53:54Z,"  We present the CAPD::DynSys library for rigorous numerical analysis of
dynamical systems. The basic interface is described together with several
interesting case studies illustrating how it can be used for computer-assisted
proofs in dynamics of ODEs.
","['\nTomasz Kapela\n', '\nMarian Mrozek\n', '\nDaniel Wilczak\n', '\nPiotr Zgliczyński\n']","25 pages, 4 figures, 11 full C++ examples",,http://dx.doi.org/10.1016/j.cnsns.2020.105578,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.DS']",10.1016/j.cnsns.2020.105578,,[]
The Polylogarithm Function in Julia,http://arxiv.org/abs/2010.09860v1,2020-10-16T06:35:17Z,2020-10-16T06:35:17Z,"  The polylogarithm function is one of the constellation of important
mathematical functions. It has a long history, and many connections to other
special functions and series, and many applications, for instance in
statistical physics. However, the practical aspects of its numerical evaluation
have not received the type of comprehensive treatments lavished on its
siblings. Only a handful of formal publications consider the evaluation of the
function, and most focus on a specific domain and/or presume arbitrary
precision arithmetic will be used. And very little of the literature contains
any formal validation of numerical performance. In this paper we present an
algorithm for calculating polylogarithms for both complex parameter and
argument and evaluate it thoroughly in comparison to the arbitrary precision
implementation in Mathematica. The implementation was created in a new
scientific computing language Julia, which is ideal for the purpose, but also
allows us to write the code in a simple, natural manner so as to make it easy
to port the implementation to other such languages.
",['\nMatthew Roughan\n'],,,http://arxiv.org/abs/2010.09860v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '33E20, 33F05, 65B10']",,,[]
Combining the Mersenne Twister and the Xorgens Designs,http://arxiv.org/abs/2011.07963v1,2020-10-10T17:50:47Z,2020-10-10T17:50:47Z,"  We combine the design of two \emph{random number generators}, \emph{Mersenne
Twister} and \emph{Xorgens}, to obtain a new class of generators with
heavy-weight characteristic polynomials (exceeded only by the {\sc well}
generators) and high speed (comparable with the originals). Tables with
parameter combinations are included for state sizes ranging from 521 to 44497
bits and each of the word lengths 32, 64, 128. These generators passed all
tests of the \emph{TestU01}-package for each 32-bit integer part and each
64-bit derived real part of the output. We determine \emph{dimension gaps} for
32-bit words, neglecting the non-linear tempering, and compare with an
alternative experimental linear tempering.
",['\nMarcel Van de Vel\n'],"8 pages, 5 tables",,http://arxiv.org/abs/2011.07963v1,cs.DS,"['cs.DS', 'cs.MS', 'math.CO', '11K45, 12E05, 12E20']",,,[]
"VECMAtk: A Scalable Verification, Validation and Uncertainty
  Quantification Toolkit for Scientific Simulations",http://arxiv.org/abs/2010.03923v2,2020-10-08T12:08:33Z,2020-10-11T22:07:38Z,"  We present the VECMA toolkit (VECMAtk), a flexible software environment for
single and multiscale simulations that introduces directly applicable and
reusable procedures for verification, validation (V&V), sensitivity analysis
(SA) and uncertainty quantification (UQ). It enables users to verify key
aspects of their applications, systematically compare and validate the
simulation outputs against observational or benchmark data, and run simulations
conveniently on any platform from the desktop to current multi-petascale
computers. In this sequel to our paper on VECMAtk which we presented last year,
we focus on a range of functional and performance improvements that we have
introduced, cover newly introduced components, and applications examples from
seven different domains such as conflict modelling and environmental sciences.
We also present several implemented patterns for UQ/SA and V&V, and guide the
reader through one example concerning COVID-19 modelling in detail.
","['\nD. Groen\n', '\nH. Arabnejad\n', '\nV. Jancauskas\n', '\nW. N. Edeling\n', '\nF. Jansson\n', '\nR. A. Richardson\n', '\nJ. Lakhlili\n', '\nL. Veen\n', '\nB. Bosak\n', '\nP. Kopta\n', '\nD. W. Wright\n', '\nN. Monnier\n', '\nP. Karlshoefer\n', '\nD. Suleimenova\n', '\nR. Sinclair\n', '\nM. Vassaux\n', '\nA. Nikishova\n', '\nM. Bieniek\n', '\nO. O. Luk\n', '\nM. Kulczewski\n', '\nE. Raffin\n', '\nD. Crommelin\n', '\nO. Hoenen\n', '\nD. P. Coster\n', '\nT. Piontek\n', '\nP. V. Coveney\n']","23 pages, 10 figures",,http://dx.doi.org/10.1098/rsta.2020.0221,cs.MS,['cs.MS'],10.1098/rsta.2020.0221,,[]
"Simflowny 3: An upgraded platform for scientific modelling and
  simulation",http://arxiv.org/abs/2010.00902v1,2020-10-02T10:04:30Z,2020-10-02T10:04:30Z,"  Simflowny is an open platform which automatically generates efficient
parallel code of scientific dynamical models for different simulation
frameworks. Here we present major upgrades on this software to support
simultaneously a quite generic family of partial differential equations. These
equations can be discretized using: (i) standard finite-difference for systems
with derivatives up to any order, (ii) High-Resolution-Shock-Capturing methods
to deal with shocks and discontinuities of balance law equations, and (iii)
particle-based methods. We have improved the adaptive-mesh-refinement
algorithms to preserve the convergence order of the numerical methods, which is
a requirement for improving scalability. Finally, we have also extended our
graphical user interface (GUI) to accommodate these and future families of
equations. This paper summarizes the formal representation and implementation
of these new families, providing several validation results.
","['\nC. Palenzuela\n', '\nB. Miñano\n', '\nA. Arbona\n', '\nC. Bona-Casas\n', '\nC. Bona\n', '\nJ. Massó\n']","11 pages, 6 figures, accepted in Computer Physics Communications",,http://dx.doi.org/10.1016/j.cpc.2020.107675,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1016/j.cpc.2020.107675,,[]
Extending C++ for Heterogeneous Quantum-Classical Computing,http://arxiv.org/abs/2010.03935v1,2020-10-08T12:49:07Z,2020-10-08T12:49:07Z,"  We present qcor - a language extension to C++ and compiler implementation
that enables heterogeneous quantum-classical programming, compilation, and
execution in a single-source context. Our work provides a first-of-its-kind C++
compiler enabling high-level quantum kernel (function) expression in a
quantum-language agnostic manner, as well as a hardware-agnostic, retargetable
compiler workflow targeting a number of physical and virtual quantum computing
backends. qcor leverages novel Clang plugin interfaces and builds upon the XACC
system-level quantum programming framework to provide a state-of-the-art
integration mechanism for quantum-classical compilation that leverages the best
from the community at-large. qcor translates quantum kernels ultimately to the
XACC intermediate representation, and provides user-extensible hooks for
quantum compilation routines like circuit optimization, analysis, and
placement. This work details the overall architecture and compiler workflow for
qcor, and provides a number of illuminating programming examples demonstrating
its utility for near-term variational tasks, quantum algorithm expression, and
feed-forward error correction schemes.
","['\nThien Nguyen\n', '\nAnthony Santana\n', '\nTyler Kharazi\n', '\nDaniel Claudino\n', '\nHal Finkel\n', '\nAlexander McCaskey\n']",,,http://arxiv.org/abs/2010.03935v1,quant-ph,"['quant-ph', 'cs.MS']",,,[]
Accelerating Sparse Matrix-Matrix Multiplication with GPU Tensor Cores,http://arxiv.org/abs/2009.14600v1,2020-09-29T14:10:15Z,2020-09-29T14:10:15Z,"  Sparse general matrix-matrix multiplication (spGEMM) is an essential
component in many scientific and data analytics applications. However, the
sparsity pattern of the input matrices and the interaction of their patterns
make spGEMM challenging. Modern GPUs include Tensor Core Units (TCUs), which
specialize in dense matrix multiplication. Our aim is to re-purpose TCUs for
sparse matrices. The key idea of our spGEMM algorithm, tSparse, is to multiply
sparse rectangular blocks using the mixed precision mode of TCUs. tSparse
partitions the input matrices into tiles and operates only on tiles which
contain one or more elements. It creates a task list of the tiles, and performs
matrix multiplication of these tiles using TCUs. To the best of our knowledge,
this is the first time that TCUs are used in the context of spGEMM. We show
that spGEMM, with our tiling approach, benefits from TCUs. Our approach
significantly improves the performance of spGEMM in comparison to cuSPARSE,
CUSP, RMerge2, Nsparse, AC-SpGEMM and spECK.
","['\nOrestis Zachariadis\n', '\nNitin Satpute\n', '\nJuan Gómez-Luna\n', '\nJoaquín Olivares\n']",Accepted in CAEE,Comput. Electr. Eng. 88 (2020) 106848,http://dx.doi.org/10.1016/j.compeleceng.2020.106848,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF']",10.1016/j.compeleceng.2020.106848,,[]
"Scipp: Scientific data handling with labeled multi-dimensional arrays
  for C++ and Python",http://arxiv.org/abs/2010.00257v1,2020-10-01T08:59:03Z,2020-10-01T08:59:03Z,"  Scipp is heavily inspired by the Python library xarray. It enriches raw
NumPy-like multi-dimensional arrays of data by adding named dimensions and
associated coordinates. Multiple arrays are combined into datasets. On top of
this, scipp introduces (i) implicit handling of physical units, (ii) implicit
propagation of uncertainties, (iii) support for histograms, i.e., bin-edge
coordinate axes, which exceed the data's dimension extent by one, and (iv)
support for event data. In conjunction these features enable a more natural and
more concise user experience. The combination of named dimensions, coordinates,
and units helps to drastically reduce the risk for programming errors. The core
of scipp is written in C++ to open opportunities for performance improvements
that a Python-based solution would not allow for. On top of the C++ core,
scipp's Python components provide functionality for plotting and content
representations, e.g., for use in Jupyter Notebooks. While none of scipp's
concepts in isolation is novel per-se, we are not aware of any project
combining all of these aspects in a single coherent software package.
","['\nSimon Heybrock\n', '\nOwen Arnold\n', '\nIgor Gudich\n', '\nDaniel Nixon\n', '\nNeil Vaytet\n']","Proceedings of ICANS-XXIII, 13 pages, 5 figures","Journal of Neutron Research, vol. Pre-press, no. Pre-press, pp.
  1-13, 2020",http://dx.doi.org/10.3233/JNR-190131,cs.MS,"['cs.MS', 'physics.data-an', 'physics.ins-det']",10.3233/JNR-190131,,[]
"Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations
  and visualizations via ParaMonte::Python library",http://arxiv.org/abs/2010.00724v1,2020-10-01T23:26:42Z,2020-10-01T23:26:42Z,"  ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial
and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for
sampling mathematical objective functions, in particular, the posterior
distributions of parameters in Bayesian modeling and analysis in data science,
Machine Learning, and scientific inference in general. In addition to providing
access to fast high-performance serial/parallel Monte Carlo and MCMC sampling
routines, the ParaMonte::Python library provides extensive post-processing and
visualization tools that aim to automate and streamline the process of model
calibration and uncertainty quantification in Bayesian data analysis.
Furthermore, the automatically-enabled restart functionality of
ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future
restart of Monte Carlo simulations, should any interruptions happen. The
ParaMonte::Python library is MIT-licensed and is permanently maintained on
GitHub at
https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.
","['\nAmir Shahmoradi\n', '\nFatemeh Bagheri\n', '\nJoshua Alexander Osborne\n']",to be submitted to JOSS,,http://arxiv.org/abs/2010.00724v1,cs.MS,"['cs.MS', 'astro-ph.IM', 'q-bio.QM', 'stat.ML']",,,[]
"ParaMonte: A high-performance serial/parallel Monte Carlo simulation
  library for C, C++, Fortran",http://arxiv.org/abs/2009.14229v1,2020-09-29T18:04:02Z,2020-09-29T18:04:02Z,"  ParaMonte (standing for Parallel Monte Carlo) is a serial and
MPI/Coarray-parallelized library of Monte Carlo routines for sampling
mathematical objective functions of arbitrary-dimensions, in particular, the
posterior distributions of Bayesian models in data science, Machine Learning,
and scientific inference. The ParaMonte library has been developed with the
design goal of unifying the **automation**, **accessibility**,
**high-performance**, **scalability**, and **reproducibility** of Monte Carlo
simulations. The current implementation of the library includes **ParaDRAM**, a
**Para**llel **D**elyaed-**R**ejection **A**daptive **M**etropolis Markov Chain
Monte Carlo sampler, accessible from a wide range of programming languages
including C, C++, Fortran, with a unified Application Programming Interface and
simulation environment across all supported programming languages. The
ParaMonte library is MIT-licensed and is permanently located and maintained at
[https://github.com/cdslaborg/paramonte](https://github.com/cdslaborg/paramonte).
","['\nAmir Shahmoradi\n', '\nFatemeh Bagheri\n']",submitted to JOSS,,http://arxiv.org/abs/2009.14229v1,cs.MS,"['cs.MS', 'astro-ph.IM', 'physics.data-an', 'q-bio.QM', 'stat.ML']",,,[]
"Instead of Rewriting Foreign Code for Machine Learning, Automatically
  Synthesize Fast Gradients",http://arxiv.org/abs/2010.01709v1,2020-10-04T22:32:51Z,2020-10-04T22:32:51Z,"  Applying differentiable programming techniques and machine learning
algorithms to foreign programs requires developers to either rewrite their code
in a machine learning framework, or otherwise provide derivatives of the
foreign code. This paper presents Enzyme, a high-performance automatic
differentiation (AD) compiler plugin for the LLVM compiler framework capable of
synthesizing gradients of statically analyzable programs expressed in the LLVM
intermediate representation (IR). Enzyme synthesizes gradients for programs
written in any language whose compiler targets LLVM IR including C, C++,
Fortran, Julia, Rust, Swift, MLIR, etc., thereby providing native AD
capabilities in these languages. Unlike traditional source-to-source and
operator-overloading tools, Enzyme performs AD on optimized IR. On a
machine-learning focused benchmark suite including Microsoft's ADBench, AD on
optimized IR achieves a geometric mean speedup of 4.5x over AD on IR before
optimization allowing Enzyme to achieve state-of-the-art performance. Packaging
Enzyme for PyTorch and TensorFlow provides convenient access to gradients of
foreign code with state-of-the art performance, enabling foreign code to be
directly incorporated into existing machine learning workflows.
","['\nWilliam S. Moses\n', '\nValentin Churavy\n']",To be published in NeurIPS 2020,,http://dx.doi.org/10.5555/3495724.3496770,cs.MS,"['cs.MS', 'cs.AI', 'cs.LG', 'cs.PF', 'cs.PL']",10.5555/3495724.3496770,,[]
Compressed Basis GMRES on High Performance GPUs,http://arxiv.org/abs/2009.12101v1,2020-09-25T09:37:38Z,2020-09-25T09:37:38Z,"  Krylov methods provide a fast and highly parallel numerical tool for the
iterative solution of many large-scale sparse linear systems. To a large
extent, the performance of practical realizations of these methods is
constrained by the communication bandwidth in all current computer
architectures, motivating the recent investigation of sophisticated techniques
to avoid, reduce, and/or hide the message-passing costs (in distributed
platforms) and the memory accesses (in all architectures).
  This paper introduces a new communication-reduction strategy for the (Krylov)
GMRES solver that advocates for decoupling the storage format (i.e., the data
representation in memory) of the orthogonal basis from the arithmetic precision
that is employed during the operations with that basis. Given that the
execution time of the GMRES solver is largely determined by the memory access,
the datatype transforms can be mostly hidden, resulting in the acceleration of
the iterative step via a lower volume of bits being retrieved from memory.
Together with the special properties of the orthonormal basis (whose elements
are all bounded by 1), this paves the road toward the aggressive customization
of the storage format, which includes some floating point as well as fixed
point formats with little impact on the convergence of the iterative process.
  We develop a high performance implementation of the ""compressed basis GMRES""
solver in the Ginkgo sparse linear algebra library and using a large set of
test problems from the SuiteSparse matrix collection we demonstrate robustness
and performance advantages on a modern NVIDIA V100 GPU of up to 50% over the
standard GMRES solver that stores all data in IEEE double precision.
","['\nJosé I. Aliaga\n', '\nHartwig Anzt\n', '\nThomas Grützmacher\n', '\nEnrique S. Quintana-Ortí\n', '\nAndrés E. Tomás\n']",,,http://arxiv.org/abs/2009.12101v1,cs.MS,['cs.MS'],,,[]
"A highly scalable approach to solving linear systems using two-stage
  multisplitting",http://arxiv.org/abs/2009.12638v1,2020-09-26T16:44:34Z,2020-09-26T16:44:34Z,"  Iterative methods for solving large sparse systems of linear equations are
widely used in many HPC applications. Extreme scaling of these methods can be
difficult, however, since global communication to form dot products is
typically required at every iteration.
  To try to overcome this limitation we propose a hybrid approach, where the
matrix is partitioned into blocks. Within each block, we use a highly optimised
(parallel) conventional solver, but we then couple the blocks together using
block Jacobi or some other multisplitting technique that can be implemented in
either a synchronous or an asynchronous fashion. This allows us to limit the
block size to the point where the conventional iterative methods no longer
scale, and to avoid global communication (and possibly synchronisation) across
all processes.
  Our block framework has been built to use PETSc, a popular scientific suite
for solving sparse linear systems, as the synchronous intra-block solver, and
we demonstrate results on up to 32768 cores of a Cray XE6 system. At this
scale, the conventional solvers are still more efficient, though trends suggest
that the hybrid approach may be beneficial at higher core counts.
","['\nNick Brown\n', '\nJ. Mark Bull\n', '\nIain Bethune\n']",,,http://arxiv.org/abs/2009.12638v1,cs.MS,['cs.MS'],,,[]
Regressor: A C program for Combinatorial Regressions,http://arxiv.org/abs/2009.12386v1,2020-09-25T18:10:14Z,2020-09-25T18:10:14Z,"  In statistics, researchers use Regression models for data analysis and
prediction in many productive sectors (industry, business, academy, etc.).
Regression models are mathematical functions representing an approximation of
dependent variable $Y$ from n independent variables $X_i \in X$. The literature
presents many regression methods divided into single and multiple regressions.
There are several procedures to generate regression models and sets of
commercial and academic tools that implement these procedures. This work
presents one open-source program called Regressor that makes models from a
specific variation of polynomial regression. These models relate the
independent variables to generate an approximation of the original output
dependent data. In many tests, Regressor was able to build models five times
more accurate than commercial tools.
","['\nEduardo M. Vasconcelos\n', '\nAdriano Gouveia de Souza\n']","6 pages, 3 figures, 1 algorithm and 1 table",,http://arxiv.org/abs/2009.12386v1,stat.AP,"['stat.AP', 'cs.MS']",,,[]
Portable high-order finite element kernels I: Streaming Operations,http://arxiv.org/abs/2009.10917v1,2020-09-23T03:11:10Z,2020-09-23T03:11:10Z,"  This paper is devoted to the development of highly efficient kernels
performing vector operations relevant in linear system solvers. In particular,
we focus on the low arithmetic intensity operations (i.e., streaming
operations) performed within the conjugate gradient iterative method, using the
parameters specified in the CEED benchmark problems for high-order hexahedral
finite elements. We propose a suite of new Benchmark Streaming tests to focus
on the distinct streaming operations which must be performed. We implemented
these new tests using the OCCA abstraction framework to demonstrate portability
of these streaming operations on different GPU architectures, and propose a
simple performance model for such kernels which can accurately capture data
movement rates as well as kernel launch costs.
","['\nNoel Chalmers\n', '\nTim Warburton\n']",,,http://arxiv.org/abs/2009.10917v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",,,[]
"AMReX: Block-Structured Adaptive Mesh Refinement for Multiphysics
  Applications",http://arxiv.org/abs/2009.12009v1,2020-09-25T02:59:30Z,2020-09-25T02:59:30Z,"  Block-structured adaptive mesh refinement (AMR) provides the basis for the
temporal and spatial discretization strategy for a number of ECP applications
in the areas of accelerator design, additive manufacturing, astrophysics,
combustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a
software framework that provides a unified infrastructure with the
functionality needed for these and other AMR applications to be able to
effectively and efficiently utilize machines from laptops to exascale
architectures. AMR reduces the computational cost and memory footprint compared
to a uniform mesh while preserving accurate descriptions of different physical
processes in complex multi-physics algorithms. AMReX supports algorithms that
solve systems of partial differential equations (PDEs) in simple or complex
geometries, and those that use particles and/or particle-mesh operations to
represent component physical processes. In this paper, we will discuss the core
elements of the AMReX framework such as data containers and iterators as well
as several specialized operations to meet the needs of the application
projects. In addition we will highlight the strategy that the AMReX team is
pursuing to achieve highly performant code across a range of accelerator-based
architectures for a variety of different applications.
","['\nWeiqun Zhang\n', '\nAndrew Myers\n', '\nKevin Gott\n', '\nAnn Almgren\n', '\nJohn Bell\n']","16 pages, 9 figures, submitted to IJHPCA",,http://arxiv.org/abs/2009.12009v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC']",,,[]
Flexible Performant GEMM Kernels on GPUs,http://arxiv.org/abs/2009.12263v4,2020-09-25T14:29:08Z,2021-11-22T09:33:21Z,"  General Matrix Multiplication or GEMM kernels take centre place in high
performance computing and machine learning. Recent NVIDIA GPUs include GEMM
accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by
the two-language problem: it requires either low-level programming which
implies low programmer productivity or using libraries that only offer a
limited set of components. Because rephrasing algorithms in terms of
established components often introduces overhead, the libraries' lack of
flexibility limits the freedom to explore new algorithms. Researchers using
GEMMs can hence not enjoy programming productivity, high performance, and
research flexibility at once.
  In this paper we solve this problem. We present three sets of abstractions
and interfaces to program GEMMs within the scientific Julia programming
language. The interfaces and abstractions are co-designed for researchers'
needs and Julia's features to achieve sufficient separation of concerns and
flexibility to easily extend basic GEMMs in many different ways without paying
a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS
and CUTLASS, we demonstrate that our performance is in the same ballpark of the
libraries, and in some cases even exceeds it, without having to write a single
line of code in CUDA C++ or assembly, and without facing flexibility
limitations.
","['\nThomas Faingnaert\n', '\nTim Besard\n', '\nBjorn De Sutter\n']",This paper was submitted to IEEE TPDS,,http://arxiv.org/abs/2009.12263v4,cs.MS,"['cs.MS', 'cs.DC', 'cs.LG', 'cs.PF']",,,[]
"QR and LQ Decomposition Matrix Backpropagation Algorithms for Square,
  Wide, and Deep -- Real or Complex -- Matrices and Their Software
  Implementation",http://arxiv.org/abs/2009.10071v4,2020-09-19T21:03:37Z,2020-12-11T12:54:23Z,"  This article presents matrix backpropagation algorithms for the QR
decomposition of matrices $A_{m, n}$, that are either square (m = n), wide (m <
n), or deep (m > n), with rank $k = min(m, n)$. Furthermore, we derive novel
matrix backpropagation results for the pivoted (full-rank) QR decomposition and
for the LQ decomposition of deep input matrices. Differentiable QR
decomposition offers a numerically stable, computationally efficient method to
solve least squares problems frequently encountered in machine learning and
computer vision. Other use cases such as graph learning and network compression
are listed in the article. Software implementation across popular deep learning
frameworks (PyTorch, TensorFlow, MXNet) incorporate the methods for general use
within the deep learning community. Furthermore, this article aids the
practitioner in understanding the matrix backpropagation methodology as part of
larger computational graphs.
","['\nDenisa A. O. Roberts\n', '\nLucas R. Roberts\n']",,,http://arxiv.org/abs/2009.10071v4,math.NA,"['math.NA', 'cs.LG', 'cs.MS', 'cs.NA', 'stat.ML']",,,[]
"A compute-bound formulation of Galerkin model reduction for linear
  time-invariant dynamical systems",http://arxiv.org/abs/2009.11742v3,2020-09-24T15:06:00Z,2021-06-01T11:55:18Z,"  This work aims to advance computational methods for projection-based reduced
order models (ROMs) of linear time-invariant (LTI) dynamical systems. For such
systems, current practice relies on ROM formulations expressing the state as a
rank-1 tensor (i.e., a vector), leading to computational kernels that are
memory bandwidth bound and, therefore, ill-suited for scalable performance on
modern many-core and hybrid computing nodes. This weakness can be particularly
limiting when tackling many-query studies, where one needs to run a large
number of simulations. This work introduces a reformulation, called rank-2
Galerkin, of the Galerkin ROM for LTI dynamical systems which converts the
nature of the ROM problem from memory bandwidth to compute bound. We present
the details of the formulation and its implementation, and demonstrate its
utility through numerical experiments using, as a test case, the simulation of
elastic seismic shear waves in an axisymmetric domain. We quantify and analyze
performance and scaling results for varying numbers of threads and problem
sizes. Finally, we present an end-to-end demonstration of using the rank-2
Galerkin ROM for a Monte Carlo sampling study. We show that the rank-2 Galerkin
ROM is one order of magnitude more efficient than the rank-1 Galerkin ROM (the
current practice) and about 970X more efficient than the full order model,
while maintaining accuracy in both the mean and statistics of the field.
","['\nFrancesco Rizzi\n', '\nEric J. Parish\n', '\nPatrick J. Blonigan\n', '\nJohn Tencer\n']","Revised version, 28 pages, 9 figures",,http://dx.doi.org/10.1016/j.cma.2021.113973,physics.comp-ph,"['physics.comp-ph', 'cs.CE', 'cs.DC', 'cs.MS', 'math.DS']",10.1016/j.cma.2021.113973,,[]
"Extendible and Efficient Python Framework for Solving Evolution
  Equations with Stabilized Discontinuous Galerkin Method",http://arxiv.org/abs/2009.13416v2,2020-09-25T16:23:57Z,2021-03-29T09:28:39Z,"  This paper discusses a Python interface for the recently published
DUNE-FEM-DG module which provides highly efficient implementations of the
Discontinuous Galerkin (DG) method for solving a wide range of non linear
partial differential equations (PDE). Although the C++ interfaces of
DUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is
necessary to make use of this powerful tool. With this work easier user
interfaces based on Python and the Unified Form Language are provided to open
DUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for
both parabolic and first order hyperbolic PDEs.
","['\nAndreas Dedner\n', '\nRobert Klöfkorn\n']","36 pages, 15 figures, various Python code examples",,http://arxiv.org/abs/2009.13416v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', 'physics.comp-ph', '65M08, 65M60, 35Q31, 35Q90, 68N99']",,,[]
Dune-CurvedGrid -- A Dune module for surface parametrization,http://arxiv.org/abs/2009.04938v3,2020-09-10T15:32:42Z,2022-02-09T14:46:01Z,"  In this paper we introduce and describe an implementation of curved (surface)
geometries within the Dune framework for grid-based discretizations. Therefore,
we employ the abstraction of geometries as local-functions bound to a grid
element, and the abstraction of a grid as connectivity of elements together
with a grid-function that can be localized to the elements to provide element
local parametrizations of the curved surface.
","['\nSimon Praetorius\n', '\nFlorian Stenger\n']",26 pages,"Arch. Num. Soft., 2022, 6(1)",http://dx.doi.org/10.11588/ans.2022.1.75917,cs.MS,"['cs.MS', 'cs.CG', '53-04 (Primary) 53A05, 58J90, 65M50, 65-04 (Secondary)', 'G.4; G.1.8']",10.11588/ans.2022.1.75917,,[]
"SeqROCTM: A Matlab toolbox for the analysis of Sequence of Random
  Objects driven by Context Tree Models",http://arxiv.org/abs/2009.06371v3,2020-09-08T15:28:32Z,2021-07-22T16:38:05Z,"  In several research problems we deal with probabilistic sequences of inputs
(e.g., sequence of stimuli) from which an agent generates a corresponding
sequence of responses and it is of interest to model the relation between them.
A new class of stochastic processes, namely \textit{sequences of random objects
driven by context tree models}, has been introduced to model such relation in
the context of auditory statistical learning. This paper introduces a freely
available Matlab toolbox (SeqROCTM) that implements this new class of
stochastic processes and three model selection procedures to make inference on
it. Besides, due to the close relation of the new mathematical framework with
context tree models, the toolbox also implements several existing model
selection algorithms for context tree models.
","['\nNoslen Hernández\n', '\nAline Duarte\n']",,,http://arxiv.org/abs/2009.06371v3,cs.AI,"['cs.AI', 'cs.MS']",,,[]
distr6: R6 Object-Oriented Probability Distributions Interface in R,http://arxiv.org/abs/2009.02993v3,2020-09-07T10:20:00Z,2021-03-20T11:04:18Z,"  distr6 is an object-oriented (OO) probability distributions interface
leveraging the extensibility and scalability of R6, and the speed and
efficiency of Rcpp. Over 50 probability distributions are currently implemented
in the package with `core' methods including density, distribution, and
generating functions, and more `exotic' ones including hazards and distribution
function anti-derivatives. In addition to simple distributions, distr6 supports
compositions such as truncation, mixtures, and product distributions. This
paper presents the core functionality of the package and demonstrates examples
for key use-cases. In addition this paper provides a critical review of the
object-oriented programming paradigms in R and describes some novel
implementations for design patterns and core object-oriented features
introduced by the package for supporting distr6 components.
","['\nRaphael Sonabend\n', '\nFranz Kiraly\n']",Accepted in The R Journal,,http://arxiv.org/abs/2009.02993v3,cs.SE,"['cs.SE', 'cs.MS', 'stat.AP', 'stat.CO']",,,[]
"An Integer Arithmetic-Based Sparse Linear Solver Using a GMRES Method
  and Iterative Refinement",http://arxiv.org/abs/2009.07495v2,2020-09-16T06:38:18Z,2021-03-03T07:19:25Z,"  In this paper, we develop a (preconditioned) GMRES solver based on integer
arithmetic, and introduce an iterative refinement framework for the solver. We
describe the data format for the coefficient matrix and vectors for the solver
that is based on integer or fixed-point numbers. To avoid overflow in
calculations, we introduce initial scaling and logical shifts (adjustments) of
operands in arithmetic operations. We present the approach for operand shifts,
considering the characteristics of the GMRES algorithm. Numerical tests
demonstrate that the integer arithmetic-based solver with iterative refinement
has comparable solver performance in terms of convergence to the standard
solver based on floating-point arithmetic. Moreover, we show that
preconditioning is important, not only for improving convergence but also
reducing the risk of overflow.
","['\nTakeshi Iwashita\n', '\nKengo Suzuki\n', '\nTakeshi Fukaya\n']",,,http://dx.doi.org/10.1109/ScalA51936.2020.00006,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1109/ScalA51936.2020.00006,,[]
"m-arcsinh: An Efficient and Reliable Function for SVM and MLP in
  scikit-learn",http://arxiv.org/abs/2009.07530v1,2020-09-16T07:59:15Z,2020-09-16T07:59:15Z,"  This paper describes the 'm-arcsinh', a modified ('m-') version of the
inverse hyperbolic sine function ('arcsinh'). Kernel and activation functions
enable Machine Learning (ML)-based algorithms, such as Support Vector Machine
(SVM) and Multi-Layer Perceptron (MLP), to learn from data in a supervised
manner. m-arcsinh, implemented in the open source Python library
'scikit-learn', is hereby presented as an efficient and reliable kernel and
activation function for SVM and MLP respectively. Improvements in reliability
and speed to convergence in classification tasks on fifteen (N = 15) datasets
available from scikit-learn and the University California Irvine (UCI) Machine
Learning repository are discussed. Experimental results demonstrate the overall
competitive classification performance of both SVM and MLP, achieved via the
proposed function. This function is compared to gold standard kernel and
activation functions, demonstrating its overall competitive reliability
regardless of the complexity of the classification tasks involved.
",['\nLuca Parisi\n'],"20 pages, 4 listings/Python code snippets, 2 figures, 15 tables",,http://arxiv.org/abs/2009.07530v1,cs.LG,"['cs.LG', 'cs.CV', 'cs.MS', 'stat.ML', 'I.2.1; I.2.6']",,,[]
"HDGlab: An open-source implementation of the hybridisable discontinuous
  Galerkin method in MATLAB",http://arxiv.org/abs/2009.08805v1,2020-09-16T21:28:09Z,2020-09-16T21:28:09Z,"  This paper presents HDGlab, an open source MATLAB implementation of the
hybridisable discontinuous Galerkin (HDG) method. The main goal is to provide a
detailed description of both the HDG method for elliptic problems and its
implementation available in HDGlab. Ultimately, this is expected to make this
relatively new advanced discretisation method more accessible to the
computational engineering community. HDGlab presents some features not
available in other implementations of the HDG method that can be found in the
free domain. First, it implements high-order polynomial shape functions up to
degree nine, with both equally-spaced and Fekete nodal distributions. Second,
it supports curved isoparametric simplicial elements in two and three
dimensions. Third, it supports non-uniform degree polynomial approximations and
it provides a flexible structure to devise degree adaptivity strategies.
Finally, an interface with the open-source high-order mesh generator Gmsh is
provided to facilitate its application to practical engineering problems.
","['\nMatteo Giacomini\n', '\nRuben Sevilla\n', '\nAntonio Huerta\n']","90 pages, 51 figures","Archives of Computational Methods in Engineering, Vol. 28, Issue
  3, pp. 1941-1986, 2021",http://dx.doi.org/10.1007/s11831-020-09502-5,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65-04, 35-04, 76-04, 65N30, 76M10']",10.1007/s11831-020-09502-5,,[]
"Accelerating Domain Propagation: an Efficient GPU-Parallel Algorithm
  over Sparse Matrices",http://arxiv.org/abs/2009.07785v5,2020-09-16T16:25:29Z,2021-08-25T15:48:02Z,"  Fast domain propagation of linear constraints has become a crucial component
of today's best algorithms and solvers for mixed integer programming and
pseudo-boolean optimization to achieve peak solving performance. Irregularities
in the form of dynamic algorithmic behaviour, dependency structures, and
sparsity patterns in the input data make efficient implementations of domain
propagation on GPUs and, more generally, on parallel architectures challenging.
This is one of the main reasons why domain propagation in state-of-the-art
solvers is single thread only. In this paper, we present a new algorithm for
domain propagation which (a) avoids these problems and allows for an efficient
implementation on GPUs, and is (b) capable of running propagation rounds
entirely on the GPU, without any need for synchronization or communication with
the CPU. We present extensive computational results which demonstrate the
effectiveness of our approach and show that ample speedups are possible on
practically relevant problems: on state-of-the-art GPUs, our geometric mean
speed-up for reasonably-large instances is around 10x to 20x and can be as high
as 180x on favorably-large instances.
","['\nBoro Sofranac\n', '\nAmbros Gleixner\n', '\nSebastian Pokutta\n']",,,http://arxiv.org/abs/2009.07785v5,cs.DC,"['cs.DC', 'cs.DM', 'cs.DS', 'cs.MS', 'math.OC']",,,[]
"A Survey of Singular Value Decomposition Methods for Distributed
  Tall/Skinny Data",http://arxiv.org/abs/2009.00761v1,2020-09-02T00:34:54Z,2020-09-02T00:34:54Z,"  The Singular Value Decomposition (SVD) is one of the most important matrix
factorizations, enjoying a wide variety of applications across numerous
application domains. In statistics and data analysis, the common applications
of SVD such as Principal Components Analysis (PCA) and linear regression.
Usually these applications arise on data that has far more rows than columns,
so-called ""tall/skinny"" matrices. In the big data analytics context, this may
take the form of hundreds of millions to billions of rows with only a few
hundred columns. There is a need, therefore, for fast, accurate, and scalable
tall/skinny SVD implementations which can fully utilize modern computing
resources. To that end, we present a survey of three different algorithms for
computing the SVD for these kinds of tall/skinny data layouts using MPI for
communication. We contextualize these with common big data analytics
techniques, principally PCA. Finally, we present both CPU and GPU timing
results from the Summit supercomputer, and discuss possible alternative
approaches.
",['\nDrew Schmidt\n'],,,http://arxiv.org/abs/2009.00761v1,cs.MS,"['cs.MS', 'stat.CO']",,,[]
"Performance Analysis of FEM Solvers on Practical Electromagnetic
  Problems",http://arxiv.org/abs/2009.04399v1,2020-09-04T21:24:36Z,2020-09-04T21:24:36Z,"  The paper presents a comparative analysis of different commercial and
academic software. The comparison aims to examine how the integrated adaptive
grid refinement methodologies can deal with challenging, electromagnetic-field
related problems. For this comparison, two benchmark problems were examined in
the paper. The first example is a solution of an L-shape domain like test
problem, which has a singularity at a certain point in the geometry. The second
problem is an induction heated aluminum rod, which accurate solution needs to
solve a non-linear, coupled physical fields. The accurate solution of this
problem requires applying adaptive mesh generation strategies or applying a
very fine mesh in the electromagnetic domain, which can significantly increase
the computational complexity. The results show that the fully-hp adaptive
meshing strategies, which are integrated into Agros-suite, can significantly
reduce the task's computational complexity compared to the automatic
h-adaptivity, which is part of the examined, popular commercial solvers.
","['\nGergely Máté Kiss\n', '\nJan Kaska\n', '\nRoberto André Henrique de Oliveira\n', '\nOlena Rubanenko\n', '\nBalázs Tóth\n']",,,http://arxiv.org/abs/2009.04399v1,cs.CE,"['cs.CE', 'cs.MS', 'G.1.10', 'G.1.10']",,,[]
"TriCG and TriMR: Two Iterative Methods for Symmetric Quasi-Definite
  Systems",http://arxiv.org/abs/2008.12863v2,2020-08-28T22:08:01Z,2021-02-08T23:53:13Z,"  We introduce iterative methods named TriCG and TriMR for solving symmetric
quasi-definite systems based on the orthogonal tridiagonalization process
proposed by Saunders, Simon and Yip in 1988. TriCG and TriMR are tantamount to
preconditioned Block-CG and Block-MINRES with two right-hand sides in which the
two approximate solutions are summed at each iteration, but require less
storage and work per iteration. We evaluate the performance of TriCG and TriMR
on linear systems generated from the SuiteSparse Matrix Collection and from
discretized and stablized Stokes equations. We compare TriCG and TriMR with
SYMMLQ and MINRES, the recommended Krylov methods for symmetric and indefinite
systems. In all our experiments, TriCG and TriMR terminate earlier than SYMMLQ
and MINRES on a residual-based stopping condition with an improvement of up to
50% in terms of number of iterations. They also terminate more reliably than
Block-CG and Block-MINRES. Experiments in quadruple and octuple precision
suggest that loss of orthogonality in the basis vectors is significantly less
pronounced in TriCG and TriMR than in Block-CG and Block-MINRES.
","['\nAlexis Montoison\n', '\nDominique Orban\n']","24 pages, 12 figures","SIAM J. Sci. Comput., 43(4), A2502-A2525, 2021",http://dx.doi.org/10.1137/20M1363030,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'math.OC', '15A06, 65F10, 65F08, 65F22, 65F25, 65F35, 65F50, 90C06, 90C90']",10.1137/20M1363030,,[]
"Introduction to Medical Image Registration with DeepReg, Between Old and
  New",http://arxiv.org/abs/2009.01924v2,2020-08-29T19:44:23Z,2020-09-07T06:45:40Z,"  This document outlines a tutorial to get started with medical image
registration using the open-source package DeepReg. The basic concepts of
medical image registration are discussed, linking classical methods to newer
methods using deep learning. Two iterative, classical algorithms using
optimisation and one learning-based algorithm using deep learning are coded
step-by-step using DeepReg utilities, all with real, open-accessible, medical
data.
","['\nN. Montana Brown\n', '\nY. Fu\n', '\nS. U. Saeed\n', '\nA. Casamitjana\n', '\nZ. M. C. Baum\n', '\nR. Delaunay\n', '\nQ. Yang\n', '\nA. Grimwood\n', '\nZ. Min\n', '\nE. Bonmati\n', '\nT. Vercauteren\n', '\nM. J. Clarkson\n', '\nY. Hu\n']",Submitted to MICCAI Educational Challenge 2020,,http://arxiv.org/abs/2009.01924v2,eess.IV,"['eess.IV', 'cs.CV', 'cs.LG', 'cs.MS']",,,[]
"Elmer FEM-Dakota: A unified open-source computational framework for
  electromagnetics and data analytics",http://arxiv.org/abs/2008.06992v2,2020-08-16T20:37:28Z,2020-12-29T03:46:58Z,"  Open-source electromagnetic design software, Elmer FEM, was interfaced with
data analytics toolkit, Dakota. Furthermore, the coupled software was validated
against a benchmark test. The interface developed provides a unified
open-source computational framework for electromagnetics and data analytics.
Its key features include uncertainty quantification, surrogate modelling and
parameter studies. This framework enables a richer understanding of model
predictions to better design electric machines in a time sensitive manner.
",['\nAnjali Sandip\n'],,,http://arxiv.org/abs/2008.06992v2,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",,,[]
Just another quantum assembly language (Jaqal),http://arxiv.org/abs/2008.08042v1,2020-08-18T17:10:00Z,2020-08-18T17:10:00Z,"  The Quantum Scientific Computing Open User Testbed (QSCOUT) is a trapped-ion
quantum computer testbed realized at Sandia National Laboratories on behalf of
the Department of Energy's Office of Science and its Advanced Scientific
Computing (ASCR) program. Here we describe Jaqal, for Just another quantum
assembly language, the programming language we invented to specify programs
executed on QSCOUT. Jaqal is useful beyond QSCOUT---it can support mutliple
hardware targets because it offloads gate names and their pulse-sequence
definitions to external files. We describe the capabilities of the Jaqal
language, our approach in designing it, and the reasons for its creation. To
learn more about QSCOUT, Jaqal, or JaqalPaq, the metaprogramming Python package
we developed for Jaqal, please visit https://qscout.sandia.gov,
https://gitlab.com/jaqal, or send an e-mail to qscout@sandia.gov.
","['\nBenjamin C. A. Morrison\n', '\nAndrew J. Landahl\n', '\nDaniel S. Lobser\n', '\nKenneth M. Rudinger\n', '\nAntonio E. Russo\n', '\nJay W. Van Der Wall\n', '\nPeter Maunz\n']","Accepted by the IEEE International Conference on Quantum Computing
  and Engineering, Oct. 12-16, 2020. Contains overlaps with the formal Jaqal
  language specification in arXiv:2003.09382, but expands significantly on the
  rationales behind the language choices made",,http://arxiv.org/abs/2008.08042v1,quant-ph,"['quant-ph', 'cs.MS']",,,[]
"Evaluating the Performance of NVIDIA's A100 Ampere GPU for Sparse Linear
  Algebra Computations",http://arxiv.org/abs/2008.08478v1,2020-08-19T14:38:07Z,2020-08-19T14:38:07Z,"  GPU accelerators have become an important backbone for scientific high
performance computing, and the performance advances obtained from adopting new
GPU hardware are significant. In this paper we take a first look at NVIDIA's
newest server line GPU, the A100 architecture part of the Ampere generation.
Specifically, we assess its performance for sparse linear algebra operations
that form the backbone of many scientific applications and assess the
performance improvements over its predecessor.
","['\nYuhsiang Mike Tsai\n', '\nTerry Cojean\n', '\nHartwig Anzt\n']",,,http://arxiv.org/abs/2008.08478v1,cs.MS,"['cs.MS', 'cs.PF']",,,[]
"BSF-skeleton: A Template for Parallelization of Iterative Numerical
  Algorithms on Cluster Computing Systems",http://arxiv.org/abs/2008.12256v3,2020-08-22T15:58:24Z,2021-06-04T14:05:06Z,"  This article describes a method for creating applications for cluster
computing systems using the parallel BSF skeleton based on the original BSF
(Bulk Synchronous Farm) model of parallel computations developed by the author
earlier. This model uses the master/slave paradigm. The main advantage of the
BSF model is that it allows to estimate the scalability of a parallel algorithm
before its implementation. Another important feature of the BSF model is the
representation of problem data in the form of lists that greatly simplifies the
logic of building applications. The BSF skeleton is designed for creating
parallel programs in C++ using the MPI library. The scope of the BSF skeleton
is iterative numerical algorithms of high computational complexity. The BSF
skeleton has the following distinctive features. - The BSF-skeleton completely
encapsulates all aspects that are associated with parallelizing a program. -
The BSF skeleton allows error-free compilation at all stages of application
development. - The BSF skeleton supports OpenMP programming model and
workflows.
",['\nLeonid B. Sokolinsky\n'],Submitted to MethodsX,"MethodsX, 2021",http://dx.doi.org/10.1016/j.mex.2021.101437,cs.DC,"['cs.DC', 'cs.MS', '68M14', 'D.1.3']",10.1016/j.mex.2021.101437,,[]
"Compact 200 line MATLAB code for inverse design in photonics by topology
  optimization: tutorial",http://arxiv.org/abs/2009.14276v5,2020-08-23T14:07:07Z,2021-02-23T12:19:51Z,"  We provide a compact 200 line MATLAB code demonstrating how topology
optimization (TopOpt) as an inverse design tool may be used in photonics,
targeting the design of two-dimensional dielectric metalenses and a metallic
reflector as examples. The physics model is solved using the finite element
method, and the code utilizes MATLAB's fmincon algorithm to solve the
optimization problem. In addition to presenting the code itself, we briefly
discuss a number of extensions and provide the code required to implement some
of these. Finally, we demonstrate the superiority of using a gradient-based
method compared to a genetic-algorithm-based method (using MATLAB's ga
algorithm) for solving inverse design problems in photonics. The MATLAB
software is freely available in the paper and may be downloaded from
https://www.topopt.mek.dtu.dk.
","['\nRasmus E. Christiansen\n', '\nOle Sigmund\n']","5 Figures, 17 pages",,http://dx.doi.org/10.1364/JOSAB.405955,cs.MS,"['cs.MS', 'cs.CE', 'physics.optics']",10.1364/JOSAB.405955,,[]
PyMGRIT: A Python Package for the parallel-in-time method MGRIT,http://arxiv.org/abs/2008.05172v1,2020-08-12T08:38:07Z,2020-08-12T08:38:07Z,"  In this paper, we introduce the Python framework PyMGRIT, which implements
the multigrid-reduction-in-time (MGRIT) algorithm for solving the (non-)linear
systems arising from the discretization of time-dependent problems. The MGRIT
algorithm is a reduction-based iterative method that allows parallel-in-time
simulations, i. e., calculating multiple time steps simultaneously in a
simulation, by using a time-grid hierarchy. The PyMGRIT framework features many
different variants of the MGRIT algorithm, ranging from different multigrid
cycle types and relaxation schemes, as well as various coarsening strategies,
including time-only and space-time coarsening, to using different time
integrators on different levels in the multigrid hierachy. PyMGRIT allows
serial runs for prototyping and testing of new approaches, as well as parallel
runs using the Message Passing Interface (MPI). Here, we describe the
implementation of the MGRIT algorithm in PyMGRIT and present the usage from
both user and developer point of views. Three examples illustrate different
aspects of the package, including pure time parallelism as well as space-time
parallelism by coupling PyMGRIT with PETSc or Firedrake, which enable spatial
parallelism through MPI.
","['\nJens Hahne\n', '\nStephanie Friedhoff\n', '\nMatthias Bolten\n']",,,http://arxiv.org/abs/2008.05172v1,cs.MS,['cs.MS'],,,[]
"A parallel structured divide-and-conquer algorithm for symmetric
  tridiagonal eigenvalue problems",http://arxiv.org/abs/2008.01990v2,2020-08-05T08:23:36Z,2020-11-28T15:09:22Z,"  In this paper, a parallel structured divide-and-conquer (PSDC) eigensolver is
proposed for symmetric tridiagonal matrices based on ScaLAPACK and a parallel
structured matrix multiplication algorithm, called PSMMA. Computing the
eigenvectors via matrix-matrix multiplications is the most computationally
expensive part of the divide-and-conquer algorithm, and one of the matrices
involved in such multiplications is a rank-structured Cauchy-like matrix. By
exploiting this particular property, PSMMA constructs the local matrices by
using generators of Cauchy-like matrices without any communication, and further
reduces the computation costs by using a structured low-rank approximation
algorithm. Thus, both the communication and computation costs are reduced.
Experimental results show that both PSMMA and PSDC are highly scalable and
scale to 4096 processes at least. PSDC has better scalability than PHDC that
was proposed in [J. Comput. Appl. Math. 344 (2018) 512--520] and only scaled to
300 processes for the same matrices. Comparing with \texttt{PDSTEDC} in
ScaLAPACK, PSDC is always faster and achieves $1.4$x--$1.6$x speedup for some
matrices with few deflations. PSDC is also comparable with ELPA, with PSDC
being faster than ELPA when using few processes and a little slower when using
many processes.
","['\nXia Liao\n', '\nShengguo Li\n', '\nYutong Lu\n', '\nJose E. Roman\n']","17 pages, 9 figures","IEEE Transactions on Parallel and Distributed Systems 32 (2021)
  367-378",http://dx.doi.org/10.1109/TPDS.2020.3019471,cs.MS,"['cs.MS', 'cs.DC']",10.1109/TPDS.2020.3019471,,[]
"Randomized Projection for Rank-Revealing Matrix Factorizations and
  Low-Rank Approximations",http://arxiv.org/abs/2008.04447v1,2020-08-10T23:02:28Z,2020-08-10T23:02:28Z,"  Rank-revealing matrix decompositions provide an essential tool in spectral
analysis of matrices, including the Singular Value Decomposition (SVD) and
related low-rank approximation techniques. QR with Column Pivoting (QRCP) is
usually suitable for these purposes, but it can be much slower than the
unpivoted QR algorithm. For large matrices, the difference in performance is
due to increased communication between the processor and slow memory, which
QRCP needs in order to choose pivots during decomposition. Our main algorithm,
Randomized QR with Column Pivoting (RQRCP), uses randomized projection to make
pivot decisions from a much smaller sample matrix, which we can construct to
reside in a faster level of memory than the original matrix. This technique may
be understood as trading vastly reduced communication for a controlled increase
in uncertainty during the decision process. For rank-revealing purposes, the
selection mechanism in RQRCP produces results that are the same quality as the
standard algorithm, but with performance near that of unpivoted QR (often an
order of magnitude faster for large matrices). We also propose two formulas
that facilitate further performance improvements. The first efficiently updates
sample matrices to avoid computing new randomized projections. The second
avoids large trailing updates during the decomposition in truncated low-rank
approximations. Our truncated version of RQRCP also provides a key initial step
in our truncated SVD approximation, TUXV. These advances open up a new
performance domain for large matrix factorizations that will support efficient
problem-solving techniques for challenging applications in science,
engineering, and data analysis.
","['\nJed A. Duersch\n', '\nMing Gu\n']","Revised from Randomized QR with Column Pivoting for publication in
  SIGEST",,http://arxiv.org/abs/2008.04447v1,cs.MS,"['cs.MS', 'math.SP', '68W20, 15A23, 15A18, 65F25']",,,[]
"EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX,
  and NumPy",http://arxiv.org/abs/2008.04175v1,2020-08-10T14:57:41Z,2020-08-10T14:57:41Z,"  EagerPy is a Python framework that lets you write code that automatically
works natively with PyTorch, TensorFlow, JAX, and NumPy. Library developers no
longer need to choose between supporting just one of these frameworks or
reimplementing the library for each framework and dealing with code
duplication. Users of such libraries can more easily switch frameworks without
being locked in by a specific 3rd party library. Beyond multi-framework
support, EagerPy also brings comprehensive type annotations and consistent
support for method chaining to any framework. The latest documentation is
available online at https://eagerpy.jonasrauber.de and the code can be found on
GitHub at https://github.com/jonasrauber/eagerpy.
","['\nJonas Rauber\n', '\nMatthias Bethge\n', '\nWieland Brendel\n']",,,http://arxiv.org/abs/2008.04175v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
A new framework for the computation of Hessians,http://arxiv.org/abs/2007.15040v1,2020-07-29T18:14:54Z,2020-07-29T18:14:54Z,"  We investigate the computation of Hessian matrices via Automatic
Differentiation, using a graph model and an algebraic model. The graph model
reveals the inherent symmetries involved in calculating the Hessian. The
algebraic model, based on Griewank and Walther's state transformations,
synthesizes the calculation of the Hessian as a formula. These dual points of
view, graphical and algebraic, lead to a new framework for Hessian computation.
This is illustrated by developing edge_pushing, a new truly reverse Hessian
computation algorithm that fully exploits the Hessian's symmetry. Computational
experiments compare the performance of edge_pushing on sixteen functions from
the CUTE collection against two algorithms available as drivers of the software
ADOL-C, and the results are very promising.
","['\nRobert M. Gower\n', '\nMargarida P. Mello\n']","24 pages, 9 figures, 2 tables","Optimization Methods and Software, 27(2):251--273, 2012",http://dx.doi.org/10.1080/10556788.2011.580098,math.OC,"['math.OC', 'cs.MS', '65K10, 65D25, 65F50']",10.1080/10556788.2011.580098,,[]
"multivar_horner: a python package for computing Horner factorisations of
  multivariate polynomials",http://arxiv.org/abs/2007.13152v2,2020-07-26T15:43:10Z,2020-07-29T13:55:07Z,"  Many applications in the sciences require numerically stable and
computationally efficient evaluation of multivariate polynomials. Finding
beneficial representations of polynomials, such as Horner factorisations, is
therefore crucial. multivar_horner, the python package presented here, is the
first open source software for computing multivariate Horner factorisations.
This work briefly outlines the functionality of the package and puts it into
reference to previous work in the field. Benchmarks additionally prove the
advantages of the implementation and Horner factorisations in general.
",['\nJannik Michelfeit\nTechnische Universität Dresden\n'],"10 pages, 4 figures, submitted to ""The Journal of Open Source
  Software""",,http://arxiv.org/abs/2007.13152v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,['Technische Universität Dresden']
"HeAT -- a Distributed and GPU-accelerated Tensor Framework for Data
  Analytics",http://arxiv.org/abs/2007.13552v2,2020-07-27T13:33:17Z,2020-11-11T08:12:25Z,"  To cope with the rapid growth in available data, the efficiency of data
analysis and machine learning libraries has recently received increased
attention. Although great advancements have been made in traditional
array-based computations, most are limited by the resources available on a
single computation node. Consequently, novel approaches must be made to exploit
distributed resources, e.g. distributed memory architectures. To this end, we
introduce HeAT, an array-based numerical programming framework for large-scale
parallel processing with an easy-to-use NumPy-like API. HeAT utilizes PyTorch
as a node-local eager execution engine and distributes the workload on
arbitrarily large high-performance computing systems via MPI. It provides both
low-level array computations, as well as assorted higher-level algorithms. With
HeAT, it is possible for a NumPy user to take full advantage of their available
resources, significantly lowering the barrier to distributed data analysis.
When compared to similar frameworks, HeAT achieves speedups of up to two orders
of magnitude.
","['\nMarkus Götz\n', '\nDaniel Coquelin\n', '\nCharlotte Debus\n', '\nKai Krajsek\n', '\nClaudia Comito\n', '\nPhilipp Knechtges\n', '\nBjörn Hagemeier\n', '\nMichael Tarnawa\n', '\nSimon Hanselmann\n', '\nMartin Siggel\n', '\nAchim Basermann\n', '\nAchim Streit\n']","10 pages, 8 figures, 5 listings, 1 table",,http://dx.doi.org/10.1109/BigData50022.2020.9378050,cs.DC,"['cs.DC', 'cs.LG', 'cs.MS', 'C.1.2; C.2.4; D.1.3; G.1.3; G.4; I.2.0; I.2.5; I.5.5']",10.1109/BigData50022.2020.9378050,,[]
The ITensor Software Library for Tensor Network Calculations,http://arxiv.org/abs/2007.14822v2,2020-07-28T15:38:57Z,2021-12-20T22:16:09Z,"  ITensor is a system for programming tensor network calculations with an
interface modeled on tensor diagram notation, which allows users to focus on
the connectivity of a tensor network without manually bookkeeping tensor
indices. The ITensor interface rules out common programming errors and enables
rapid prototyping of tensor network algorithms. After discussing the philosophy
behind the ITensor approach, we show examples of each part of the interface
including Index objects, the ITensor product operator, tensor factorizations,
tensor storage types, algorithms for matrix product state (MPS) and matrix
product operator (MPO) tensor networks, quantum number conserving block-sparse
tensors, and the NDTensors library. We also review publications that have used
ITensor for quantum many-body physics and for other areas where tensor networks
are increasingly applied. To conclude we discuss promising features and
optimizations to be added in the future.
","['\nMatthew Fishman\n', '\nSteven R. White\n', '\nE. Miles Stoudenmire\n']","Submitted to SciPost Physics Codebases. Version 2 contains benchmarks
  of ITensor C++ and Julia versions, and link to external benchmarks including
  TeNPy software",SciPost Phys. Codebases 4 (2022),http://dx.doi.org/10.21468/SciPostPhysCodeb.4,cs.MS,"['cs.MS', 'cond-mat.str-el', 'physics.comp-ph']",10.21468/SciPostPhysCodeb.4,,[]
Optimizing Block-Sparse Matrix Multiplications on CUDA with TVM,http://arxiv.org/abs/2007.13055v1,2020-07-26T04:50:51Z,2020-07-26T04:50:51Z,"  We implemented and optimized matrix multiplications between dense and
block-sparse matrices on CUDA. We leveraged TVM, a deep learning compiler, to
explore the schedule space of the operation and generate efficient CUDA code.
With the automatic parameter tuning in TVM, our cross-thread reduction based
implementation achieved competitive or better performance compared with other
state-of-the-art frameworks.
",['\nZijing Gu\n'],,,http://arxiv.org/abs/2007.13055v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.LG', 'cs.NA', 'math.NA']",,,[]
"Improved Time Warp Edit Distance -- A Parallel Dynamic Program in Linear
  Memory",http://arxiv.org/abs/2007.16135v1,2020-07-31T15:31:05Z,2020-07-31T15:31:05Z,"  Edit Distance is a classic family of dynamic programming problems, among
which Time Warp Edit Distance refines the problem with the notion of a metric
and temporal elasticity. A novel Improved Time Warp Edit Distance algorithm
that is both massively parallelizable and requiring only linear storage is
presented. This method uses the procession of a three diagonal band to cover
the original dynamic program space. Every element of the diagonal update can be
computed in parallel. The core method is a feature of the TWED Longest Common
Subsequence data dependence and is applicable to dynamic programs that share
similar band subproblem structure. The algorithm has been implemented as a CUDA
C library with Python bindings. Speedups for challenging problems are
phenomenal.
",['\nGarrett Wright\n'],16 pages,,http://arxiv.org/abs/2007.16135v1,cs.CG,"['cs.CG', 'cs.DC', 'cs.LG', 'cs.MS', 'math.MG']",,,[]
"Approaches to the implementation of generalized complex numbers in the
  Julia language",http://arxiv.org/abs/2007.09737v1,2020-07-19T18:24:08Z,2020-07-19T18:24:08Z,"  In problems of mathematical physics, to study the structures of spaces using
the Cayley-Klein models in theoretical calculations, the use of generalized
complex numbers is required. In the case of computational experiments, such
tasks require their high-quality implementation in a programming language. The
proposed small implementation of generalized complex numbers in modern
programming languages have several disadvantages. In this article, we propose
using the Julia language as the language for implementing generalized complex
numbers, not least because it supports the multiple dispatch mechanism. The
paper demonstrates the approach to the implementation of one of the types of
generalized complex numbers, namely dual numbers. We place particular emphasis
on the description of the use of the multiple dispatch mechanism to implement a
new numerical type. The resulting implementation of dual numbers can be
considered as a prototype for a complete software module for supporting
generalized complex numbers.
","['\nMigran N. Gevorkyan\n', '\nAnna V. Korolkova\n', '\nDmitry S. Kulyabov\n']",in English; in Russian,"in CEUR Workshop Proceedings, vol. 2639, 141-157 (2020)",http://arxiv.org/abs/2007.09737v1,cs.MS,['cs.MS'],,,[]
An Adaptive Solver for Systems of Linear Equations,http://arxiv.org/abs/2007.11208v2,2020-07-22T05:30:33Z,2020-09-01T03:18:59Z,"  Computational implementations for solving systems of linear equations often
rely on a one-size-fits-all approach based on LU decomposition of dense
matrices stored in column-major format. Such solvers are typically implemented
with the aid of the xGESV set of functions available in the low-level LAPACK
software, with the aim of reducing development time by taking advantage of
well-tested routines. However, this straightforward approach does not take into
account various matrix properties which can be exploited to reduce the
computational effort and/or to increase numerical stability. Furthermore,
direct use of LAPACK functions can be error-prone for non-expert users and
results in source code that has little resemblance to originating mathematical
expressions. We describe an adaptive solver that we have implemented inside
recent versions of the high-level Armadillo C++ library for linear algebra. The
solver automatically detects several common properties of a given system
(banded, triangular, symmetric positive definite), followed by solving the
system via mapping to a set of suitable LAPACK functions best matched to each
property. The solver also detects poorly conditioned systems and automatically
seeks a solution via singular value decomposition as a fallback. We show that
the adaptive solver leads to notable speedups, while also freeing the user from
using direct calls to cumbersome LAPACK functions.
","['\nConrad Sanderson\n', '\nRyan Curtin\n']",,,http://dx.doi.org/10.1109/ICSPCS50536.2020.9309998,cs.MS,"['cs.MS', '65Y04, 65Y15, 65F45, 65H10, 15-04, 68N30', 'G.4; G.1.3; H.3.4']",10.1109/ICSPCS50536.2020.9309998,,[]
"Languages for modeling the RED active queue management algorithms:
  Modelica vs. Julia",http://arxiv.org/abs/2007.09488v1,2020-07-18T17:49:33Z,2020-07-18T17:49:33Z,"  This work is devoted to the study of the capabilities of the Modelica and
Julia programming languages for the implementation of a continuously discrete
paradigm in modeling hybrid systems that contain both continuous and discrete
aspects of behavior. A system consisting of an incoming stream that is
processed according to the Transmission Control Protocol (TCP) and a router
that processes traffic using the Random Early Detection (RED) algorithm acts as
a simulated threshold system.
","['\nAnna Maria Yu. Apreutesey\n', '\nAnna V. Korolkova\n', '\nDmitry S. Kulyabov\n']",in English; in Russian,"in CEUR Workshop Proceedings, vol. 2639, 130-140 (2020)",http://arxiv.org/abs/2007.09488v1,cs.NI,"['cs.NI', 'cs.MS']",,,[]
Tegula -- exploring a galaxy of two-dimensional periodic tilings,http://arxiv.org/abs/2007.10625v1,2020-07-21T07:04:42Z,2020-07-21T07:04:42Z,"  Periodic tilings play a role in the decorative arts, in construction and in
crystal structures. Combinatorial tiling theory allows the systematic
generation, visualization and exploration of such tilings of the plane, sphere
and hyperbolic plane, using advanced algorithms and software.Here we present a
""galaxy"" of tilings that consists of the set of all 2.4 billion different types
of periodic tilings that have Dress complexity up to 24. We make these
available in a database and provide a new program called Tegula that can be
used to search and visualize such tilings.
  Availability: All tilings and software and are open source and available
here: https://ab.inf.uni-tuebingen.de/software/tegula.
","['\nRüdiger Zeller\n', '\nOlaf Delgado Friedrichs\n', '\nDaniel H. Huson\n']",,,http://arxiv.org/abs/2007.10625v1,math.CO,"['math.CO', 'cs.MS', '51-04', 'G.4; E.0; K.3']",,,[]
"Accelerating Geometric Multigrid Preconditioning with Half-Precision
  Arithmetic on GPUs",http://arxiv.org/abs/2007.07539v1,2020-07-15T08:27:33Z,2020-07-15T08:27:33Z,"  With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs,
high-performance computing applications can benefit from lower precision at
appropriate spots to speed up the overall execution time. In this paper, we
investigate a mixed-precision geometric multigrid method to solve large sparse
systems of equations stemming from discretization of elliptic PDEs. While the
final solution is always computed with high-precision accuracy, an iterative
refinement approach with multigrid preconditioning in lower precision and
residuum scaling is employed. We compare the FP64 baseline for Poisson's
equation to purely FP16 multigrid preconditioning and to the employment of
FP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count
is almost not affected by using lower accuracy, the solver runtime is
considerably decreased due to the reduced memory transfer and a speedup of up
to 2.5x is gained for the overall solver. We investigate the performance of
selected kernels with the hierarchical Roofline model.
","['\nKyaw L. Oo\n', '\nAndreas Vogel\n']",,,http://arxiv.org/abs/2007.07539v1,cs.MS,"['cs.MS', 'cs.AR', 'cs.PF']",,,[]
Blends in Maple,http://arxiv.org/abs/2007.05041v2,2020-07-09T19:27:10Z,2020-11-27T19:58:28Z,"  A blend of two Taylor series for the same smooth real- or complex-valued
function of a single variable can be useful for approximation. We use an
explicit formula for a two-point Hermite interpolational polynomial to
construct such blends. We show a robust Maple implementation that can stably
and efficiently evaluate blends using linear-cost Horner form, evaluate their
derivatives to arbitrary order at the same time, or integrate a blend exactly.
The implementation is suited for use with evalhf. We provide a top-level user
interface and efficient module exports for programmatic use. This work was
presented at the Maple Conference 2020. See www.maplesoft.com/mapleconference
","['\nRobert M. Corless\n', '\nErik Postma\n']","20 pages, 14 figures",,http://arxiv.org/abs/2007.05041v2,cs.MS,"['cs.MS', '65D05, 65D32, 68W30', 'I.1.1; G.1.2; G.1.7']",,,[]
"A Novel Approach to Generate Correctly Rounded Math Libraries for New
  Floating Point Representations",http://arxiv.org/abs/2007.05344v3,2020-07-09T17:45:15Z,2020-11-20T16:24:32Z,"  Given the importance of floating-point~(FP) performance in numerous domains,
several new variants of FP and its alternatives have been proposed (e.g.,
Bfloat16, TensorFloat32, and Posits). These representations do not have
correctly rounded math libraries. Further, the use of existing FP libraries for
these new representations can produce incorrect results. This paper proposes a
novel approach for generating polynomial approximations that can be used to
implement correctly rounded math libraries. Existing methods generate
polynomials that approximate the real value of an elementary function $f(x)$
and produce wrong results due to approximation errors and rounding errors in
the implementation. In contrast, our approach generates polynomials that
approximate the correctly rounded value of $f(x)$ (i.e., the value of $f(x)$
rounded to the target representation). It provides more margin to identify
efficient polynomials that produce correctly rounded results for all inputs. We
frame the problem of generating efficient polynomials that produce correctly
rounded results as a linear programming problem. Our approach guarantees that
we produce the correct result even with range reduction techniques. Using our
approach, we have developed correctly rounded, yet faster, implementations of
elementary functions for multiple target representations.
","['\nJay P. Lim\n', '\nMridul Aanjaneya\n', '\nJohn Gustafson\n', '\nSantosh Nagarakatte\n']",44 pages,,http://arxiv.org/abs/2007.05344v3,cs.MS,['cs.MS'],,,[]
ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians,http://arxiv.org/abs/2007.05094v1,2020-07-09T22:11:48Z,2020-07-09T22:11:48Z,"  The computation of first and second-order derivatives is a staple in many
computing applications, ranging from machine learning to scientific computing.
We propose an algorithm to automatically differentiate algorithms written in a
subset of C99 code and its efficient implementation as a Python script. We
demonstrate that our algorithm enables automatic, reliable, and efficient
differentiation of common algorithms used in physical simulation and geometry
processing.
","['\nDeshana Desai\n', '\nEtai Shuchatowitz\n', '\nZhongshi Jiang\n', '\nTeseo Schneider\n', '\nDaniele Panozzo\n']",,"SoftwareX, Volume 17, 2022",http://dx.doi.org/10.1016/j.softx.2021.100901,cs.MS,"['cs.MS', 'cs.SC']",10.1016/j.softx.2021.100901,,[]
Volesti: Volume Approximation and Sampling for Convex Polytopes in R,http://arxiv.org/abs/2007.01578v3,2020-07-03T09:47:14Z,2021-09-04T10:05:01Z,"  Sampling from high dimensional distributions and volume approximation of
convex bodies are fundamental operations that appear in optimization, finance,
engineering, artificial intelligence and machine learning. In this paper we
present volesti, an R package that provides efficient, scalable algorithms for
volume estimation, uniform and Gaussian sampling from convex polytopes. volesti
scales to hundreds of dimensions, handles efficiently three different types of
polyhedra and provides non existing sampling routines to R. We demonstrate the
power of volesti by solving several challenging problems using the R language.
","['\nApostolos Chalkis\n', '\nVissarion Fisikopoulos\n']","19 pages, 8 figures, 3 tables",The R Journal 13:2 (2021) 561-577,http://dx.doi.org/10.32614/RJ-2021-077,stat.CO,"['stat.CO', 'cs.CG', 'cs.MS', '62, 68, 52', 'G.3; G.4']",10.32614/RJ-2021-077,,[]
"Algorithm 1019: A Task-based Multi-shift QR/QZ Algorithm with Aggressive
  Early Deflation",http://arxiv.org/abs/2007.03576v3,2020-07-07T15:53:50Z,2021-12-15T21:26:36Z,"  The QR algorithm is one of the three phases in the process of computing the
eigenvalues and the eigenvectors of a dense nonsymmetric matrix. This paper
describes a task-based QR algorithm for reducing an upper Hessenberg matrix to
real Schur form. The task-based algorithm also supports generalized eigenvalue
problems (QZ algorithm) but this paper concentrates on the standard case. The
task-based algorithm adopts previous algorithmic improvements, such as
tightly-coupled multi-shifts and Aggressive Early Deflation (AED), and also
incorporates several new ideas that significantly improve the performance. This
includes, but is not limited to, the elimination of several synchronization
points, the dynamic merging of previously separate computational steps, the
shortening and the prioritization of the critical path, and experimental GPU
support. The task-based implementation is demonstrated to be multiple times
faster than multi-threaded LAPACK and ScaLAPACK in both single-node and
multi-node configurations on two different machines based on Intel and AMD
CPUs. The implementation is built on top of the StarPU runtime system and is
part of the open-source StarNEig library.
",['\nMirko Myllykoski\n'],"36 pages, 20 figures, 9 tables. Peer-reviewed version","ACM Trans. Math. Softw. 48 (1), 2022",http://dx.doi.org/10.1145/3495005,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', '97N80, 15A18, 65F15, 65Y05, 68W10, 68W15', 'F.1.2; F.2.1; G.1.3']",10.1145/3495005,,[]
Algorithmic differentiation of hyperbolic flow problems,http://arxiv.org/abs/2007.05330v1,2020-07-10T12:20:20Z,2020-07-10T12:20:20Z,"  We are interested in the development of an algorithmic differentiation
framework for computing approximations to tangent vectors to scalar and systems
of hyperbolic partial differential equations. The main difficulty of such a
numerical method is the presence of shock waves that are resolved by proposing
a numerical discretization of the calculus introduced in Bressan and Marson
[Rend. Sem. Mat. Univ. Padova, 94:79-94, 1995]. Numerical results are presented
for the one-dimensional Burgers equation and the Euler equations. Using the
essential routines of a state-of-the-art code for computational fluid dynamics
(CFD) as a starting point, three modifications are required to apply the
introduced calculus. First, the CFD code is modified to solve an additional
equation for the shock location. Second, we customize the computation of the
corresponding tangent to the shock location. Finally, the modified method is
enhanced by algorithmic differentiation. Applying the introduced calculus to
problems of the Burgers equation and the Euler equations, it is found that
correct sensitivities can be computed, whereas the application of black-box
algorithmic differentiation fails.
","['\nMichael Herty\n', '\nJonathan Hüser\n', '\nUwe Naumann\n', '\nThomas Schilden\n', '\nWolfgang Schröder\n']",,,http://dx.doi.org/10.1016/j.jcp.2021.110110,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'physics.flu-dyn']",10.1016/j.jcp.2021.110110,,[]
"fenicsR13: A Tensorial Mixed Finite Element Solver for the Linear R13
  Equations Using the FEniCS Computing Platform",http://arxiv.org/abs/2007.05944v2,2020-07-12T09:07:24Z,2020-11-03T15:42:16Z,"  We present a mixed finite element solver for the linearized R13 equations of
non-equilibrium gas dynamics. The Python implementation builds upon the
software tools provided by the FEniCS computing platform. We describe a new
tensorial approach utilizing the extension capabilities of FEniCS's Unified
Form Language (UFL) to define required differential operators for tensors above
second degree. The presented solver serves as an example for implementing
tensorial variational formulations in FEniCS, for which the documentation and
literature seem to be very sparse. Using the software abstraction levels
provided by the UFL allows an almost one-to-one correspondence between the
underlying mathematics and the resulting source code. Test cases support the
correctness of the proposed method using validation with exact solutions. To
justify the usage of extended gas flow models, we discuss typical application
cases involving rarefaction effects. We provide the documented and validated
solver publicly.
","['\nLambert Theisen\n', '\nManuel Torrilhon\n']","29 pages, 13 figures, 8 listings, 3 table. Submitted to ACM
  Transactions on Mathematical Software (TOMS)",,http://dx.doi.org/10.1145/3442378,cs.CE,"['cs.CE', 'cs.MS', 'physics.flu-dyn', '65N30, 65-04, 76P05, 76-04, 35Q35, 35-04', 'G.1.8; G.4; J.2']",10.1145/3442378,,[]
"Assign optimization for algorithmic differentiation reuse index
  management strategies",http://arxiv.org/abs/2006.12992v3,2020-06-23T13:40:46Z,2023-08-15T12:10:56Z,"  The identification of primal variables and adjoint variables is usually done
via indices in operator overloading algorithmic differentiation tools. One
approach is a linear management scheme, which is easy to implement and supports
memory optimization for copy statements. An alternative approach performs a
reuse of indices, which requires more implementation effort but results in much
smaller adjoint vectors. Therefore, the vector mode of algorithmic
differentiation scales better with the reuse management scheme. In this paper,
we present a novel approach that reuses the indices and allows the copy
optimization, thus combining the advantages of the two aforementioned schemes.
The new approach is compared to the known approaches on a simple synthetic test
case and a real-world example using the computational fluid dynamics solver
SU2.
","['\nMax Sagebaum\n', '\nJohannes Blühdorn\n', '\nNicolas R. Gauger\n']","15 pages, 4 figures, 4 tables",,http://arxiv.org/abs/2006.12992v3,cs.MS,"['cs.MS', '68N30', 'G.1.4; G.4; D.2.2']",,,[]
"Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to
  HIP",http://arxiv.org/abs/2006.14290v1,2020-06-25T10:22:02Z,2020-06-25T10:22:02Z,"  With AMD reinforcing their ambition in the scientific high performance
computing ecosystem, we extend the hardware scope of the Ginkgo linear algebra
package to feature a HIP backend for AMD GPUs. In this paper, we report and
discuss the porting effort from CUDA, the extension of the HIP framework to add
missing features such as cooperative groups, the performance price of compiling
HIP code for AMD architectures, and the design of a library providing native
backends for NVIDIA and AMD GPUs while minimizing code duplication by using a
shared code base.
","['\nYuhsiang M. Tsai\nKarlsruhe Institute of Technology\n', '\nTerry Cojean\nKarlsruhe Institute of Technology\n', '\nTobias Ribizel\nKarlsruhe Institute of Technology\n', '\nHartwig Anzt\nKarlsruhe Institute of Technology\nUniversity of Tennessee, Innovative Computing Lab\n']",Preprint submitted to HeteroPar,,http://arxiv.org/abs/2006.14290v1,cs.MS,['cs.MS'],,,"['Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology', 'University of Tennessee, Innovative Computing Lab']"
"Ginkgo: A Modern Linear Operator Algebra Framework for High Performance
  Computing",http://arxiv.org/abs/2006.16852v2,2020-06-30T14:42:48Z,2020-07-01T08:31:08Z,"  In this paper, we present Ginkgo, a modern C++ math library for scientific
high performance computing. While classical linear algebra libraries act on
matrix and vector objects, Ginkgo's design principle abstracts all
functionality as ""linear operators"", motivating the notation of a ""linear
operator algebra library"". Ginkgo's current focus is oriented towards providing
sparse linear algebra functionality for high performance GPU architectures, but
given the library design, this focus can be easily extended to accommodate
other algorithms and hardware architectures. We introduce this sophisticated
software architecture that separates core algorithms from architecture-specific
back ends and provide details on extensibility and sustainability measures. We
also demonstrate Ginkgo's usability by providing examples on how to use its
functionality inside the MFEM and deal.ii finite element ecosystems. Finally,
we offer a practical demonstration of Ginkgo's high performance on
state-of-the-art GPU architectures.
","['\nHartwig Anzt\n', '\nTerry Cojean\n', '\nGoran Flegar\n', '\nFritz Göbel\n', '\nThomas Grützmacher\n', '\nPratik Nayak\n', '\nTobias Ribizel\n', '\nYuhsiang Mike Tsai\n', '\nEnrique S. Quintana-Ortí\n']",Preprint submitted to ACM Transactions on Mathematical Software,,http://arxiv.org/abs/2006.16852v2,cs.MS,"['cs.MS', 'D.2; G.1.3; G.4']",,,[]
"SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and
  preconditioned iterative methods",http://arxiv.org/abs/2007.00056v1,2020-06-30T18:39:50Z,2020-06-30T18:39:50Z,"  Hybrid CPU-GPU algorithms for Algebraic Multigrid methods (AMG) to
efficiently utilize both CPU and GPU resources are presented. In particular,
hybrid AMG framework focusing on minimal utilization of GPU memory with
performance on par with GPU-only implementations is developed. The hybrid AMG
framework can be tuned to operate at a significantly lower GPU-memory,
consequently, enables to solve large algebraic systems. Combining the hybrid
AMG framework as a preconditioner with Krylov Subspace solvers like Conjugate
Gradient, BiCG methods provides a solver stack to solve a large class of
problems. The performance of the proposed hybrid AMG framework is analysed for
an array of matrices with different properties and size. Further, the
performance of CPU-GPU algorithms are compared with the GPU-only
implementations to illustrate the significantly lower memory requirements.
","['\nSashikumaar Ganesan\n', '\nManan Shah\n']","21 pages, 17 figures",,http://arxiv.org/abs/2007.00056v1,cs.MS,"['cs.MS', '65F10, 65F50, 65N55, 65Y05']",,,[]
Adaptive SpMV/SpMSpV on GPUs for Input Vectors of Varied Sparsity,http://arxiv.org/abs/2006.16767v3,2020-06-30T13:20:02Z,2020-12-17T12:28:15Z,"  Despite numerous efforts for optimizing the performance of Sparse Matrix and
Vector Multiplication (SpMV) on modern hardware architectures, few works are
done to its sparse counterpart, Sparse Matrix and Sparse Vector Multiplication
(SpMSpV), not to mention dealing with input vectors of varied sparsity. The key
challenge is that depending on the sparsity levels, distribution of data, and
compute platform, the optimal choice of SpMV/SpMSpV kernel can vary, and a
static choice does not suffice. In this paper, we propose an adaptive
SpMV/SpMSpV framework, which can automatically select the appropriate
SpMV/SpMSpV kernel on GPUs for any sparse matrix and vector at the runtime.
Based on systematic analysis on key factors such as computing pattern, workload
distribution and write-back strategy, eight candidate SpMV/SpMSpV kernels are
encapsulated into the framework to achieve high performance in a seamless
manner. A comprehensive study on machine learning based kernel selector is
performed to choose the kernel and adapt with the varieties of both the input
and hardware from both accuracy and overhead perspectives. Experiments
demonstrate that the adaptive framework can substantially outperform the
previous state-of-the-art in real-world applications on NVIDIA Tesla K40m, P100
and V100 GPUs.
","['\nMin Li\n', '\nYulong Ao\n', '\nChao Yang\n']",12 pages,,http://arxiv.org/abs/2006.16767v3,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Sparse Approximate Multifrontal Factorization with Butterfly Compression
  for High Frequency Wave Equations",http://arxiv.org/abs/2007.00202v2,2020-07-01T03:27:33Z,2021-10-18T16:48:34Z,"  We present a fast and approximate multifrontal solver for large-scale sparse
linear systems arising from finite-difference, finite-volume or finite-element
discretization of high-frequency wave equations. The proposed solver leverages
the butterfly algorithm and its hierarchical matrix extension for compressing
and factorizing large frontal matrices via graph-distance guided entry
evaluation or randomized matrix-vector multiplication-based schemes. Complexity
analysis and numerical experiments demonstrate $\mathcal{O}(N\log^2 N)$
computation and $\mathcal{O}(N)$ memory complexity when applied to an $N\times
N$ sparse system arising from 3D high-frequency Helmholtz and Maxwell problems.
","['\nYang Liu\n', '\nPieter Ghysels\n', '\nLisa Claus\n', '\nXiaoye Sherry Li\n']",,SIAM Journal on Scientific Computing. 2021(0):S367-91,http://dx.doi.org/10.1137/20M1349667,cs.MS,"['cs.MS', 'cs.CE', '15A23, 65F50, 65R10, 65R20']",10.1137/20M1349667,,[]
"The flare Package for High Dimensional Linear Regression and Precision
  Matrix Estimation in R",http://arxiv.org/abs/2006.15419v1,2020-06-27T18:01:56Z,2020-06-27T18:01:56Z,"  This paper describes an R package named flare, which implements a family of
new high dimensional regression methods (LAD Lasso, SQRT Lasso, $\ell_q$ Lasso,
and Dantzig selector) and their extensions to sparse precision matrix
estimation (TIGER and CLIME). These methods exploit different nonsmooth loss
functions to gain modeling flexibility, estimation robustness, and tuning
insensitiveness. The developed solver is based on the alternating direction
method of multipliers (ADMM). The package flare is coded in double precision C,
and called from R by a user-friendly interface. The memory usage is optimized
by using the sparse matrix output. The experiments show that flare is efficient
and can scale up to large problems.
","['\nXingguo Li\n', '\nTuo Zhao\n', '\nXiaoming Yuan\n', '\nHan Liu\n']",,Journal of Machine Learning Research 16 (2015) 553-557,http://arxiv.org/abs/2006.15419v1,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS']",,,[]
"Hierarchical Jacobi Iteration for Structured Matrices on GPUs using
  Shared Memory",http://arxiv.org/abs/2006.16465v1,2020-06-30T01:36:58Z,2020-06-30T01:36:58Z,"  High fidelity scientific simulations modeling physical phenomena typically
require solving large linear systems of equations which result from
discretization of a partial differential equation (PDE) by some numerical
method. This step often takes a vast amount of computational time to complete,
and therefore presents a bottleneck in simulation work. Solving these linear
systems efficiently requires the use of massively parallel hardware with high
computational throughput, as well as the development of algorithms which
respect the memory hierarchy of these hardware architectures to achieve high
memory bandwidth.
  In this paper, we present an algorithm to accelerate Jacobi iteration for
solving structured problems on graphics processing units (GPUs) using a
hierarchical approach in which multiple iterations are performed within on-chip
shared memory every cycle. A domain decomposition style procedure is adopted in
which the problem domain is partitioned into subdomains whose data is copied to
the shared memory of each GPU block. Jacobi iterations are performed internally
within each block's shared memory, avoiding the need to perform expensive
global memory accesses every step. We test our algorithm on the linear systems
arising from discretization of Poisson's equation in 1D and 2D, and observe
speedup in convergence using our shared memory approach compared to a
traditional Jacobi implementation which only uses global memory on the GPU. We
observe a x8 speedup in convergence in the 1D problem and a nearly x6 speedup
in the 2D case from the use of shared memory compared to a conventional GPU
approach.
","['\nMohammad Shafaet Islam\n', '\nQiqi Wang\n']","22 pages, 13 figures",,http://arxiv.org/abs/2006.16465v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Efficient parallel 3D computation of the compressible Euler equations
  with an invariant-domain preserving second-order finite-element scheme",http://arxiv.org/abs/2007.00094v2,2020-06-30T20:19:45Z,2021-02-02T21:07:20Z,"  We discuss the efficient implementation of a high-performance second-order
collocation-type finite-element scheme for solving the compressible Euler
equations of gas dynamics on unstructured meshes. The solver is based on the
convex limiting technique introduced by Guermond et al. (SIAM J. Sci. Comput.
40, A3211-A3239, 2018). As such it is invariant-domain preserving, i.e., the
solver maintains important physical invariants and is guaranteed to be stable
without the use of ad-hoc tuning parameters. This stability comes at the
expense of a significantly more involved algorithmic structure that renders
conventional high-performance discretizations challenging. We develop an
algorithmic design that allows SIMD vectorization of the compute kernel,
identify the main ingredients for a good node-level performance, and report
excellent weak and strong scaling of a hybrid thread/MPI parallelization.
","['\nMatthias Maier\n', '\nMartin Kronbichler\n']",,,http://arxiv.org/abs/2007.00094v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
On Designing GPU Algorithms with Applications to Mesh Refinement,http://arxiv.org/abs/2007.00324v1,2020-07-01T08:43:12Z,2020-07-01T08:43:12Z,"  We present a set of rules to guide the design of GPU algorithms. These rules
are grounded on the principle of reducing waste in GPU utility to achieve good
speed up. In accordance to these rules, we propose GPU algorithms for 2D
constrained, 3D constrained and 3D Restricted Delaunay refinement problems
respectively. Our algorithms take a 2D planar straight line graph (PSLG) or 3D
piecewise linear complex (PLC) $\mathcal{G}$ as input, and generate quality
meshes conforming or approximating to $\mathcal{G}$. The implementation of our
algorithms shows that they are the first to run an order of magnitude faster
than current state-of-the-art counterparts in sequential and parallel manners
while using similar numbers of Steiner points to produce triangulations of
comparable qualities. It thus reduces the computing time of mesh refinement
from possibly hours to a few seconds or minutes for possible use in interactive
graphics applications.
","['\nZhenghai Chen\n', '\nTiow-Seng Tan\n', '\nHong-Yang Ong\n']",,,http://arxiv.org/abs/2007.00324v1,cs.GR,"['cs.GR', 'cs.DC', 'cs.MS']",,,[]
Array Programming with NumPy,http://arxiv.org/abs/2006.10256v1,2020-06-18T03:39:27Z,2020-06-18T03:39:27Z,"  Array programming provides a powerful, compact, expressive syntax for
accessing, manipulating, and operating on data in vectors, matrices, and
higher-dimensional arrays. NumPy is the primary array programming library for
the Python language. It plays an essential role in research analysis pipelines
in fields as diverse as physics, chemistry, astronomy, geoscience, biology,
psychology, material science, engineering, finance, and economics. For example,
in astronomy, NumPy was an important part of the software stack used in the
discovery of gravitational waves and the first imaging of a black hole. Here we
show how a few fundamental array concepts lead to a simple and powerful
programming paradigm for organizing, exploring, and analyzing scientific data.
NumPy is the foundation upon which the entire scientific Python universe is
constructed. It is so pervasive that several projects, targeting audiences with
specialized needs, have developed their own NumPy-like interfaces and array
objects. Because of its central position in the ecosystem, NumPy increasingly
plays the role of an interoperability layer between these new array computation
libraries.
","['\nCharles R. Harris\n', '\nK. Jarrod Millman\n', '\nStéfan J. van der Walt\n', '\nRalf Gommers\n', '\nPauli Virtanen\n', '\nDavid Cournapeau\n', '\nEric Wieser\n', '\nJulian Taylor\n', '\nSebastian Berg\n', '\nNathaniel J. Smith\n', '\nRobert Kern\n', '\nMatti Picus\n', '\nStephan Hoyer\n', '\nMarten H. van Kerkwijk\n', '\nMatthew Brett\n', '\nAllan Haldane\n', '\nJaime Fernández del Río\n', '\nMark Wiebe\n', '\nPearu Peterson\n', '\nPierre Gérard-Marchant\n', '\nKevin Sheppard\n', '\nTyler Reddy\n', '\nWarren Weckesser\n', '\nHameer Abbasi\n', '\nChristoph Gohlke\n', '\nTravis E. Oliphant\n']",,"Nature 585, 357 (2020)",http://dx.doi.org/10.1038/s41586-020-2649-2,cs.MS,"['cs.MS', 'stat.CO']",10.1038/s41586-020-2649-2,,[]
"Robust and scalable h-adaptive aggregated unfitted finite elements for
  interface elliptic problems",http://arxiv.org/abs/2006.11042v2,2020-06-19T09:50:02Z,2021-02-11T12:20:12Z,"  This work introduces a novel, fully robust and highly-scalable, $h$-adaptive
aggregated unfitted finite element method for large-scale interface elliptic
problems. The new method is based on a recent distributed-memory implementation
of the aggregated finite element method atop a highly-scalable Cartesian
forest-of-trees mesh engine. It follows the classical approach of weakly
coupling nonmatching discretisations at the interface to model internal
discontinuities at the interface. We propose a natural extension of a
single-domain parallel cell aggregation scheme to problems with a finite number
of interfaces; it straightforwardly leads to aggregated finite element spaces
that have the structure of a Cartesian product. We demonstrate, through
standard numerical analysis and exhaustive numerical experimentation on several
complex Poisson and linear elasticity benchmarks, that the new technique enjoys
the following properties: well-posedness, robustness with respect to cut
location and material contrast, optimal ($h$-adaptive) approximation
properties, high scalability and easy implementation in large-scale finite
element codes. As a result, the method offers great potential as a useful
finite element solver for large-scale interface problems modelled by partial
differential equations.
","['\nEric Neiva\n', '\nSantiago Badia\n']","24 pages, 13 figures",,http://dx.doi.org/10.1016/j.cma.2021.113769,math.NA,"['math.NA', 'cs.CE', 'cs.MS', 'cs.NA']",10.1016/j.cma.2021.113769,,[]
"AutoMat -- Automatic Differentiation for Generalized Standard Materials
  on GPUs",http://arxiv.org/abs/2006.04391v2,2020-06-08T07:38:28Z,2020-10-06T11:41:40Z,"  We propose a universal method for the evaluation of generalized standard
materials that greatly simplifies the material law implementation process. By
means of automatic differentiation and a numerical integration scheme, AutoMat
reduces the implementation effort to two potential functions. By moving AutoMat
to the GPU, we close the performance gap to conventional evaluation routines
and demonstrate in detail that the expression level reverse mode of automatic
differentiation as well as its extension to second order derivatives can be
applied inside CUDA kernels. We underline the effectiveness and the
applicability of AutoMat by integrating it into the FFT-based homogenization
scheme of Moulinec and Suquet and discuss the benefits of using AutoMat with
respect to runtime and solution accuracy for an elasto-viscoplastic example.
","['\nJohannes Blühdorn\n', '\nNicolas R. Gauger\n', '\nMatthias Kabel\n']","28 pages, 15 figures, 7 tables; new layout, more detailed proof of
  Theorem 1",,http://dx.doi.org/10.1007/s00466-021-02105-2,cs.CE,"['cs.CE', 'cs.MS', 'G.1.4; G.1.7; G.4; J.2']",10.1007/s00466-021-02105-2,,[]
"The aggregated unfitted finite element method on parallel tree-based
  adaptive meshes",http://arxiv.org/abs/2006.05373v2,2020-06-09T16:08:13Z,2021-02-11T12:10:49Z,"  In this work, we present an adaptive unfitted finite element scheme that
combines the aggregated finite element method with parallel adaptive mesh
refinement. We introduce a novel scalable distributed-memory implementation of
the resulting scheme on locally-adapted Cartesian forest-of-trees meshes. We
propose a two-step algorithm to construct the finite element space at hand by
means of a discrete extension operator that carefully mixes aggregation
constraints of problematic degrees of freedom, which get rid of the small cut
cell problem, and standard hanging degree of freedom constraints, which ensure
trace continuity on non-conforming meshes. Following this approach, we derive a
finite element space that can be expressed as the original one plus
well-defined linear constraints. Moreover, it requires minimum parallelization
effort, using standard functionality available in existing large-scale finite
element codes. Numerical experiments demonstrate its optimal mesh adaptation
capability, robustness to cut location and parallel efficiency, on classical
Poisson $hp$-adaptivity benchmarks. Our work opens the path to functional and
geometrical error-driven dynamic mesh adaptation with the aggregated finite
element method in large-scale realistic scenarios. Likewise, it can offer
guidance for bridging other scalable unfitted methods and parallel adaptive
mesh refinement.
","['\nSantiago Badia\n', '\nAlberto F. Martín\n', '\nEric Neiva\n', '\nFrancesc Verdugo\n']","25 pages, 14 figures",,http://dx.doi.org/10.1137/20M1344512,math.NA,"['math.NA', 'cs.CE', 'cs.MS', 'cs.NA']",10.1137/20M1344512,,[]
"On Computing the Kronecker Structure of Polynomial and Rational Matrices
  using Julia",http://arxiv.org/abs/2006.06825v2,2020-06-09T08:36:42Z,2020-09-06T11:44:24Z,"  In this paper we discuss the mathematical background and the computational
aspects which underly the implementation of a collection of Julia functions in
the MatrixPencils package for the determination of structural properties of
polynomial and rational matrices. We primarily focus on the computation of the
finite and infinite spectral structures (e.g., eigenvalues, zeros, poles) as
well as the left and right singular structures (e.g., Kronecker indices), which
play a fundamental role in the structure of the solution of many problems
involving polynomial and rational matrices. The basic analysis tool is the
determination of the Kronecker structure of linear matrix pencils using
numerically reliable algorithms, which is used in conjunction with several
linearization techniques of polynomial and rational matrices. Examples of
polynomial and rational matrices, which exhibit all relevant structural
features, are considered to illustrate the main mathematical concepts and the
capabilities of implemented tools.
",['\nAndreas Varga\n'],28 pages,,http://arxiv.org/abs/2006.06825v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '26C10, 30C10, 93B10, 93B60, 93C05']",,,[]
"Signal Processing for a Reverse-GPS Wildlife Tracking System: CPU and
  GPU Implementation Experiences",http://arxiv.org/abs/2005.10445v3,2020-05-21T03:28:52Z,2021-05-27T07:15:52Z,"  We present robust high-performance implementations of signal-processing tasks
performed by a high-throughput wildlife tracking system called ATLAS. The
system tracks radio transmitters attached to wild animals by estimating the
time of arrival of radio packets to multiple receivers (base stations).
Time-of-arrival estimation of wideband radio signals is computationally
expensive, especially in acquisition mode (when the time of transmission is not
known, not even approximately). These computations are a bottleneck that limits
the throughput of the system. We developed a sequential high-performance CPU
implementation of the computations a few years back, and more recencely a GPU
implementation. Both strive to balance performance with simplicity,
maintainability, and development effort, as most real-world codes do. The paper
reports on the two implementations and carefully evaluates their performance.
The evaluations indicates that the GPU implementation dramatically improves
performance and power-performance relative to the sequential CPU implementation
running on a desktop CPU typical of the computers in current base stations.
Performance improves by more than 50X on a high-end GPU and more than 4X with a
GPU platform that consumes almost 5 times less power than the CPU platform.
Performance-per-Watt ratios also improve (by more than 16X), and so do the
price-performance ratios.
","['\nYaniv Rubinpur\n', '\nSivan Toledo\n']","Revised (very slightly, changed a few sentences describing Figure 7)",,http://arxiv.org/abs/2005.10445v3,cs.DC,"['cs.DC', 'cs.MS']",,,[]
SymJAX: symbolic CPU/GPU/TPU programming,http://arxiv.org/abs/2005.10635v1,2020-05-21T13:37:25Z,2020-05-21T13:37:25Z,"  SymJAX is a symbolic programming version of JAX simplifying graph
input/output/updates and providing additional functionalities for general
machine learning and deep learning applications. From an user perspective
SymJAX provides a la Theano experience with fast graph optimization/compilation
and broad hardware support, along with Lasagne-like deep learning
functionalities.
",['\nRandall Balestriero\n'],,,http://arxiv.org/abs/2005.10635v1,cs.MS,"['cs.MS', 'cs.CV']",,,[]
Model Evidence with Fast Tree Based Quadrature,http://arxiv.org/abs/2005.11300v1,2020-05-22T17:48:06Z,2020-05-22T17:48:06Z,"  High dimensional integration is essential to many areas of science, ranging
from particle physics to Bayesian inference. Approximating these integrals is
hard, due in part to the difficulty of locating and sampling from regions of
the integration domain that make significant contributions to the overall
integral. Here, we present a new algorithm called Tree Quadrature (TQ) that
separates this sampling problem from the problem of using those samples to
produce an approximation of the integral. TQ places no qualifications on how
the samples provided to it are obtained, allowing it to use state-of-the-art
sampling algorithms that are largely ignored by existing integration
algorithms. Given a set of samples, TQ constructs a surrogate model of the
integrand in the form of a regression tree, with a structure optimised to
maximise integral precision. The tree divides the integration domain into
smaller containers, which are individually integrated and aggregated to
estimate the overall integral. Any method can be used to integrate each
individual container, so existing integration methods, like Bayesian Monte
Carlo, can be combined with TQ to boost their performance. On a set of
benchmark problems, we show that TQ provides accurate approximations to
integrals in up to 15 dimensions; and in dimensions 4 and above, it outperforms
simple Monte Carlo and the popular Vegas method.
","['\nThomas Foster\n', '\nChon Lok Lei\n', '\nMartin Robinson\n', '\nDavid Gavaghan\n', '\nBen Lambert\n']",,,http://arxiv.org/abs/2005.11300v1,stat.ML,"['stat.ML', 'cs.LG', 'cs.MS', 'stat.CO']",,,[]
copent: Estimating Copula Entropy and Transfer Entropy in R,http://arxiv.org/abs/2005.14025v3,2020-05-27T10:01:12Z,2021-03-27T00:41:58Z,"  Statistical independence and conditional independence are two fundamental
concepts in statistics and machine learning. Copula Entropy is a mathematical
concept defined by Ma and Sun for multivariate statistical independence
measuring and testing, and also proved to be closely related to conditional
independence (or transfer entropy). As the unified framework for measuring both
independence and causality, CE has been applied to solve several related
statistical or machine learning problems, including association discovery,
structure learning, variable selection, and causal discovery. The nonparametric
methods for estimating copula entropy and transfer entropy were also proposed
previously. This paper introduces copent, the R package which implements these
proposed methods for estimating copula entropy and transfer entropy. The
implementation detail of the package is introduced. Three examples with
simulated data and real-world data on variable selection and causal discovery
are also presented to demonstrate the usage of this package. The examples on
variable selection and causal discovery show the strong ability of copent on
testing (conditional) independence compared with the related packages. The
copent package is available on the Comprehensive R Archive Network (CRAN) and
also on GitHub at https://github.com/majianthu/copent.
",['\nJian Ma\n'],"18 pages, 3 figures",,http://arxiv.org/abs/2005.14025v3,stat.CO,"['stat.CO', 'cs.IT', 'cs.LG', 'cs.MS', 'math.IT', 'stat.ME']",,,[]
A modular extension for a computer algebra system,http://arxiv.org/abs/2005.05261v1,2020-05-11T17:05:30Z,2020-05-11T17:05:30Z,"  Computer algebra systems are complex software systems that cover a wide range
of scientific and practical problems. However, the absolute coverage cannot be
achieved. Often, it is required to create a user extension for an existing
computer algebra system. In this case, the extensibility of the system should
be taken into account. In this paper, we consider a technology for extending
the SymPy computer algebra system with a low-level module that implements a
random number generator.
","['\nMigran N. Gevorkyan\n', '\nAnna V. Korolkova\n', '\nDmitry S. Kulyabov\n', '\nLeonid A. Sevastianov\n']",in English; in Russian,,http://dx.doi.org/10.1134/S036176882002005X,cs.MS,"['cs.MS', 'cs.SC']",10.1134/S036176882002005X,,[]
"Reproducibility of Parallel Preconditioned Conjugate Gradient in Hybrid
  Programming Environments",http://arxiv.org/abs/2005.07282v1,2020-05-14T22:10:15Z,2020-05-14T22:10:15Z,"  The Preconditioned Conjugate Gradient method is often employed for the
solution of linear systems of equations arising in numerical simulations of
physical phenomena. While being widely used, the solver is also known for its
lack of accuracy while computing the residual. In this article, we propose two
algorithmic solutions that originate from the ExBLAS project to enhance the
accuracy of the solver as well as to ensure its reproducibility in a hybrid MPI
+ OpenMP tasks programming environment. One is based on ExBLAS and preserves
every bit of information until the final rounding, while the other relies upon
floating-point expansions and, hence, expands the intermediate precision.
Instead of converting the entire solver into its ExBLAS-related implementation,
we identify those parts that violate reproducibility/non-associativity, secure
them, and combine this with the sequential executions. These algorithmic
strategies are reinforced with programmability suggestions to assure
deterministic executions. Finally, we verify these approaches on two modern HPC
systems: both versions deliver reproducible number of iterations, residuals,
direct errors, and vector-solutions for the overhead of less than 37.7 % on 768
cores.
","['\nRoman Iakymchuk\n', '\nMaria Barreda\n', '\nStef Graillat\n', '\nJose I. Aliaga\n', '\nEnrique S. Quintana-Orti\n']",,,http://arxiv.org/abs/2005.07282v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
AutoHOOT: Automatic High-Order Optimization for Tensors,http://arxiv.org/abs/2005.04540v2,2020-05-10T01:15:37Z,2020-12-24T20:18:57Z,"  High-order optimization methods, including Newton's method and its variants
as well as alternating minimization methods, dominate the optimization
algorithms for tensor decompositions and tensor networks. These tensor methods
are used for data analysis and simulation of quantum systems. In this work, we
introduce AutoHOOT, the first automatic differentiation (AD) framework
targeting at high-order optimization for tensor computations. AutoHOOT takes
input tensor computation expressions and generates optimized derivative
expressions. In particular, AutoHOOT contains a new explicit Jacobian / Hessian
expression generation kernel whose outputs maintain the input tensors'
granularity and are easy to optimize. The expressions are then optimized by
both the traditional compiler optimization techniques and specific tensor
algebra transformations. Experimental results show that AutoHOOT achieves
competitive CPU and GPU performance for both tensor decomposition and tensor
network applications compared to existing AD software and other tensor
computation libraries with manually written kernels. The tensor methods
generated by AutoHOOT are also well-parallelizable, and we demonstrate good
scalability on a distributed memory supercomputer.
","['\nLinjian Ma\n', '\nJiayu Ye\n', '\nEdgar Solomonik\n']","18 pages, 8 figures",,http://arxiv.org/abs/2005.04540v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Batched computation of the singular value decompositions of order two by
  the AVX-512 vectorization",http://arxiv.org/abs/2005.07403v1,2020-05-15T08:16:11Z,2020-05-15T08:16:11Z,"  In this paper a vectorized algorithm for simultaneously computing up to eight
singular value decompositions (SVDs, each of the form $A=U\Sigma V^{\ast}$) of
real or complex matrices of order two is proposed. The algorithm extends to a
batch of matrices of an arbitrary length $n$, that arises, for example, in the
annihilation part of the parallel Kogbetliantz algorithm for the SVD of a
square matrix of order $2n$. The SVD algorithm for a single matrix of order two
is derived first. It scales, in most instances error-free, the input matrix $A$
such that its singular values $\Sigma_{ii}$ cannot overflow whenever its
elements are finite, and then computes the URV factorization of the scaled
matrix, followed by the SVD of a non-negative upper-triangular middle factor. A
vector-friendly data layout for the batch is then introduced, where the
same-indexed elements of each of the input and the output matrices form
vectors, and the algorithm's steps over such vectors are described. The
vectorized approach is then shown to be about three times faster than
processing each matrix in isolation, while slightly improving accuracy over the
straightforward method for the $2\times 2$ SVD.
",['\nVedran Novaković\n'],"Preprint of an article submitted for consideration in Parallel
  Processing Letters ( https://www.worldscientific.com/worldscinet/ppl )","Parallel Process. Lett. 30 (2020), 4; 2050015",http://dx.doi.org/10.1142/S0129626420500152,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65F15 (Primary) 65Y05, 65Y10 (Secondary)']",10.1142/S0129626420500152,,[]
"SciANN: A Keras/Tensorflow wrapper for scientific computations and
  physics-informed deep learning using artificial neural networks",http://arxiv.org/abs/2005.08803v2,2020-05-11T22:55:15Z,2020-09-16T03:18:44Z,"  In this paper, we introduce SciANN, a Python package for scientific computing
and physics-informed deep learning using artificial neural networks. SciANN
uses the widely used deep-learning packages Tensorflow and Keras to build deep
neural networks and optimization models, thus inheriting many of Keras's
functionalities, such as batch optimization and model reuse for transfer
learning. SciANN is designed to abstract neural network construction for
scientific computations and solution and discovery of partial differential
equations (PDE) using the physics-informed neural networks (PINN) architecture,
therefore providing the flexibility to set up complex functional forms. We
illustrate, in a series of examples, how the framework can be used for curve
fitting on discrete data, and for solution and discovery of PDEs in strong and
weak forms. We summarize the features currently available in SciANN, and also
outline ongoing and future developments.
","['\nEhsan Haghighat\n', '\nRuben Juanes\n']",,,http://dx.doi.org/10.1016/j.cma.2020.113552,cs.OH,"['cs.OH', 'cs.LG', 'cs.MS', '74S30 (primary), 74S05, 74B05, 74L05, 74L10 (secondary)', 'J.2']",10.1016/j.cma.2020.113552,,[]
"The JuliaConnectoR: a functionally oriented interface for integrating
  Julia in R",http://arxiv.org/abs/2005.06334v2,2020-05-13T14:18:34Z,2021-03-29T19:14:29Z,"  Like many groups considering the new programming language Julia, we faced the
challenge of accessing the algorithms that we develop in Julia from R.
Therefore, we developed the R package JuliaConnectoR, available from the CRAN
repository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), in
particular for making advanced deep learning tools available. For
maintainability and stability, we decided to base communication between R and
Julia on TCP, using an optimized binary format for exchanging data. Our package
also specifically contains features that allow for a convenient interactive use
in R. This makes it easy to develop R extensions with Julia or to simply call
functionality from Julia packages in R. Interacting with Julia objects and
calling Julia functions becomes user-friendly, as Julia functions and variables
are made directly available as objects in the R workspace. We illustrate the
further features of our package with code examples, and also discuss advantages
over the two alternative packages JuliaCall and XRJulia. Finally, we
demonstrate the usage of the package with a more extensive example for
employing neural ordinary differential equations, a recent deep learning
technique that has received much attention. This example also provides more
general guidance for integrating deep learning techniques from Julia into R.
","['\nStefan Lenz\n', '\nMaren Hackenberg\n', '\nHarald Binder\n']","23 pages, 3 figures, 4 tables",,http://arxiv.org/abs/2005.06334v2,cs.MS,"['cs.MS', 'cs.LG', 'cs.PL', 'stat.CO', 'stat.ML']",,,[]
"Custom-Precision Mathematical Library Explorations for Code Profiling
  and Optimization",http://arxiv.org/abs/2005.02732v1,2020-05-06T11:06:11Z,2020-05-06T11:06:11Z,"  The typical processors used for scientific computing have fixed-width
data-paths. This implies that mathematical libraries were specifically
developed to target each of these fixed precisions (binary16, binary32,
binary64). However, to address the increasing energy consumption and throughput
requirements of scientific applications, library and hardware designers are
moving beyond this one-size-fits-all approach. In this article we propose to
study the effects and benefits of using user-defined floating-point formats and
target accuracies in calculations involving mathematical functions. Our tool
collects input-data profiles and iteratively explores lower precisions for each
call-site of a mathematical function in user applications. This profiling data
will be a valuable asset for specializing and fine-tuning mathematical function
implementations for a given application. We demonstrate the tool's capabilities
on SGP4, a satellite tracking application. The profile data shows the potential
for specialization and provides insight into answering where it is useful to
provide variable-precision designs for elementary function evaluation.
","['\nDavid Defour\nLP2A\n', '\nPablo de Oliveira Castro\nPRISM, LI-PaRAD\n', '\nMatei Istoan\nUVSQ, LI-PaRAD\n', '\nEric Petit\n']",,,http://arxiv.org/abs/2005.02732v1,cs.MS,['cs.MS'],,,"['LP2A', 'PRISM, LI-PaRAD', 'UVSQ, LI-PaRAD']"
Delayed approximate matrix assembly in multigrid with dynamic precisions,http://arxiv.org/abs/2005.03606v1,2020-05-07T17:06:01Z,2020-05-07T17:06:01Z,"  The accurate assembly of the system matrix is an important step in any code
that solves partial differential equations on a mesh. We either explicitly set
up a matrix, or we work in a matrix-free environment where we have to be able
to quickly return matrix entries upon demand. Either way, the construction can
become costly due to non-trivial material parameters entering the equations,
multigrid codes requiring cascades of matrices that depend upon each other, or
dynamic adaptive mesh refinement that necessitates the recomputation of matrix
entries or the whole equation system throughout the solve. We propose that
these constructions can be performed concurrently with the multigrid cycles.
Initial geometric matrices and low accuracy integrations kickstart the
multigrid, while improved assembly data is fed to the solver as and when it
becomes available. The time to solution is improved as we eliminate an
expensive preparation phase traditionally delaying the actual computation. We
eliminate algorithmic latency. Furthermore, we desynchronise the assembly from
the solution process. This anarchic increase of the concurrency level improves
the scalability. Assembly routines are notoriously memory- and
bandwidth-demanding. As we work with iteratively improving operator accuracies,
we finally propose the use of a hierarchical, lossy compression scheme such
that the memory footprint is brought down aggressively where the system matrix
entries carry little information or are not yet available with high accuracy.
","['\nCharles D. Murray\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1002/cpe.5941,cs.MS,['cs.MS'],10.1002/cpe.5941,,[]
Various Ways to Quantify BDMPs,http://arxiv.org/abs/2004.13283v1,2020-04-28T04:21:21Z,2020-04-28T04:21:21Z,"  A Boolean logic driven Markov process (BDMP) is a dependability analysis
model that defines a continuous-time Markov chain (CTMC). This formalism has
high expressive power, yet it remains readable because its graphical
representation stays close to standard fault trees. The size of a BDMP is
roughly speaking proportional to the size of the system it models, whereas the
size of the CTMC specified by this BDMP suffers from exponential growth. Thus
quantifying large BDMPs can be a challenging task. The most general method to
quantify them is Monte Carlo simulation, but this may be intractable for highly
reliable systems. On the other hand, some subcategories of BDMPs can be
processed with much more efficient methods. For example, BDMPs without repairs
can be translated into dynamic fault trees, a formalism accepted as an input of
the STORM model checker, that performs numerical calculations on sparse
matrices, or they can be processed with the tool FIGSEQ that explores paths
going to a failure state and calculates their probabilities. BDMPs with repairs
can be quantified by FIGSEQ (BDMPs capturing quickly and completely repairable
behaviors are solved by a different algorithm), and by the I&AB (Initiator and
All Barriers) method, recently published and implemented in a prototype version
of RISKSPECTRUM PSA. This tool, based exclusively on Boolean representations
looks for and quantifies minimal cut sets of the system, i.e., minimal
combinations of component failures that induce the loss of the system. This
allows a quick quantification of large models with repairable components,
standby redundancies and some other types of dependencies between omponents.
All these quantification methods have been tried on a benchmark whose
definition was published at the MARS 2017 workshop: the model of emergency
power supplies of a nuclear power plant. In this paper, after a recall of the
theoretical principles of the various quantification methods, we compare their
performances on that benchmark.
","['\nMarc Bouissou\nEDF\n', '\nShahid Khan\nRWTH Aachen University\n', '\nJoost-Pieter Katoen\nRWTH Aachen University\n', ""\nPavel Krcal\nLloyd's Register\n""]","In Proceedings MARS 2020, arXiv:2004.12403","EPTCS 316, 2020, pp. 1-14",http://dx.doi.org/10.4204/EPTCS.316.1,cs.CE,"['cs.CE', 'cs.MS']",10.4204/EPTCS.316.1,,"['EDF', 'RWTH Aachen University', 'RWTH Aachen University', ""Lloyd's Register""]"
"CS-TSSOS: Correlative and term sparsity for large-scale polynomial
  optimization",http://arxiv.org/abs/2005.02828v2,2020-05-06T13:55:03Z,2021-06-08T21:12:01Z,"  This work proposes a new moment-SOS hierarchy, called CS-TSSOS, for solving
large-scale sparse polynomial optimization problems. Its novelty is to exploit
simultaneously correlative sparsity and term sparsity by combining advantages
of two existing frameworks for sparse polynomial optimization. The former is
due to Waki et al. while the latter was initially proposed by Wang et al. and
later exploited in the TSSOS hierarchy. In doing so we obtain CS-TSSOS -- a
two-level hierarchy of semidefinite programming relaxations with (i), the
crucial property to involve blocks of SDP matrices and (ii), the guarantee of
convergence to the global optimum under certain conditions. We demonstrate its
efficiency and scalability on several large-scale instances of the celebrated
Max-Cut problem and the important industrial optimal power flow problem,
involving up to six thousand variables and tens of thousands of constraints.
","['\nJie Wang\n', '\nVictor Magron\n', '\nJean B. Lasserre\n', '\nNgoc Hoang Anh Mai\n']","28 pages, 8 figures, 8 tables",,http://arxiv.org/abs/2005.02828v2,math.OC,"['math.OC', 'cs.MS']",,,[]
Synergistic CPU-FPGA Acceleration of Sparse Linear Algebra,http://arxiv.org/abs/2004.13907v1,2020-04-29T01:06:52Z,2020-04-29T01:06:52Z,"  This paper describes REAP, a software-hardware approach that enables high
performance sparse linear algebra computations on a cooperative CPU-FPGA
platform. REAP carefully separates the task of organizing the matrix elements
from the computation phase. It uses the CPU to provide a first-pass
re-organization of the matrix elements, allowing the FPGA to focus on the
computation. We introduce a new intermediate representation that allows the CPU
to communicate the sparse data and the scheduling decisions to the FPGA. The
computation is optimized on the FPGA for effective resource utilization with
pipelining. REAP improves the performance of Sparse General Matrix
Multiplication (SpGEMM) and Sparse Cholesky Factorization by 3.2X and 1.85X
compared to widely used sparse libraries for them on the CPU, respectively.
","['\nMohammadreza Soltaniyeh\n', '\nRichard P. Martin\n', '\nSantosh Nagarakatte\n']",12 pages,,http://arxiv.org/abs/2004.13907v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PL']",,,[]
"A practical approach to testing random number generators in computer
  algebra systems",http://arxiv.org/abs/2004.08913v1,2020-04-19T17:19:19Z,2020-04-19T17:19:19Z,"  This paper has a practical aim. For a long time, implementations of
pseudorandom number generators in standard libraries of programming languages
had poor quality. The situation started to improve only recently. Up to now, a
large number of libraries and weakly supported mathematical packages use
outdated algorithms for random number generation. Four modern sets of
statistical tests that can be used for verifying random number generators are
described. It is proposed to use command line utilities, which makes it
possible to avoid low-level programming in such languages as C or C++. Only
free open source systems are considered.
","['\nMigran N. Gevorkyan\n', '\nDmitry S. Kulyabov\n', '\nAnastasia V. Demidova\n', '\nAnna V. Korolkova\n']","in English, in Russian",,http://dx.doi.org/10.1134/S096554252001008X,cs.MS,"['cs.MS', 'cs.SC']",10.1134/S096554252001008X,,[]
"Fully Parallel Mesh I/O using PETSc DMPlex with an Application to
  Waveform Modeling",http://arxiv.org/abs/2004.08729v2,2020-04-18T23:26:04Z,2020-09-15T11:48:01Z,"  Large-scale PDE simulations using high-order finite-element methods on
unstructured meshes are an indispensable tool in science and engineering. The
widely used open-source PETSc library offers an efficient representation of
generic unstructured meshes within its DMPlex module. This paper details our
recent implementation of parallel mesh reading and topological interpolation
(computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply
these developments to seismic wave propagation scenarios on Mars as an example
application. The principal motivation is to overcome single-node memory limits
and reach mesh sizes which were impossible before. Moreover, we demonstrate
that scalability of I/O and topological interpolation goes beyond 12'000 cores,
and memory-imposed limits on mesh size vanish.
","['\nVaclav Hapla\n', '\nMatthew G. Knepley\n', '\nMichael Afanasiev\n', '\nChristian Boehm\n', '\nMartin van Driel\n', '\nLion Krischer\n', '\nAndreas Fichtner\n']","23 pages, 11 figures",SIAM J. Sci. Comput. 43 (2021) C127-C153,http://dx.doi.org/10.1137/20M1332748,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65-04, 65Y05, 65M50, 05C90, 35L05']",10.1137/20M1332748,,[]
GAPS: Generator for Automatic Polynomial Solvers,http://arxiv.org/abs/2004.11765v1,2020-04-24T14:11:28Z,2020-04-24T14:11:28Z,"  Minimal problems in computer vision raise the demand of generating efficient
automatic solvers for polynomial equation systems. Given a polynomial system
repeated with different coefficient instances, the traditional Gr\""obner basis
or normal form based solution is very inefficient. Fortunately the Gr\""obner
basis of a same polynomial system with different coefficients is found to share
consistent inner structure. By precomputing such structures offline, Gr\""obner
basis as well as the polynomial system solutions can be solved automatically
and efficiently online. In the past decade, several tools have been released to
generate automatic solvers for a general minimal problems. The most recent tool
autogen from Larsson et al. is a representative of these tools with
state-of-the-art performance in solver efficiency. GAPS wraps and improves
autogen with more user-friendly interface, more functionality and better
stability. We demonstrate in this report the main approach and enhancement
features of GAPS. A short tutorial of the software is also included.
","['\nBo Li\n', '\nViktor Larsson\n']",,,http://arxiv.org/abs/2004.11765v1,cs.CV,"['cs.CV', 'cs.MS', 'cs.RO', 'cs.SC']",,,[]
Geomstats: A Python Package for Riemannian Geometry in Machine Learning,http://arxiv.org/abs/2004.04667v1,2020-04-07T20:41:50Z,2020-04-07T20:41:50Z,"  We introduce Geomstats, an open-source Python toolbox for computations and
statistics on nonlinear manifolds, such as hyperbolic spaces, spaces of
symmetric positive definite matrices, Lie groups of transformations, and many
more. We provide object-oriented and extensively unit-tested implementations.
Among others, manifolds come equipped with families of Riemannian metrics, with
associated exponential and logarithmic maps, geodesics and parallel transport.
Statistics and learning algorithms provide methods for estimation, clustering
and dimension reduction on manifolds. All associated operations are vectorized
for batch computation and provide support for different execution backends,
namely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper
presents the package, compares it with related libraries and provides relevant
code examples. We show that Geomstats provides reliable building blocks to
foster research in differential geometry and statistics, and to democratize the
use of Riemannian geometry in machine learning applications. The source code is
freely available under the MIT license at \url{geomstats.ai}.
","['\nNina Miolane\n', '\nAlice Le Brigant\n', '\nJohan Mathe\n', '\nBenjamin Hou\n', '\nNicolas Guigui\n', '\nYann Thanwerdas\n', '\nStefan Heyder\n', '\nOlivier Peltre\n', '\nNiklas Koep\n', '\nHadi Zaatiti\n', '\nHatem Hajri\n', '\nYann Cabanes\n', '\nThomas Gerald\n', '\nPaul Chauchat\n', '\nChristian Shewmake\n', '\nBernhard Kainz\n', '\nClaire Donnat\n', '\nSusan Holmes\n', '\nXavier Pennec\n']",,,http://arxiv.org/abs/2004.04667v1,cs.LG,"['cs.LG', 'cs.MS']",,,[]
Maintaining a Library of Formal Mathematics,http://arxiv.org/abs/2004.03673v2,2020-04-07T19:52:20Z,2020-05-26T11:47:21Z,"  The Lean mathematical library mathlib is developed by a community of users
with very different backgrounds and levels of experience. To lower the barrier
of entry for contributors and to lessen the burden of reviewing contributions,
we have developed a number of tools for the library which check proof
developments for subtle mistakes in the code and generate documentation suited
for our varied audience.
","['\nFloris van Doorn\n', '\nGabriel Ebner\n', '\nRobert Y. Lewis\n']",To appear in Proceedings of CICM 2020,,http://dx.doi.org/10.1007/978-3-030-53518-6_16,cs.PL,"['cs.PL', 'cs.MS', 'math.HO']",10.1007/978-3-030-53518-6_16,,[]
Automatic Differentiation in ROOT,http://arxiv.org/abs/2004.04435v1,2020-04-09T09:18:50Z,2020-04-09T09:18:50Z,"  In mathematics and computer algebra, automatic differentiation (AD) is a set
of techniques to evaluate the derivative of a function specified by a computer
program. AD exploits the fact that every computer program, no matter how
complicated, executes a sequence of elementary arithmetic operations (addition,
subtraction, multiplication, division, etc.), elementary functions (exp, log,
sin, cos, etc.) and control flow statements. AD takes source code of a function
as input and produces source code of the derived function. By applying the
chain rule repeatedly to these operations, derivatives of arbitrary order can
be computed automatically, accurately to working precision, and using at most a
small constant factor more arithmetic operations than the original program.
  This paper presents AD techniques available in ROOT, supported by Cling, to
produce derivatives of arbitrary C/C++ functions through implementing source
code transformation and employing the chain rule of differential calculus in
both forward mode and reverse mode. We explain its current integration for
gradient computation in TFormula. We demonstrate the correctness and
performance improvements in ROOT's fitting algorithms.
","['\nVassil Vassilev\nPrinceton University\n', '\nAleksandr Efremov\nPrinceton University\n', '\nOksana Shadura\nUniversity of Nebraska Lincoln\n']",Submitted as a proceeding for CHEP 2019,,http://dx.doi.org/10.1051/epjconf/202024502015,cs.MS,"['cs.MS', 'cs.CL', 'cs.SE']",10.1051/epjconf/202024502015,,"['Princeton University', 'Princeton University', 'University of Nebraska Lincoln']"
"Vectorization and Minimization of Memory Footprint for Linear High-Order
  Discontinuous Galerkin Schemes",http://arxiv.org/abs/2003.12787v1,2020-03-28T13:27:09Z,2020-03-28T13:27:09Z,"  We present a sequence of optimizations to the performance-critical compute
kernels of the high-order discontinuous Galerkin solver of the hyperbolic PDE
engine ExaHyPE -- successively tackling bottlenecks due to SIMD operations,
cache hierarchies and restrictions in the software design.
  Starting from a generic scalar implementation of the numerical scheme, our
first optimized variant applies state-of-the-art optimization techniques by
vectorizing loops, improving the data layout and using Loop-over-GEMM to
perform tensor contractions via highly optimized matrix multiplication
functions provided by the LIBXSMM library. We show that memory stalls due to a
memory footprint exceeding our L2 cache size hindered the vectorization gains.
We therefore introduce a new kernel that applies a sum factorization approach
to reduce the kernel's memory footprint and improve its cache locality. With
the L2 cache bottleneck removed, we were able to exploit additional
vectorization opportunities, by introducing a hybrid
Array-of-Structure-of-Array data layout that solves the data layout conflict
between matrix multiplications kernels and the point-wise functions to
implement PDE-specific terms.
  With this last kernel, evaluated in a benchmark simulation at high polynomial
order, only 2\% of the floating point operations are still performed using
scalar instructions and 22.5\% of the available performance is achieved.
","['\nJean-Matthieu Gallard\n', '\nLeonhard Rannabauer\n', '\nAnne Reinarz\n', '\nMichael Bader\n']",PDSEC 2020,,http://arxiv.org/abs/2003.12787v1,cs.MS,['cs.MS'],,,[]
Local congruence of chain complexes,http://arxiv.org/abs/2004.00046v1,2020-03-31T18:15:32Z,2020-03-31T18:15:32Z,"  The object of this paper is to transform a set of local chain complexes to a
single global complex using an equivalence relation of congruence of cells,
solving topologically the numerical inaccuracies of floating-point arithmetics.
While computing the space arrangement generated by a collection of cellular
complexes, one may start from independently and efficiently computing the
intersection of each single input 2-cell with the others. The topology of these
intersections is codified within a set of (0-2)-dimensional chain complexes.
The target of this paper is to merge the local chains by using the equivalence
relations of {\epsilon}-congruence between 0-, 1-, and 2-cells (elementary
chains). In particular, we reduce the block-diagonal coboundary matrices
[\Delta_0] and [\Delta_1], used as matrix accumulators of the local coboundary
chains, to the global matrices [\delta_0] and [\delta_1], representative of
congruence topology, i.e., of congruence quotients between all 0-,1-,2-cells,
via elementary algebraic operations on their columns. This algorithm is
codified using the Julia porting of the SuiteSparse:GraphBLAS implementation of
the GraphBLAS standard, conceived to efficiently compute algorithms on large
graphs using linear algebra and sparse matrices [1, 2].
","['\nGianmaria DelMonte\n', '\nElia Onofri\n', '\nGiorgio Scorzelli\n', '\nAlberto Paoluzzi\n']",to submit,,http://arxiv.org/abs/2004.00046v1,cs.CG,"['cs.CG', 'cs.MS']",,,[]
"Interpolation of Dense and Sparse Rational Functions and other
  Improvements in $\texttt{FireFly}$",http://arxiv.org/abs/2004.01463v2,2020-04-03T10:40:08Z,2021-05-03T18:02:27Z,"  We present the main improvements and new features in version $\texttt{2.0}$
of the open-source $\texttt{C++}$ library $\texttt{FireFly}$ for the
interpolation of rational functions. This includes algorithmic improvements,
e.g. a hybrid algorithm for dense and sparse rational functions and an
algorithm to identify and remove univariate factors. The new version is applied
to a Feynman-integral reduction to showcase the runtime improvements achieved.
Moreover, $\texttt{FireFly}$ now supports parallelization with $\texttt{MPI}$
and offers new tools like a parser for expressions or an executable for the
insertion of replacement tables.
","['\nJonas Klappert\n', '\nSven Yannick Klein\n', '\nFabian Lange\n']","28 pages, 10 tables, 1 figure",Comput. Phys. Commun. 264 (2021) 107968,http://dx.doi.org/10.1016/j.cpc.2021.107968,cs.MS,"['cs.MS', 'cs.SC', 'hep-ph']",10.1016/j.cpc.2021.107968,,[]
FlexRiLoG -- A SageMath Package for Motions of Graphs,http://arxiv.org/abs/2003.12029v1,2020-03-26T16:50:43Z,2020-03-26T16:50:43Z,"  In this paper we present the SageMath package FlexRiLoG (short for flexible
and rigid labelings of graphs). Based on recent results the software generates
motions of graphs using special edge colorings. The package computes and
illustrates the colorings and the motions. We present the structure and usage
of the package.
","['\nGeorg Grasegger\n', '\nJan Legerský\n']",,"In: Bigatti A., Carette J., Davenport J., Joswig M., de Wolff T.
  (eds) Mathematical Software - ICMS 2020. Lecture Notes in Computer Science,
  vol. 12097",http://dx.doi.org/10.1007/978-3-030-52200-1_44,cs.MS,"['cs.MS', 'cs.RO', 'math.CO', '52C25, 68R10']",10.1007/978-3-030-52200-1_44,,[]
Making RooFit Ready for Run 3,http://arxiv.org/abs/2003.12861v1,2020-03-28T18:22:20Z,2020-03-28T18:22:20Z,"  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used
in most searches and measurements at the Large Hadron Collider. The data to be
collected in Run 3 will enable measurements with higher precision and models
with larger complexity, but also require faster data processing. In this work,
first results on modernising RooFit's collections, restructuring data flow and
vectorising likelihood fits in RooFit will be discussed. These improvements
will enable the LHC experiments to process larger datasets without having to
compromise with respect to model complexity, as fitting times would increase
significantly with the large datasets to be expected in Run 3.
","['\nStephan Hageboeck\n', '\nLorenzo Moneta\n']","5 pages, 5 figures. Proceedings of ACAT 2019. Submitted to Journal Of
  Physics: Conference Series",2020 J. Phys.: Conf. Ser. 1525 012114,http://dx.doi.org/10.1088/1742-6596/1525/1/012114,cs.MS,"['cs.MS', 'hep-ex', 'physics.data-an']",10.1088/1742-6596/1525/1/012114,,[]
"A Faster, More Intuitive RooFit",http://arxiv.org/abs/2003.12875v3,2020-03-28T19:12:32Z,2020-07-27T12:36:28Z,"  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used
in most searches and measurements at the Large Hadron Collider as well as at
$B$ factories. Larger datasets to be collected at e.g. the High-Luminosity LHC
will enable measurements with higher precision, but will require faster data
processing to keep fitting times stable. In this work, a simplification of
RooFit's interfaces and a redesign of its internal dataflow is presented.
Interfaces are being extended to look and feel more STL-like to be more
accessible both from C++ and Python to improve interoperability and ease of
use, while maintaining compatibility with old code. The redesign of the
dataflow improves cache locality and data loading, and can be used to process
batches of data with vectorised SIMD computations. This reduces the time for
computing unbinned likelihoods by a factor four to 16. This will allow to fit
larger datasets of the future in the same time or faster than today's fits.
",['\nStephan Hageboeck\n'],"6 pages, 2 figures. Proceedings of 24th International Conference on
  Computing in High Energy & Nuclear Physics. Submitted to EPJ Web of
  Conferences v2: Correct a function name, minor improvements of wording
  suggested by reviewer v3: Update a code listing",EPJ Web Conf. 245 (2020) 06007,http://dx.doi.org/10.1051/epjconf/202024506007,cs.MS,"['cs.MS', 'hep-ex', 'physics.data-an']",10.1051/epjconf/202024506007,,[]
"Pressio: Enabling projection-based model reduction for large-scale
  nonlinear dynamical systems",http://arxiv.org/abs/2003.07798v3,2020-03-17T16:25:10Z,2021-09-01T07:17:29Z,"  This work introduces Pressio, an open-source project aimed at enabling
leading-edge projection-based reduced order models (ROMs) for large-scale
nonlinear dynamical systems in science and engineering. Pressio provides
model-reduction methods that can reduce both the number of spatial and temporal
degrees of freedom for any dynamical system expressible as a system of
parameterized ordinary differential equations (ODEs). We leverage this simple,
expressive mathematical framework as a pivotal design choice to enable a
minimal application programming interface (API) that is natural to dynamical
systems. The core component of Pressio is a C++11 header-only library that
leverages generic programming to support applications with arbitrary data types
and arbitrarily complex programming models. This is complemented with Python
bindings to expose these C++ functionalities to Python users with negligible
overhead and no user-required binding code. We discuss the distinguishing
characteristics of Pressio relative to existing model-reduction libraries,
outline its key design features, describe how the user interacts with it, and
present two test cases -- including one with over 20 million degrees of freedom
-- that highlight the performance results of Pressio and illustrate the breath
of problems that can be addressed with it.
","['\nFrancesco Rizzi\n', '\nPatrick J. Blonigan\n', '\nEric J. Parish\n', '\nKevin T. Carlberg\n']","32 pages, 5 figures, supplement of 6 pages; Added references in
  intro, corrected fig5b, few more clarifications in sec4.2",,http://arxiv.org/abs/2003.07798v3,cs.MS,"['cs.MS', 'cs.CE', 'physics.comp-ph', 'physics.flu-dyn']",,,[]
"Scalable parallel algorithm for solving non-stationary systems of linear
  inequalities",http://arxiv.org/abs/2003.09956v2,2020-03-22T17:44:23Z,2020-08-21T06:12:56Z,"  In this paper, a scalable iterative projection-type algorithm for solving
non-stationary systems of linear inequalities is considered. A non-stationary
system is understood as a large-scale system of inequalities in which
coefficients and constant terms can change during the calculation process. The
proposed parallel algorithm uses the concept of pseudo-projection which
generalizes the notion of orthogonal projection. The parallel pseudo-projection
algorithm is implemented using the parallel BSF-skeleton. An analytical
estimation of the algorithm scalability boundary is obtained on the base of the
BSF cost metric. The large-scale computational experiments were performed on a
cluster computing system. The obtained results confirm the efficiency of the
proposed approach.
","['\nLeonid B. Sokolinsky\n', '\nIrina M. Sokolinskaya\n']","This a preprint of the Work accepted for publication in Lobachevskii
  Journal of Mathematics, \c{opyright} 2020, Springer Nature",Lobachevskii J. Math. 41 (2020) 1571-1580,http://dx.doi.org/10.1134/S1995080220080181,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'math.OC', '90-08', 'G.4']",10.1134/S1995080220080181,,[]
"Geometric Sparsification of Closeness Relations: Eigenvalue Clustering
  for Computing Matrix Functions",http://arxiv.org/abs/2003.11914v1,2020-03-23T08:21:58Z,2020-03-23T08:21:58Z,"  We show how to efficiently solve a clustering problem that arises in a method
to evaluate functions of matrices. The problem requires finding the connected
components of a graph whose vertices are eigenvalues of a real or complex
matrix and whose edges are pairs of eigenvalues that are at most \delta away
from each other. Davies and Higham proposed solving this problem by enumerating
the edges of the graph, which requires at least $\Omega(n^{2})$ work. We show
that the problem can be solved by computing the Delaunay triangulation of the
eigenvalues, removing from it long edges, and computing the connected
components of the remaining edges in the triangulation. This leads to an
$O(n\log n)$ algorithm. We have implemented both algorithms using CGAL, a
mature and sophisticated computational-geometry software library, and we
demonstrate that the new algorithm is much faster in practice than the naive
algorithm. We also present a tight analysis of the naive algorithm, showing
that it performs $\Theta(n^{2})$ work, and correct a misrepresentation in the
original statement of the problem. To the best of our knowledge, this is the
first application of computational geometry to solve a real-world problem in
numerical linear algebra.
","['\nNir Goren\n', '\nDan Halperin\n', '\nSivan Toledo\n']",,,http://arxiv.org/abs/2003.11914v1,cs.CG,"['cs.CG', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"An R Package for generating covariance matrices for maximum-entropy
  sampling from precipitation chemistry data",http://arxiv.org/abs/2003.06316v2,2020-03-13T14:23:22Z,2020-03-19T15:06:22Z,"  We present an open-source R package (MESgenCov v 0.1.0) for temporally
fitting multivariate precipitation chemistry data and extracting a covariance
matrix for use in the MESP (maximum-entropy sampling problem). We provide
multiple functionalities for modeling and model assessment. The package is
tightly coupled with NADP/NTN (National Atmospheric Deposition Program /
National Trends Network) data from their set of 379 monitoring sites,
1978--present. The user specifies the sites, chemicals, and time period
desired, fits an appropriate user-specified univariate model for each site and
chemical selected, and the package produces a covariance matrix for use by MESP
algorithms.
","['\nHessa Al-Thani\n', '\nJon Lee\n']",,,http://arxiv.org/abs/2003.06316v2,cs.MS,"['cs.MS', '90C27, 62M30, 62M10, 94A17']",,,[]
"COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for
  Social Inquiry",http://arxiv.org/abs/2003.03099v1,2020-03-06T09:27:10Z,2020-03-06T09:27:10Z,"  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into
complex data/systems, designed to increase non-expert access to the tools of
computational social science (i.e., cluster analysis, artificial intelligence,
data visualization, data forecasting, and scenario simulation). In particular,
COMPLEX-IT aids social inquiry though a heavy emphasis on learning about the
complex data/system under study, which it does by (a) identifying and
forecasting major and minor clusters/trends; (b) visualizing their complex
causality; and (c) simulating scenarios for potential interventions. COMPLEX-IT
is accessible through the web or can be run locally and is powered by R and the
Shiny web framework.
","['\nCorey Schimpf\n', '\nBrian Castellani\n']",,Journal of Open Research Software (2020) 8:25,http://dx.doi.org/10.5334/jors.298,cs.MS,"['cs.MS', 'cs.CY']",10.5334/jors.298,,[]
"Airline Crew Pairing Optimization Framework for Large Networks with
  Multiple Crew Bases and Hub-and-Spoke Subnetworks",http://arxiv.org/abs/2003.03994v2,2020-03-09T09:34:20Z,2020-11-18T23:27:33Z,"  Crew Pairing Optimization aims at generating a set of flight sequences (crew
pairings), covering all flights in an airline's flight schedule, at minimum
cost, while satisfying several legality constraints. CPO is critically
important for airlines' business viability, considering that the crew operating
cost is their second-largest expense. It poses an NP-hard combinatorial
optimization problem, to tackle which, the state-of-the-art relies on relaxing
the underlying Integer Programming Problem (IPP) into a Linear Programming
Problem (LPP), solving the latter through Column Generation (CG) technique, and
integerization of the resulting LPP solution. However, with the growing scale
and complexity of the flight networks (those with a large number of flights,
multiple crew bases and/or multiple hub-and-spoke subnetworks), the utility of
the conventional CG-practices has become questionable. This paper proposed an
Airline Crew Pairing Optimization Framework, AirCROP, whose constitutive
modules include the Legal Crew Pairing Generator, Initial Feasible Solution
Generator, and an Optimization Engine built on heuristic-based
CG-implementation. In this paper, besides the design of AirCROP's modules,
insights into important questions related to how these modules interact, which
the literature is otherwise silent on, have been shared. These relate to the
sensitivity of AirCROP's performance towards: sources of variability over
multiple runs for a given problem, initialization method, and termination
parameters for LPP-solutioning and IPP-solutioning. The efficacy of the AirCROP
has been demonstrated on real-world large-scale and complex flight networks
(with over 4200 flights, 15 crew bases, and billion-plus pairings). It is hoped
that with the emergence of such complex flight networks, this paper shall serve
as an important milestone for affiliated research and applications.
","['\nDivyam Aggarwal\n', '\nDhish Kumar Saxena\n', '\nThomas Bäck\n', '\nMichael Emmerich\n']","28 pages, 3 figures, 9 tables, manuscript submitted for review in a
  refereed journal. A patent application, based on this research, has been
  filed in the Netherlands Patent Office. Moreover, D. Aggarwal (author)
  received the IEEE-ITSS Young Professionals Travelling Fellowship Award for
  presenting this research work at IEEE ITSC 2019, held in Auckland, New
  Zealand in October 2019",,http://arxiv.org/abs/2003.03994v2,cs.MS,"['cs.MS', 'math.OC']",,,[]
Evaluating Abstract Asynchronous Schwarz solvers on GPUs,http://arxiv.org/abs/2003.05361v2,2020-03-11T15:28:53Z,2020-05-05T12:14:52Z,"  With the commencement of the exascale computing era, we realize that the
majority of the leadership supercomputers are heterogeneous and massively
parallel even on a single node with multiple co-processors such as GPUs and
multiple cores on each node. For example, ORNLs Summit accumulates six NVIDIA
Tesla V100s and 42 core IBM Power9s on each node. Synchronizing across all
these compute resources in a single node or even across multiple nodes is
prohibitively expensive. Hence it is necessary to develop and study
asynchronous algorithms that circumvent this issue of bulk-synchronous
computing for massive parallelism. In this study, we examine the asynchronous
version of the abstract Restricted Additive Schwarz method as a solver where we
do not explicitly synchronize, but allow for communication of the data between
the sub-domains to be completely asynchronous thereby removing the bulk
synchronous nature of the algorithm.
  We accomplish this by using the onesided RMA functions of the MPI standard.
We study the benefits of using such an asynchronous solver over its synchronous
counterpart on both multi-core architectures and on multiple GPUs. We also
study the communication patterns and local solvers and their effect on the
global solver. Finally, we show that this concept can render attractive runtime
benefits over the synchronous counterparts.
","['\nPratik Nayak\n', '\nTerry Cojean\n', '\nHartwig Anzt\n']",Preprint submitted to IJHPCA,,http://arxiv.org/abs/2003.05361v2,cs.DC,"['cs.DC', 'cs.MS']",,,[]
FunGrim: a symbolic library for special functions,http://arxiv.org/abs/2003.06181v1,2020-03-13T10:07:21Z,2020-03-13T10:07:21Z,"  We present the Mathematical Functions Grimoire (FunGrim), a website and
database of formulas and theorems for special functions. We also discuss the
symbolic computation library used as the backend and main development tool for
FunGrim, and the Grim formula language used in these projects to represent
mathematical content semantically.
",['\nFredrik Johansson\nLFANT\n'],,,http://arxiv.org/abs/2003.06181v1,cs.MS,"['cs.MS', 'cs.SC']",,,['LFANT']
"Matrix Equations, Sparse Solvers: M-M.E.S.S.-2.0.1 -- Philosophy,
  Features and Application for (Parametric) Model",http://arxiv.org/abs/2003.02088v2,2020-03-04T14:02:21Z,2020-05-09T12:42:10Z,"  Matrix equations are omnipresent in (numerical) linear algebra and systems
theory. Especially in model order reduction (MOR) they play a key role in many
balancing based reduction methods for linear dynamical systems. When these
systems arise from spatial discretizations of evolutionary partial differential
equations, their coefficient matrices are typically large and sparse. Moreover,
the numbers of inputs and outputs of these systems are typically far smaller
than the number of spatial degrees of freedom. Then, in many situations the
solutions of the corresponding large-scale matrix equations are observed to
have low (numerical) rank. This feature is exploited by M-M.E.S.S. to find
successively larger low-rank factorizations approximating the solutions. This
contribution describes the basic philosophy behind the implementation and the
features of the package, as well as its application in the model order
reduction of large-scale linear time-invariant (LTI) systems and parametric LTI
systems.
","['\nPeter Benner\n', '\nMartin Köhler\n', '\nJens Saak\n']","18 pages, 4 figures, 5 tables",,http://arxiv.org/abs/2003.02088v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Flexible numerical optimization with ensmallen,http://arxiv.org/abs/2003.04103v4,2020-03-09T12:57:42Z,2023-11-15T14:51:17Z,"  This report provides an introduction to the ensmallen numerical optimization
library, as well as a deep dive into the technical details of how it works. The
library provides a fast and flexible C++ framework for mathematical
optimization of arbitrary user-supplied functions. A large set of pre-built
optimizers is provided, including many variants of Stochastic Gradient Descent
and Quasi-Newton optimizers. Several types of objective functions are
supported, including differentiable, separable, constrained, and categorical
objective functions. Implementation of a new optimizer requires only one
method, while a new objective function requires typically only one or two C++
methods. Through internal use of C++ template metaprogramming, ensmallen
provides support for arbitrary user-supplied callbacks and automatic inference
of unsupplied methods without any runtime overhead. Empirical comparisons show
that ensmallen outperforms other optimization frameworks (such as Julia and
SciPy), sometimes by large margins. The library is available at
https://ensmallen.org and is distributed under the permissive BSD license.
","['\nRyan R. Curtin\n', '\nMarcus Edel\n', '\nRahul Ganesh Prabhu\n', '\nSuryoday Basak\n', '\nZhihao Lou\n', '\nConrad Sanderson\n']",https://ensmallen.org/,,http://arxiv.org/abs/2003.04103v4,cs.MS,"['cs.MS', 'cs.LG', 'cs.SE', 'math.OC']",,,[]
"Parallel Robust Computation of Generalized Eigenvectors of Matrix
  Pencils",http://arxiv.org/abs/2003.04776v1,2020-03-10T14:37:39Z,2020-03-10T14:37:39Z,"  In this paper we consider the problem of computing generalized eigenvectors
of a matrix pencil in real Schur form. In exact arithmetic, this problem can be
solved using substitution. In practice, substitution is vulnerable to
floating-point overflow. The robust solvers xTGEVC in LAPACK prevent overflow
by dynamically scaling the eigenvectors. These subroutines are sequential
scalar codes which compute the eigenvectors one by one. In this paper we
discuss how to derive robust blocked algorithms. The new StarNEig library
contains a robust task-parallel solver Zazamoukh which runs on top of StarPU.
Our numerical experiments show that Zazamoukh achieves a super-linear speedup
compared with DTGEVC for sufficiently large matrices.
","['\nCarl Christian Kjelgaard Mikkelsen\n', '\nMirko Myllykoski\n']","This manuscript was accepted to 13th International Conference on
  Parallel Processing and Applied Mathematics (PPAM2019), Bialystok, Poland,
  September 8-11, 2019. The final authenticated version is available online at
  https://doi.org/10.1007/978-3-030-43229-4_6 (DOI valid from May 8, 2020
  onward). First author's first name is ""Carl Christian"" and last name
  ""Kjelgaard Mikkelsen""",LNCS 12043 (2020) 58-69,http://dx.doi.org/10.1007/978-3-030-43229-4_6,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",10.1007/978-3-030-43229-4_6,,[]
"Optimization of Generalized Jacobian Chain Products without Memory
  Constraints",http://arxiv.org/abs/2003.05755v3,2020-03-12T12:49:19Z,2020-10-10T18:30:08Z,"  The efficient computation of Jacobians represents a fundamental challenge in
computational science and engineering. Large-scale modular numerical simulation
programs can be regarded as sequences of evaluations of in our case
differentiable modules with corresponding local Jacobians. The latter are
typically not available. Tangent and adjoint versions of the individual modules
are assumed to be given as results of algorithmic differentiation instead. The
classical (Jacobian) matrix chain product formulation is extended with the
optional evaluation of matrix-free Jacobian-matrix and matrix-Jacobian products
as tangents and adjoints. We propose a dynamic programming algorithm for the
minimization of the computational cost of such generalized Jacobian chain
products without considering constraints on the available persistent system
memory. In other words, the naive evaluation of an adjoint of the entire
simulation program is assumed to be a feasible option. No checkpointing is
required. Under the given assumptions we obtain optimal solutions which improve
the best state of the art methods by factors of up to seven on a set of
randomly generated problem instances of growing size.
",['\nUwe Naumann\n'],14 pages,,http://arxiv.org/abs/2003.05755v3,math.NA,"['math.NA', 'cs.DM', 'cs.MS', 'cs.NA']",,,[]
Parametric model order reduction using pyMOR,http://arxiv.org/abs/2003.05825v2,2020-03-12T14:50:53Z,2020-07-02T15:20:02Z,"  pyMOR is a free software library for model order reduction that includes both
reduced basis and system-theoretic methods. All methods are implemented in
terms of abstract vector and operator interfaces, which allows direct
integration of pyMOR's algorithms with a wide array of external PDE solvers. In
this contribution, we give a brief overview of the available methods and
experimentally compare them for the parametric instationary thermal-block
benchmark defined in arXiv:2003.00846.
","['\nPetar Mlinarić\n', '\nStephan Rave\n', '\nJens Saak\n']","9 pages, 6 figures",,http://dx.doi.org/10.1007/978-3-030-72983-7_17,cs.MS,"['cs.MS', 'cs.NA', 'cs.SY', 'eess.SY', 'math.NA', 'math.OC']",10.1007/978-3-030-72983-7_17,,[]
SplineLib: A Modern Multi-Purpose C++ Spline Library,http://arxiv.org/abs/2002.12323v1,2020-02-27T18:43:07Z,2020-02-27T18:43:07Z,"  This paper provides the description of a novel, multi-purpose spline library.
In accordance with the increasingly diverse modes of usage of splines, it is
multi-purpose in the sense that it supports geometry representation, finite
element analysis, and optimization. The library features reading and writing
for various file formats and a wide range of spline manipulation algorithms.
Further, a new efficient and objective-oriented algorithm for B-spline basis
function evaluation is included. All features are available by a spline-type
independent interface. The library is written in modern C++ with CMake as build
system. This enables it for usage in typical scientific applications. It is
provided as open-source library.
","['\nMarkus Frings\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n', '\nNorbert Hosters\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n', '\nCorinna Müller\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n', '\nMax Spahn\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n', '\nChristoph Susen\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n', '\nKonstantin Key\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n', '\nStefanie Elgeti\nChair for Computational Analysis of Technical Systems, Aachen, Germany\n']","16 pages, 4 figures, submitted to Advances in Engineering Software",,http://arxiv.org/abs/2002.12323v1,cs.MS,"['cs.MS', 'G.1.1; D.1.5; D.3.3; J.6']",,,"['Chair for Computational Analysis of Technical Systems, Aachen, Germany', 'Chair for Computational Analysis of Technical Systems, Aachen, Germany', 'Chair for Computational Analysis of Technical Systems, Aachen, Germany', 'Chair for Computational Analysis of Technical Systems, Aachen, Germany', 'Chair for Computational Analysis of Technical Systems, Aachen, Germany', 'Chair for Computational Analysis of Technical Systems, Aachen, Germany', 'Chair for Computational Analysis of Technical Systems, Aachen, Germany']"
NLOptControl: A modeling language for solving optimal control problems,http://arxiv.org/abs/2003.00142v2,2020-02-29T00:55:28Z,2020-04-30T18:44:31Z,"  Current direct-collocation-based optimal control software is either easy to
use or fast, but not both. This is a major limitation for users that are trying
to formulate complex optimal control problems (OCPs) for use in on-line
applications. This paper introduces NLOptControl, an open-source modeling
language that allows users to both easily formulate and quickly solve nonlinear
OCPs using direct-collocation methods. To achieve these attributes,
NLOptControl (1) is written in an efficient, dynamically-typed computing
language called Julia, (2) extends an optimization modeling language called
JuMP to provide a natural algebraic syntax for modeling nonlinear OCPs; and (3)
uses reverse automatic differentiation with the acrylic-coloring method to
exploit sparsity in the Hessian matrix. This work explores the novel design
features of NLOptControl and compares its syntax and speed to those of PROPT.
The syntax comparisons shows that NLOptControl models OCPs more concisely than
PROPT. The speeds of various collocation methods within PROPT and NLOptControl
are benchmarked over a range of collocation points using performance profiles;
overall, NLOptControl's single, two, and four interval pseudospectral methods
are roughly $14$, $26$, and $36$ times faster than PROPT's, respectively.
NLOptControl is well-suited to improve existing off-line and on-line control
systems and to engender new ones.
","['\nHuckleberry Febbo\n', '\nParamsothy Jayakumar\n', '\nJeffrey L. Stein\n', '\nTulga Ersal\n']",,,http://arxiv.org/abs/2003.00142v2,cs.MS,"['cs.MS', 'math.OC']",,,[]
NeuralSens: Sensitivity Analysis of Neural Networks,http://arxiv.org/abs/2002.11423v2,2020-02-26T12:05:59Z,2021-02-08T07:01:36Z,"  Neural networks are important tools for data-intensive analysis and are
commonly applied to model non-linear relationships between dependent and
independent variables. However, neural networks are usually seen as ""black
boxes"" that offer minimal information about how the input variables are used to
predict the response in a fitted model. This article describes the
\pkg{NeuralSens} package that can be used to perform sensitivity analysis of
neural networks using the partial derivatives method. Functions in the package
can be used to obtain the sensitivities of the output with respect to the input
variables, evaluate variable importance based on sensitivity measures and
characterize relationships between input and output variables. Methods to
calculate sensitivities are provided for objects from common neural network
packages in \proglang{R}, including \pkg{neuralnet}, \pkg{nnet}, \pkg{RSNNS},
\pkg{h2o}, \pkg{neural}, \pkg{forecast} and \pkg{caret}. The article presents
an overview of the techniques for obtaining information from neural network
models, a theoretical foundation of how are calculated the partial derivatives
of the output with respect to the inputs of a multi-layer perceptron model, a
description of the package structure and functions, and applied examples to
compare \pkg{NeuralSens} functions with analogous functions from other
available \proglang{R} packages.
","['\nJ. Pizarroso\n', '\nJ. Portela\n', '\nA. Muñoz\n']","28 pages, 12 figures, submitted to Journal of Statistical Software
  (JSS) https://www.jstatsoft.org/index",,http://dx.doi.org/10.18637/jss.v102.i07,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",10.18637/jss.v102.i07,,[]
MORLAB -- The Model Order Reduction LABoratory,http://arxiv.org/abs/2002.12682v1,2020-02-28T12:42:26Z,2020-02-28T12:42:26Z,"  For an easy use of model order reduction techniques in applications, software
solutions are needed. In this paper, we describe the MORLAB, Model Order
Reduction LABoratory, toolbox as an efficient implementation of model reduction
techniques for dense, medium-scale linear time-invariant systems. Giving an
introduction to the underlying programming principles of the toolbox, we show
the basic idea of spectral splitting and present an overview about implemented
model reduction techniques. Two numerical examples are used to illustrate
different use cases of the MORLAB toolbox.
","['\nPeter Benner\n', '\nSteffen W. R. Werner\n']","17 pages, 6 figures, 5 tables","International Series of Numerical Mathematics, 171:393-415, 2021",http://dx.doi.org/10.1007/978-3-030-72983-7_19,cs.MS,"['cs.MS', 'cs.NA', 'cs.SY', 'eess.SY', 'math.NA', 'math.OC']",10.1007/978-3-030-72983-7_19,,[]
FEAST Eigenvalue Solver v4.0 User Guide,http://arxiv.org/abs/2002.04807v1,2020-02-12T05:26:04Z,2020-02-12T05:26:04Z,"  The FEAST library package represents an unified framework for solving various
family of eigenvalue problems and achieving accuracy, robustness,
high-performance and scalability on parallel architectures. Its originality
lies with a new transformative numerical approach to the traditional eigenvalue
algorithm design - the FEAST algorithm. The algorithm gathers key elements from
complex analysis, numerical linear algebra and approximation theory, to
construct an optimal subspace iteration technique using approximate spectral
projectors. FEAST can be used for solving both standard and generalized forms
of the Hermitian or non-Hermitian problems (linear or non-linear), and it
belongs to the family of contour integration eigensolvers. FEAST's main
computational task consists of a numerical quadrature computation that involves
solving independent linear systems along a complex contour, each with multiple
right hand sides. In v4.0, FEAST has been reimplemented using an inverse
residual iteration algorithm which enables the linear systems to be solved with
very low accuracy (in single precision) with no impact on the FEAST double
precision convergence rate. As a result, v4.0 is on average 3-4 times faster
than v2.1 and v3.0 using new default optimization parameters (v2.1 has been
featured as Intel-MKL's principal HPC eigensolver since 2013). v4.0 also
implements new important features such as IFEAST (using Inexact Iterative
solver), Non-linear polynomial FEAST, and PFEAST with its 3-MPI levels of
parallelism. FEAST is both a comprehensive library package, and an easy to use
software. It includes flexible reverse communication interfaces and ready to
use driver interfaces for dense, banded and sparse systems.
",['\nEric Polizzi\n'],,,http://arxiv.org/abs/2002.04807v1,cs.MS,['cs.MS'],,,[]
"The Space of Mathematical Software Systems -- A Survey of Paradigmatic
  Systems",http://arxiv.org/abs/2002.04955v1,2020-02-12T12:46:17Z,2020-02-12T12:46:17Z,"  Mathematical software systems are becoming more and more important in pure
and applied mathematics in order to deal with the complexity and scalability
issues inherent in mathematics. In the last decades we have seen a cambric
explosion of increasingly powerful but also diverging systems. To give
researchers a guide to this space of systems, we devise a novel
conceptualization of mathematical software that focuses on five aspects:
inference covers formal logic and reasoning about mathematical statements via
proofs and models, typically with strong emphasis on correctness; computation
covers algorithms and software libraries for representing and manipulating
mathematical objects, typically with strong emphasis on efficiency;
concretization covers generating and maintaining collections of mathematical
objects conforming to a certain pattern, typically with strong emphasis on
complete enumeration; narration covers describing mathematical contexts and
relations, typically with strong emphasis on human readability; finally,
organization covers representing mathematical contexts and objects in
machine-actionable formal languages, typically with strong emphasis on
expressivity and system interoperability. Despite broad agreement that an ideal
system would seamlessly integrate all these aspects, research has diversified
into families of highly specialized systems focusing on a single aspect and
possibly partially integrating others, each with their own communities,
challenges, and successes. In this survey, we focus on the commonalities and
differences of these systems from the perspective of a future multi-aspect
system.
","['\nKatja Bercic\n', '\nJacques Carette\n', '\nWilliam M. Farmer\n', '\nMichael Kohlhase\n', '\nDennis Müller\n', '\nFlorian Rabe\n', '\nYasmine Sharoda\n']",,,http://arxiv.org/abs/2002.04955v1,cs.MS,['cs.MS'],,,[]
"Task-based, GPU-accelerated and Robust Library for Solving Dense
  Nonsymmetric Eigenvalue Problems",http://arxiv.org/abs/2002.05024v1,2020-02-12T14:28:55Z,2020-02-12T14:28:55Z,"  In this paper, we present the StarNEig library for solving dense nonsymmetric
standard and generalized eigenvalue problems. The library is built on top of
the StarPU runtime system and targets both shared and distributed memory
machines. Some components of the library have support for GPU acceleration. The
library is currently in an early beta state and supports only real matrices.
Support for complex matrices is planned for a future release. This paper is
aimed at potential users of the library. We describe the design choices and
capabilities of the library, and contrast them to existing software such as
ScaLAPACK. StarNEig implements a ScaLAPACK compatibility layer which should
assist new users in the transition to StarNEig. We demonstrate the performance
of the library with a sample of computational experiments.
","['\nMirko Myllykoski\n', '\nCarl Christian Kjelgaard Mikkelsen\n']","18 pages, 11 figures (18 when counting sub-figures), 1 tex-files.
  Invited article submitted to Concurrency and Computation: Practice and
  Experience. Second author's first name is ""Carl Christian"" and last name
  ""Kjelgaard Mikkelsen""",Concurrency Computat Pract Exper. (2020) e5915,http://dx.doi.org/10.1002/cpe.5915,cs.MS,"['cs.MS', 'cs.DC']",10.1002/cpe.5915,,[]
"hyper.deal: An efficient, matrix-free finite-element library for
  high-dimensional partial differential equations",http://arxiv.org/abs/2002.08110v1,2020-02-19T11:25:35Z,2020-02-19T11:25:35Z,"  This work presents the efficient, matrix-free finite-element library
hyper.deal for solving partial differential equations in two to six dimensions
with high-order discontinuous Galerkin methods. It builds upon the
low-dimensional finite-element library deal.II to create complex
low-dimensional meshes and to operate on them individually. These meshes are
combined via a tensor product on the fly and the library provides new
special-purpose highly optimized matrix-free functions exploiting domain
decomposition as well as shared memory via MPI-3.0 features. Both node-level
performance analyses and strong/weak-scaling studies on up to 147,456 CPU cores
confirm the efficiency of the implementation. Results of the library hyper.deal
are reported for high-dimensional advection problems and for the solution of
the Vlasov--Poisson equation in up to 6D phase space.
","['\nPeter Munch\n', '\nKatharina Kormann\n', '\nMartin Kronbichler\n']","33 pages, 18 figures",,http://arxiv.org/abs/2002.08110v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'G.4']",,,[]
Computing rank-revealing factorizations of matrices stored out-of-core,http://arxiv.org/abs/2002.06960v2,2020-02-17T13:58:08Z,2020-03-04T12:18:40Z,"  This paper describes efficient algorithms for computing rank-revealing
factorizations of matrices that are too large to fit in RAM, and must instead
be stored on slow external memory devices such as solid-state or spinning disk
hard drives (out-of-core or out-of-memory). Traditional algorithms for
computing rank revealing factorizations, such as the column pivoted QR
factorization, or techniques for computing a full singular value decomposition
of a matrix, are very communication intensive. They are naturally expressed as
a sequence of matrix-vector operations, which become prohibitively expensive
when data is not available in main memory. Randomization allows these methods
to be reformulated so that large contiguous blocks of the matrix can be
processed in bulk. The paper describes two distinct methods. The first is a
blocked version of column pivoted Householder QR, organized as a ""left-looking""
method to minimize the number of write operations (which are more expensive
than read operations on a spinning disk drive). The second method results in a
so called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where
$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an
algorithm-by-blocks, in which floating point operations overlap read and write
operations. The second method incorporates power iterations, and is
exceptionally good at revealing the numerical rank; it can often be used as a
substitute for a full singular value decomposition. Numerical experiments
demonstrate that the new algorithms are almost as fast when processing data
stored on a hard drive as traditional algorithms are for data stored in main
memory. To be precise, the computational time for fully factorizing an $n\times
n$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only
marginally larger when the matrix is stored out of core.
","['\nNathan Heavner\n', '\nPer-Gunnar Martinsson\n', '\nGregorio Quintana-Ortí\n']","23 pages, 11 figures, 1 table",,http://arxiv.org/abs/2002.06960v2,cs.MS,"['cs.MS', 'cs.CL', 'cs.DC', 'cs.DS', 'cs.NA', 'math.NA', 'G.1.3; G.4; C.4; D.1.3; F.2.1']",,,[]
Large-Scale Discrete Fourier Transform on TPUs,http://arxiv.org/abs/2002.03260v3,2020-02-09T01:15:13Z,2020-12-11T20:55:42Z,"  In this work, we present two parallel algorithms for the large-scale discrete
Fourier transform (DFT) on Tensor Processing Unit (TPU) clusters. The two
parallel algorithms are associated with two formulations of DFT: one is based
on the Kronecker product, to be specific, dense matrix multiplications between
the input data and the Vandermonde matrix, denoted as KDFT in this work; the
other is based on the famous Cooley-Tukey algorithm and phase adjustment,
denoted as FFT in this work. Both KDFT and FFT formulations take full advantage
of TPU's strength in matrix multiplications. The KDFT formulation allows direct
use of nonuniform inputs without additional step. In the two parallel
algorithms, the same strategy of data decomposition is applied to the input
data. Through the data decomposition, the dense matrix multiplications in KDFT
and FFT are kept local within TPU cores, which can be performed completely in
parallel. The communication among TPU cores is achieved through the one-shuffle
scheme in both parallel algorithms, with which sending and receiving data takes
place simultaneously between two neighboring cores and along the same direction
on the interconnect network. The one-shuffle scheme is designed for the
interconnect topology of TPU clusters, minimizing the time required by the
communication among TPU cores. Both KDFT and FFT are implemented in TensorFlow.
The three-dimensional complex DFT is performed on an example of dimension $8192
\times 8192 \times 8192$ with a full TPU Pod: the run time of KDFT is 12.66
seconds and that of FFT is 8.3 seconds. Scaling analysis is provided to
demonstrate the high parallel efficiency of the two DFT implementations on
TPUs.
","['\nTianjian Lu\n', '\nYi-Fan Chen\n', '\nBlake Hechtman\n', '\nTao Wang\n', '\nJohn Anderson\n']",,,http://arxiv.org/abs/2002.03260v3,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"A toolbox of Equation-Free functions in Matlab\Octave for efficient
  system level simulation",http://arxiv.org/abs/2002.01895v2,2020-01-31T11:20:04Z,2020-04-07T04:33:03Z,"  The `equation-free toolbox' empowers the computer-assisted analysis of
complex, multiscale systems. Its aim is to enable you to immediately use
microscopic simulators to perform macro-scale system level tasks and analysis,
because micro-scale simulations are often the best available description of a
system. The methodology bypasses the derivation of macroscopic evolution
equations by computing the micro-scale simulator only over short bursts in time
on small patches in space, with bursts and patches well-separated in time and
space respectively. We introduce the suite of coded equation-free functions in
an accessible way, link to more detailed descriptions, discuss their
mathematical support, and introduce a novel and efficient algorithm for
Projective Integration. Some facets of toolbox development of equation-free
functions are then detailed. Download the toolbox functions
(https://github.com/uoa1184615/EquationFreeGit) and use to empower efficient
and accurate simulation in a wide range of your science and engineering
problems.
","['\nJohn Maclean\n', '\nJ. E. Bunder\n', '\nA. J. Roberts\n']","35 pages, 4 figures",,http://arxiv.org/abs/2002.01895v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Butterfly factorization via randomized matrix-vector multiplications,http://arxiv.org/abs/2002.03400v1,2020-02-09T17:19:44Z,2020-02-09T17:19:44Z,"  This paper presents an adaptive randomized algorithm for computing the
butterfly factorization of a $m\times n$ matrix with $m\approx n$ provided that
both the matrix and its transpose can be rapidly applied to arbitrary vectors.
The resulting factorization is composed of $O(\log n)$ sparse factors, each
containing $O(n)$ nonzero entries. The factorization can be attained using
$O(n^{3/2}\log n)$ computation and $O(n\log n)$ memory resources. The proposed
algorithm applies to matrices with strong and weak admissibility conditions
arising from surface integral equation solvers with a rigorous error bound, and
is implemented in parallel.
","['\nYang Liu\n', '\nXin Xing\n', '\nHan Guo\n', '\nEric Michielssen\n', '\nPieter Ghysels\n', '\nXiaoye Sherry Li\n']",,,http://arxiv.org/abs/2002.03400v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"lbmpy: Automatic code generation for efficient parallel lattice
  Boltzmann methods",http://arxiv.org/abs/2001.11806v2,2020-01-31T13:00:26Z,2020-04-11T09:09:36Z,"  Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic
computational fluid dynamics solvers. Many variants have been developed that
vary in complexity, accuracy, and computational cost. Extensions are available
to simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In
this work we present lbmpy, a code generation package that supports a wide
variety of different methods and provides a generic development environment for
new schemes as well. A high-level domain-specific language allows the user to
formulate, extend and test various lattice Boltzmann schemes. The method
specification is represented in a symbolic intermediate representation.
Transformations that operate on this intermediate representation optimize and
parallelize the method, yielding highly efficient lattice Boltzmann compute
kernels not only for single- and two-relaxation-time schemes but also for
multi-relaxation-time, cumulant, and entropically stabilized methods. An
integration into the HPC framework waLBerla makes massively parallel,
distributed simulations possible, which is demonstrated through scaling
experiments on the SuperMUC-NG supercomputing system
","['\nMartin Bauer\n', '\nHarald Köstler\n', '\nUlrich Rüde\n']",,,http://arxiv.org/abs/2001.11806v2,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC']",,,[]
Fast Cubic Spline Interpolation,http://arxiv.org/abs/2001.09253v1,2020-01-25T02:06:31Z,2020-01-25T02:06:31Z,"  The Numerical Recipes series of books are a useful resource, but all the
algorithms they contain cannot be used within open-source projects. In this
paper we develop drop-in alternatives to the two algorithms they present for
cubic spline interpolation, showing as much of our work as possible to allow
for replication or criticsm. The output of the new algorithms is compared to
the old, and found to be no different within the limits imposed by
floating-point precision. Benchmarks of all these algorithms, plus variations
which may run faster in certain instances, are performed. In general, all these
algorithms have approximately the same execution time when interpolating curves
with few control points on feature-rich Intel processors; as the number of
control points increases or processor features are removed, the new algorithms
become consistently faster than the old. Exceptions to that generalization are
explored to create implementation guidelines, such as when to expect division
to be faster than multiplication.
",['\nHaysn Hornbeck\n'],,,http://arxiv.org/abs/2001.09253v1,cs.MS,['cs.MS'],,,[]
Automatically Harnessing Sparse Acceleration,http://arxiv.org/abs/2001.07938v1,2020-01-22T10:04:36Z,2020-01-22T10:04:36Z,"  Sparse linear algebra is central to many scientific programs, yet compilers
fail to optimize it well. High-performance libraries are available, but
adoption costs are significant. Moreover, libraries tie programs into
vendor-specific software and hardware ecosystems, creating non-portable code.
  In this paper, we develop a new approach based on our specification Language
for implementers of Linear Algebra Computations (LiLAC). Rather than requiring
the application developer to (re)write every program for a given library, the
burden is shifted to a one-off description by the library implementer. The
LiLAC-enabled compiler uses this to insert appropriate library routines without
source code changes.
  LiLAC provides automatic data marshaling, maintaining state between calls and
minimizing data transfers. Appropriate places for library insertion are
detected in compiler intermediate representation, independent of source
languages.
  We evaluated on large-scale scientific applications written in FORTRAN;
standard C/C++ and FORTRAN benchmarks; and C++ graph analytics kernels. Across
heterogeneous platforms, applications and data sets we show speedups of
1.1$\times$ to over 10$\times$ without user intervention.
","['\nPhilip Ginsbach\n', '\nBruce Collie\n', ""\nMichael F. P. O'Boyle\n""]",Accepted to CC 2020,,http://dx.doi.org/10.1145/3377555.3377893,cs.PF,"['cs.PF', 'cs.MS']",10.1145/3377555.3377893,,[]
"juSFEM: A Julia-based Open-source Package of Parallel Smoothed Finite
  Element Method (S-FEM) for Elastic Problems",http://arxiv.org/abs/2001.08849v1,2020-01-23T23:37:15Z,2020-01-23T23:37:15Z,"  The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve
more accurate results than the conventional FEM. Currently, much commercial
software and many open-source packages have been developed to analyze various
science and engineering problems using the FEM. However, there is little work
focusing on designing and developing software or packages for the S-FEM. In
this paper, we design and implement an open-source package of the parallel
S-FEM for elastic problems by utilizing the Julia language on multi-core CPU.
The Julia language is a fast, easy-to-use, and open-source programming language
that was originally designed for high-performance computing. We term our
package as juSFEM. To the best of the authors knowledge, juSFEM is the first
package of parallel S-FEM developed with the Julia language. To verify the
correctness and evaluate the efficiency of juSFEM, two groups of benchmark
tests are conducted. The benchmark results show that (1) juSFEM can achieve
accurate results when compared to commercial FEM software ABAQUS, and (2)
juSFEM only requires 543 seconds to calculate the displacements of a 3D elastic
cantilever beam model which is composed of approximately 2 million tetrahedral
elements, while in contrast the commercial FEM software needs 930 seconds for
the same calculation model; (3) the parallel juSFEM executed on the 24-core CPU
is approximately 20x faster than the corresponding serial version. Moreover,
the structure and function of juSFEM are easily modularized, and the code in
juSFEM is clear and readable, which is convenient for further development.
","['\nZenan Huo\n', '\nGang Mei\n', '\nNengxiong Xu\n']","Revised version submitted to Computers & Mathematics with
  Applications on Dec. 4, 2019","Computers & Mathematics with Applications, 2020",http://dx.doi.org/10.1016/j.camwa.2020.01.027,cs.MS,"['cs.MS', 'cs.CE']",10.1016/j.camwa.2020.01.027,,[]
pymoo: Multi-objective Optimization in Python,http://arxiv.org/abs/2002.04504v1,2020-01-22T16:04:24Z,2020-01-22T16:04:24Z,"  Python has become the programming language of choice for research and
industry projects related to data science, machine learning, and deep learning.
Since optimization is an inherent part of these research fields, more
optimization related frameworks have arisen in the past few years. Only a few
of them support optimization of multiple conflicting objectives at a time, but
do not provide comprehensive tools for a complete multi-objective optimization
task. To address this issue, we have developed pymoo, a multi-objective
optimization framework in Python. We provide a guide to getting started with
our framework by demonstrating the implementation of an exemplary constrained
multi-objective optimization scenario. Moreover, we give a high-level overview
of the architecture of pymoo to show its capabilities followed by an
explanation of each module and its corresponding sub-modules. The
implementations in our framework are customizable and algorithms can be
modified/extended by supplying custom operators. Moreover, a variety of single,
multi and many-objective test problems are provided and gradients can be
retrieved by automatic differentiation out of the box. Also, pymoo addresses
practical needs, such as the parallelization of function evaluations, methods
to visualize low and high-dimensional spaces, and tools for multi-criteria
decision making. For more information about pymoo, readers are encouraged to
visit: https://pymoo.org
","['\nJulian Blank\n', '\nKalyanmoy Deb\n']",,IEEE Access 8 (2020) 89497-89509,http://dx.doi.org/10.1109/ACCESS.2020.2990567,cs.NE,"['cs.NE', 'cs.LG', 'cs.MS', 'G.1.6; I.2.0; D.2.0']",10.1109/ACCESS.2020.2990567,,[]
"MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary
  Multivariate Distributions by means of Method Overloading",http://arxiv.org/abs/2001.07625v1,2020-01-21T16:03:57Z,2020-01-21T16:03:57Z,"  This manuscript outlines a software package that facilitates working with
probability distributions by means of Monte-Carlo methods, in a way that allows
for propagation of multivariate probability distributions through arbitrary
functions. We provide a \emph{type} that represents probability distributions
by an internal vector of unweighted samples, \texttt{Particles}, which is a
subtype of a \texttt{Real} number and behaves just like a regular real number
in calculations by means of method overloading. This makes the software easy to
work with and presents minimal friction for the user. We highlight how this
design facilitates optimal usage of SIMD instructions and showcase the package
for uncertainty propagation through an off-the-shelf ODE solver, as well as for
robust probabilistic optimization with automatic differentiation.
",['\nFredrik Bagge Carlson\n'],"5 pages, 4 figure, 5 code blocks, 2 tables",,http://arxiv.org/abs/2001.07625v1,cs.MS,"['cs.MS', 'stat.CO', 'stat.OT']",,,[]
"SLEEF: A Portable Vectorized Library of C Standard Mathematical
  Functions",http://arxiv.org/abs/2001.09258v1,2020-01-25T03:05:52Z,2020-01-25T03:05:52Z,"  In this paper, we present techniques used to implement our portable
vectorized library of C standard mathematical functions written entirely in C
language. In order to make the library portable while maintaining good
performance, intrinsic functions of vector extensions are abstracted by inline
functions or preprocessor macros. We implemented the functions so that they can
use sub-features of vector extensions such as fused multiply-add, mask
registers and extraction of mantissa. In order to make computation with SIMD
instructions efficient, the library only uses a small number of conditional
branches, and all the computation paths are vectorized. We devised a variation
of the Payne-Hanek argument reduction for trigonometric functions and a
floating point remainder, both of which are suitable for vector computation. We
compare the performance of our library to Intel SVML.
","['\nNaoki Shibata\n', '\nFrancesco Petrogalli\n']","in IEEE Transactions on Parallel and Distributed Systems. This is a
  version with all appendices included in a PDF. Accompanying software can be
  accessed at https://sleef.org or https://codeocean.com/capsule/6861013",,http://dx.doi.org/10.1109/TPDS.2019.2960333,cs.MS,"['cs.MS', 'cs.DC', 'cs.PL']",10.1109/TPDS.2019.2960333,,[]
"Awkward Arrays in Python, C++, and Numba",http://arxiv.org/abs/2001.06307v2,2020-01-15T16:48:07Z,2020-07-02T20:46:11Z,"  The Awkward Array library has been an important tool for physics analysis in
Python since September 2018. However, some interface and implementation issues
have been raised in Awkward Array's first year that argue for a
reimplementation in C++ and Numba. We describe those issues, the new
architecture, and present some examples of how the new interface will look to
users. Of particular importance is the separation of kernel functions from data
structure management, which allows a C++ implementation and a Numba
implementation to share kernel functions, and the algorithm that transforms
record-oriented data into columnar Awkward Arrays.
","['\nJim Pivarski\nPrinceton University\n', '\nPeter Elmer\nPrinceton University\n', '\nDavid Lange\nPrinceton University\n']","To be published in CHEP 2019 proceedings, EPJ Web of Conferences;
  post-review update",,http://dx.doi.org/10.1051/epjconf/202024505023,cs.MS,"['cs.MS', 'hep-ex']",10.1051/epjconf/202024505023,,"['Princeton University', 'Princeton University', 'Princeton University']"
"Issues with rounding in the GCC implementation of the ISO 18037:2008
  standard fixed-point arithmetic",http://arxiv.org/abs/2001.01496v3,2020-01-06T11:37:04Z,2020-04-30T09:58:03Z,"  We describe various issues caused by the lack of round-to-nearest mode in the
\textit{gcc} compiler implementation of the fixed-point arithmetic data types
and operations. We demonstrate that round-to-nearest is not performed in the
conversion of constants, conversion from one numerical type to a less precise
type and results of multiplications. Furthermore, we show that mixed-precision
operations in fixed-point arithmetic lose precision on arguments, even before
carrying out arithmetic operations. The ISO 18037:2008 standard was created to
standardize C language extensions, including fixed-point arithmetic, for
embedded systems. Embedded systems are usually based on ARM processors, of
which approximately 100 billion have been manufactured by now. Therefore, the
observations about numerical issues that we discuss in this paper can be rather
dangerous and are important to address, given the wide ranging type of
applications that these embedded systems are running.
",['\nMantas Mikaitis\n'],"To appear in the proceedings of the 27th IEEE Symposium on Computer
  Arithmetic",,http://dx.doi.org/10.1109/ARITH48897.2020.00028,cs.MS,['cs.MS'],10.1109/ARITH48897.2020.00028,,[]
Linnea: Automatic Generation of Efficient Linear Algebra Programs,http://arxiv.org/abs/1912.12924v1,2019-12-30T13:39:46Z,2019-12-30T13:39:46Z,"  The translation of linear algebra computations into efficient sequences of
library calls is a non-trivial task that requires expertise in both linear
algebra and high-performance computing. Almost all high-level languages and
libraries for matrix computations (e.g., Matlab, Eigen) internally use
optimized kernels such as those provided by BLAS and LAPACK; however, their
translation algorithms are often too simplistic and thus lead to a suboptimal
use of said kernels, resulting in significant performance losses. In order to
combine the productivity offered by high-level languages, and the performance
of low-level kernels, we are developing Linnea, a code generator for linear
algebra problems. As input, Linnea takes a high-level description of a linear
algebra problem; as output, it returns an efficient sequence of calls to
high-performance kernels. Linnea uses a custom best-first search algorithm to
find a first solution in less than a second, and increasingly better solutions
when given more time. In 125 test problems, the code generated by Linnea almost
always outperforms Matlab, Julia, Eigen and Armadillo, with speedups up to and
exceeding 10x.
","['\nHenrik Barthels\n', '\nChristos Psarras\n', '\nPaolo Bientinesi\n']",Extended version of arXiv:1907.02778,,http://arxiv.org/abs/1912.12924v1,cs.MS,['cs.MS'],,,[]
"A Hybrid MPI-CUDA Approach for Nonequispaced Discrete Fourier
  Transformation",http://arxiv.org/abs/2001.01583v1,2020-01-01T07:01:00Z,2020-01-01T07:01:00Z,"  Nonequispaced discrete Fourier transformation (NDFT) is widely applied in all
aspects of computational science and engineering. The computational efficiency
and accuracy of NDFT has always been a critical issue in hindering its
comprehensive applications both in intensive and in extensive aspects of
scientific computing. In our previous work (2018, S.-C. Yang et al., Appl.
Comput. Harmon. Anal. 44, 273), a CUNFFT method was proposed and it shown
outstanding performance in handling NDFT at intermediate scale based on CUDA
(Compute Unified Device Architecture) technology. In the current work, we
further improved the computational efficiency of the CUNTTF method using an
efficient MPI-CUDA hybrid parallelization (HP) scheme of NFFT to achieve a
cutting-edge treatment of NDFT at super extended scale. Within this HP-NFFT
method, the spatial domain of NDFT is decomposed into several parts according
to the accumulative feature of NDFT and the detailed number of CPU and GPU
nodes. These decomposed NDFT subcells are independently calculated on different
CPU nodes using a MPI process-level parallelization mode, and on different GPU
nodes using a CUDA threadlevel parallelization mode and CUNFFT algorithm. A
massive benchmarking of the HP-NFFT method indicates that this method exhibit a
dramatic improvement in computational efficiency for handling NDFT at super
extended scale without loss of computational precision. Furthermore, the
HP-NFFT method is validated via the calculation of Madelung constant of
fluorite crystal structure, and thereafter verified that this method is robust
for the calculation of electrostatic interactions between charged ions in
molecular dynamics simulation systems.
","['\nSheng-Chun Yang\n', '\nYong-Lei Wang\n']","16 pages, 16 figures",Comput. Phys. Commun. (2020),http://dx.doi.org/10.1016/j.cpc.2020.107513,cs.MS,"['cs.MS', 'cond-mat.soft', 'physics.chem-ph', 'physics.comp-ph']",10.1016/j.cpc.2020.107513,,[]
"Medusa: A C++ Library for solving PDEs using Strong Form Mesh-Free
  methods",http://arxiv.org/abs/1912.13282v1,2019-12-31T12:11:17Z,2019-12-31T12:11:17Z,"  Medusa, a novel library for implementation of strong form mesh-free methods,
is described. We identify and present common parts and patterns among many such
methods reported in the literature, such as node positioning, stencil selection
and stencil weight computation. Many different algorithms exist for each part
and the possible combinations offer a plethora of possibilities for
improvements of solution procedures that are far from fully understood. As a
consequence there are still many unanswered questions in mesh-free community
resulting in vivid ongoing research in the field. Medusa implements the core
mesh-free elements as independent blocks, which offers users great flexibility
in experimenting with the method they are developing, as well as easily
comparing it with other existing methods. The paper describes the chosen
abstractions and their usage, illustrates aspects of the philosophy and design,
offers some executions time benchmarks and demonstrates the application of the
library on cases from linear elasticity and fluid flow in irregular 2D and 3D
domains.
","['\nJure Slak\n', '\nGregor Kosec\n']",,"ACM Transactions on Mathematical Software 47(3), June 2021",http://dx.doi.org/10.1145/3450966,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65M99', 'G.4']",10.1145/3450966,,[]
LEoPart: a particle library for FEniCS,http://arxiv.org/abs/1912.13375v2,2019-12-23T21:26:49Z,2020-05-29T07:37:53Z,"  This paper introduces LEoPart, an add-on for the open source finite element
software library FEniCS to seamlessly integrate Lagrangian particle
functionality with (Eulerian) mesh-based finite element (FE) approaches.
LEoPart - which is so much as to say: `Lagrangian-Eulerian on Particles' -
contains tools for efficient, accurate and scalable advection of Lagrangian
particles on arbitrary polyhedral meshes. In addition, LEoPart comes with
several projection operators for exchanging information between the scattered
particles and the mesh and \textit{vice versa}. These projection operators are
based on a variational framework, which allows extension to high-order
accuracy. In particular, by implementing a dedicated PDE-constrained
particle-mesh projection operator, LEoPart provides all the tools for
diffusion-free advection, while simultaneously achieving optimal convergence
and ensuring conservation of the projected particle quantities on the
underlying mesh. A range of numerical examples that are prototypical to passive
and active tracer methods highlight the properties and the parallel performance
of the different tools in LEoPart. Finally, future developments are identified.
The source code for LEoPart is actively maintained and available under an open
source license at https://bitbucket.org/jakob_maljaars/leopart.
","['\nJakob M. Maljaars\n', '\nChris N. Richardson\n', '\nNathan Sime\n']","35 pages, 13 figures",,http://dx.doi.org/10.1016/j.camwa.2020.04.023,cs.MS,['cs.MS'],10.1016/j.camwa.2020.04.023,,[]
"AVaN Pack: An Analytical/Numerical Solution for Variance-Based
  Sensitivity Analysis",http://arxiv.org/abs/1912.11369v1,2019-12-22T01:33:32Z,2019-12-22T01:33:32Z,"  Sensitivity analysis is an important concept to analyze the influences of
parameters in a system, an equation or a collection of data. The methods used
for sensitivity analysis are divided into deterministic and statistical
techniques. Generally, deterministic techniques analyze fixed points of a model
whilst stochastic techniques analyze a range of values. Deterministic methods
fail in analyze the entire range of input values and stochastic methods
generate outcomes with random errors. In this manuscript, we are interested in
stochastic methods, mainly in variance-based techniques such as Variance and
Sobol indices, since this class of techniques is largely used on literature.
The objective of this manuscript is to present an analytical solution for
variance based sensitive analysis. As a result of this research, two small
programs were developed in Javascript named as AVaN Pack (Analysis of Variance
through Numerical solution). These programs allow users to find the
contribution of each individual parameter in any function by means of a
mathematical solution, instead of sampling-based ones.
","['\nEduardo Vasconcelos\n', '\nAdriano Souza\n', '\nKelvin Dias\n']","13 pages, 1 Figure, 2 tables",,http://arxiv.org/abs/1912.11369v1,stat.OT,"['stat.OT', 'cs.MS']",,,[]
"PCPATCH: software for the topological construction of multigrid
  relaxation methods",http://arxiv.org/abs/1912.08516v4,2019-12-18T11:03:11Z,2021-07-05T16:21:35Z,"  Effective relaxation methods are necessary for good multigrid convergence.
For many equations, standard Jacobi and Gau{\ss}-Seidel are inadequate, and
more sophisticated space decompositions are required; examples include problems
with semidefinite terms or saddle point structure. In this paper we present a
unifying software abstraction, PCPATCH, for the topological construction of
space decompositions for multigrid relaxation methods. Space decompositions are
specified by collecting topological entities in a mesh (such as all vertices or
faces) and applying a construction rule (such as taking all degrees of freedom
in the cells around each entity). The software is implemented in PETSc and
facilitates the elegant expression of a wide range of schemes merely by varying
solver options at runtime. In turn, this allows for the very rapid development
of fast solvers for difficult problems.
","['\nPatrick E. Farrell\n', '\nMatthew G. Knepley\n', '\nLawrence Mitchell\n', '\nFlorian Wechsung\n']","22 pages, minor fixes in bibliography",ACM Transactions on Mathematical Software 47(3):25 (2021),http://dx.doi.org/10.1145/3445791,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1145/3445791,,[]
Assembly of multiscale linear PDE operators,http://arxiv.org/abs/1912.09319v1,2019-12-19T15:59:24Z,2019-12-19T15:59:24Z,"  In numerous applications the mathematical model consists of different
processes coupled across a lower dimensional manifold. Due to the multiscale
coupling, finite element discretization of such models presents a challenge.
Assuming that only singlescale finite element forms can be assembled we present
here a simple algorithm for representing multiscale models as linear operators
suitable for Krylov methods. Flexibility of the approach is demonstrated by
numerical examples with coupling across dimensionality gap 1 and 2.
Preconditioners for several of the problems are discussed.
",['\nMiroslav Kuchta\n'],,,http://arxiv.org/abs/1912.09319v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Strategies for the vectorized Block Conjugate Gradients method,http://arxiv.org/abs/1912.11930v1,2019-12-26T20:41:05Z,2019-12-26T20:41:05Z,"  Block Krylov methods have recently gained a lot of attraction. Due to their
increased arithmetic intensity they offer a promising way to improve
performance on modern hardware. Recently Frommer et al. presented a block
Krylov framework that combines the advantages of block Krylov methods and data
parallel methods. We review this framework and apply it on the Block Conjugate
Gradients method,to solve linear systems with multiple right hand sides. In
this course we consider challenges that occur on modern hardware, like a
limited memory bandwidth, the use of SIMD instructions and the communication
overhead. We present a performance model to predict the efficiency of different
Block CG variants and compare these with experimental numerical results.
","['\nNils-Arne Dreier\n', '\nChristian Engwer\n']",,,http://arxiv.org/abs/1912.11930v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"High Accuracy Low Precision QR Factorization and Least Square Solver on
  GPU with TensorCore",http://arxiv.org/abs/1912.05508v1,2019-12-11T18:14:52Z,2019-12-11T18:14:52Z,"  Driven by the insatiable needs to process ever larger amount of data with
more complex models, modern computer processors and accelerators are beginning
to offer half precision floating point arithmetic support, and extremely
optimized special units such as NVIDIA TensorCore on GPU and Google Tensor
Processing Unit (TPU) that does half precision matrix-matrix multiplication
exceptionally efficiently. In this paper we present a large scale mixed
precision linear least square solver that achieves high accuracy using the low
precision TensorCore GPU. The mixed precision system consists of both
innovative algorithms and implementations, and is shown to be up to 14x faster
than single precision cuSOLVER at QR matrix factorization at large scale with
slightly lower accuracy, and up to 10x faster than double precision direct QR
least square solver with comparable accuracy.
","['\nShaoshuai Zhang\n', '\nPanruo Wu\n']",11 pages,,http://arxiv.org/abs/1912.05508v1,cs.MS,['cs.MS'],,,[]
"Alsvinn: A Fast multi-GPGPU finite volume solver with a strong emphasis
  on reproducibility",http://arxiv.org/abs/1912.07645v1,2019-12-16T19:17:46Z,2019-12-16T19:17:46Z,"  We present the Alsvinn simulator, a fast multi general purpose graphical
processing unit (GPGPU) finite volume solver for hyperbolic conservation laws
in multiple space dimensions. Alsvinn has native support for uncertainty
quantifications, and exhibits excellent scaling on top tier compute clusters.
",['\nKjetil Lye\n'],,,http://arxiv.org/abs/1912.07645v1,cs.MS,['cs.MS'],,,[]
"PETSc TSAdjoint: a discrete adjoint ODE solver for first-order and
  second-order sensitivity analysis",http://arxiv.org/abs/1912.07696v2,2019-12-16T20:45:42Z,2021-10-26T20:44:57Z,"  We present a new software system PETSc TSAdjoint for first-order and
second-order adjoint sensitivity analysis of time-dependent nonlinear
differential equations. The derivative calculation in PETSc TSAdjoint is
essentially a high-level algorithmic differentiation process. The adjoint
models are derived by differentiating the timestepping algorithms and
implemented based on the parallel infrastructure in PETSc. Full differentiation
of the library code including MPI routines thus is avoided, and users do not
need to derive their own adjoint models for their specific applications. PETSc
TSAdjoint can compute the first-order derivative, that is, the gradient of a
scalar functional, and the Hessian-vector product that carries second-order
derivative information, while requiring minimal input (a few callbacks) from
the users. Optimal checkpointing schemes are employed by the adjoint model in a
manner that is transparent to users. Usability, efficiency, and scalability are
demonstrated through examples from a variety of applications.
","['\nHong Zhang\n', '\nEmil M. Constantinescu\n', '\nBarry F. Smith\n']",,,http://arxiv.org/abs/1912.07696v2,cs.MS,['cs.MS'],,,[]
"High Performance Solution of Skew-symmetric Eigenvalue Problems with
  Applications in Solving the Bethe-Salpeter Eigenvalue Problem",http://arxiv.org/abs/1912.04062v2,2019-12-09T14:10:45Z,2020-04-20T15:21:13Z,"  We present a high-performance solver for dense skew-symmetric matrix
eigenvalue problems. Our work is motivated by applications in computational
quantum physics, where one solution approach to solve the so-called
Bethe-Salpeter equation involves the solution of a large, dense, skew-symmetric
eigenvalue problem. The computed eigenpairs can be used to compute the optical
absorption spectrum of molecules and crystalline systems. One state-of-the art
high-performance solver package for symmetric matrices is the ELPA (Eigenvalue
SoLvers for Petascale Applications) library. We extend the methods available in
ELPA to skew-symmetric matrices. This way, the presented solution method can
benefit from the optimizations available in ELPA that make it a
well-established, efficient and scalable library, such as GPU support. We
compare performance and scalability of our method to the only available
high-performance approach for skew-symmetric matrices, an indirect route
involving complex arithmetic. In total, we achieve a performance that is up to
3.67 higher than the reference method using Intel's ScaLAPACK implementation.
The runtime to solve the Bethe-Salpeter-Eigenvalue problem can be improved by a
factor of 10. Our method is freely available in the current release of the ELPA
library.
","['\nCarolin Penke\n', '\nAndreas Marek\n', '\nChristian Vorwerk\n', '\nClaudia Draxl\n', '\nPeter Benner\n']",,,http://dx.doi.org/10.1016/j.parco.2020.102639,math.NA,"['math.NA', 'cs.DS', 'cs.MS', 'cs.NA', '65Y05, 15B57', 'G.1.3; G.4']",10.1016/j.parco.2020.102639,,[]
Eigen-AD: Algorithmic Differentiation of the Eigen Library,http://arxiv.org/abs/1911.12604v2,2019-11-28T09:07:08Z,2020-06-22T12:42:13Z,"  In this work we present useful techniques and possible enhancements when
applying an Algorithmic Differentiation (AD) tool to the linear algebra library
Eigen using our in-house AD by overloading (AD-O) tool dco/c++ as a case study.
After outlining performance and feasibility issues when calculating derivatives
for the official Eigen release, we propose Eigen-AD, which enables different
optimization options for an AD-O tool by providing add-on modules for Eigen.
The range of features includes a better handling of expression templates for
general performance improvements, as well as implementations of symbolically
derived expressions for calculating derivatives of certain core operations. The
software design allows an AD-O tool to provide specializations to automatically
include symbolic operations and thereby keep the look and feel of plain AD by
overloading. As a showcase, dco/c++ is provided with such a module and its
significant performance improvements are validated by benchmarks.
","['\nPatrick Peltzer\n', '\nJohannes Lotz\n', '\nUwe Naumann\n']","Updated with accepted version for ICCS 2020 conference proceedings.
  The final authenticated publication is available online at
  https://doi.org/10.1007/978-3-030-50371-0_51. See v1 for the original,
  extended preprint. 14 pages, 7 figures","Computational Science - ICCS 2020: 20th International Conference,
  Amsterdam, The Netherlands, June 3-5, 2020, Proceedings, Part I, 12137,
  690-704",http://dx.doi.org/10.1007/978-3-030-50371-0_51,cs.MS,['cs.MS'],10.1007/978-3-030-50371-0_51,,[]
"Replicated Computational Results (RCR) Report for ""Code Generation for
  Generally Mapped Finite Elements""",http://arxiv.org/abs/1912.00488v1,2019-12-01T19:39:16Z,2019-12-01T19:39:16Z,"  ""Code Generation for Generally Mapped Finite Elements"" includes performance
results for the finite element methods discussed in that manuscript. The
authors provided a Zenodo archive with the Firedrake components and
dependencies used, as well as the scripts that generated the results. The
software was installed on two similar platforms; then, new results were
gathered and compared to the original results. After completing this process,
the results have been deemed replicable by the reviewer.
",['\nNeil Lindquist\n'],"7 pages, 7 figures. Submitted to ACM Transactions on Mathematical
  Software","ACM Transactions on Mathematical Software (TOMS): Volume 45 Issue
  4, December 2019",http://dx.doi.org/10.1145/3360984,cs.MS,"['cs.MS', '10002944.10011123.10011676, 10002950.10003705.10011686,\n  10002950.10003705.10003707', 'G.1.8; G.4']",10.1145/3360984,,[]
CheasePy,http://arxiv.org/abs/1912.01589v1,2019-12-03T18:39:11Z,2019-12-03T18:39:11Z,"  CheasePy is code written in Python to run the CHEASE (Cubic Hermite Element
Axisymmetric Static Equilibrium) code, which solves the Grad-Shafranov equation
for toroidal MHD equilibria using pressure and current profiles and fixed
plasma boundaries that is defined by a set of experimental data points (R,Z).
The CheasePy code allows an iterative running of the CHEASE code either to
check the preservation of MHD equilibria or converging to an experimentally
defined total toroidal plasma current by modifying any input quantity.
",['\nEhab Hassan\n'],,,http://arxiv.org/abs/1912.01589v1,cs.MS,['cs.MS'],,,[]
bertha: Project Skeleton for Scientific Software,http://arxiv.org/abs/1912.01640v2,2019-12-03T19:25:20Z,2020-03-25T22:20:07Z,"  Science depends heavily on reliable and easy-to-use software packages, such
as mathematical libraries or data analysis tools. Developing such packages
requires a lot of effort, which is too often avoided due to the lack of funding
or recognition. In order to reduce the efforts required to create sustainable
software packages, we present a project skeleton that ensures the best software
engineering practices from the start of a project, or serves as reference for
existing projects.
","['\nMichael Riesch\n', '\nTien Dat Nguyen\n', '\nChristian Jirauschek\n']",Source code available at https://gitlab.com/cph-tum/bertha,PLoS One. 2020; 15(3): e0230557,http://dx.doi.org/10.1371/journal.pone.0230557,cs.MS,['cs.MS'],10.1371/journal.pone.0230557,,[]
"Using performance analysis tools for parallel-in-time integrators --
  Does my time-parallel code do what I think it does?",http://arxiv.org/abs/1911.13027v2,2019-11-29T09:58:23Z,2020-08-28T12:32:34Z,"  While many ideas and proofs of concept for parallel-in-time integration
methods exists, the number of large-scale, accessible time-parallel codes is
rather small. This is often due to the apparent or subtle complexity of the
algorithms and the many pitfalls awaiting developers of parallel numerical
software. One example of such a time-parallel code is pySDC, which implements,
among others, the parallel full approximation scheme in space and time
(PFASST). Inspired by nonlinear multigrid ideas, PFASST allows to integrate
multiple time-steps simultaneously using a space-time hierarchy of spectral
deferred corrections. In this paper we demonstrate the application of
performance analysis tools to the PFASST implementation pySDC. Tracing the path
we took for this work, we highlight the obstacles encountered, describe
remedies and explain the sometimes surprising findings made possible by the
tools. Although focusing only on a single implementation of a particular
parallel-in-time integrator, we hope that our results and in particular the way
we obtained them are a blueprint for other time-parallel codes.
","['\nRobert Speck\n', '\nMichael Knobloch\n', '\nSebastian Lührs\n', '\nAndreas Gocht\n']","31 pages, 15 figures, CVS Proceedings of the 9th PinT Workshop",,http://arxiv.org/abs/1911.13027v2,cs.PF,"['cs.PF', 'cs.MS']",,,[]
Recent Developments in Iterative Methods for Reducing Synchronization,http://arxiv.org/abs/1912.00816v1,2019-12-02T14:22:42Z,2019-12-02T14:22:42Z,"  On modern parallel architectures, the cost of synchronization among
processors can often dominate the cost of floating-point computation. Several
modifications of the existing methods have been proposed in order to keep the
communication cost as low as possible. This paper aims at providing a brief
overview of recent advances in parallel iterative methods for solving
large-scale problems. We refer the reader to the related references for more
details on the derivation, implementation, performance, and analysis of these
techniques.
","['\nQinmeng Zou\n', '\nFrederic Magoules\n']",,"18th International Symposium on Distributed Computing and
  Applications for Business Engineering and Science (DCABES), 2019, IEEE",http://dx.doi.org/10.1109/DCABES48411.2019.00048,cs.DC,"['cs.DC', 'cs.MS']",10.1109/DCABES48411.2019.00048,,[]
"PFASST-ER: Combining the Parallel Full Approximation Scheme in Space and
  Time with parallelization across the method",http://arxiv.org/abs/1912.00702v1,2019-12-02T12:00:03Z,2019-12-02T12:00:03Z,"  To extend prevailing scaling limits when solving time-dependent partial
differential equations, the parallel full approximation scheme in space and
time (PFASST) has been shown to be a promising parallel-in-time integrator.
Similar to a space-time multigrid, PFASST is able to compute multiple
time-steps simultaneously and is therefore in particular suitable for
large-scale applications on high performance computing systems. In this work we
couple PFASST with a parallel spectral deferred correction (SDC) method,
forming an unprecedented doubly time-parallel integrator. While PFASST provides
global, large-scale ""parallelization across the step"", the inner parallel SDC
method allows to integrate each individual time-step ""parallel across the
method"" using a diagonalized local Quasi-Newton solver. This new method, which
we call ""PFASST with Enhanced concuRrency"" (PFASST-ER), therefore exposes even
more temporal parallelism. For two challenging nonlinear reaction-diffusion
problems, we show that PFASST-ER works more efficiently than the classical
variants of PFASST and can be used to run parallel-in-time beyond the number of
time-steps.
","['\nRuth Schöbel\n', '\nRobert Speck\n']","12 pages, 12 figures, CVS PinT Workshop Proceedings",,http://arxiv.org/abs/1912.00702v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",,,[]
"PyTorch: An Imperative Style, High-Performance Deep Learning Library",http://arxiv.org/abs/1912.01703v1,2019-12-03T22:06:05Z,2019-12-03T22:06:05Z,"  Deep learning frameworks have often focused on either usability or speed, but
not both. PyTorch is a machine learning library that shows that these two goals
are in fact compatible: it provides an imperative and Pythonic programming
style that supports code as a model, makes debugging easy and is consistent
with other popular scientific computing libraries, while remaining efficient
and supporting hardware accelerators such as GPUs.
  In this paper, we detail the principles that drove the implementation of
PyTorch and how they are reflected in its architecture. We emphasize that every
aspect of PyTorch is a regular Python program under the full control of its
user. We also explain how the careful and pragmatic implementation of the key
components of its runtime enables them to work together to achieve compelling
performance.
  We demonstrate the efficiency of individual subsystems, as well as the
overall speed of PyTorch on several common benchmarks.
","['\nAdam Paszke\n', '\nSam Gross\n', '\nFrancisco Massa\n', '\nAdam Lerer\n', '\nJames Bradbury\n', '\nGregory Chanan\n', '\nTrevor Killeen\n', '\nZeming Lin\n', '\nNatalia Gimelshein\n', '\nLuca Antiga\n', '\nAlban Desmaison\n', '\nAndreas Köpf\n', '\nEdward Yang\n', '\nZach DeVito\n', '\nMartin Raison\n', '\nAlykhan Tejani\n', '\nSasank Chilamkurthy\n', '\nBenoit Steiner\n', '\nLu Fang\n', '\nJunjie Bai\n', '\nSoumith Chintala\n']","12 pages, 3 figures, NeurIPS 2019",,http://arxiv.org/abs/1912.01703v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
differint: A Python Package for Numerical Fractional Calculus,http://arxiv.org/abs/1912.05303v1,2019-12-03T21:22:29Z,2019-12-03T21:22:29Z,"  Fractional calculus has become widely studied and applied to physical
problems in recent years. As a result, many methods for the numerical
computation of fractional derivatives and integrals have been defined. However,
these algorithms are often programmed in an ad hoc manner, requiring
researchers to implement and debug their own code. This work introduces the
\textit{differint} software package, which offers a single repository for
multiple numerical algorithms for the computation of fractional derivatives and
integrals. This package is coded in the open-source Python programming
language. The Gr\""unwald-Letnikov, improved Gr\""unwald-Letnikov, and
Riemann-Liouville algorithms from the fractional calculus are included in this
package. The algorithms presented are computed from their descriptions found in
[2]. This work concludes with suggestions for the application of the
\textit{differint} software package.
",['\nMatthew Adams\n'],,,http://arxiv.org/abs/1912.05303v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Role-Oriented Code Generation in an Engine for Solving Hyperbolic PDE
  Systems",http://arxiv.org/abs/1911.06817v2,2019-11-15T10:07:24Z,2020-03-28T13:21:09Z,"  The development of a high performance PDE solver requires the combined
expertise of interdisciplinary teams with respect to application domain,
numerical scheme and low-level optimization. In this paper, we present how the
ExaHyPE engine facilitates the collaboration of such teams by isolating three
roles: application, algorithms, and optimization expert. We thus support team
members in letting them focus on their own area of expertise while integrating
their contributions into an HPC production code. Inspired by web application
development practices, ExaHyPE relies on two custom code generation modules,
the Toolkit and the Kernel Generator, which follow a Model-View-Controller
architectural pattern on top of the Jinja2 template engine library. Using
Jinja2's templates to abstract the critical components of the engine and
generated glue code, we isolate the application development from the engine.
The template language also allows us to define and use custom template macros
that isolate low-level optimizations from the numerical scheme described in the
templates. We present three use cases, each focusing on one of our user roles,
showcasing how the design of the code generation modules allows to easily
expand the solver schemes to support novel demands from applications, to add
optimized algorithmic schemes (with reduced memory footprint, e.g.), or provide
improved low-level SIMD vectorization support.
","['\nJean-Matthieu Gallard\n', '\nLukas Krenz\n', '\nLeonhard Rannabauer\n', '\nAnne Reinarz\n', '\nMichael Bader\n']",SC19 SE-HER,,http://arxiv.org/abs/1911.06817v2,cs.MS,"['cs.MS', 'cs.SE']",,,[]
"Semi-Automatic Task Graph Construction for $\mathcal{H}$-Matrix
  Arithmetic",http://arxiv.org/abs/1911.07531v1,2019-11-18T10:36:43Z,2019-11-18T10:36:43Z,"  A new method to construct task graphs for \mcH-matrix arithmetic is
introduced, which uses the information associated with all tasks of the
standard recursive \mcH-matrix algorithms, e.g., the block index set of the
matrix blocks involved in the computation. Task refinement, i.e., the
replacement of tasks by sub-computations, is then used to proceed in the
\mcH-matrix hierarchy until the matrix blocks containing the actual matrix data
are reached. This process is a natural extension of the classical, recursive
way in which \mcH-matrix arithmetic is defined and thereby simplifies the
efficient usage of many-core systems. Examples for standard and accumulator
based \mcH-arithmetic are shown for model problems with different block
structures.
","['\nSteffen Börm\n', '\nSven Christophersen\n', '\nRonald Kriemann\n']",,,http://arxiv.org/abs/1911.07531v1,cs.MS,"['cs.MS', 'cs.DC', '65F05, 65Y05, 65Y20, 68W10, 68W40']",,,[]
"The Linear Algebra Mapping Problem. Current state of linear algebra
  languages and libraries",http://arxiv.org/abs/1911.09421v2,2019-11-21T11:42:14Z,2021-09-05T20:24:18Z,"  We observe a disconnect between the developers and the end users of linear
algebra libraries. On the one hand, the numerical linear algebra and the
high-performance communities invest significant effort in the development and
optimization of highly sophisticated numerical kernels and libraries, aiming at
the maximum exploitation of both the properties of the input matrices, and the
architectural features of the target computing platform. On the other hand, end
users are progressively less likely to go through the error-prone and time
consuming process of directly using said libraries by writing their code in C
or Fortran; instead, languages and libraries such as Matlab, Julia, Eigen and
Armadillo, which offer a higher level of abstraction, are becoming more and
more popular. Users are given the opportunity to code matrix computations with
a syntax that closely resembles the mathematical description; it is then a
compiler or an interpreter that internally maps the input program to lower
level kernels, as provided by libraries such as BLAS and LAPACK. Unfortunately,
our experience suggests that in terms of performance, this translation is
typically vastly suboptimal.
  In this paper, we first introduce the Linear Algebra Mapping Problem, and
then investigate how effectively a benchmark of test problems is solved by
popular high-level programming languages. Specifically, we consider Matlab,
Octave, Julia, R, Armadillo (C++), Eigen (C++), and NumPy (Python); the
benchmark is meant to test both standard compiler optimizations such as common
subexpression elimination and loop-invariant code motion, as well as linear
algebra specific optimizations such as optimal parenthesization of a matrix
product and kernel selection for matrices with properties. The aim of this
study is to give concrete guidelines for the development of languages and
libraries that support linear algebra computations.
","['\nChristos Psarras\n', '\nHenrik Barthels\n', '\nPaolo Bientinesi\n']",,,http://dx.doi.org/10.1145/3549935,cs.MS,"['cs.MS', 'cs.PL']",10.1145/3549935,,[]
MFEM: a modular finite element methods library,http://arxiv.org/abs/1911.09220v2,2019-11-20T23:49:09Z,2020-07-13T18:16:51Z,"  MFEM is an open-source, lightweight, flexible and scalable C++ library for
modular finite element methods that features arbitrary high-order finite
element meshes and spaces, support for a wide variety of discretization
approaches and emphasis on usability, portability, and high-performance
computing efficiency. MFEM's goal is to provide application scientists with
access to cutting-edge algorithms for high-order finite element meshing,
discretizations and linear solvers, while enabling researchers to quickly and
easily develop and test new algorithms in very general, fully unstructured,
high-order, parallel and GPU-accelerated settings. In this paper we describe
the underlying algorithms and finite element abstractions provided by MFEM,
discuss the software implementation, and illustrate various applications of the
library.
","['\nRobert Anderson\n', '\nJulian Andrej\n', '\nAndrew Barker\n', '\nJamie Bramwell\n', '\nJean-Sylvain Camier\n', '\nJakub Cerveny\n', '\nVeselin Dobrev\n', '\nYohann Dudouit\n', '\nAaron Fisher\n', '\nTzanio Kolev\n', '\nWill Pazner\n', '\nMark Stowell\n', '\nVladimir Tomov\n', '\nJohann Dahm\n', '\nDavid Medina\n', '\nStefano Zampini\n']","36 pages, 21 figures",,http://dx.doi.org/10.1016/j.camwa.2020.06.009,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1016/j.camwa.2020.06.009,,[]
"HILUCSI: Simple, Robust, and Fast Multilevel ILU for Large-Scale
  Saddle-Point Problems from PDEs",http://arxiv.org/abs/1911.10139v5,2019-11-22T16:59:53Z,2021-05-28T14:13:29Z,"  Incomplete factorization is a widely used preconditioning technique for
Krylov subspace methods for solving large-scale sparse linear systems. Its
multilevel variants, such as ILUPACK, are more robust for many symmetric or
unsymmetric linear systems than the traditional, single-level incomplete LU (or
ILU) techniques. However, the previous multilevel ILU techniques still lacked
robustness and efficiency for some large-scale saddle-point problems, which
often arise from systems of partial differential equations (PDEs). We introduce
HILUCSI, or Hierarchical Incomplete LU-Crout with Scalability-oriented and
Inverse-based dropping. As a multilevel preconditioner, HILUCSI statically and
dynamically permutes individual rows and columns to the next level for deferred
factorization. Unlike ILUPACK, HILUCSI applies symmetric preprocessing
techniques at the top levels but always uses unsymmetric preprocessing and
unsymmetric factorization at the coarser levels. The deferring combined with
mixed preprocessing enabled a unified treatment for nearly or partially
symmetric systems, and simplified the implementation by avoiding mixed $1\times
1$ and $2\times 2$ pivots for symmetric indefinite systems. We show that this
combination improves robustness for indefinite systems without compromising
efficiency. Furthermore, to enable superior efficiency for large-scale systems
with millions or more unknowns, HILUCSI introduces a scalability-oriented
dropping in conjunction with a variant of inverse-based dropping. We
demonstrate the effectiveness of HILUCSI for dozens of benchmark problems,
including those from the mixed formulation of the Poisson equation, Stokes
equations, and Navier-Stokes equations. We also compare its performance with
ILUPACK, the supernodal ILUTP in SuperLU, and multithreaded direct solvers in
PARDISO and MUMPS.
","['\nQiao Chen\n', '\nAditi Ghai\n', '\nXiangmin Jiao\n']",Submitted to Numerical Linear Algebra with Applications (NLAA),Numerical Linear Algebra with Applications (2021),http://dx.doi.org/10.1002/nla.2400,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1002/nla.2400,,[]
DISROPT: a Python Framework for Distributed Optimization,http://arxiv.org/abs/1911.02410v2,2019-11-06T14:39:41Z,2020-05-20T17:43:21Z,"  In this paper we introduce DISROPT, a Python package for distributed
optimization over networks. We focus on cooperative set-ups in which an
optimization problem must be solved by peer-to-peer processors (without central
coordinators) that have access only to partial knowledge of the entire problem.
To reflect this, agents in DISROPT are modeled as entities that are initialized
with their local knowledge of the problem. Agents then run local routines and
communicate with each other to solve the global optimization problem. A simple
syntax has been designed to allow for an easy modeling of the problems. The
package comes with many distributed optimization algorithms that are already
embedded. Moreover, the package provides full-fledged functionalities for
communication and local computation, which can be used to design and implement
new algorithms. DISROPT is available at github.com/disropt/disropt under the
GPL license, with a complete documentation and many examples.
","['\nFrancesco Farina\n', '\nAndrea Camisa\n', '\nAndrea Testa\n', '\nIvano Notarnicola\n', '\nGiuseppe Notarstefano\n']",,IFAC-PapersOnLine 2020,http://dx.doi.org/10.1016/j.ifacol.2020.12.382,math.OC,"['math.OC', 'cs.MS']",10.1016/j.ifacol.2020.12.382,,[]
MOOSE: Enabling Massively Parallel Multiphysics Simulation,http://arxiv.org/abs/1911.04488v1,2019-11-11T18:20:43Z,2019-11-11T18:20:43Z,"  Harnessing modern parallel computing resources to achieve complex
multi-physics simulations is a daunting task. The Multiphysics Object Oriented
Simulation Environment (MOOSE) aims to enable such development by providing
simplified interfaces for specification of partial differential equations,
boundary conditions, material properties, and all aspects of a simulation
without the need to consider the parallel, adaptive, nonlinear, finite-element
solve that is handled internally. Through the use of interfaces and
inheritance, each portion of a simulation becomes reusable and composable in a
manner that allows disparate research groups to share code and create an
ecosystem of growing capability that lowers the barrier for the creation of
multiphysics simulation codes. Included within the framework is a unique
capability for building multiscale, multiphysics simulations through
simultaneous execution of multiple sub-applications with data transfers between
the scales. Other capabilities include automatic differentiation, scaling to a
large number of processors, hybrid parallelism, and mesh adaptivity. To date,
MOOSE-based applications have been created in areas of science and engineering
such as nuclear physics, geothermal science, magneto-hydrodynamics, seismic
events, compressible and incompressible fluid flow, microstructure evolution,
and advanced manufacturing processes.
","['\nCody J. Permann\n', '\nDerek R. Gaston\n', '\nDavid Andrs\n', '\nRobert W. Carlsen\n', '\nFande Kong\n', '\nAlexander D. Lindsay\n', '\nJason M. Miller\n', '\nJohn W. Peterson\n', '\nAndrew E. Slaughter\n', '\nRoy H. Stogner\n', '\nRichard C. Martineau\n']","10 Pages of content, 2 Figures, 30 References",SoftwareX. 11 (2020) 100430,http://dx.doi.org/10.1016/j.softx.2020.100430,cs.MS,"['cs.MS', 'physics.comp-ph']",10.1016/j.softx.2020.100430,,[]
"Abstractions and automated algorithms for mixed domain finite element
  methods",http://arxiv.org/abs/1911.01166v1,2019-11-04T12:42:42Z,2019-11-04T12:42:42Z,"  Mixed dimensional partial differential equations (PDEs) are equations
coupling unknown fields defined over domains of differing topological
dimension. Such equations naturally arise in a wide range of scientific fields
including geology, physiology, biology and fracture mechanics. Mixed
dimensional PDEs are also commonly encountered when imposing non-standard
conditions over a subspace of lower dimension e.g. through a Lagrange
multiplier. In this paper, we present general abstractions and algorithms for
finite element discretizations of mixed domain and mixed dimensional PDEs of
co-dimension up to one (i.e. nD-mD with |n-m| <= 1). We introduce high level
mathematical software abstractions together with lower level algorithms for
expressing and efficiently solving such coupled systems. The concepts
introduced here have also been implemented in the context of the FEniCS finite
element software. We illustrate the new features through a range of examples,
including a constrained Poisson problem, a set of Stokes-type flow models and a
model for ionic electrodiffusion.
","['\nCécile Daversin-Catty\n', '\nChris N. Richardson\n', '\nAda J. Ellingsrud\n', '\nMarie E. Rognes\n']",,,http://arxiv.org/abs/1911.01166v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Exa-Dune -- Flexible PDE Solvers, Numerical Methods and Applications",http://arxiv.org/abs/1911.01492v2,2019-11-04T21:17:47Z,2019-11-06T11:15:15Z,"  In the Exa-Dune project we have developed, implemented and optimised
numerical algorithms and software for the scalable solution of partial
differential equations (PDEs) on future exascale systems exhibiting a
heterogeneous massively parallel architecture. In order to cope with the
increased probability of hardware failures, one aim of the project was to add
flexible, application-oriented resilience capabilities into the framework.
Continuous improvement of the underlying hardware-oriented numerical methods
have included GPU-based sparse approximate inverses, matrix-free
sum-factorisation for high-order discontinuous Galerkin discretisations as well
as partially matrix-free preconditioners. On top of that, additional
scalability is facilitated by exploiting massive coarse grained parallelism
offered by multiscale and uncertainty quantification methods where we have
focused on the adaptive choice of the coarse/fine scale and the overlap region
as well as the combination of local reduced basis multiscale methods and the
multilevel Monte-Carlo algorithm. Finally, some of the concepts are applied in
a land-surface model including subsurface flow and surface runoff.
","['\nPeter Bastian\n', '\nMirco Altenbernd\n', '\nNils-Arne Dreier\n', '\nChristian Engwer\n', '\nJorrit Fahlke\n', '\nRené Fritze\n', '\nMarkus Geveler\n', '\nDominik Göddeke\n', '\nOleg Iliev\n', '\nOlaf Ippisch\n', '\nJan Mohring\n', '\nSteffen Müthing\n', '\nMario Ohlberger\n', '\nDirk Ribbrock\n', '\nNikolay Shegunov\n', '\nStefan Turek\n']",,,http://arxiv.org/abs/1911.01492v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
TensorTrace: an application to contract tensor networks,http://arxiv.org/abs/1911.02558v1,2019-11-06T18:57:01Z,2019-11-06T18:57:01Z,"  Tensor network methods are a conceptually elegant framework for encoding
complicated datasets, where high-order tensors are approximated as networks of
low-order tensors. In practice, however, the numeric implementation of tensor
network algorithms is often a labor-intensive and error-prone task, even for
experienced researchers in this area. \emph{TensorTrace} is application
designed to alleviate the burden of contracting tensor networks: it provides a
graphic drawing interface specifically tailored for the construction of tensor
network diagrams, from which the code for their optimal contraction can then be
automatically generated (in the users choice of the MATLAB, Python or Julia
languages). \emph{TensorTrace} is freely available at
\url{https://www.tensortrace.com} with versions for Windows, Mac and Ubuntu.
",['\nGlen Evenbly\n'],"5 pages, 5 figures",,http://arxiv.org/abs/1911.02558v1,quant-ph,"['quant-ph', 'cond-mat.str-el', 'cs.MS']",,,[]
"The deal.II finite element library: design, features, and insights",http://arxiv.org/abs/1910.13247v2,2019-10-24T13:40:13Z,2020-02-17T11:06:13Z,"  deal.II is a state-of-the-art finite element library focused on generality,
dimension-independent programming, parallelism, and extensibility. Herein, we
outline its primary design considerations and its sophisticated features such
as distributed meshes, $hp$-adaptivity, support for complex geometries, and
matrix-free algorithms. But deal.II is more than just a software library: It is
also a diverse and worldwide community of developers and users, as well as an
educational platform. We therefore also discuss some of the technical and
social challenges and lessons learned in running a large community software
project over the course of two decades.
","['\nDaniel Arndt\n', '\nWolfgang Bangerth\n', '\nDenis Davydov\n', '\nTimo Heister\n', '\nLuca Heltai\n', '\nMartin Kronbichler\n', '\nMatthias Maier\n', '\nJean-Paul Pelteret\n', '\nBruno Turcksin\n', '\nDavid Wells\n']","36 pages, 3 figures","Computers {\&} Mathematics with Applications, 81: 407--422, 2021",http://dx.doi.org/10.1016/j.camwa.2020.02.022,cs.MS,['cs.MS'],10.1016/j.camwa.2020.02.022,,[]
"Effect of Mixed Precision Computing on H-Matrix Vector Multiplication in
  BEM Analysis",http://arxiv.org/abs/1911.00093v1,2019-10-30T04:07:52Z,2019-10-30T04:07:52Z,"  Hierarchical Matrix (H-matrix) is an approximation technique which splits a
target dense matrix into multiple submatrices, and where a selected portion of
submatrices are low-rank approximated. The technique substantially reduces both
time and space complexity of dense matrix vector multiplication, and hence has
been applied to numerous practical problems.
  In this paper, we aim to accelerate the H-matrix vector multiplication by
introducing mixed precision computing, where we employ both binary64 (FP64) and
binary32 (FP32) arithmetic operations. We propose three methods to introduce
mixed precision computing to H-matrix vector multiplication, and then evaluate
them in a boundary element method (BEM) analysis. The numerical tests examine
the effects of mixed precision computing, particularly on the required
simulation time and rate of convergence of the iterative (BiCG-STAB) linear
solver. We confirm the effectiveness of the proposed methods.
","['\nRise Ooi\n', '\nTakeshi Iwashita\n', '\nTakeshi Fukaya\n', '\nAkihiro Ida\n', '\nRio Yokota\n']","Accepted manuscript to International Conference on High Performance
  Computing in Asia-Pacific Region (HPCAsia2020), January 15--17, 2020,
  Fukuoka, Japan",,http://dx.doi.org/10.1145/3368474.3368479,cs.MS,"['cs.MS', 'cs.DC']",10.1145/3368474.3368479,,[]
"NEP: a module for the parallel solution of nonlinear eigenvalue problems
  in SLEPc",http://arxiv.org/abs/1910.11712v3,2019-10-25T13:28:04Z,2021-01-15T16:46:13Z,"  SLEPc is a parallel library for the solution of various types of large-scale
eigenvalue problems. In the last years we have been developing a module within
SLEPc, called NEP, that is intended for solving nonlinear eigenvalue problems.
These problems can be defined by means of a matrix-valued function that depends
nonlinearly on a single scalar parameter. We do not consider the particular
case of polynomial eigenvalue problems (which are implemented in a different
module in SLEPc) and focus here on rational eigenvalue problems and other
general nonlinear eigenproblems involving square roots or any other nonlinear
function. The paper discusses how the NEP module has been designed to fit the
needs of applications and provides a description of the available solvers,
including some implementation details such as parallelization. Several test
problems coming from real applications are used to evaluate the performance and
reliability of the solvers.
","['\nCarmen Campos\n', '\nJose E. Roman\n']",,"ACM Trans. Math. Software, 47(3), Article 23, 2021",http://dx.doi.org/10.1145/3447544,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1145/3447544,,[]
"An Optimized, Parallel Computation of the Ghost Layer for Adaptive
  Hybrid Forest Meshes",http://arxiv.org/abs/1910.10641v1,2019-10-22T11:54:16Z,2019-10-22T11:54:16Z,"  We discuss parallel algorithms to gather topological information about
off-process mesh neighbor elements. This information is commonly called the
ghost layer, whose creation is a fundamental, necessary task in executing most
parallel, element-based computer simulations. Approaches differ in that the
ghost layer may either be inherently part of the mesh data structure that is
maintained and modified, or kept separate and constructed/deleted as needed.
  In this work, we present an updated design following the latter approach,
which we favor for its modularity of algorithms and data structures. We target
arbitrary adaptive, non-conforming forest-of-(oc)trees meshes of mixed element
shapes, such as cubes, prisms, and tetrahedra, and restrict ourselves to
face-ghosts. Our algorithm has low complexity and redundancy since we reduce it
to generic codimension-1 subalgorithms that can be flexibly combined. We cover
several existing solutions as special cases and optimize further using
recursive, amortized tree searches and traversals.
","['\nJohannes Holke\n', '\nDavid Knapp\n', '\nCarsten Burstedde\n']","33 pages, 12 figures, 13 tables. arXiv admin note: substantial text
  overlap with arXiv:1803.04970",,http://arxiv.org/abs/1910.10641v1,cs.DC,"['cs.DC', 'cs.MS', '65M50, 68W10, 65Y05, 65D18']",,,[]
"Some remarks on the performance of Matlab, Python and Octave in
  simulating dynamical systems",http://arxiv.org/abs/1910.06117v1,2019-10-14T12:59:45Z,2019-10-14T12:59:45Z,"  Matlab has been considered as a leader computational platform for many
engineering fields. Well documented and reliable, Matlab presents as a great
advantage its ability to increase the user productivity. However, Python and
Octave are among some of the languages that have challenged Matlab. Octave and
Python are well known examples of high-level scripting languages, with a great
advantage of being open source software. The novelty of this paper is devoted
to offer a comparison among these tree languages in the simulation of dynamical
systems. We have applied the lower bound error to estimate the error of
simulation. The comparison was performed with the chaotic systems Duffing-Ueda
oscillator and the Chua's circuit, both identified with polynomial NARMAX.
Octave presents the best reliable outcome. Nevertheless, Matlab needs the
lowest time to undertake the same activity. Python has presented the worse
result for the stop simulation criterion.
","['\nP. F. S. Guedes\n', '\nE. G. Nepomuceno\n']","SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro
  Preto. 7 pages",,http://arxiv.org/abs/1910.06117v1,cs.MS,"['cs.MS', 'cs.SY', 'eess.SY']",,,[]
"A user-guide to Gridap -- grid-based approximation of partial
  differential equations in Julia",http://arxiv.org/abs/1910.01412v2,2019-10-03T11:42:32Z,2020-04-22T12:19:57Z,"  We present Gridap, a new scientific software library for the numerical
approximation of partial differential equations (PDEs) using grid-based
approximations. Gridap is an open-source software project exclusively written
in the Julia programming language. The main motivation behind the development
of this library is to provide an easy-to-use framework for the development of
complex PDE solvers in a dynamically typed style without sacrificing the
performance of statically typed languages. This work is a tutorial-driven user
guide to the library. It covers some popular linear and nonlinear PDE systems
for scalar and vector fields, single and multi-field problems, conforming and
nonconforming finite element discretizations, on structured and unstructured
meshes of simplices and hexahedra.
","['\nFrancesc Verdugo\n', '\nSantiago Badia\n']",,,http://arxiv.org/abs/1910.01412v2,cs.MS,['cs.MS'],,,[]
"DBCSR: A Library for Dense Matrix Multiplications on Distributed
  GPU-Accelerated Systems",http://arxiv.org/abs/1910.04796v1,2019-10-10T18:23:26Z,2019-10-10T18:23:26Z,"  Most, if not all the modern scientific simulation packages utilize matrix
algebra operations. Among the operation of the linear algebra, one of the most
important kernels is the multiplication of matrices, dense and sparse. Examples
of application of such a kernel are in electronic structure calculations,
machine learning, data mining, graph processing, and digital signal processing.
Several optimized libraries exist that can achieve high-performance on
distributed systems. Only a few of them target distributed GPU-accelerated
systems. In most of the cases, these libraries are provided and optimized by
system vendors for their specific computer systems. In this paper, we present
the DBCSR library (Distributed Block Compressed Sparse Row) for the distributed
dense matrix-matrix multiplications. Although the library is specifically
designed for block-sparse matrix-matrix multiplications, we optimized it for
the dense case on GPU-accelerated systems. We show that the DBCSR outperforms
the multiplication of matrices of different sizes and shapes provided by a
vendor optimized GPU version of the ScaLAPACK library up to 2.5x (1.4x on
average).
","['\nIlia Sivkov\n', '\nAlfio Lazzaro\n', '\nJuerg Hutter\n']","5 pages, 4 figures, proceeding of the 2019 International
  Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON)",,http://arxiv.org/abs/1910.04796v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Implementing evaluation strategies for continuous real functions,http://arxiv.org/abs/1910.04891v1,2019-10-10T22:05:52Z,2019-10-10T22:05:52Z,"  We give a technical overview of our exact-real implementation of various
representations of the space of continuous unary real functions over the unit
domain and a family of associated (partial) operations, including integration,
range computation, as well as pointwise addition, multiplication, division,
sine, cosine, square root and maximisation.
  We use several representations close to the usual theoretical model, based on
an oracle that evaluates the function at a point or over an interval. We also
include several representations based on an oracle that computes a converging
sequence of rigorous (piecewise or one-piece) polynomial and rational
approximations over the whole unit domain. Finally, we describe ""local""
representations that combine both approaches, i.e. oracle-like representations
that return a rigorous symbolic approximation of the function over a requested
interval sub-domain with a requested effort.
  See also our paper ""Representations and evaluation strategies for feasibly
approximable functions"" which compares the efficiency of these representations
and algorithms and also formally describes and analyses one of the key
algorithms, namely a polynomial-time division of functions in a
piecewise-polynomial representation. We do not reproduce this division
algorithm here.
","['\nMichal Konečný\n', '\nEike Neumann\n']",,,http://arxiv.org/abs/1910.04891v1,cs.LO,"['cs.LO', 'cs.MS']",,,[]
GPU Fast Convolution via the Overlap-and-Save Method in Shared Memory,http://arxiv.org/abs/1910.01972v2,2019-10-04T14:41:10Z,2020-04-10T15:04:13Z,"  We present an implementation of the overlap-and-save method, a method for the
convolution of very long signals with short response functions, which is
tailored to GPUs. We have implemented several FFT algorithms (using the CUDA
programming language) which exploit GPU shared memory, allowing for GPU
accelerated convolution. We compare our implementation with an implementation
of the overlap-and-save algorithm utilizing the NVIDIA FFT library (cuFFT). We
demonstrate that by using a shared memory based FFT we can achieved significant
speed-ups for certain problem sizes and lower the memory requirements of the
overlap-and-save method on GPUs.
","['\nKarel Adámek\n', '\nSofia Dimoudi\n', '\nMike Giles\n', '\nWesley Armour\n']",accepted to ACM TACO,"ACM Trans. Archit. Code Optim. 17, 3, Article 18 (September 2020)",http://dx.doi.org/10.1145/3394116,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF']",10.1145/3394116,,[]
"Distributed-Memory Tensor Completion for Generalized Loss Functions in
  Python using New Sparse Tensor Kernels",http://arxiv.org/abs/1910.02371v3,2019-10-06T04:48:05Z,2021-05-24T22:31:55Z,"  Tensor computations are increasingly prevalent numerical techniques in data
science, but pose unique challenges for high-performance implementation. We
provide novel algorithms and systems infrastructure which enable efficient
parallel implementation of algorithms for tensor completion with generalized
loss functions. Specifically, we consider alternating minimization, coordinate
minimization, and a quasi-Newton (generalized Gauss-Newton) method. By
extending the Cyclops library, we implement all of these methods in high-level
Python syntax. To make possible tensor completion for very sparse tensors, we
introduce new multi-tensor primitives, for which we provide specialized
parallel implementations. We compare these routines to pairwise contraction of
sparse tensors by reduction to hypersparse matrix formats, and find that the
multi-tensor routines are more efficient in theoretical cost and execution time
in experiments. We provide microbenchmarking results on the Stampede2
supercomputer to demonstrate the efficiency of the new primitives and Cyclops
functionality. We then study the performance of the tensor completion methods
for a synthetic tensor with 10 billion nonzeros and the Netflix dataset,
considering both least squares and Poisson loss functions.
","['\nNavjot Singh\n', '\nZecheng Zhang\n', '\nXiaoxiao Wu\n', '\nNaijing Zhang\n', '\nSiyuan Zhang\n', '\nEdgar Solomonik\n']",,,http://arxiv.org/abs/1910.02371v3,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
Optimizing Geometric Multigrid Methods with Evolutionary Computation,http://arxiv.org/abs/1910.02749v2,2019-10-07T12:23:28Z,2019-10-08T08:44:43Z,"  For many linear and nonlinear systems that arise from the discretization of
partial differential equations the construction of an efficient multigrid
solver is a challenging task. Here we present a novel approach for the
optimization of geometric multigrid methods that is based on evolutionary
computation, a generic program optimization technique inspired by the principle
of natural evolution. A multigrid solver is represented as a tree of
mathematical expressions which we generate based on a tailored grammar. The
quality of each solver is evaluated in terms of convergence and compute
performance using automated local Fourier analysis (LFA) and roofline
performance modeling, respectively. Based on these objectives a multi-objective
optimization is performed using strongly typed genetic programming with a
non-dominated sorting based selection. To evaluate the model-based prediction
and to target concrete applications, scalable implementations of an evolved
solver can be automatically generated with the ExaStencils framework. We
demonstrate our approach by constructing multigrid solvers for the steady-state
heat equation with constant and variable coefficients that consistently perform
better than common V- and W-cycles.
","['\nJonas Schmitt\n', '\nSebastian Kuckuk\n', '\nHarald Köstler\n']",,,http://arxiv.org/abs/1910.02749v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'cs.NE']",,,[]
Efficient Stochastic Programming in Julia,http://arxiv.org/abs/1909.10451v3,2019-09-23T16:10:43Z,2021-01-12T20:54:12Z,"  We present StochasticPrograms.jl, a user-friendly and powerful open-source
framework for stochastic programming written in the Julia language. The
framework includes both modeling tools and structure-exploiting optimization
algorithms. Stochastic programming models can be efficiently formulated using
expressive syntax and models can be instantiated, inspected, and analyzed
interactively. The framework scales seamlessly to distributed environments.
Small instances of a model can be run locally to ensure correctness, while
larger instances are automatically distributed in a memory-efficient way onto
supercomputers or clouds and solved using parallel optimization algorithms.
These structure-exploiting solvers are based on variations of the classical
L-shaped and progressive-hedging algorithms. We provide a concise mathematical
background for the various tools and constructs available in the framework,
along with code listings exemplifying their usage. Both software innovations
related to the implementation of the framework and algorithmic innovations
related to the structured solvers are highlighted. We conclude by demonstrating
strong scaling properties of the distributed algorithms on numerical benchmarks
in a multi-node setup.
","['\nMartin Biel\n', '\nMikael Johansson\n']",,,http://dx.doi.org/10.1287/ijoc.2022.1158,math.OC,"['math.OC', 'cs.MS', '90C15, 90C06, 90C90']",10.1287/ijoc.2022.1158,,[]
SUNDIALS Multiphysics+MPIManyVector Performance Testing,http://arxiv.org/abs/1909.12966v1,2019-09-27T21:48:40Z,2019-09-27T21:48:40Z,"  In this report we document performance test results on a SUNDIALS-based
multiphysics demonstration application. We aim to assess the large-scale
parallel performance of new capabilities that have been added to the SUNDIALS
suite of time integrators and nonlinear solvers in recent years under funding
from both the Exascale Computing Project (ECP) and the Scientific Discovery
through Advanced Scientific (SciDAC) program, specifically: (a) SUNDIALS' new
MPIManyVector module, that allows extreme flexibility in how a solution
""vector"" is staged on computational resources, (b) ARKode's new multirate
integration module, MRIStep, allowing high-order accurate calculations that
subcycle ""fast"" processes within ""slow"" ones, (c) SUNDIALS' new flexible linear
solver interfaces, that allow streamlined specification of problem-specific
linear solvers, and (d) SUNDIALS' new N_Vector additions of ""fused"" vector
operations (to increase arithmetic intensity) and separation of reduction
operations into ""local"" and ""global"" versions (to reduce latency by combining
multiple reductions into a single MPI_Allreduce call). We anticipate that
subsequent reports will extend this work to investigate a variety of other new
features, including SUNDIALS' generic SUNNonlinearSolver interface and
accelerator-enabled N_Vector modules, and upcoming MRIStep extensions to
support custom ""fast"" integrators (that leverage problem structure) and IMEX
integration of the ""slow"" time scale (to add diffusion).
","['\nDaniel R. Reynolds\n', '\nDavid J. Gardner\n', '\nCody J. Balos\n', '\nCarol S. Woodward\n']","15 pages, 3 figures",,http://arxiv.org/abs/1909.12966v1,cs.DC,"['cs.DC', 'cs.MS', '65Y05, 65L06, 65M06, 65Y20, 65Z05']",,,[]
The DUNE Framework: Basic Concepts and Recent Developments,http://arxiv.org/abs/1909.13672v3,2019-09-30T13:15:53Z,2020-06-22T16:27:51Z,"  This paper presents the basic concepts and the module structure of the
Distributed and Unified Numerics Environment and reflects on recent
developments and general changes that happened since the release of the first
Dune version in 2007 and the main papers describing that state [1, 2]. This
discussion is accompanied with a description of various advanced features, such
as coupling of domains and cut cells, grid modifications such as adaptation and
moving domains, high order discretizations and node level performance,
non-smooth multigrid methods, and multiscale methods. A brief discussion on
current and future development directions of the framework concludes the paper.
","['\nPeter Bastian\n', '\nMarkus Blatt\n', '\nAndreas Dedner\n', '\nNils-Arne Dreier\n', '\nChristian Engwer\n', '\nRené Fritze\n', '\nCarsten Gräser\n', '\nChristoph Grüninger\n', '\nDominic Kempf\n', '\nRobert Klöfkorn\n', '\nMario Ohlberger\n', '\nOliver Sander\n']","69 pages, 14 figures, 4 tables and various code examples",,http://arxiv.org/abs/1909.13672v3,cs.MS,"['cs.MS', 'cs.DC', '76S05, 68N01']",,,[]
"Multithreaded Filtering Preconditioner for Diffusion Equation on
  Structured Grid",http://arxiv.org/abs/1909.09771v2,2019-09-21T04:15:31Z,2021-09-20T18:25:02Z,"  A parallel and nested version of a frequency filtering preconditioner is
proposed for linear systems corresponding to diffusion equation on a structured
grid. The proposed preconditioner is found to be robust with respect to jumps
in the diffusion coefficients. The storage requirement for the preconditioner
is O(N),where N is number of rows of matrix, hence, a fairly large problem of
size more than 42 million unknowns has been solved on a quad core machine with
64GB RAM. The parallelism is achieved using twisted factorization and SIMD
operations. The preconditioner achieves a speedup of 3.3 times on a quad core
processor clocked at 4.2 GHz, and compared to a well known algebraic multigrid
method, it is significantly faster in both setup and solve times for diffusion
equations with jumps.
","['\nAbhinav Aggarwal\n', '\nShivam Kakkar\n', '\nPawan Kumar\n']",9 pages,,http://arxiv.org/abs/1909.09771v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems,http://arxiv.org/abs/1909.10051v2,2019-09-22T17:34:20Z,2019-11-23T13:58:41Z,"  Fuzzy logic is an accepted and well-developed approach for constructing
verbal models. Fuzzy based methods are getting more popular, while the
engineers deal with more daily life tasks. This paper presents a new Python
toolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing software
tools is an important issue for facilitating the practical use of theoretical
results. There are limited tools for implementing IT2FLSs in Python. The
developed PyIT2FLS is providing a set of tools for fast and easy modeling of
fuzzy systems. This paper includes a brief description of how developed toolkit
can be used. Also, three examples are given showing the usage of the developed
toolkit for simulating IT2FLSs. First, a simple rule-based system is developed
and it's codes are presented in the paper. The second example is the prediction
of the Mackey-Glass chaotic time series using IT2FLS. In this example, the
Particle Swarm Optimization (PSO) algorithm is used for determining system
parameters while minimizing the mean square error. In the last example, an
IT2FPID is designed and used for controlling a linear time-delay system. The
code for the examples are available on toolkit's GitHub page:
\url{https://github.com/Haghrah/PyIT2FLS}. The simulations and their results
confirm the ability of the developed toolkit to be used in a wide range of the
applications.
","['\nAmir Arslan Haghrah\n', '\nSehraneh Ghaemi\n']",,,http://arxiv.org/abs/1909.10051v2,eess.SY,"['eess.SY', 'cs.MS', 'cs.SY']",,,[]
PySPH: a Python-based framework for smoothed particle hydrodynamics,http://arxiv.org/abs/1909.04504v3,2019-09-10T14:11:27Z,2020-12-28T19:31:36Z,"  PySPH is an open-source, Python-based, framework for particle methods in
general and Smoothed Particle Hydrodynamics (SPH) in particular. PySPH allows a
user to define a complete SPH simulation using pure Python. High-performance
code is generated from this high-level Python code and executed on either
multiple cores, or on GPUs, seamlessly. It also supports distributed execution
using MPI. PySPH supports a wide variety of SPH schemes and formulations. These
include, incompressible and compressible fluid flow, elastic dynamics, rigid
body dynamics, shallow water equations, and other problems. PySPH supports a
variety of boundary conditions including mirror, periodic, solid wall, and
inlet/outlet boundary conditions. The package is written to facilitate reuse
and reproducibility. This paper discusses the overall design of PySPH and
demonstrates many of its features. Several example results are shown to
demonstrate the range of features that PySPH provides.
","['\nPrabhu Ramachandran\n', '\nAditya Bhosale\n', '\nKunal Puri\n', '\nPawan Negi\n', '\nAbhinav Muta\n', '\nA Dinesh\n', '\nDileep Menon\n', '\nRahul Govind\n', '\nSuraj Sanka\n', '\nAmal S Sebastian\n', '\nAnanyo Sen\n', '\nRohan Kaushik\n', '\nAnshuman Kumar\n', '\nVikas Kurapati\n', '\nMrinalgouda Patil\n', '\nDeep Tavker\n', '\nPankaj Pandey\n', '\nChandrashekhar Kaushik\n', '\nArkopal Dutt\n', '\nArpit Agarwal\n']","39 pages, 19 figures","ACM Transactions on Mathematical Software, volume 47, number 4,
  article 34, July 2021",http://dx.doi.org/10.1145/3460773,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1145/3460773,,[]
"DuMu$^\text{x}$ 3 -- an open-source simulator for solving flow and
  transport problems in porous media with a focus on model coupling",http://arxiv.org/abs/1909.05052v1,2019-09-11T13:48:47Z,2019-09-11T13:48:47Z,"  We present version 3 of the open-source simulator for flow and transport
processes in porous media DuMu$^\text{x}$. DuMu$^\text{x}$ is based on the
modular C++ framework Dune (Distributed and Unified Numerics Environment) and
is developed as a research code with a focus on modularity and reusability. We
describe recent efforts in improving the transparency and efficiency of the
development process and community-building, as well as efforts towards quality
assurance and reproducible research. In addition to a major redesign of many
simulation components in order to facilitate setting up complex simulations in
DuMu$^\text{x}$, version 3 introduces a more consistent abstraction of finite
volume schemes. Finally, the new framework for multi-domain simulations is
described, and three numerical examples demonstrate its flexibility.
","['\nTimo Koch\n', '\nDennis Gläser\n', '\nKilian Weishaupt\n', '\nSina Ackermann\n', '\nMartin Beck\n', '\nBeatrix Becker\n', '\nSamuel Burbulla\n', '\nHolger Class\n', '\nEdward Coltman\n', '\nSimon Emmert\n', '\nThomas Fetzer\n', '\nChristoph Grüninger\n', '\nKatharina Heck\n', '\nJohannes Hommel\n', '\nTheresa Kurz\n', '\nMelanie Lipp\n', '\nFarid Mohammadi\n', '\nSamuel Scherrer\n', '\nMartin Schneider\n', '\nGabriele Seitz\n', '\nLeopold Stadler\n', '\nMartin Utz\n', '\nFelix Weinhardt\n', '\nBernd Flemisch\n']",,,http://dx.doi.org/10.1016/j.camwa.2020.02.012,cs.CE,"['cs.CE', 'cs.MS', '97N80']",10.1016/j.camwa.2020.02.012,,[]
"PittPack: An Open-Source Poisson's Equation Solver for Extreme-Scale
  Computing with Accelerators",http://arxiv.org/abs/1909.05423v1,2019-09-12T01:15:30Z,2019-09-12T01:15:30Z,"  We present a parallel implementation of a direct solver for the Poisson's
equation on extreme-scale supercomputers with accelerators. We introduce a
chunked-pencil decomposition as the domain-decomposition strategy to distribute
work among processing elements to achieve superior scalability at large number
of accelerators. Chunked-pencil decomposition enables overlapping nodal
communication and data transfer between the central processing units (CPUs) and
the graphics processing units (GPUs). Second, it improves data locality by
keeping neighboring elements in adjacent memory locations. Third, it allows
usage of shared-memory for certain segments of the algorithm when possible, and
last but not least, it enables contiguous message transfer among the nodes. Two
different communication patterns are designed. The fist pattern aims to fully
overlap the communication with data transfer and designed for speedup of
overall turnaround time, whereas the second method concentrates on low memory
usage and is more network friendly for computations at extreme scale. To ensure
software portability, we interleave OpenACC with MPI in the software. The
numerical solution and its formal second order of accuracy is verified using
method of manufactured solutions for various combinations of boundary
conditions. Weak scaling analysis is performed using up to 1.1 trillion
Cartesian mesh points using 16384 GPUs on a petascale leadership class
supercomputer.
","['\nJaber J. Hasbestan\n', '\nInanc Senocak\n']","41 pages, 18 figures, 3 listings",,http://dx.doi.org/10.1016/j.cpc.2020.107272,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1016/j.cpc.2020.107272,,[]
"A Low-Memory Time-Efficient Implementation of Outermorphisms for
  Higher-Dimensional Geometric Algebras",http://arxiv.org/abs/1909.02408v1,2019-09-05T13:43:32Z,2019-09-05T13:43:32Z,"  From the beginning of David Hestenes rediscovery of geometric algebra in the
1960s, outermorphisms have been a cornerstone in the mathematical development
of GA. Many important mathematical formulations in GA can be expressed as
outermorphisms such as versor products, linear projection operators, and
mapping between related coordinate frames. Over the last two decades, GA-based
mathematical models and software implementations have been developed in many
fields of science and engineering. As such, efficient implementations of
outermorphisms are of significant importance within this context. This work
attempts to shed some light on the problem of optimizing software
implementations of outermorphisms for practical prototyping applications using
geometric algebra. The approach we propose here for implementing outermorphisms
requires orders of magnitude less memory compared to other common approaches,
while being comparable in time performance, especially for high-dimensional
geometric algebras.
",['\nAhmad Hosny Eid\n'],,,http://arxiv.org/abs/1909.02408v1,cs.MS,['cs.MS'],,,[]
"Computing Derivatives for PETSc Adjoint Solvers using Algorithmic
  Differentiation",http://arxiv.org/abs/1909.02836v1,2019-09-06T11:53:02Z,2019-09-06T11:53:02Z,"  Most nonlinear partial differential equation (PDE) solvers require the
Jacobian matrix associated to the differential operator. In PETSc, this is
typically achieved by either an analytic derivation or numerical approximation
method such as finite differences. For complex applications, hand-coding the
Jacobian can be time-consuming and error-prone, yet computationally efficient.
Whilst finite difference approximations are straight-forward to implement, they
have high arithmetic complexity and low accuracy. Alternatively, one may
compute Jacobians using algorithmic differentiation (AD), yielding the same
derivatives as an analytic derivation, with the added benefit that the
implementation is problem independent. In this work, the operator overloading
AD tool ADOL-C is applied to generate Jacobians for time-dependent, nonlinear
PDEs and their adjoints. Various strategies are considered, including
compressed and matrix-free approaches. In numerical experiments with a 2D
diffusion-reaction model, the performance of these strategies has been studied
and compared to the hand-derived version.
","['\nJ. G. Wallwork\n', '\nP. Hovland\n', '\nH. Zhang\n', '\nO. Marin\n']","14 pages, 3 figures, 2 listings, 1 table",,http://arxiv.org/abs/1909.02836v1,cs.MS,"['cs.MS', '68U01']",,,[]
"The surrogate matrix methodology: A reference implementation for
  low-cost assembly in isogeometric analysis",http://arxiv.org/abs/1909.04029v1,2019-09-08T06:42:21Z,2019-09-08T06:42:21Z,"  A reference implementation of a new method in isogeometric analysis (IGA) is
presented. It delivers low-cost variable-scale approximations (surrogates) of
the matrices which IGA conventionally requires to be computed by element-scale
quadrature. To generate surrogate matrices, quadrature must only be performed
on a fraction of the elements in the computational domain. In this way,
quadrature determines only a subset of the entries in the final matrix. The
remaining matrix entries are computed by a simple B-spline interpolation
procedure. We present the modifications and extensions required for a reference
implementation in the open-source IGA software library GeoPDEs. The exposition
is fashioned to help facilitate similar modifications in other contemporary
software libraries.
","['\nDaniel Drzisga\n', '\nBrendan Keith\n', '\nBarbara Wohlmuth\n']",,"MethodsX, 7:100813 (2020)",http://dx.doi.org/10.1016/j.mex.2020.100813,cs.MS,['cs.MS'],10.1016/j.mex.2020.100813,,[]
Implicit Hari--Zimmermann algorithm for the generalized SVD on the GPUs,http://arxiv.org/abs/1909.00101v3,2019-08-31T00:52:09Z,2020-10-13T22:28:39Z,"  A parallel, blocked, one-sided Hari--Zimmermann algorithm for the generalized
singular value decomposition (GSVD) of a real or a complex matrix pair $(F,G)$
is here proposed, where $F$ and $G$ have the same number of columns, and are
both of the full column rank. The algorithm targets either a single graphics
processing unit (GPU), or a cluster of those, performs all non-trivial
computation exclusively on the GPUs, requires the minimal amount of memory to
be reasonably expected, scales acceptably with the increase of the number of
GPUs available, and guarantees the reproducible, bitwise identical output of
the runs repeated over the same input and with the same number of GPUs.
","['\nVedran Novaković\n', '\nSanja Singer\n']","A minor revision of the revised submission, with the supplementary
  material attached","Int. J. High Perform. Comput. Appl. 35 (2021), 2; 170-205",http://dx.doi.org/10.1177/1094342020972772,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F15, 65F25, 65Y05, 65Y10']",10.1177/1094342020972772,,[]
PLANC: Parallel Low Rank Approximation with Non-negativity Constraints,http://arxiv.org/abs/1909.01149v1,2019-08-30T15:09:53Z,2019-08-30T15:09:53Z,"  We consider the problem of low-rank approximation of massive dense
non-negative tensor data, for example to discover latent patterns in video and
imaging applications. As the size of data sets grows, single workstations are
hitting bottlenecks in both computation time and available memory. We propose a
distributed-memory parallel computing solution to handle massive data sets,
loading the input data across the memories of multiple nodes and performing
efficient and scalable parallel algorithms to compute the low-rank
approximation. We present a software package called PLANC (Parallel Low Rank
Approximation with Non-negativity Constraints), which implements our solution
and allows for extension in terms of data (dense or sparse, matrices or tensors
of any order), algorithm (e.g., from multiplicative updating techniques to
alternating direction method of multipliers), and architecture (we exploit GPUs
to accelerate the computation in this work).We describe our parallel
distributions and algorithms, which are careful to avoid unnecessary
communication and computation, show how to extend the software to include new
algorithms and/or constraints, and report efficiency and scalability results
for both synthetic and real-world data sets.
","['\nSrinivas Eswar\n', '\nKoby Hayashi\n', '\nGrey Ballard\n', '\nRamakrishnan Kannan\n', '\nMichael A. Matheson\n', '\nHaesun Park\n']",arXiv admin note: text overlap with arXiv:1806.07985,,http://arxiv.org/abs/1909.01149v1,math.NA,"['math.NA', 'cs.DC', 'cs.MS', 'cs.NA']",,,[]
OpenMP parallelization of multiple precision Taylor series method,http://arxiv.org/abs/1908.09301v1,2019-08-25T11:21:56Z,2019-08-25T11:21:56Z,"  OpenMP parallelization of multiple precision Taylor series method is
proposed. A very good parallel performance scalability and parallel efficiency
inside one computation node of a CPU-cluster is observed. We explain the
details of the parallelization on the classical example of the Lorentz
equations. The same approach can be applied straightforwardly to a large class
of chaotic dynamical systems.
","['\nS. Dimova\n', '\nI. Hristov\n', '\nR. Hristova\n', '\nI. Puzynin\n', '\nT. Puzynina\n', '\nZ. Sharipov\n', '\nN. Shegunov\n', '\nZ. Tukhliev\n']","8 pages, 3 figures",,http://arxiv.org/abs/1908.09301v1,cs.MS,"['cs.MS', 'math.DS']",,,[]
High Performance Block Incomplete LU Factorization,http://arxiv.org/abs/1908.10169v1,2019-08-27T12:54:20Z,2019-08-27T12:54:20Z,"  Many application problems that lead to solving linear systems make use of
preconditioned Krylov subspace solvers to compute their solution. Among the
most popular preconditioning approaches are incomplete factorization methods
either as single-level approaches or within a multilevel framework. We will
present a block incomplete factorization that is based on skillfully blocking
the system initially and throughout the factorization. This approach allows for
the use of cache-optimized dense matrix kernels such as level-3 BLAS or LAPACK.
We will demonstrate how this block approach outperforms the scalar method often
by orders of magnitude on modern architectures, paving the way for its
prospective use inside various multilevel incomplete factorization approaches
or other applications where the core part relies on an incomplete
factorization.
","['\nMatthias Bollhöfer\n', '\nOlaf Schenk\n', '\nFabio Verbosio\n']",,,http://arxiv.org/abs/1908.10169v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"SODECL: An Open Source Library for Calculating Multiple Orbits of a
  System of Stochastic Differential Equations in Parallel",http://arxiv.org/abs/1908.03869v2,2019-08-11T08:28:55Z,2020-02-17T19:38:33Z,"  Stochastic differential equations (SDEs) are widely used to model systems
affected by random processes. In general, the analysis of an SDE model requires
numerical solutions to be generated many times over multiple parameter
combinations. However, this process often requires considerable computational
resources to be practicable. Due to the embarrassingly parallel nature of the
task, devices such as multi-core processors and graphics processing units
(GPUs) can be employed for acceleration.
  Here, we present {\bf SODECL} (\url{https://github.com/avramidis/sodecl}), a
software library that utilises such devices to calculate multiple orbits of an
SDE model. To evaluate the acceleration provided by SODECL, we compared the
time required to calculate multiple orbits of an exemplar stochastic model when
one CPU core is used, to the time required when using all CPU cores or a GPU.
In addition, to assess scalability, we investigated how the model size affected
execution time on different parallel compute devices.
  Our results show that when using all 32 CPU cores of a high-end
high-performance computing node, the task is accelerated by a factor of up to
$\simeq$6.7, compared to when using a single CPU core. Executing the task on a
high-end GPU yielded accelerations of up to $\simeq$4.5, compared to a single
CPU core.
","['\nEleftherios Avramidis\n', '\nMarta Lalik\n', '\nOzgur E. Akman\n']","19 pages, 11 figures, 13 tables",,http://arxiv.org/abs/1908.03869v2,cs.MS,['cs.MS'],,,[]
ArborX: A Performance Portable Geometric Search Library,http://arxiv.org/abs/1908.11807v2,2019-08-16T18:17:32Z,2020-06-18T16:10:40Z,"  Searching for geometric objects that are close in space is a fundamental
component of many applications. The performance of search algorithms comes to
the forefront as the size of a problem increases both in terms of total object
count as well as in the total number of search queries performed. Scientific
applications requiring modern leadership-class supercomputers also pose an
additional requirement of performance portability, i.e. being able to
efficiently utilize a variety of hardware architectures. In this paper, we
introduce a new open-source C++ search library, ArborX, which we have designed
for modern supercomputing architectures. We examine scalable search algorithms
with a focus on performance, including a highly efficient parallel bounding
volume hierarchy implementation, and propose a flexible interface making it
easy to integrate with existing applications. We demonstrate the performance
portability of ArborX on multi-core CPUs and GPUs, and compare it to the
state-of-the-art libraries such as Boost.Geometry.Index and nanoflann.
","['\nD. Lebrun-Grandié\n', '\nA. Prokopenko\n', '\nB. Turcksin\n', '\nS. R. Slattery\n']",,,http://dx.doi.org/10.1145/3412558,cs.DC,"['cs.DC', 'cs.MS']",10.1145/3412558,,[]
"Open Traffic Models -- A framework for hybrid simulation of
  transportation networks",http://arxiv.org/abs/1908.04009v1,2019-08-12T05:46:21Z,2019-08-12T05:46:21Z,"  This paper introduces a new approach to hybrid traffic modeling, along with
its implementation in software. The software allows modelers to assign traffic
models to individual links in a network. Each model implements a series of
methods, refered to as the modeling interface. These methods are used by the
program to exchange information between adjacent models. Traffic controllers
are implemented in a similar manner. The paper outlines the important
components of the method: the network description, the description of demands,
and the modeling and control interfaces. We include tests demonstrating the
propagation of congestion between pairs of macroscpoic, mesoscopic, and
microscopic models. Open Traffic Models is an open source implementation of
these concepts, and is available at https://github.com/ggomes/otm-sim.
",['\nGabriel Gomes\n'],,,http://arxiv.org/abs/1908.04009v1,cs.MS,"['cs.MS', 'cs.SY', 'eess.SY']",,,[]
"A tutorial-driven introduction to the parallel finite element library
  FEMPAR v1.0.0",http://arxiv.org/abs/1908.00891v1,2019-08-02T14:45:02Z,2019-08-02T14:45:02Z,"  This work is a user guide to the FEMPAR scientific software library. FEMPAR
is an open-source object-oriented framework for the simulation of partial
differential equations (PDEs) using finite element methods on
distributed-memory platforms. It provides a rich set of tools for numerical
discretization and built-in scalable solvers for the resulting linear systems
of equations. An application expert that wants to simulate a PDE-governed
problem has to extend the framework with a description of the weak form of the
PDE at hand (and additional perturbation terms for non-conforming
approximations). We show how to use the library by going through three
different tutorials. The first tutorial simulates a linear PDE (Poisson
equation) in a serial environment for a structured mesh using both continuous
and discontinuous Galerkin finite element methods. The second tutorial extends
it with adaptive mesh refinement on octree meshes. The third tutorial is a
distributed-memory version of the previous one that combines a scalable octree
handler and a scalable domain decomposition solver. The exposition is
restricted to linear PDEs and simple geometries to keep it concise. The
interested user can dive into more tutorials available in the FEMPAR public
repository to learn about further capabilities of the library, e.g., nonlinear
PDEs and nonlinear solvers, time integration, multi-field PDEs, block
preconditioning, or unstructured mesh handling.
","['\nSantiago Badia\n', '\nAlberto F. Martín\n']",,,http://dx.doi.org/10.1016/j.cpc.2019.107059,cs.MS,['cs.MS'],10.1016/j.cpc.2019.107059,,[]
PyLops -- A Linear-Operator Python Library for large scale optimization,http://arxiv.org/abs/1907.12349v1,2019-07-29T11:53:46Z,2019-07-29T11:53:46Z,"  Linear operators and optimisation are at the core of many algorithms used in
signal and image processing, remote sensing, and inverse problems. For small to
medium-scale problems, existing software packages (e.g., MATLAB, Python numpy
and scipy) allow for explicitly building dense (or sparse) matrices and
performing algebraic operations (e.g., computation of matrix-vector products
and manipulation of matrices) with syntax that closely represents their
corresponding analytical forms. However, many real application, large-scale
operators do not lend themselves to explicit matrix representations, usually
forcing practitioners to forego of the convenient linear-algebra syntax
available for their explicit-matrix counterparts. PyLops is an open-source
Python library providing a flexible and scalable framework for the creation and
combination of so-called linear operators, class-based entities that represent
matrices and inherit their associated syntax convenience, but do not rely on
the creation of explicit matrices. We show that PyLops operators can
dramatically reduce the memory load and CPU computations compared to
explicit-matrix calculations, while still allowing users to seamlessly use
their existing knowledge of compact matrix-based syntax that scales to any
problem size because no explicit matrices are required.
","['\nMatteo Ravasi\n', '\nIvan Vasconcelos\n']",,,http://arxiv.org/abs/1907.12349v1,cs.MS,['cs.MS'],,,[]
"Characteristics-based Simulink implementation of first-order quasilinear
  partial differential equations",http://arxiv.org/abs/1907.13419v2,2019-07-31T11:18:54Z,2020-04-23T15:46:33Z,"  The paper deals with solving first-order quasilinear partial differential
equations in an online simulation environment, such as Simulink, utilizing the
well-known and well-recommended method of characteristics. Compared to the
commonly applied space discretization methods on static grids, the
characteristics-based approach provides better numerical stability. Simulink
subsystem implementing the method of characteristics is developed. It employs
Simulink's built-in solver and its zero-crossing detection algorithm to perform
simultaneous integration of a pool of characteristics as well as to create new
characteristics dynamically and discard the old ones. Numerical accuracy of the
solution thus obtained is established. The subsystem has been tested on a
full-state feedback example and produced better results than the space
discretization-based ""method of lines"". The implementation is available for
download and can be used in a wide range of models.
","['\nAnton Ponomarev\n', '\nJulian Hofmann\n', '\nLutz Gröll\n']",Abridged and updated conference version. Accepted to SIMULTECH 2020,,http://dx.doi.org/10.5220/0009569001390146,cs.MS,['cs.MS'],10.5220/0009569001390146,,[]
"GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on
  the GPU",http://arxiv.org/abs/1908.01407v5,2019-08-04T21:54:05Z,2021-06-15T03:29:49Z,"  High-performance implementations of graph algorithms are challenging to
implement on new parallel hardware such as GPUs because of three challenges:
(1) the difficulty of coming up with graph building blocks, (2) load imbalance
on parallel hardware, and (3) graph problems having low arithmetic intensity.
To address some of these challenges, GraphBLAS is an innovative, on-going
effort by the graph analytics community to propose building blocks based on
sparse linear algebra, which will allow graph algorithms to be expressed in a
performant, succinct, composable and portable manner. In this paper, we examine
the performance challenges of a linear-algebra-based approach to building graph
frameworks and describe new design principles for overcoming these bottlenecks.
Among the new design principles is exploiting input sparsity, which allows
users to write graph algorithms without specifying push and pull direction.
Exploiting output sparsity allows users to tell the backend which values of the
output in a single vectorized computation they do not want computed.
Load-balancing is an important feature for balancing work amongst parallel
workers. We describe the important load-balancing features for handling graphs
with different characteristics. The design principles described in this paper
have been implemented in ""GraphBLAST"", the first high-performance linear
algebra-based graph framework on NVIDIA GPUs that is open-source. The results
show that on a single GPU, GraphBLAST has on average at least an order of
magnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL,
comparable performance to the fastest GPU hardwired primitives and
shared-memory graph frameworks Ligra and Gunrock, and better performance than
any other GPU graph framework, while offering a simpler and more concise
programming model.
","['\nCarl Yang\n', '\nAydin Buluc\n', '\nJohn D. Owens\n']","50 pages, 14 figures, 14 tables, to appear in ACM Transactions on
  Mathematical Software",,http://arxiv.org/abs/1908.01407v5,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Testing performance with and without Block Low Rank Compression in MUMPS
  and the new PaStiX 6.0 for JOREK nonlinear MHD simulations",http://arxiv.org/abs/1907.13442v1,2019-07-31T12:16:19Z,2019-07-31T12:16:19Z,"  The interface to the MUMPS solver was updated in the JOREK MHD code to
support Block Low Rank (BLR) compression and an interface to the new PaStiX
solver version 6 has been implemented supporting BLR as well. First tests were
carried out with JOREK, which solves a large sparse matrix system iteratively
in each time step. For the preconditioning, a direct solver is applied in the
code to sub-matrices, and at this point BLR was applied with the results being
summarized in this report. For a simple case with a linearly growing mode,
results with both solvers look promising with a considerable reduction of the
memory consumption by several ten percent was obtained. A direct increase in
performance was seen in particular configurations already.
  The choice of the BLR accuracy parameter $\epsilon$ proves to be critical in
this simple test and also in more realistic simulations, which were carried out
only with MUMPS due to the limited time available. The more realistic test
showed an increase in run time when using BLR, which was mitigated when using
larger values of $\epsilon$. However, the GMRes iterative solver does not reach
convergence anymore when $\epsilon$ is too large, since the preconditioner
becomes too inaccurate in that case. It is thus critical to use an $\epsilon$
as large as possible, while still reaching convergence. More tests regarding
this optimum will be necessary in the future. BLR can also lead to an indirect
speed-up in particular cases, when the simulation can be run on a smaller
number of compute nodes due to the reduced memory consumption.
","['\nRichard Nies\n', '\nMatthias Hoelzl\n']","21 pages, 14 figures",,http://arxiv.org/abs/1907.13442v1,cs.PF,"['cs.PF', 'cs.MS', '65F50']",,,[]
"pySOT and POAP: An event-driven asynchronous framework for surrogate
  optimization",http://arxiv.org/abs/1908.00420v1,2019-07-30T18:06:18Z,2019-07-30T18:06:18Z,"  This paper describes Plumbing for Optimization with Asynchronous Parallelism
(POAP) and the Python Surrogate Optimization Toolbox (pySOT). POAP is an
event-driven framework for building and combining asynchronous optimization
strategies, designed for global optimization of expensive functions where
concurrent function evaluations are useful. POAP consists of three components:
a worker pool capable of function evaluations, strategies to propose
evaluations or other actions, and a controller that mediates the interaction
between the workers and strategies. pySOT is a collection of synchronous and
asynchronous surrogate optimization strategies, implemented in the POAP
framework. We support the stochastic RBF method by Regis and Shoemaker along
with various extensions of this method, and a general surrogate optimization
strategy that covers most Bayesian optimization methods. We have implemented
many different surrogate models, experimental designs, acquisition functions,
and a large set of test problems. We make an extensive comparison between
synchronous and asynchronous parallelism and find that the advantage of
asynchronous computation increases as the variance of the evaluation time or
number of processors increases. We observe a close to linear speed-up with 4,
8, and 16 processors in both the synchronous and asynchronous setting.
","['\nDavid Eriksson\n', '\nDavid Bindel\n', '\nChristine A. Shoemaker\n']",,,http://arxiv.org/abs/1908.00420v1,math.OC,"['math.OC', 'cs.LG', 'cs.MS', 'stat.ML']",,,[]
Semi-Lagrangian Vlasov simulation on GPUs,http://arxiv.org/abs/1907.08316v2,2019-07-18T23:26:49Z,2020-03-17T14:11:02Z,"  In this paper, our goal is to efficiently solve the Vlasov equation on GPUs.
A semi-Lagrangian discontinuous Galerkin scheme is used for the discretization.
Such kinetic computations are extremely expensive due to the high-dimensional
phase space. The SLDG code, which is publicly available under the MIT license
abstracts the number of dimensions and uses a shared codebase for both GPU and
CPU based simulations. We investigate the performance of the implementation on
a range of both Tesla (V100, Titan V, K80) and consumer (GTX 1080 Ti) GPUs. Our
implementation is typically able to achieve a performance of approximately 470
GB/s on a single GPU and 1600 GB/s on four V100 GPUs connected via NVLink. This
results in a speedup of about a factor of ten (comparing a single GPU with a
dual socket Intel Xeon Gold node) and approximately a factor of 35 (comparing a
single node with and without GPUs). In addition, we investigate the effect of
single precision computation on the performance of the SLDG code and
demonstrate that a template based dimension independent implementation can
achieve good performance regardless of the dimensionality of the problem.
",['\nLukas Einkemmer\n'],,,http://dx.doi.org/10.1016/j.cpc.2020.107351,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1016/j.cpc.2020.107351,,[]
"Distributions.jl: Definition and Modeling of Probability Distributions
  in the JuliaStats Ecosystem",http://arxiv.org/abs/1907.08611v3,2019-07-19T17:59:56Z,2021-07-12T09:30:49Z,"  Random variables and their distributions are a central part in many areas of
statistical methods. The Distributions.jl package provides Julia users and
developers tools for working with probability distributions, leveraging Julia
features for their intuitive and flexible manipulation, while remaining highly
efficient through zero-cost abstractions.
","['\nMathieu Besançon\n', '\nTheodore Papamarkou\n', '\nDavid Anthoff\n', '\nAlex Arslan\n', '\nSimon Byrne\n', '\nDahua Lin\n', '\nJohn Pearson\n']",,,http://dx.doi.org/10.18637/jss.v098.i16,stat.CO,"['stat.CO', 'cs.MS']",10.18637/jss.v098.i16,,[]
"A Hermite-like basis for faster matrix-free evaluation of interior
  penalty discontinuous Galerkin operators",http://arxiv.org/abs/1907.08492v1,2019-07-19T12:52:49Z,2019-07-19T12:52:49Z,"  This work proposes a basis for improved throughput of matrix-free evaluation
of discontinuous Galerkin symmetric interior penalty discretizations on
hexahedral elements. The basis relies on ideas of Hermite polynomials. It is
used in a fully discontinuous setting not for higher order continuity but to
minimize the effective stencil width, namely to limit the neighbor access of an
element to one data point for the function value and one for the derivative.
The basis is extended to higher orders with nodal contributions derived from
roots of Jacobi polynomials and extended to multiple dimensions with tensor
products, which enable the use of sum factorization. The beneficial effect of
the reduced data access on modern processors is shown. Furthermore, the
viability of the basis in the context of multigrid solvers is analyzed. While a
plain point-Jacobi approach is less efficient than with the best nodal
polynomials, a basis change via sum-factorization techniques enables the
combination of the fast matrix-vector products with effective multigrid
constituents. The basis change is essentially for free on modern hardware
because these computations can be hidden behind the cost of the data access.
","['\nMartin Kronbichler\n', '\nKatharina Kormann\n', '\nNiklas Fehn\n', '\nPeter Munch\n', '\nJulius Witte\n']","20 pages, 8 figures",,http://arxiv.org/abs/1907.08492v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'cs.PF']",,,[]
"The LAPW method with eigendecomposition based on the Hari--Zimmermann
  generalized hyperbolic SVD",http://arxiv.org/abs/1907.08560v2,2019-07-19T16:13:30Z,2020-06-22T17:43:28Z,"  In this paper we propose an accurate, highly parallel algorithm for the
generalized eigendecomposition of a matrix pair $(H, S)$, given in a factored
form $(F^{\ast} J F, G^{\ast} G)$. Matrices $H$ and $S$ are generally complex
and Hermitian, and $S$ is positive definite. This type of matrices emerges from
the representation of the Hamiltonian of a quantum mechanical system in terms
of an overcomplete set of basis functions. This expansion is part of a class of
models within the broad field of Density Functional Theory, which is considered
the golden standard in condensed matter physics. The overall algorithm consists
of four phases, the second and the fourth being optional, where the two last
phases are computation of the generalized hyperbolic SVD of a complex matrix
pair $(F,G)$, according to a given matrix $J$ defining the hyperbolic scalar
product. If $J = I$, then these two phases compute the GSVD in parallel very
accurately and efficiently.
","['\nSanja Singer\n', '\nEdoardo Di Napoli\n', '\nVedran Novaković\n', '\nGayatri Čaklović\n']","The supplementary material is available at
  https://web.math.pmf.unizg.hr/mfbda/papers/sm-SISC.pdf due to its size. This
  revised manuscript is currently being considered for publication","SIAM J. Sci. Comput. 42 (2020), C265-C293",http://dx.doi.org/10.1137/19M1277813,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F15, 65F25, 65Y05, 65Z05']",10.1137/19M1277813,,[]
SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python,http://arxiv.org/abs/1907.10121v1,2019-07-23T20:31:36Z,2019-07-23T20:31:36Z,"  SciPy is an open source scientific computing library for the Python
programming language. SciPy 1.0 was released in late 2017, about 16 years after
the original version 0.1 release. SciPy has become a de facto standard for
leveraging scientific algorithms in the Python programming language, with more
than 600 unique code contributors, thousands of dependent packages, over
100,000 dependent repositories, and millions of downloads per year. This
includes usage of SciPy in almost half of all machine learning projects on
GitHub, and usage by high profile projects including LIGO gravitational wave
analysis and creation of the first-ever image of a black hole (M87). The
library includes functionality spanning clustering, Fourier transforms,
integration, interpolation, file I/O, linear algebra, image processing,
orthogonal distance regression, minimization algorithms, signal processing,
sparse matrix handling, computational geometry, and statistics. In this work,
we provide an overview of the capabilities and development practices of the
SciPy library and highlight some recent technical developments.
","['\nPauli Virtanen\n', '\nRalf Gommers\n', '\nTravis E. Oliphant\n', '\nMatt Haberland\n', '\nTyler Reddy\n', '\nDavid Cournapeau\n', '\nEvgeni Burovski\n', '\nPearu Peterson\n', '\nWarren Weckesser\n', '\nJonathan Bright\n', '\nStéfan J. van der Walt\n', '\nMatthew Brett\n', '\nJoshua Wilson\n', '\nK. Jarrod Millman\n', '\nNikolay Mayorov\n', '\nAndrew R. J. Nelson\n', '\nEric Jones\n', '\nRobert Kern\n', '\nEric Larson\n', '\nCJ Carey\n', '\nİlhan Polat\n', '\nYu Feng\n', '\nEric W. Moore\n', '\nJake VanderPlas\n', '\nDenis Laxalde\n', '\nJosef Perktold\n', '\nRobert Cimrman\n', '\nIan Henriksen\n', '\nE. A. Quintero\n', '\nCharles R Harris\n', '\nAnne M. Archibald\n', '\nAntônio H. Ribeiro\n', '\nFabian Pedregosa\n', '\nPaul van Mulbregt\n', '\nSciPy 1. 0 Contributors\n']","Article source data is available here:
  https://github.com/scipy/scipy-articles","Nature Methods 17, 261 (2020)",http://dx.doi.org/10.1038/s41592-019-0686-2,cs.MS,"['cs.MS', 'cs.DS', 'cs.SE', 'physics.comp-ph']",10.1038/s41592-019-0686-2,,[]
Unveiling patterns in xorshift128+ pseudorandom number generators,http://arxiv.org/abs/1907.03251v3,2019-07-07T08:40:33Z,2021-08-24T12:36:01Z,"  Xorshift128+ is a newly proposed pseudorandom number generator (PRNG), which
is now the standard PRNG on a number of platforms. We demonstrate that
three-dimensional plots of the random points generated by the generator have
visible structures: they concentrate on particular planes in the cube. We
provide a mathematical analysis of this phenomenon.
","['\nHiroshi Haramoto\n', '\nMakoto Matsumoto\n', '\nMutsuo Saito\n']",,,http://arxiv.org/abs/1907.03251v3,cs.MS,"['cs.MS', '65C10']",,,[]
Optimizing Xeon Phi for Interactive Data Analysis,http://arxiv.org/abs/1907.03195v1,2019-07-06T22:04:25Z,2019-07-06T22:04:25Z,"  The Intel Xeon Phi manycore processor is designed to provide high performance
matrix computations of the type often performed in data analysis. Common data
analysis environments include Matlab, GNU Octave, Julia, Python, and R.
Achieving optimal performance of matrix operations within data analysis
environments requires tuning the Xeon Phi OpenMP settings, process pinning, and
memory modes. This paper describes matrix multiplication performance results
for Matlab and GNU Octave over a variety of combinations of process counts and
OpenMP threads and Xeon Phi memory modes. These results indicate that using
KMP_AFFINITY=granlarity=fine, taskset pinning, and all2all cache memory mode
allows both Matlab and GNU Octave to achieve 66% of the practical peak
performance for process counts ranging from 1 to 64 and OpenMP threads ranging
from 1 to 64. These settings have resulted in generally improved performance
across a range of applications and has enabled our Xeon Phi system to deliver
significant results in a number of real-world applications.
","['\nChansup Byun\n', '\nJeremy Kepner\n', '\nWilliam Arcand\n', '\nDavid Bestor\n', '\nWilliam Bergeron\n', '\nMatthew Hubbell\n', '\nVijay Gadepally\n', '\nMichael Houle\n', '\nMichael Jones\n', '\nAnne Klein\n', '\nLauren Milechin\n', '\nPeter Michaleas\n', '\nJulie Mullen\n', '\nAndrew Prout\n', '\nAntonio Rosa\n', '\nSiddharth Samsi\n', '\nCharles Yee\n', '\nAlbert Reuther\n']","6 pages, 5 figures, accepted in IEEE High Performance Extreme
  Computing (HPEC) conference 2019",,http://dx.doi.org/10.1109/HPEC.2019.8916300,cs.PF,"['cs.PF', 'cs.DC', 'cs.MS']",10.1109/HPEC.2019.8916300,,[]
"A generic finite element framework on parallel tree-based adaptive
  meshes",http://arxiv.org/abs/1907.03709v2,2019-07-08T16:30:39Z,2020-04-09T15:06:02Z,"  In this work we formally derive and prove the correctness of the algorithms
and data structures in a parallel, distributed-memory, generic finite element
framework that supports h-adaptivity on computational domains represented as
forest-of-trees. The framework is grounded on a rich representation of the
adaptive mesh suitable for generic finite elements that is built on top of a
low-level, light-weight forest-of-trees data structure handled by a
specialized, highly parallel adaptive meshing engine, for which we have
identified the requirements it must fulfill to be coupled into our framework.
Atop this two-layered mesh representation, we build the rest of data structures
required for the numerical integration and assembly of the discrete system of
linear equations. We consider algorithms that are suitable for both
subassembled and fully-assembled distributed data layouts of linear system
matrices. The proposed framework has been implemented within the FEMPAR
scientific software library, using p4est as a practical forest-of-octrees
demonstrator. A strong scaling study of this implementation when applied to
Poisson and Maxwell problems reveals remarkable scalability up to 32.2K CPU
cores and 482.2M degrees of freedom. Besides, a comparative performance study
of FEMPAR and the state-of-the-art deal.ii finite element software shows at
least comparative performance, and at most factor 2-3 improvements in the
h-adaptive approximation of a Poisson problem with first- and second-order
Lagrangian finite elements, respectively.
","['\nSantiago Badia\n', '\nAlberto F. Martín\n', '\nEric Neiva\n', '\nFrancesc Verdugo\n']",,,http://dx.doi.org/10.1137/20M1328786,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1137/20M1328786,,[]
Out-of-core singular value decomposition,http://arxiv.org/abs/1907.06470v1,2019-07-15T12:41:47Z,2019-07-15T12:41:47Z,"  Singular value decomposition (SVD) is a standard matrix factorization
technique that produces optimal low-rank approximations of matrices. It has
diverse applications, including machine learning, data science and signal
processing. However, many common problems involve very large matrices that
cannot fit in the main memory of commodity computers, making it impractical to
use standard SVD algorithms that assume fast random access or large amounts of
space for intermediate calculations. To address this issue, we have implemented
an out-of-core (external memory) randomized SVD solution that is fully scalable
and efficiently parallelizable. This solution factors both dense and sparse
matrices of arbitrarily large size within arbitrarily small memory limits,
efficiently using out-of-core storage as needed. It uses an innovative
technique for partitioning matrices that lends itself to out-of-core and
parallel processing, as well as memory and I/O use planning, automatic load
balancing, performance tuning, and makes possible a number of other practical
enhancements to the current state-of-the-art. Furthermore, by using persistent
external storage (generally HDDs or SSDs), users can resume interrupted
operations without having to recalculate previously performed steps, solving a
major practical problem in factoring very large matrices.
","['\nVadim Demchik\n', '\nMiroslav Bačák\n', '\nStefan Bordag\n']","11 pages, 4 figures",,http://arxiv.org/abs/1907.06470v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Remark on Algorithm 680: evaluation of the complex error function: Cause
  and Remedy for the Loss of Accuracy Near the Real Axis",http://arxiv.org/abs/1906.12199v1,2019-06-27T11:56:05Z,2019-06-27T11:56:05Z,"  In this remark we identify the cause of the loss of accuracy in the
computation of the Faddeyeva function, w(z), near the real axis when using
Algorithm 680. We provide a simple correction to this problem which allows us
to restore this code as one of the important reference routines for accuracy
comparisons.
",['\nMofreh Zaghloul\n'],,"ACM Transactions on Mathematical Software, Vol. 45, No. 2, Article
  24.(2019)",http://dx.doi.org/10.1145/3309681,cs.MS,['cs.MS'],10.1145/3309681,,[]
"Investigating the OPS intermediate representation to target GPUs in the
  Devito DSL",http://arxiv.org/abs/1906.10811v1,2019-06-26T02:11:08Z,2019-06-26T02:11:08Z,"  The Devito DSL is a code generation tool for the solution of partial
differential equations using the finite difference method specifically aimed at
seismic inversion problems.
  In this work we investigate the integration of OPS, an API to generate highly
optimized code for applications running on structured meshes targeting various
platforms, within Devito as a mean of bringing it to the GPU realm by providing
an implementation of a OPS backend in Devito, obtaining considerable speed ups
compared to the core Devito backend.
",['\nVincenzo Pandolfo\n'],,,http://arxiv.org/abs/1906.10811v1,cs.MS,"['cs.MS', 'cs.PL']",,,[]
A Modular and Extensible Software Architecture for Particle Dynamics,http://arxiv.org/abs/1906.10963v1,2019-06-26T10:45:40Z,2019-06-26T10:45:40Z,"  Creating a highly parallel and flexible discrete element software requires an
interdisciplinary approach, where expertise from different disciplines is
combined. On the one hand domain specialists provide interaction models between
particles. On the other hand high-performance computing specialists optimize
the code to achieve good performance on different hardware architectures. In
particular, the software must be carefully crafted to achieve good scaling on
massively parallel supercomputers. Combining all this in a flexible and
extensible, widely usable software is a challenging task. In this article we
outline the design decisions and concepts of a newly developed particle
dynamics code MESA-PD that is implemented as part of the waLBerla multi-physics
framework. Extensibility, flexibility, but also performance and scalability are
primary design goals for the new software framework. In particular, the new
modular architecture is designed such that physical models can be modified and
extended by domain scientists without understanding all details of the parallel
computing functionality and the underlying distributed data structures that are
needed to achieve good performance on current supercomputer architectures. This
goal is achieved by combining the high performance simulation framework
waLBerla with code generation techniques. All code and the code generator are
released as open source under GPLv3 within the publicly available waLBerla
framework (www.walberla.net).
","['\nSebastian Eibl\n', '\nUlrich Rüde\n']","Proceedings Of The 8Th International Conference On Discrete Element
  Methods",,http://arxiv.org/abs/1906.10963v1,cs.SE,"['cs.SE', 'cs.MS']",,,[]
Multi-dimensional interpolations in C++,http://arxiv.org/abs/1907.02597v1,2019-07-03T08:16:49Z,2019-07-03T08:16:49Z,"  A C++ software design is presented that can be used to interpolate data in
any number of dimensions. The design is based on a combination of templates of
functional collections of elements and so-called type lists. The design allows
for different search methodologies and interpolation techniques in each
dimension. It is also possible to expand and reduce the number of dimensions,
to interpolate composite data types and to produce on-the-fly additional values
such as derivatives of the interpolating function.
",['\nMaarten de Jong\n'],,,http://arxiv.org/abs/1907.02597v1,cs.MS,"['cs.MS', 'cs.PL']",,,[]
"Parallel Performance of Algebraic Multigrid Domain Decomposition
  (AMG-DD)",http://arxiv.org/abs/1906.10575v2,2019-06-25T14:47:23Z,2020-01-21T12:18:59Z,"  Algebraic multigrid (AMG) is a widely used scalable solver and preconditioner
for large-scale linear systems resulting from the discretization of a wide
class of elliptic PDEs. While AMG has optimal computational complexity, the
cost of communication has become a significant bottleneck that limits its
scalability as processor counts continue to grow on modern machines. This paper
examines the design, implementation, and parallel performance of a novel
algorithm, Algebraic Multigrid Domain Decomposition (AMG-DD), designed
specifically to limit communication. The goal of AMG-DD is to provide a
low-communication alternative to standard AMG V-cycles by trading some
additional computational overhead for a significant reduction in communication
cost. Numerical results show that AMG-DD achieves superior accuracy per
communication cost compared to AMG, and speedup over AMG is demonstrated on a
large GPU cluster.
","['\nWayne B. Mitchell\n', '\nRobert Strzodka\n', '\nRobert D. Falgout\n']",,,http://arxiv.org/abs/1906.10575v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",,,[]
"A High-Performance Implementation of a Robust Preconditioner for
  Heterogeneous Problems",http://arxiv.org/abs/1906.10944v2,2019-06-26T09:59:13Z,2020-06-16T10:02:14Z,"  We present an efficient implementation of the highly robust and scalable
GenEO preconditioner in the high-performance PDE framework DUNE. The GenEO
coarse space is constructed by combining low energy solutions of a local
generalised eigenproblem using a partition of unity. In this paper we
demonstrate both weak and strong scaling for the GenEO solver on over 15,000
cores by solving an industrially motivated problem with over 200 million
degrees of freedom. Further, we show that for highly complex parameter
distributions arising in certain real-world applications, established methods
become intractable while GenEO remains fully effective. The purpose of this
paper is two-fold: to demonstrate the robustness and high parallel efficiency
of the solver and to document the technical details that are crucial to the
efficiency of the code.
","['\nLinus Seelinger\n', '\nAnne Reinarz\n', '\nRobert Scheichl\n']",Fixed error in definition of partition of unity,,http://arxiv.org/abs/1906.10944v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', '68U20']",,,[]
Solving Polynomial Systems with phcpy,http://arxiv.org/abs/1907.00096v1,2019-06-28T22:19:04Z,2019-06-28T22:19:04Z,"  The solutions of a system of polynomials in several variables are often
needed, e.g.: in the design of mechanical systems, and in phase-space analyses
of nonlinear biological dynamics. Reliable, accurate, and comprehensive
numerical solutions are available through PHCpack, a FOSS package for solving
polynomial systems with homotopy continuation. This paper explores new
developments in phcpy, a scripting interface for PHCpack, over the past five
years. For instance, phcpy is now available online through a JupyterHub server
featuring Python2, Python3, and SageMath kernels. As small systems are solved
in real-time by phcpy, they are suitable for interactive exploration through
the notebook interface. Meanwhile, phcpy supports GPU parallelization,
improving the speed and quality of solutions to much larger polynomial systems.
From various model design and analysis problems in STEM, certain classes of
polynomial system frequently arise, to which phcpy is well-suited.
","['\nJasmine Otto\n', '\nAngus Forbes\n', '\nJan Verschelde\n']",Accepted for publication in the SciPy 2019 proceedings,,http://arxiv.org/abs/1907.00096v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.SC', 'math.AG']",,,[]
GPU-based Parallel Computation Support for Stan,http://arxiv.org/abs/1907.01063v2,2019-07-01T20:36:16Z,2020-05-16T23:23:03Z,"  This paper details an extensible OpenCL framework that allows Stan to utilize
heterogeneous compute devices. It includes GPU-optimized routines for the
Cholesky decomposition, its derivative, other matrix algebra primitives and
some commonly used likelihoods, with more additions planned for the near
future. Stan users can now benefit from large speedups offered by GPUs with
little effort and without changes to their existing Stan code. We demonstrate
the practical utility of our work with two examples - logistic regression and
Gaussian Process regression.
","['\nRok Češnovar\n', '\nSteve Bronder\n', '\nDavor Sluga\n', '\nJure Demšar\n', '\nTadej Ciglarič\n', '\nSean Talts\n', '\nErik Štrumbelj\n']",,,http://arxiv.org/abs/1907.01063v2,cs.MS,"['cs.MS', 'cs.DC', 'stat.CO']",,,[]
"bayes4psy -- an Open Source R Package for Bayesian Statistics in
  Psychology",http://arxiv.org/abs/1907.01952v1,2019-07-03T14:01:23Z,2019-07-03T14:01:23Z,"  Research in psychology generates interesting data sets and unique statistical
modelling tasks. However, these tasks, while important, are often very
specific, so appropriate statistical models and methods cannot be found in
accessible Bayesian tools. As a result, the use of Bayesian methods is limited
to those that have the technical and statistical fundamentals that are required
for probabilistic programming. Such knowledge is not part of the typical
psychology curriculum and is a difficult obstacle for psychology students and
researchers to overcome. The goal of the bayes4psy package is to bridge this
gap and offer a collection of models and methods to be used for data analysis
that arises from psychology experiments and as a teaching tool for Bayesian
statistics in psychology. The package contains Bayesian t-test and
bootstrapping and models for analyzing reaction times, success rates, and
colors. It also provides all the diagnostic, analytic and visualization tools
for the modern Bayesian data analysis workflow.
","['\nJure Demšar\n', '\nGrega Repovš\n', '\nErik Štrumbelj\n']",,,http://arxiv.org/abs/1907.01952v1,stat.AP,"['stat.AP', 'cs.MS', 'stat.ME']",,,[]
hyppo: A Multivariate Hypothesis Testing Python Package,http://arxiv.org/abs/1907.02088v6,2019-07-03T18:05:25Z,2021-04-01T15:13:13Z,"  We introduce hyppo, a unified library for performing multivariate hypothesis
testing, including independence, two-sample, and k-sample testing. While many
multivariate independence tests have R packages available, the interfaces are
inconsistent and most are not available in Python. hyppo includes many state of
the art multivariate testing procedures. The package is easy-to-use and is
flexible enough to enable future extensions. The documentation and all releases
are available at https://hyppo.neurodata.io.
","['\nSambit Panda\n', '\nSatish Palaniappan\n', '\nJunhao Xiong\n', '\nEric W. Bridgeford\n', '\nRonak Mehta\n', '\nCencheng Shen\n', '\nJoshua T. Vogelstein\n']","5 pages, 1 figure",,http://arxiv.org/abs/1907.02088v6,stat.CO,"['stat.CO', 'cs.MS', 'stat.ME', 'stat.ML']",,,[]
"Algorithms and data structures for matrix-free finite element operators
  with MPI-parallel sparse multi-vectors",http://arxiv.org/abs/1907.01005v1,2019-07-01T18:24:46Z,2019-07-01T18:24:46Z,"  Traditional solution approaches for problems in quantum mechanics scale as
$\mathcal O(M^3)$, where $M$ is the number of electrons. Various methods have
been proposed to address this issue and obtain linear scaling $\mathcal O(M)$.
One promising formulation is the direct minimization of energy. Such methods
take advantage of physical localization of the solution, namely that the
solution can be sought in terms of non-orthogonal orbitals with local support.
In this work a numerically efficient implementation of sparse parallel vectors
within the open-source finite element library deal.II is proposed. The main
algorithmic ingredient is the matrix-free evaluation of the Hamiltonian
operator by cell-wise quadrature. Based on an a-priori chosen support for each
vector we develop algorithms and data structures to perform (i) matrix-free
sparse matrix multivector products (SpMM), (ii) the projection of an operator
onto a sparse sub-space (inner products), and (iii) post-multiplication of a
sparse multivector with a square matrix. The node-level performance is analyzed
using a roofline model. Our matrix-free implementation of finite element
operators with sparse multivectors achieves the performance of 157 GFlop/s on
Intel Cascade Lake architecture. Strong and weak scaling results are reported
for a typical benchmark problem using quadratic and quartic finite element
bases.
","['\nDenis Davydov\n', '\nMartin Kronbichler\n']","29 pages, 12 figures",,http://arxiv.org/abs/1907.01005v1,cs.MS,"['cs.MS', 'cs.DS', 'cs.NA', 'math.NA', 'physics.comp-ph']",,,[]
Bspline solids manipulation with Mathematica,http://arxiv.org/abs/1906.07574v1,2019-06-14T02:45:35Z,2019-06-14T02:45:35Z,"  Bspline solids are used for solid objects modeling in R3. Mathematica
incorporates a several commands to manipulate symbolic and graphically Bspline
basis functions and to graphically manipulate Bsplines curves and surfaces;
however, it does not incorporate any command to the graphical manipulation of
Bspline solids. In this paper, we describe a new Mathematica program to compute
and plotting the Bspline solids. The output obtained is consistent with
Mathematica's notation. The performance of the commands are discussed by using
some illustrative examples.
","['\nR. Ipanaqué\n', '\nR. Velezmoro\n', '\nR. T. Urbina\n']","12 pages, 19 figures",,http://arxiv.org/abs/1906.07574v1,cs.MS,"['cs.MS', '68N15']",,,[]
Program Generation for Linear Algebra Using Multiple Layers of DSLs,http://arxiv.org/abs/1906.08613v1,2019-06-20T13:44:41Z,2019-06-20T13:44:41Z,"  Numerical software in computational science and engineering often relies on
highly-optimized building blocks from libraries such as BLAS and LAPACK, and
while such libraries provide portable performance for a wide range of computing
architectures, they still present limitations in terms of flexibility. We
advocate a domain-specific program generator capable of producing library
routines tailored to the specific needs of the application in terms of sizes,
interface, and target architecture.
","['\nDaniele G. Spampinato\nETH Zurich\n', '\nDiego Fabregat-Traver\nRWTH Aachen University\n', '\nMarkus Püschel\nETH Zurich\n', '\nPaolo Bientinesi\nRWTH Aachen University\n']",,,http://arxiv.org/abs/1906.08613v1,cs.MS,['cs.MS'],,,"['ETH Zurich', 'RWTH Aachen University', 'ETH Zurich', 'RWTH Aachen University']"
Computing Theta Functions with Julia,http://arxiv.org/abs/1906.06507v2,2019-06-15T09:22:03Z,2020-11-09T16:41:43Z,"  We present a new package Theta.jl for computing with the Riemann theta
function. It is implemented in Julia and offers accurate numerical evaluation
of theta functions with characteristics and their derivatives of arbitrary
order. Our package is optimized for multiple evaluations of theta functions for
the same Riemann matrix, in small dimensions. As an application, we report on
experimental approaches to the Schottky problem in genus five.
","['\nDaniele Agostini\n', '\nLynn Chua\n']","v2: to appear in the Journal of Software for Algebra and Geometry.
  Content reorganized according to the published version",J. Softw. Alg. Geom. 11 (2021) 41-51,http://dx.doi.org/10.2140/jsag.2021.11.41,cs.MS,"['cs.MS', 'math.AG', 'math.CV']",10.2140/jsag.2021.11.41,,[]
"SPSMAT: GNU Octave software package for spectral and pseudospectral
  methods",http://arxiv.org/abs/1906.09964v1,2019-06-20T21:18:49Z,2019-06-20T21:18:49Z,"  SPSMAT (Spectral/Pseudospectral matrix method) is an add-on for Octave, that
helps you solve nonfractional-/fractional ordinary/partial
differential/integral equations. In this version, as the first version, the
well-defined spectral or pseudospectral algorithms are considered to solve
differential and integral equations. The motivation is that there are few
software packages available that make such methods easy to use for
practitioners in the field of scientific computing. Additionally, one of the
most practical platforms in computation, MATLAB, is currently not supporting
beneficial and free numerical method for the solution of differential
equations--to the best author's knowledge. To remedy this situation, this paper
provides a description of its relevant uploaded open source software package
and is a broad guidance to describe how to work with this toolbox.
","['\nSobhan Latifi\n', '\nMehdi Delkhosh\n']","8 pages, 5 figures",,http://arxiv.org/abs/1906.09964v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Bembel: The Fast Isogeometric Boundary Element C++ Library for Laplace,
  Helmholtz, and Electric Wave Equation",http://arxiv.org/abs/1906.00785v1,2019-06-03T13:22:27Z,2019-06-03T13:22:27Z,"  In this article, we present Bembel, the C++ library featuring higher order
isogeometric Galerkin boundary element methods for Laplace, Helmholtz, and
Maxwell problems. Bembel is compatible with geometries from the Octave NURBS
package and provides an interface to the Eigen template library for linear
algebra operations. For computational efficiency, it applies an embedded fast
multipole method tailored to the isogeometric analysis framework and a parallel
matrix assembly based on OpenMP.
","['\nJ. Dölz\n', '\nH. Harbrecht\n', '\nS. Kurz\n', '\nM. Multerer\n', '\nS. Schöps\n', '\nF. Wolf\n']",,,http://arxiv.org/abs/1906.00785v1,cs.MS,['cs.MS'],,,[]
Exploiting nested task-parallelism in the $\mathcal{H}-LU$ factorization,http://arxiv.org/abs/1906.00874v1,2019-06-03T15:29:17Z,2019-06-03T15:29:17Z,"  We address the parallelization of the LU factorization of hierarchical
matrices ($\mathcal{H}$-matrices) arising from boundary element methods. Our
approach exploits task-parallelism via the OmpSs programming model and runtime,
which discovers the data-flow parallelism intrinsic to the operation at
execution time, via the analysis of data dependencies based on the memory
addresses of the tasks' operands. This is especially challenging for
$\mathcal{H}$-matrices, as the structures containing the data vary in dimension
during the execution. We tackle this issue by decoupling the data structure
from that used to detect dependencies. Furthermore, we leverage the support for
weak operands and early release of dependencies, recently introduced in
OmpSs-2, to accelerate the execution of parallel codes with nested
task-parallelism and fine-grain tasks.
","['\nRocío Carratalá-Sáez\n', '\nSven Christophersen\n', '\nJosé I. Aliaga\n', '\nVicenç Beltran\n', '\nSteffen Börm\n', '\nEnrique S. Quintana-Ortí\n']",,"Journal of Computational Science, volume 33, pages 20-33 (2019)",http://dx.doi.org/10.1016/j.jocs.2019.02.004,cs.MS,"['cs.MS', 'cs.DC', 'math.NA', '68W10, 65N38, 65F05']",10.1016/j.jocs.2019.02.004,,[]
"Raising the Performance of the Tinker-HP Molecular Modeling Package
  [Article v1.0]",http://arxiv.org/abs/1906.01211v4,2019-06-04T06:01:37Z,2021-12-04T16:44:44Z,"  This living paper reviews the present High Performance Computing (HPC)
capabilities of the Tinker-HP molecular modeling package. We focus here on the
reference, double precision, massively parallel molecular dynamics engine
present in Tinker-HP and dedicated to perform large scale simulations. We show
how it can be adapted to recent Intel Central Processing Unit (CPU) petascale
architectures. First, we discuss the new set of Intel Advanced Vector
Extensions 512 (Intel AVX-512) instructions present in recent Intel processors
(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)
allowing for larger vectorization enhancements. These instructions constitute
the central source of potential computational gains when using the latest
processors, justifying important vectorization efforts for developers. We then
briefly review the organization of the Tinker-HP code and identify the
computational hotspots which require Intel AVX-512 optimization and we propose
a general and optimal strategy to vectorize those particular parts of the code.
We intended to present our optimization strategy in a pedagogical way so it
could benefit to other researchers and students interested in gaining
performances in their own software. Finally we present the performance
enhancements obtained compared to the unoptimized code both sequentially and at
the scaling limit in parallel for classical non-polarizable (CHARMM) and
polarizable force fields (AMOEBA). This paper never ceases to be updated as we
accumulate new data on the associated Github repository between new versions of
this living paper.
","['\nLuc-Henri Jolly\n', '\nAlejandro Duran\n', '\nLouis Lagardère\n', '\nJay W. Ponder\n', '\nPengyu Ren\n', '\nJean-Philip Piquemal\n']",,"LiveCoMS, 1 (2019) 10409",http://dx.doi.org/10.33011/livecoms.1.2.10409,cs.MS,"['cs.MS', 'cs.DC', 'physics.chem-ph', 'physics.comp-ph']",10.33011/livecoms.1.2.10409,,[]
"Nektar++: enhancing the capability and application of high-fidelity
  spectral/$hp$ element methods",http://arxiv.org/abs/1906.03489v2,2019-06-08T17:01:12Z,2019-11-26T19:22:23Z,"  Nektar++ is an open-source framework that provides a flexible,
high-performance and scalable platform for the development of solvers for
partial differential equations using the high-order spectral/$hp$ element
method. In particular, Nektar++ aims to overcome the complex implementation
challenges that are often associated with high-order methods, thereby allowing
them to be more readily used in a wide range of application areas. In this
paper, we present the algorithmic, implementation and application developments
associated with our Nektar++ version 5.0 release. We describe some of the key
software and performance developments, including our strategies on parallel
I/O, on in situ processing, the use of collective operations for exploiting
current and emerging hardware, and interfaces to enable multi-solver coupling.
Furthermore, we provide details on a newly developed Python interface that
enables a more rapid introduction for new users unfamiliar with spectral/$hp$
element methods, C++ and/or Nektar++. This release also incorporates a number
of numerical method developments - in particular: the method of moving frames,
which provides an additional approach for the simulation of equations on
embedded curvilinear manifolds and domains; a means of handling spatially
variable polynomial order; and a novel technique for quasi-3D simulations to
permit spatially-varying perturbations to the geometry in the homogeneous
direction. Finally, we demonstrate the new application-level features provided
in this release, namely: a facility for generating high-order curvilinear
meshes called NekMesh; a novel new AcousticSolver for aeroacoustic problems;
our development of a 'thick' strip model for the modelling of fluid-structure
interaction problems in the context of vortex-induced vibrations. We conclude
by commenting some directions for future code development and expansion.
","['\nDavid Moxey\n', '\nChris D. Cantwell\n', '\nYan Bao\n', '\nAndrea Cassinelli\n', '\nGiacomo Castiglioni\n', '\nSehun Chun\n', '\nEmilia Juda\n', '\nEhsan Kazemi\n', '\nKilian Lackhove\n', '\nJulian Marcon\n', '\nGianmarco Mengaldo\n', '\nDouglas Serson\n', '\nMichael Turner\n', '\nHui Xu\n', '\nJoaquim Peiró\n', '\nRobert M. Kirby\n', '\nSpencer J. Sherwin\n']","21 pages, 14 figures",Computer Physics Communications 249 (2020) 107110,http://dx.doi.org/10.1016/j.cpc.2019.107110,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'physics.flu-dyn']",10.1016/j.cpc.2019.107110,,[]
Landau: language for dynamical systems with automatic differentiation,http://arxiv.org/abs/1905.10206v1,2019-05-24T12:52:05Z,2019-05-24T12:52:05Z,"  Most numerical solvers used to determine free variables of dynamical systems
rely on first-order derivatives of the state of the system w.r.t. the free
variables. The number of the free variables can be fairly large. One of the
approaches of obtaining those derivatives is the integration of the derivatives
simultaneously with the dynamical equations, which is best done with the
automatic differentiation technique. Even though there exist many automatic
differentiation tools, none have been found to be scalable and usable for
practical purposes of dynamic systems modeling. Landau is a Turing incomplete
statically typed domain-specific language aimed to fill this gap. The Turing
incompleteness provides the ability of sophisticated source code analysis and,
as a result, a highly optimized compiled code. Among other things, the language
syntax supports functions, compile-time ranged for loops, if/else branching
constructions, real variables and arrays, and the ability to manually discard
calculation where the automatic derivatives values are expected to be
negligibly small. In spite of reasonable restrictions, the language is rich
enough to express and differentiate any cumbersome paper-equation with
practically no effort.
","['\nIvan Dolgakov\n', '\nDmitry Pavlov\n']",,,http://arxiv.org/abs/1905.10206v1,cs.MS,['cs.MS'],,,[]
"Recursive blocked algorithms for linear systems with Kronecker product
  structure",http://arxiv.org/abs/1905.09539v1,2019-05-23T08:54:45Z,2019-05-23T08:54:45Z,"  Recursive blocked algorithms have proven to be highly efficient at the
numerical solution of the Sylvester matrix equation and its generalizations. In
this work, we show that these algorithms extend in a seamless fashion to
higher-dimensional variants of generalized Sylvester matrix equations, as they
arise from the discretization of PDEs with separable coefficients or the
approximation of certain models in macroeconomics. By combining recursions with
a mechanism for merging dimensions, an efficient algorithm is derived that
outperforms existing approaches based on Sylvester solvers.
","['\nMinhong Chen\n', '\nDaniel Kressner\n']",,,http://arxiv.org/abs/1905.09539v1,math.NA,"['math.NA', 'cs.MS']",,,[]
Robust Task-Parallel Solution of the Triangular Sylvester Equation,http://arxiv.org/abs/1905.10574v1,2019-05-25T11:31:17Z,2019-05-25T11:31:17Z,"  The Bartels-Stewart algorithm is a standard approach to solving the dense
Sylvester equation. It reduces the problem to the solution of the triangular
Sylvester equation. The triangular Sylvester equation is solved with a variant
of backward substitution. Backward substitution is prone to overflow. Overflow
can be avoided by dynamic scaling of the solution matrix. An algorithm which
prevents overflow is said to be robust. The standard library LAPACK contains
the robust scalar sequential solver dtrsyl. This paper derives a robust,
level-3 BLAS-based task-parallel solver. By adding overflow protection, our
robust solver closes the gap between problems solvable by LAPACK and problems
solvable by existing non-robust task-parallel solvers. We demonstrate that our
robust solver achieves a similar performance as non-robust solvers.
","['\nAngelika Schwarz\n', '\nCarl Christian Kjelgaard Mikkelsen\n']","10 pages, 7 figures",,http://arxiv.org/abs/1905.10574v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
On the Parallelization of Triangular Decomposition of Polynomial Systems,http://arxiv.org/abs/1906.00039v1,2019-05-31T19:16:47Z,2019-05-31T19:16:47Z,"  We discuss the parallelization of algorithms for solving polynomial systems
symbolically by way of triangular decomposition. Algorithms for solving
polynomial systems combine low-level routines for performing arithmetic
operations on polynomials and high-level procedures which produce the different
components (points, curves, surfaces) of the solution set. The latter
""component-level"" parallelization of triangular decompositions, our focus here,
belongs to the class of dynamic irregular parallel applications. Possible
speedup factors depend on geometrical properties of the solution set (number of
components, their dimensions and degrees); these algorithms do not scale with
the number of processors. In this paper we combine two different concurrency
schemes, the fork-join model and producer-consumer patterns, to better capture
opportunities for component-level parallelization. We report on our
implementation with the publicly available BPAS library. Our experimentation
with 340 systems yields promising results.
","['\nMohammadali Asadi\n', '\nAlexander Brandt\n', '\nRobert H. C. Moir\n', '\nMarc Moreno Maza\n', '\nYuzhen Xie\n']",,,http://arxiv.org/abs/1906.00039v1,cs.SC,"['cs.SC', 'cs.DC', 'cs.MS']",,,[]
"Introduction to StarNEig -- A Task-based Library for Solving
  Nonsymmetric Eigenvalue Problems",http://arxiv.org/abs/1905.04975v1,2019-05-13T11:20:09Z,2019-05-13T11:20:09Z,"  In this paper, we present the StarNEig library for solving dense
non-symmetric (generalized) eigenvalue problems. The library is built on top of
the StarPU runtime system and targets both shared and distributed memory
machines. Some components of the library support GPUs. The library is currently
in an early beta state and only real arithmetic is supported. Support for
complex data types is planned for a future release. This paper is aimed for
potential users of the library. We describe the design choices and capabilities
of the library, and contrast them to existing software such as ScaLAPACK.
StarNEig implements a ScaLAPACK compatibility layer that should make it easy
for a new user to transition to StarNEig. We demonstrate the performance of the
library with a small set of computational experiments.
","['\nMirko Myllykoski\n', '\nCarl Christian Kjelgaard Mikkelsen\n']","10 pages, 4 figures (10 when counting sub-figures), 2 tex-files.
  Submitted to PPAM 2019, 13th international conference on parallel processing
  and applied mathematics, September 8-11, 2019. Proceedings will be published
  after the conference by Springer in the LNCS series. Second author's first
  name is ""Carl Christian"" and last name ""Kjelgaard Mikkelsen""",LNCS 12043 (2020) 70-81,http://dx.doi.org/10.1007/978-3-030-43229-4_7,cs.DC,"['cs.DC', 'cs.MS', '97N80, 15A18, 65F15, 65Y05, 68W10, 68W15', 'G.4; J.2']",10.1007/978-3-030-43229-4_7,,[]
"Analysis of heterogeneous computing approaches to simulating heat
  transfer in heterogeneous material",http://arxiv.org/abs/1905.07622v1,2019-05-18T18:35:41Z,2019-05-18T18:35:41Z,"  The simulation of heat flow through heterogeneous material is important for
the design of structural and electronic components. Classical analytical
solutions to the heat equation PDE are not known for many such domains, even
those having simple geometries. The finite element method can provide
approximations to a weak form continuum solution, with increasing accuracy as
the number of degrees of freedom in the model increases. This comes at a cost
of increased memory usage and computation time; even when taking advantage of
sparse matrix techniques for the finite element system matrix. We summarize
recent approaches in solving problems in structural mechanics and steady state
heat conduction which do not require the explicit assembly of any system
matrices, and adapt them to a method for solving the time-depended flow of
heat. These approaches are highly parallelizable, and can be performed on
graphical processing units (GPUs). Furthermore, they lend themselves to the
simulation of heterogeneous material, with a minimum of added complexity. We
present the mathematical framework of assembly-free FEM approaches, through
which we summarize the benefits of GPU computation. We discuss our
implementation using the OpenCL computing framework, and show how it is further
adapted for use on multiple GPUs. We compare the performance of single and dual
GPUs implementations of our method with previous GPU computing strategies from
the literature and a CPU sparse matrix approach. The utility of the novel
method is demonstrated through the solution of a real-world coefficient inverse
problem that requires thousands of transient heat flow simulations, each of
which involves solving a 1 million degree of freedom linear system over
hundreds of time steps.
","['\nAndrew Loeb\n', '\nChristopher Earls\n']",,,http://arxiv.org/abs/1905.07622v1,math.NA,"['math.NA', 'cs.MS']",,,[]
"Parallel memory-efficient all-at-once algorithms for the sparse matrix
  triple products in multigrid methods",http://arxiv.org/abs/1905.08423v1,2019-05-21T03:20:38Z,2019-05-21T03:20:38Z,"  Multilevel/multigrid methods is one of the most popular approaches for
solving a large sparse linear system of equations, typically, arising from the
discretization of partial differential equations. One critical step in the
multilevel/multigrid methods is to form coarse matrices through a sequence of
sparse matrix triple products. A commonly used approach for the triple products
explicitly involves two steps, and during each step a sparse matrix-matrix
multiplication is employed. This approach works well for many applications with
a good computational efficiency, but it has a high memory overhead since some
auxiliary matrices need to be temporarily stored for accomplishing the
calculations. In this work, we propose two new algorithms that construct a
coarse matrix with taking one pass through the input matrices without involving
any auxiliary matrices for saving memory. The new approaches are referred to as
""all-at-once"" and ""merged all-at-once"", and the traditional method is denoted
as ""two-step"". The all-at-once and the merged all-at-once algorithms are
implemented based on hash tables in PETSc as part of this work with a careful
consideration on the performance in terms of the compute time and the memory
usage. We numerically show that the proposed algorithms and their
implementations are perfectly scalable in both the compute time and the memory
usage with up to 32,768 processor cores for a model problem with 27 billions of
unknowns. The scalability is also demonstrated for a realistic neutron
transport problem with over 2 billion unknowns on a supercomputer with 10,000
processor cores. Compared with the traditional two-step method, the all-at-once
and the merged all-at-once algorithms consume much less memory for both the
model problem and the realistic neutron transport problem meanwhile they are
able to maintain the computational efficiency.
",['\nFande Kong\n'],"14 pages, 10 figures. Submitted to The International Journal of High
  Performance Computing Applications",,http://arxiv.org/abs/1905.08423v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Software System Design based on Patterns for Newton-Type Methods,http://arxiv.org/abs/1905.04642v1,2019-05-12T04:04:22Z,2019-05-12T04:04:22Z,"  A wide range of engineering applications uses optimisation techniques as part
of their solution process. The researcher uses specialized software that
implements well-known optimisation techniques to solve his problem. However,
when it comes to develop original optimisation techniques that fit a particular
problem the researcher has no option but to implement his own new method from
scratch. This leads to large development times and error prone code that, in
general, will not be reused for any other application. In this work, we present
a novel methodology that simplifies, fasten and improves the development
process of scientific software. This methodology guide us on the identification
of design patterns. The application of this methodology generates reusable,
flexible and high quality scientific software. Furthermore, the produced
software becomes a documented tool to transfer the knowledge on the development
process of scientific software. We apply this methodology for the design of an
optimisation framework implementing Newton's type methods which can be used as
a fast prototyping tool of new optimisation techniques based on Newton's type
methods. The abstraction, reusability and flexibility of the developed
framework is measured by means of Martin's metric. The results indicate that
the developed software is highly reusable.
","['\nRicardo Serrato Barrera\n', '\nGustavo Rodríguez Gómez\n', '\nJulio César Pérez Sansalvador\n', '\nSaul E. Pomares Hernández\n', '\nLeticia Flores Pulido\n', '\nAntonio Muñoz\n']","19 pages, 11 Figures",,http://dx.doi.org/10.1007/s00607-019-00759-8,cs.MS,"['cs.MS', 'cs.PL', 'cs.SE', '68N19']",10.1007/s00607-019-00759-8,,[]
"ExaHyPE: An Engine for Parallel Dynamically Adaptive Simulations of Wave
  Problems",http://arxiv.org/abs/1905.07987v3,2019-05-20T10:53:27Z,2020-05-18T11:43:55Z,"  ExaHyPE (""An Exascale Hyperbolic PDE Engine"") is a software engine for
solving systems of first-order hyperbolic partial differential equations
(PDEs). Hyperbolic PDEs are typically derived from the conservation laws of
physics and are useful in a wide range of application areas. Applications
powered by ExaHyPE can be run on a student's laptop, but are also able to
exploit thousands of processor cores on state-of-the-art supercomputers. The
engine is able to dynamically increase the accuracy of the simulation using
adaptive mesh refinement where required. Due to the robustness and shock
capturing abilities of ExaHyPE's numerical methods, users of the engine can
simulate linear and non-linear hyperbolic PDEs with very high accuracy. Users
can tailor the engine to their particular PDE by specifying evolved quantities,
fluxes, and source terms. A complete simulation code for a new hyperbolic PDE
can often be realised within a few hours - a task that, traditionally, can take
weeks, months, often years for researchers starting from scratch. In this
paper, we showcase ExaHyPE's workflow and capabilities through real-world
scenarios from our two main application areas: seismology and astrophysics.
","['\nAnne Reinarz\n', '\nDominic E. Charrier\n', '\nMichael Bader\n', '\nLuke Bovard\n', '\nMichael Dumbser\n', '\nKenneth Duru\n', '\nFrancesco Fambri\n', '\nAlice-Agnes Gabriel\n', '\nJean-Matthieu Gallard\n', '\nSven Köppel\n', '\nLukas Krenz\n', '\nLeonhard Rannabauer\n', '\nLuciano Rezzolla\n', '\nPhilipp Samfass\n', '\nMaurizio Tavelli\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1016/j.cpc.2020.107251,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1016/j.cpc.2020.107251,,[]
Disciplined Quasiconvex Programming,http://arxiv.org/abs/1905.00562v3,2019-05-02T03:19:49Z,2020-02-27T20:03:44Z,"  We present a composition rule involving quasiconvex functions that
generalizes the classical composition rule for convex functions. This rule
complements well-known rules for the curvature of quasiconvex functions under
increasing functions and pointwise maximums. We refer to the class of
optimization problems generated by these rules, along with a base set of
quasiconvex and quasiconcave functions, as disciplined quasiconvex programs.
Disciplined quasiconvex programming generalizes disciplined convex programming,
the class of optimization problems targeted by most modern domain-specific
languages for convex optimization. We describe an implementation of disciplined
quasiconvex programming that makes it possible to specify and solve quasiconvex
programs in CVXPY 1.0.
","['\nAkshay Agrawal\n', '\nStephen Boyd\n']",p. 4: corrected typos,,http://arxiv.org/abs/1905.00562v3,math.OC,"['math.OC', 'cs.MS']",,,[]
"An optimizing multi-platform source-to-source compiler framework for the
  NEURON MODeling Language",http://arxiv.org/abs/1905.02241v1,2019-05-06T19:20:54Z,2019-05-06T19:20:54Z,"  Domain-specific languages (DSLs) play an increasingly important role in the
generation of high performing software. They allow the user to exploit specific
knowledge encoded in the constructs for the generation of code adapted to a
particular hardware architecture; at the same time, they make it easier to
generate optimized code for a multitude of platforms as the transformation has
to be encoded only once. Here, we describe a new code generation framework
(NMODL) for an existing DSL in the NEURON framework, a widely used software for
massively parallel simulation of biophysically detailed brain tissue models.
Existing NMODL DSL transpilers lack either essential features to generate
optimized code or capability to parse the diversity of existing models in the
user community. Our NMODL framework has been tested against a large number of
previously published user models and offers high-level domain-specific
optimizations and symbolic algebraic simplifications before target code
generation. Furthermore, rich analysis tools are provided allowing the
scientist to introspect models. NMODL implements multiple SIMD and SPMD targets
optimized for modern hardware. Benchmarks were performed on Intel Skylake,
Intel KNL and AMD Naples platforms. When comparing NMODL-generated kernels with
NEURON we observe a speedup of up to 20x, resulting into overall speedups of
two different production simulations by $\sim$10x. When compared to a
previously published SIMD optimized version that heavily relied on
auto-vectorization by the compiler still a speedup of up to $\sim$2x is
observed.
","['\nPramod Kumbhar\n', '\nOmar Awile\n', '\nLiam Keegan\n', '\nJorge Blanco Alonso\n', '\nJames King\n', '\nMichael Hines\n', '\nFelix Schürmann\n']",,,http://arxiv.org/abs/1905.02241v1,cs.MS,"['cs.MS', 'q-bio.NC']",,,[]
"P3DFFT: a framework for parallel computations of Fourier transforms in
  three dimensions",http://arxiv.org/abs/1905.02803v1,2019-05-07T20:47:58Z,2019-05-07T20:47:58Z,"  Fourier and related transforms is a family of algorithms widely employed in
diverse areas of computational science, notoriously difficult to scale on
high-performance parallel computers with large number of processing elements
(cores). This paper introduces a popular software package called P3DFFT
implementing Fast Fourier Transforms (FFT) in three dimensions (3D) in a highly
efficient and scalable way. It overcomes a well-known scalability bottleneck of
3D FFT implementations by using two-dimensional domain decomposition. Designed
for portable performance, P3DFFT achieves excellent timings for a number of
systems and problem sizes. On Cray XT5 system P3DFFT attains 45% efficiency in
weak scaling from 128 to 65,536 computational cores. Library features include
Fourier and Chebyshev transforms, Fortran and C interfaces, in- and
out-of-place transforms, uneven data grids, single and double precision. P3DFFT
is available as open source at http://code.google.com/p/p3dfft/. This paper
discusses P3DFFT implementation and performance in a way that helps guide the
user in making optimal choices for parameters of their runs.
",['\nDmitry Pekurovsky\n'],,"SIAM Journal on Scientific Computing, 34(4), C192-C209 (2012)",http://dx.doi.org/10.1137/11082748X,cs.DC,"['cs.DC', 'cs.MS']",10.1137/11082748X,,[]
"Performance Engineering for Real and Complex Tall & Skinny Matrix
  Multiplication Kernels on GPUs",http://arxiv.org/abs/1905.03136v2,2019-05-08T15:11:46Z,2020-02-18T15:54:31Z,"  General matrix-matrix multiplications with double-precision real and complex
entries (DGEMM and ZGEMM) in vendor-supplied BLAS libraries are best optimized
for square matrices but often show bad performance for tall & skinny matrices,
which are much taller than wide. NVIDIA's current CUBLAS implementation
delivers only a fraction of the potential performance as indicated by the
roofline model in this case. We describe the challenges and key characteristics
of an implementation that can achieve close to optimal performance. We further
evaluate different strategies of parallelization and thread distribution, and
devise a flexible, configurable mapping scheme. To ensure flexibility and allow
for highly tailored implementations we use code generation combined with
autotuning. For a large range of matrix sizes in the domain of interest we
achieve at least 2/3 of the roofline performance and often substantially
outperform state-of-the art CUBLAS results on an NVIDIA Volta GPGPU.
","['\nDominik Ernst\n', '\nGeorg Hager\n', '\nJonas Thies\n', '\nGerhard Wellein\n']","12 pages, 22 figures. Extended version of arXiv:1905.03136v1 for
  journal submission",,http://dx.doi.org/10.1007/978-3-030-43229-4_43,cs.MS,"['cs.MS', 'cs.PF']",10.1007/978-3-030-43229-4_43,,[]
Non-Conforming Mesh Refinement for High-Order Finite Elements,http://arxiv.org/abs/1905.04033v1,2019-05-10T09:41:30Z,2019-05-10T09:41:30Z,"  We propose a general algorithm for non-conforming adaptive mesh refinement
(AMR) of unstructured meshes in high-order finite element codes. Our focus is
on h-refinement with a fixed polynomial order. The algorithm handles
triangular, quadrilateral, hexahedral and prismatic meshes of arbitrarily high
order curvature, for any order finite element space in the de Rham sequence. We
present a flexible data structure for meshes with hanging nodes and a general
procedure to construct the conforming interpolation operator, both in serial
and in parallel. The algorithm and data structure allow anisotropic refinement
of tensor product elements in 2D and 3D, and support unlimited refinement
ratios of adjacent elements. We report numerical experiments verifying the
correctness of the algorithms, and perform a parallel scaling study to show
that we can adapt meshes containing billions of elements and run efficiently on
393,000 parallel tasks. Finally, we illustrate the integration of dynamic AMR
into a high-order Lagrangian hydrodynamics solver.
","['\nJakub Červený\n', '\nVeselin Dobrev\n', '\nTzanio Kolev\n']",,,http://arxiv.org/abs/1905.04033v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
"Matlab vs. OpenCV: A Comparative Study of Different Machine Learning
  Algorithms",http://arxiv.org/abs/1905.01213v4,2019-05-03T14:58:58Z,2019-08-14T12:20:37Z,"  Scientific Computing relies on executing computer algorithms coded in some
programming languages. Given a particular available hardware, algorithms speed
is a crucial factor. There are many scientific computing environments used to
code such algorithms. Matlab is one of the most tremendously successful and
widespread scientific computing environments that is rich of toolboxes,
libraries, and data visualization tools. OpenCV is a (C++)-based library
written primarily for Computer Vision and its related areas. This paper
presents a comparative study using 20 different real datasets to compare the
speed of Matlab and OpenCV for some Machine Learning algorithms. Although
Matlab is more convenient in developing and data presentation, OpenCV is much
faster in execution, where the speed ratio reaches more than 80 in some cases.
The best of two worlds can be achieved by exploring using Matlab or similar
environments to select the most successful algorithm; then, implementing the
selected algorithm using OpenCV or similar environments to gain a speed factor.
","['\nAhmed A. Elsayed\n', '\nWaleed A. Yousef\n']","This manuscript was composed in 2011 as part of a research pursued
  that time",,http://arxiv.org/abs/1905.01213v4,cs.LG,"['cs.LG', 'cs.MS', 'cs.SE', 'stat.ML']",,,[]
"A new object-oriented framework for solving multiphysics problems via
  combination of different numerical methods",http://arxiv.org/abs/1905.00104v1,2019-04-28T06:24:06Z,2019-04-28T06:24:06Z,"  Many interesting phenomena are characterized by the complex interaction of
different physical processes, each often best modeled numerically via a
specific approach. In this paper, we present the design and implementation of
an object-oriented framework for performing multiphysics simulations that
allows for the monolithic coupling of different numerical schemes. In contrast,
most of the currently available simulation tools are tailored towards a
specific numerical model, so that one must resort to coupling different codes
externally based on operator splitting. The current framework has been
developed following the C++11 standard, and its main aim is to provide an
environment that affords enough flexibility for developers to implement complex
models while at the same time giving end users a maximum amount of control over
finer details of the simulation without having to write additional code. The
main challenges towards realizing these objectives are discussed in the paper,
together with the manner in which they are addressed. Along with core objects
representing the framework skeleton, we present the various polymorphic classes
that may be utilized by developers to implement new formulations, material
models and solution algorithms. The code architecture is designed to allow
achievement of the aforementioned functionalities with a minimum level of
inheritance in order to improve the learning curve for programmers who are not
acquainted with the software. Key capabilities of the framework are
demonstrated via the solution of numerical examples dealing on composite
torsion, Biot poroelasticity (featuring a combined finite element-finite volume
formulation), and brittle crack propagation using a phase-field approach.
",['\nJuan Michael Sargado\n'],,,http://arxiv.org/abs/1905.00104v1,cs.MS,"['cs.MS', 'math.NA']",,,[]
A Flexible Framework for Parallel Multi-Dimensional DFTs,http://arxiv.org/abs/1904.10119v2,2019-04-23T02:16:49Z,2019-12-22T21:04:22Z,"  Multi-dimensional discrete Fourier transforms (DFT) are typically decomposed
into multiple 1D transforms. Hence, parallel implementations of any
multi-dimensional DFT focus on parallelizing within or across the 1D DFT.
Existing DFT packages exploit the inherent parallelism across the 1D DFTs and
offer rigid frameworks, that cannot be extended to incorporate both forms of
parallelism and various data layouts to enable some of the parallelism.
However, in the era of exascale, where systems have thousand of nodes and
intricate network topologies, flexibility and parallel efficiency are key
aspects all multi-dimensional DFT frameworks need to have in order to map and
scale the computation appropriately. In this work, we present a flexible
framework, built on the Redistribution Operations and Tensor Expressions (ROTE)
framework, that facilitates the development of a family of parallel
multi-dimensional DFT algorithms by 1) unifying the two parallelization schemes
within a single framework, 2) exploiting the two different parallelization
schemes to different degrees and 3) using different data layouts to distribute
the data across the compute nodes. We demonstrate the need of a versatile
framework and thus a need for a family of parallel multi-dimensional DFT
algorithms on the K-Computer, where we show almost linear strong scaling
results for problem sizes of 1024^3 on 32k compute nodes.
","['\nDoru Thom Popovici\n', '\nMartin D. Schatz\n', '\nFranz Franchetti\n', '\nTze Meng Low\n']",,,http://arxiv.org/abs/1904.10119v2,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"Stochastic rounding and reduced-precision fixed-point arithmetic for
  solving neural ordinary differential equations",http://arxiv.org/abs/1904.11263v5,2019-04-25T11:26:40Z,2020-01-22T10:07:04Z,"  Although double-precision floating-point arithmetic currently dominates
high-performance computing, there is increasing interest in smaller and simpler
arithmetic types. The main reasons are potential improvements in energy
efficiency and memory footprint and bandwidth. However, simply switching to
lower-precision types typically results in increased numerical errors. We
investigate approaches to improving the accuracy of reduced-precision
fixed-point arithmetic types, using examples in an important domain for
numerical computation in neuroscience: the solution of Ordinary Differential
Equations (ODEs). The Izhikevich neuron model is used to demonstrate that
rounding has an important role in producing accurate spike timings from
explicit ODE solution algorithms. In particular, fixed-point arithmetic with
stochastic rounding consistently results in smaller errors compared to single
precision floating-point and fixed-point arithmetic with round-to-nearest
across a range of neuron behaviours and ODE solvers. A computationally much
cheaper alternative is also investigated, inspired by the concept of dither
that is a widely understood mechanism for providing resolution below the least
significant bit (LSB) in digital signal processing. These results will have
implications for the solution of ODEs in other subject areas, and should also
be directly relevant to the huge range of practical problems that are
represented by Partial Differential Equations (PDEs).
","['\nMichael Hopkins\n', '\nMantas Mikaitis\n', '\nDave R. Lester\n', '\nSteve Furber\n']",Submitted to Philosophical Transactions of the Royal Society A,,http://dx.doi.org/10.1098/rsta.2019.0052,cs.DS,"['cs.DS', 'cs.MS']",10.1098/rsta.2019.0052,,[]
Softmax Optimizations for Intel Xeon Processor-based Platforms,http://arxiv.org/abs/1904.12380v2,2019-04-28T20:19:22Z,2019-05-27T08:33:00Z,"  Softmax is popular normalization method used in machine learning. Deep
learning solutions like Transformer or BERT use the softmax function
intensively, so it is worthwhile to optimize its performance. This article
presents our methodology of optimization and its results applied to softmax. By
presenting this methodology, we hope to increase an interest in deep learning
optimizations for CPUs. We believe that the optimization process presented here
could be transferred to other deep learning frameworks such as TensorFlow or
PyTorch.
","['\nJacek Czaja\nIntel Corporation\n', '\nMichal Gallus\nIntel Corporation\n', '\nTomasz Patejko\nIntel Corporation\n', '\nJian Tang\nBaidu\n']",,,http://arxiv.org/abs/1904.12380v2,cs.MS,"['cs.MS', 'cs.LG']",,,"['Intel Corporation', 'Intel Corporation', 'Intel Corporation', 'Baidu']"
"Big Math and the One-Brain Barrier A Position Paper and Architecture
  Proposal",http://arxiv.org/abs/1904.10405v2,2019-04-23T16:15:52Z,2019-10-22T05:02:06Z,"  Over the last decades, a class of important mathematical results have
required an ever increasing amount of human effort to carry out. For some, the
help of computers is now indispensable. We analyze the implications of this
trend towards ""big mathematics"", its relation to human cognition, and how
machine support for big math can be organized. The central contribution of this
position paper is an information model for ""doing mathematics"", which posits
that humans very efficiently integrate four aspects: inference, computation,
tabulation, and narration around a well-organized core of mathematical
knowledge. The challenge for mathematical software systems is that these four
aspects need to be integrated as well. We briefly survey the state of the art.
","['\nJacques Carette\n', '\nWilliam M. Farmer\n', '\nMichael Kohlhase\n', '\nFlorian Rabe\n']",,,http://arxiv.org/abs/1904.10405v2,cs.MS,"['cs.MS', 'cs.AI', 'math.HO']",,,[]
"$\mathtt{bimEX}$: A Mathematica package for exact computations in $3+1$
  bimetric relativity",http://arxiv.org/abs/1904.10464v2,2019-04-23T18:00:01Z,2020-01-15T12:29:37Z,"  We present $\mathtt{bimEX}$, a Mathematica package for exact computations in
3$+$1 bimetric relativity. It is based on the $\mathtt{xAct}$ bundle, which can
handle computations involving both abstract tensors and their components. In
this communication, we refer to the latter case as concrete computations. The
package consists of two main parts. The first part involves the abstract
tensors, and focuses on how to deal with multiple metrics in $\mathtt{xAct}$.
The second part takes an ansatz for the primary variables in a chart as the
input, and returns the covariant BSSN bimetric equations in components in that
chart. Several functions are implemented to make this process as fast and
user-friendly as possible. The package has been used and tested extensively in
spherical symmetry and was the workhorse in obtaining the bimetric covariant
BSSN equations and reproducing the bimetric 3$+$1 equations in the spherical
polar chart.
",['\nFrancesco Torsello\n'],"9 pages. It matches with the published version. GitHub repository at
  https://github.com/nubirel/bimEX. Program files doi:
  http://dx.doi.org/10.17632/2s5d7csc9w.1",Computer Physics Communications 247 (2020) 106948,http://dx.doi.org/10.1016/j.cpc.2019.106948,cs.SC,"['cs.SC', 'astro-ph.CO', 'cs.MS', 'gr-qc']",10.1016/j.cpc.2019.106948,,[]
The MOMMS Family of Matrix Multiplication Algorithms,http://arxiv.org/abs/1904.05717v1,2019-04-11T14:25:27Z,2019-04-11T14:25:27Z,"  As the ratio between the rate of computation and rate with which data can be
retrieved from various layers of memory continues to deteriorate, a question
arises: Will the current best algorithms for computing matrix-matrix
multiplication on future CPUs continue to be (near) optimal? This paper
provides compelling analytical and empirical evidence that the answer is ""no"".
The analytical results guide us to a new family of algorithms of which the
current state-of-the-art ""Goto's algorithm"" is but one member. The empirical
results, on architectures that were custom built to reduce the amount of
bandwidth to main memory, show that under different circumstances, different
and particular members of the family become more superior. Thus, this family
will likely start playing a prominent role going forward.
","['\nTyler M. Smith\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1904.05717v1,cs.MS,['cs.MS'],,,[]
"Leveraging the bfloat16 Artificial Intelligence Datatype For
  Higher-Precision Computations",http://arxiv.org/abs/1904.06376v1,2019-04-12T19:04:47Z,2019-04-12T19:04:47Z,"  In recent years fused-multiply-add (FMA) units with lower-precision
multiplications and higher-precision accumulation have proven useful in machine
learning/artificial intelligence applications, most notably in training deep
neural networks due to their extreme computational intensity. Compared to
classical IEEE-754 32 bit (FP32) and 64 bit (FP64) arithmetic, these reduced
precision arithmetic can naturally be sped up disproportional to their
shortened width. The common strategy of all major hardware vendors is to
aggressively further enhance their performance disproportionately. One
particular FMA operation that multiplies two BF16 numbers while accumulating in
FP32 has been found useful in deep learning, where BF16 is the 16-bit floating
point datatype with IEEE FP32 numerical range but 8 significant bits of
precision. In this paper, we examine the use this FMA unit to implement
higher-precision matrix routines in terms of potential performance gain and
implications on accuracy. We demonstrate how a decomposition into multiple
smaller datatypes can be used to assemble a high-precision result, leveraging
the higher precision accumulation of the FMA unit. We first demonstrate that
computations of vector inner products and by natural extension, matrix-matrix
products can be achieved by decomposing FP32 numbers in several BF16 numbers
followed by appropriate computations that can accommodate the dynamic range and
preserve accuracy compared to standard FP32 computations, while projecting up
to 5.2x speed-up. Furthermore, we examine solution of linear equations
formulated in the residual form that allows for iterative refinement. We
demonstrate that the solution obtained to be comparable to those offered by
FP64 under a large range of linear system condition numbers.
","['\nGreg Henry\n', '\nPing Tak Peter Tang\n', '\nAlexander Heinecke\n']",Accepted at ARITH26,,http://arxiv.org/abs/1904.06376v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"Towards whole program generation of quadrature-free discontinuous
  Galerkin methods for the shallow water equations",http://arxiv.org/abs/1904.08684v1,2019-04-18T11:02:13Z,2019-04-18T11:02:13Z,"  The shallow water equations (SWE) are a commonly used model to study
tsunamis, tides, and coastal ocean circulation. However, there exist various
approaches to discretize and solve them efficiently. Which of them is best for
a certain scenario is often not known and, in addition, depends heavily on the
used HPC platform. From a simulation software perspective, this places a
premium on the ability to adapt easily to different numerical methods and
hardware architectures. One solution to this problem is to apply code
generation techniques and to express methods and specific hardware-dependent
implementations on different levels of abstraction. This allows for a
separation of concerns and makes it possible, e.g., to exchange the
discretization scheme without having to rewrite all low-level optimized
routines manually. In this paper, we show how code for an advanced
quadrature-free discontinuous Galerkin (DG) discretized shallow water equation
solver can be generated. Here, we follow the multi-layered approach from the
ExaStencils project that starts from the continuous problem formulation, moves
to the discrete scheme, spells out the numerical algorithms, and, finally, maps
to a representation that can be transformed to a distributed memory parallel
implementation by our in-house Scala-based source-to-source compiler. Our
contributions include: A new quadrature-free discontinuous Galerkin
formulation, an extension of the class of supported computational grids, and an
extension of our toolchain allowing to evaluate discrete integrals stemming
from the DG discretization implemented in Python. As first results we present
the whole toolchain and also demonstrate the convergence of our method for
higher order DG discretizations.
","['\nSara Faghih-Naini\n', '\nSebastian Kuckuk\n', '\nVadym Aizinger\n', '\nDaniel Zint\n', '\nRoberto Grosso\n', '\nHarald Köstler\n']",,,http://arxiv.org/abs/1904.08684v1,cs.MS,"['cs.MS', 'cs.CE']",,,[]
"Cross-Platform Performance Portability Using Highly Parametrized SYCL
  Kernels",http://arxiv.org/abs/1904.05347v1,2019-04-10T17:58:23Z,2019-04-10T17:58:23Z,"  Over recent years heterogeneous systems have become more prevalent across HPC
systems, with over 100 supercomputers in the TOP500 incorporating GPUs or other
accelerators. These hardware platforms have different performance
characteristics and optimization requirements. In order to make the most of
multiple accelerators a developer has to provide implementations of their
algorithms tuned for each device. Hardware vendors provide libraries targeting
their devices specifically, which provide good performance but frequently have
different API designs, hampering portability.
  The SYCL programming model allows users to write heterogeneous programs using
completely standard C++, and so developers have access to the power of C++
templates when developing compute kernels. In this paper we show that by
writing highly parameterized kernels for matrix multiplies and convolutions we
achieve performance competitive with vendor implementations across different
architectures. Furthermore, tuning for new devices amounts to choosing the
combinations of kernel parameters that perform best on the hardware.
","['\nJohn Lawson\n', '\nMehdi Goli\n', '\nDuncan McBain\n', '\nDaniel Soutar\n', '\nLouis Sugy\n']","11 pages, 9 figures, 4 tables",,http://arxiv.org/abs/1904.05347v1,cs.PF,"['cs.PF', 'cs.DC', 'cs.LG', 'cs.MS']",,,[]
"Tea: A High-level Language and Runtime System for Automating Statistical
  Analysis",http://arxiv.org/abs/1904.05387v1,2019-04-10T18:44:55Z,2019-04-10T18:44:55Z,"  Though statistical analyses are centered on research questions and
hypotheses, current statistical analysis tools are not. Users must first
translate their hypotheses into specific statistical tests and then perform API
calls with functions and parameters. To do so accurately requires that users
have statistical expertise. To lower this barrier to valid, replicable
statistical analysis, we introduce Tea, a high-level declarative language and
runtime system. In Tea, users express their study design, any parametric
assumptions, and their hypotheses. Tea compiles these high-level specifications
into a constraint satisfaction problem that determines the set of valid
statistical tests, and then executes them to test the hypothesis. We evaluate
Tea using a suite of statistical analyses drawn from popular tutorials. We show
that Tea generally matches the choices of experts while automatically switching
to non-parametric tests when parametric assumptions are not met. We simulate
the effect of mistakes made by non-expert users and show that Tea automatically
avoids both false negatives and false positives that could be produced by the
application of incorrect statistical tests.
","['\nEunice Jun\n', '\nMaureen Daum\n', '\nJared Roesch\n', '\nSarah E. Chasins\n', '\nEmery D. Berger\n', '\nRene Just\n', '\nKatharina Reinecke\n']",11 pages,,http://dx.doi.org/10.1145/3332165.3347940,cs.PL,"['cs.PL', 'cs.HC', 'cs.MS']",10.1145/3332165.3347940,,[]
"Reducing Communication in Algebraic Multigrid with Multi-step Node Aware
  Communication",http://arxiv.org/abs/1904.05838v2,2019-04-11T16:43:11Z,2019-04-24T12:27:20Z,"  Algebraic multigrid (AMG) is often viewed as a scalable $\mathcal{O}(n)$
solver for sparse linear systems. Yet, parallel AMG lacks scalability due to
increasingly large costs associated with communication, both in the initial
construction of a multigrid hierarchy as well as the iterative solve phase.
This work introduces a parallel implementation of AMG to reduce the cost of
communication, yielding an increase in scalability. Standard inter-process
communication consists of sending data regardless of the send and receive
process locations. Performance tests show notable differences in the cost of
intra- and inter-node communication, motivating a restructuring of
communication. In this case, the communication schedule takes advantage of the
less costly intra-node communication, reducing both the number and size of
inter-node messages. Node-centric communication extends to the range of
components in both the setup and solve phase of AMG, yielding an increase in
the weak and strong scalability of the entire method.
","['\nAmanda Bienz\n', '\nLuke Olson\n', '\nWilliam Gropp\n']","11 pages, 21 figures",,http://arxiv.org/abs/1904.05838v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'cs.PF']",,,[]
Computing huge Groebner basis like cyclic10 over $\Q$ with Giac,http://arxiv.org/abs/1903.12427v1,2019-03-29T10:00:47Z,2019-03-29T10:00:47Z,"  We present a short description on how to fine-tune the modular algorithm
implemented in the Giac computer algebra system to reconstruct huge Groebner
basis over $\Q$.The classical cyclic10 benchmark will serve as example.
",['\nBernard Parisse\nIF\n'],,,http://arxiv.org/abs/1903.12427v1,cs.SC,"['cs.SC', 'cs.MS']",,,['IF']
"COFFEE -- An MPI-parallelized Python package for the numerical evolution
  of differential equations",http://arxiv.org/abs/1903.12482v2,2019-03-29T12:40:01Z,2019-07-04T06:47:49Z,"  COFFEE (ConFormal Field Equation Evolver) is a Python package primarily
developed to numerically evolve systems of partial differential equations over
time using the method of lines. It includes a variety of time integrators and
finite differencing stencils with the summation-by-parts property, as well as
pseudo-spectral functionality for angular derivatives of spin-weighted
functions. Some additional capabilities include being MPI-parallelisable on a
variety of different geometries, HDF data output and post processing scripts to
visualize data, and an actions class that allows users to create code for
analysis after each timestep.
","['\nGeorgios Doulis\n', '\nJörg Frauendiener\n', '\nChris Stevens\n', '\nBen Whale\n']","12 pages, 1 figure, accepted to be published in SoftwareX","SoftwareX 10, 100283 (2019)",http://dx.doi.org/10.1016/j.softx.2019.100283,cs.MS,"['cs.MS', 'gr-qc']",10.1016/j.softx.2019.100283,,[]
"A Flexible, Parallel, Adaptive Geometric Multigrid method for FEM",http://arxiv.org/abs/1904.03317v2,2019-04-05T23:05:33Z,2021-08-03T17:11:38Z,"  We present the design and implementation details of a geometric multigrid
method on adaptively refined meshes for massively parallel computations. The
method uses local smoothing on the refined part of the mesh. Partitioning is
achieved by using a space filling curve for the leaf mesh and distributing
ancestors in the hierarchy based on the leaves. We present a model of the
efficiency of mesh hierarchy distribution and compare its predictions to
runtime measurements. The algorithm is implemented as part of the deal.II
finite element library and as such available to the public.
","['\nThomas C. Clevenger\n', '\nTimo Heister\n', '\nGuido Kanschat\n', '\nMartin Kronbichler\n']",,,http://dx.doi.org/10.1145/3425193,cs.NA,"['cs.NA', 'cs.MS']",10.1145/3425193,,[]
A study of vectorization for matrix-free finite element methods,http://arxiv.org/abs/1903.08243v2,2019-03-19T20:15:03Z,2020-05-19T14:23:13Z,"  Vectorization is increasingly important to achieve high performance on modern
hardware with SIMD instructions. Assembly of matrices and vectors in the finite
element method, which is characterized by iterating a local assembly kernel
over unstructured meshes, poses difficulties to effective vectorization.
Maintaining a user-friendly high-level interface with a suitable degree of
abstraction while generating efficient, vectorized code for the finite element
method is a challenge for numerical software systems and libraries. In this
work, we study cross-element vectorization in the finite element framework
Firedrake via code transformation and demonstrate the efficacy of such an
approach by evaluating a wide range of matrix-free operators spanning different
polynomial degrees and discretizations on two recent CPUs using three
mainstream compilers. Our experiments show that our approaches for
cross-element vectorization achieve 30\% of theoretical peak performance for
many examples of practical significance, and exceed 50\% for cases with high
arithmetic intensities, with consistent speed-up over (intra-element)
vectorization restricted to the local assembly kernels.
","['\nTianjiao Sun\n', '\nLawrence Mitchell\n', '\nKaushik Kulkarni\n', '\nAndreas Klöckner\n', '\nDavid A. Ham\n', '\nPaul H. J. Kelly\n']",,"International Journal of High Performance Computing Applications
  (2020)",http://dx.doi.org/10.1177/1094342020945005,cs.MS,['cs.MS'],10.1177/1094342020945005,,[]
pyLLE: a Fast and User Friendly Lugiato-Lefever Equation Solver,http://arxiv.org/abs/1903.10441v2,2019-03-22T17:38:23Z,2019-05-30T12:12:54Z,"  We present the development of pyLLE, a freely accessible and cross-platform
Lugiato-Lefever equation solver programmed in Python and Julia and optimized
for the simulation of microresonator frequency combs. Examples illustrating its
operation, the simplicity of use, and performance against other programming
language are presented. The documentation of the software can be found at
https://gregmoille.github.io/pyLLE/
","['\nGregory Moille\n', '\nQing Li\n', '\nXiyuan Lu\n', '\nKartik Srinivasan\n']",,"Journal of Research of National Institute of Standards and
  Technology, Volume 124, Article No. 124012 (2019)",http://dx.doi.org/10.6028/jres.124.012,cs.MS,"['cs.MS', 'physics.optics']",10.6028/jres.124.012,,[]
"Yet Another Tensor Toolbox for discontinuous Galerkin methods and other
  applications",http://arxiv.org/abs/1903.11521v1,2019-03-27T16:17:01Z,2019-03-27T16:17:01Z,"  The numerical solution of partial differential equations is at the heart of
many grand challenges in supercomputing. Solvers based on high-order
discontinuous Galerkin (DG) discretisation have been shown to scale on large
supercomputers with excellent performance and efficiency, if the implementation
exploits all levels of parallelism and is tailored to the specific
architecture. However, every year new supercomputers emerge and the list of
hardware-specific considerations grows, simultaneously with the list of desired
features in a DG code. Thus we believe that a sustainable DG code needs an
abstraction layer to implement the numerical scheme in a suitable language. We
explore the possibility to abstract the numerical scheme as small tensor
operations, describe them in a domain-specific language (DSL) resembling the
Einstein notation, and to map them to existing code generators which generate
small matrix matrix multiplication routines. The compiler for our DSL
implements classic optimisations that are used for large tensor contractions,
and we present novel optimisation techniques such as equivalent sparsity
patterns and optimal index permutations for temporary tensors. Our application
examples, which include the earthquake simulation software SeisSol, show that
the generated kernels achieve over 50 % peak performance while the DSL
considerably simplifies the implementation.
","['\nCarsten Uphoff\n', '\nMichael Bader\n']",Submitted to ACM TOMS,,http://dx.doi.org/10.1145/3406835,cs.MS,"['cs.MS', 'cs.DC']",10.1145/3406835,,[]
GNA: new framework for statistical data analysis,http://arxiv.org/abs/1903.05567v1,2019-03-13T16:09:08Z,2019-03-13T16:09:08Z,"  We report on the status of GNA --- a new framework for fitting large-scale
physical models. GNA utilizes the data flow concept within which a model is
represented by a directed acyclic graph. Each node is an operation on an array
(matrix multiplication, derivative or cross section calculation, etc). The
framework enables the user to create flexible and efficient large-scale lazily
evaluated models, handle large numbers of parameters, propagate parameters'
uncertainties while taking into account possible correlations between them, fit
models, and perform statistical analysis. The main goal of the paper is to give
an overview of the main concepts and methods as well as reasons behind their
design. Detailed technical information is to be published in further works.
","['\nAnna Fatkina\n', '\nMaxim Gonchar\n', '\nAnastasia Kalitkina\n', '\nLiudmila Kolupaeva\n', '\nDmitry Naumov\n', '\nDmitry Selivanov\n', '\nKonstantin Treskov\n']","9 pages, 3 figures, CHEP 2018, submitted to EPJ Web of Conferences",,http://dx.doi.org/10.1051/epjconf/201921405024,cs.MS,['cs.MS'],10.1051/epjconf/201921405024,,[]
"On the Efficacy and High-Performance Implementation of Quaternion Matrix
  Multiplication",http://arxiv.org/abs/1903.05575v1,2019-03-13T16:19:27Z,2019-03-13T16:19:27Z,"  Quaternion symmetry is ubiquitous in the physical sciences. As such, much
work has been afforded over the years to the development of efficient schemes
to exploit this symmetry using real and complex linear algebra. Recent years
have also seen many advances in the formal theoretical development of
explicitly quaternion linear algebra with promising applications in image
processing and machine learning. Despite these advances, there do not currently
exist optimized software implementations of quaternion linear algebra. The
leverage of optimized linear algebra software is crucial in the achievement of
high levels of performance on modern computing architectures, and thus provides
a central tool in the development of high-performance scientific software. In
this work, a case will be made for the efficacy of high-performance quaternion
linear algebra software for appropriate problems. In this pursuit, an optimized
software implementation of quaternion matrix multiplication will be presented
and will be shown to outperform a vendor tuned implementation for the analogous
complex matrix operation. The results of this work pave the path for further
development of high-performance quaternion linear algebra software which will
improve the performance of the next generation of applicable scientific
applications.
","['\nDavid Williams-Young\n', '\nXiaosong Li\n']",,,http://arxiv.org/abs/1903.05575v1,cs.MS,['cs.MS'],,,[]
"Auto-Vectorizing TensorFlow Graphs: Jacobians, Auto-Batching And Beyond",http://arxiv.org/abs/1903.04243v1,2019-03-08T03:11:02Z,2019-03-08T03:11:02Z,"  We propose a static loop vectorization optimization on top of high level
dataflow IR used by frameworks like TensorFlow. A new statically vectorized
parallel-for abstraction is provided on top of TensorFlow, and used for
applications ranging from auto-batching and per-example gradients, to jacobian
computation, optimized map functions and input pipeline optimization. We report
huge speedups compared to both loop based implementations, as well as run-time
batching adopted by the DyNet framework.
","['\nAshish Agarwal\n', '\nIgor Ganichev\n']",,,http://arxiv.org/abs/1903.04243v1,cs.DC,"['cs.DC', 'cs.LG', 'cs.MS']",,,[]
"Performance Analysis of Effective Symbolic Methods for Solving Band
  Matrix SLAEs",http://arxiv.org/abs/1903.02423v1,2019-03-04T19:44:24Z,2019-03-04T19:44:24Z,"  This paper presents an experimental performance study of implementations of
three symbolic algorithms for solving band matrix systems of linear algebraic
equations with heptadiagonal, pentadiagonal, and tridiagonal coefficient
matrices. The only assumption on the coefficient matrix in order for the
algorithms to be stable is nonsingularity. These algorithms are implemented
using the GiNaC library of C++ and the SymPy library of Python, considering
five different data storing classes. Performance analysis of the
implementations is done using the high-performance computing (HPC) platforms
""HybriLIT"" and ""Avitohol"". The experimental setup and the results from the
conducted computations on the individual computer systems are presented and
discussed. An analysis of the three algorithms is performed.
","['\nMilena Veneva\n', '\nAlexander Ayriyan\n']","7 pages, 9 tables, 4 figures",,http://dx.doi.org/10.1051/epjconf/201921405004,cs.MS,['cs.MS'],10.1051/epjconf/201921405004,,[]
"Takin: An open-source software for experiment planning, visualisation,
  and data analysis",http://arxiv.org/abs/1903.02632v2,2019-02-26T10:56:52Z,2021-02-16T08:27:39Z,"  Due to the instrument's non-trivial resolution function, measurements on
triple-axis spectrometers require extra care from the experimenter in order to
obtain optimal results and to avoid unwanted spurious artefacts. We present a
free and open-source software system that aims to ease many of the tasks
encountered during the planning phase, in the execution and in data treatment
of experiments performed on neutron triple-axis spectrometers. The software is
currently in use and has been successfully tested at the MLZ, but can be
configured to work with other triple-axis instruments and instrument control
systems.
","['\nT. Weber\n', '\nR. Georgii\n', '\nP. Böni\n']","This is a collection of the three software papers on ""Takin""","SoftwareX 5 121-126 (2016); SoftwareX 6 148-149 (2017); SoftwareX
  14, 100667 (2021)",http://dx.doi.org/10.1016/j.softx.2016.06.002,physics.ins-det,"['physics.ins-det', 'cs.MS']","10.1016/j.softx.2016.06.002 10.1016/j.softx.2017.06.002
  10.1016/j.softx.2021.100667",,[]
"Algorithms and software for projections onto intersections of convex and
  non-convex sets with applications to inverse problems",http://arxiv.org/abs/1902.09699v2,2019-02-26T01:52:07Z,2019-03-07T09:11:03Z,"  We propose algorithms and software for computing projections onto the
intersection of multiple convex and non-convex constraint sets. The software
package, called SetIntersectionProjection, is intended for the regularization
of inverse problems in physical parameter estimation and image processing. The
primary design criterion is working with multiple sets, which allows us to
solve inverse problems with multiple pieces of prior knowledge. Our algorithms
outperform the well known Dykstra's algorithm when individual sets are not easy
to project onto because we exploit similarities between constraint sets. Other
design choices that make the software fast and practical to use, include
recently developed automatic selection methods for auxiliary algorithm
parameters, fine and coarse grained parallelism, and a multilevel acceleration
scheme. We provide implementation details and examples that show how the
software can be used to regularize inverse problems. Results show that we
benefit from working with all available prior information and are not limited
to one or two regularizers because of algorithmic, computational, or
hyper-parameter selection issues.
","['\nBas Peters\n', '\nFelix J. Herrmann\n']","37 pages, 9 figures",,http://arxiv.org/abs/1902.09699v2,cs.MS,"['cs.MS', 'math.OC', '68U10, 86A22, 90C06']",,,[]
"Vector operations for accelerating expensive Bayesian computations -- a
  tutorial guide",http://arxiv.org/abs/1902.09046v3,2019-02-25T00:38:23Z,2020-12-14T06:22:53Z,"  Many applications in Bayesian statistics are extremely computationally
intensive. However, they are often inherently parallel, making them prime
targets for modern massively parallel processors. Multi-core and distributed
computing is widely applied in the Bayesian community, however, very little
attention has been given to fine-grain parallelisation using single instruction
multiple data (SIMD) operations that are available on most modern commodity
CPUs and is the basis of GPGPU computing. In this work, we practically
demonstrate, using standard programming libraries, the utility of the SIMD
approach for several topical Bayesian applications. We show that SIMD can
improve the floating point arithmetic performance resulting in up to $6\times$
improvement in serial algorithm performance. Importantly, these improvements
are multiplicative to any gains achieved through multi-core processing. We
illustrate the potential of SIMD for accelerating Bayesian computations and
provide the reader with techniques for exploiting modern massively parallel
processing environments using standard tools.
","['\nDavid J. Warne\nQueensland University of Technology\n', '\nScott A. Sisson\nUniversity of New South Wales\n', '\nChristopher Drovandi\nQueensland University of Technology\n']",,,http://dx.doi.org/10.1214/21-BA1265,stat.CO,"['stat.CO', 'cs.DC', 'cs.MS', 'cs.PF', 'stat.ML', '62F15, 62C10, 68W10, 65Y05,']",10.1214/21-BA1265,,"['Queensland University of Technology', 'University of New South Wales', 'Queensland University of Technology']"
The BLAS API of BLASFEO: optimizing performance for small matrices,http://arxiv.org/abs/1902.08115v4,2019-02-21T16:05:43Z,2020-02-04T12:26:49Z,"  BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization and other applications targeting relatively small matrices.
BLASFEO defines an API which uses a packed matrix format as its native format.
This format is analogous to the internal memory buffers of optimized BLAS, but
it is exposed to the user and it removes the packing cost from the routine
call. For matrices fitting in cache, BLASFEO outperforms optimized BLAS
implementations, both open-source and proprietary. This paper investigates the
addition of a standard BLAS API to the BLASFEO framework, and proposes an
implementation switching between two or more algorithms optimized for different
matrix sizes. Thanks to the modular assembly framework in BLASFEO, tailored
linear algebra kernels with mixed column- and panel-major arguments are easily
developed. This BLAS API has lower performance than the BLASFEO API, but it
nonetheless outperforms optimized BLAS and especially LAPACK libraries for
matrices fitting in cache. Therefore, it can boost a wide range of
applications, where standard BLAS and LAPACK libraries are employed and the
matrix size is moderate. In particular, this paper investigates the benefits in
scientific programming languages such as Octave, SciPy and Julia.
","['\nGianluca Frison\n', '\nTommaso Sartor\n', '\nAndrea Zanelli\n', '\nMoritz Diehl\n']",,"ACM Transactions on Mathematical Software (TOMS): Volume 46 Issue
  2, May 2020",http://dx.doi.org/10.1145/3378671,cs.MS,['cs.MS'],10.1145/3378671,,[]
"Distributed-memory parallelization of the aggregated unfitted finite
  element method",http://arxiv.org/abs/1902.01168v2,2019-02-04T13:24:47Z,2019-08-07T06:05:31Z,"  The aggregated unfitted finite element method (AgFEM) is a methodology
recently introduced in order to address conditioning and stability problems
associated with embedded, unfitted, or extended finite element methods. The
method is based on removal of basis functions associated with badly cut cells
by introducing carefully designed constraints, which results in well-posed
systems of linear algebraic equations, while preserving the optimal
approximation order of the underlying finite element spaces. The specific goal
of this work is to present the implementation and performance of the method on
distributed-memory platforms aiming at the efficient solution of large-scale
problems. In particular, we show that, by considering AgFEM, the resulting
systems of linear algebraic equations can be effectively solved using standard
algebraic multigrid preconditioners. This is in contrast with previous works
that consider highly customized preconditioners in order to allow one the usage
of iterative solvers in combination with unfitted techniques. Another novelty
with respect to the methods available in the literature is the problem sizes
that can be handled with the proposed approach. While most of previous
references discussing linear solvers for unfitted methods are based on serial
non-scalable algorithms, we propose a parallel distributed-memory method able
to efficiently solve problems at large scales. This is demonstrated by means of
a weak scaling test defined on complex 3D domains up to 300M degrees of freedom
and one billion cells on 16K CPU cores in the Marenostrum-IV platform. The
parallel implementation of the AgFEM method is available in the large-scale
finite element package FEMPAR.
","['\nFrancesc Verdugo\n', '\nAlberto F. Martín\n', '\nSantiago Badia\n']",,,http://dx.doi.org/10.1016/j.cma.2019.112583,cs.NA,"['cs.NA', 'cs.MS']",10.1016/j.cma.2019.112583,,[]
"Hierarchical Matrix Operations on GPUs: Matrix-Vector Multiplication and
  Compression",http://arxiv.org/abs/1902.01829v1,2019-02-05T17:59:51Z,2019-02-05T17:59:51Z,"  Hierarchical matrices are space and time efficient representations of dense
matrices that exploit the low rank structure of matrix blocks at different
levels of granularity. The hierarchically low rank block partitioning produces
representations that can be stored and operated on in near-linear complexity
instead of the usual polynomial complexity of dense matrices. In this paper, we
present high performance implementations of matrix vector multiplication and
compression operations for the $\mathcal{H}^2$ variant of hierarchical matrices
on GPUs. This variant exploits, in addition to the hierarchical block
partitioning, hierarchical bases for the block representations and results in a
scheme that requires only $O(n)$ storage and $O(n)$ complexity for the mat-vec
and compression kernels. These two operations are at the core of algebraic
operations for hierarchical matrices, the mat-vec being a ubiquitous operation
in numerical algorithms while compression/recompression represents a key
building block for other algebraic operations, which require periodic
recompression during execution. The difficulties in developing efficient GPU
algorithms come primarily from the irregular tree data structures that underlie
the hierarchical representations, and the key to performance is to recast the
computations on flattened trees in ways that allow batched linear algebra
operations to be performed. This requires marshaling the irregularly laid out
data in a way that allows them to be used by the batched routines. Marshaling
operations only involve pointer arithmetic with no data movement and as a
result have minimal overhead. Our numerical results on covariance matrices from
2D and 3D problems from spatial statistics show the high efficiency our
routines achieve---over 550GB/s for the bandwidth-limited mat-vec and over
850GFLOPS/s in sustained performance for the compression on the P100 Pascal
GPU.
","['\nWajih Halim Boukaram\n', '\nGeorge Turkiyyah\n', '\nDavid E. Keyes\n']",,,http://arxiv.org/abs/1902.01829v1,cs.DS,"['cs.DS', 'cs.MS']",,,[]
"Faster Remainder by Direct Computation: Applications to Compilers and
  Software Libraries",http://arxiv.org/abs/1902.01961v3,2019-02-05T22:33:20Z,2019-11-20T16:52:47Z,"  On common processors, integer multiplication is many times faster than
integer division. Dividing a numerator n by a divisor d is mathematically
equivalent to multiplication by the inverse of the divisor (n / d = n x 1/d).
If the divisor is known in advance---or if repeated integer divisions will be
performed with the same divisor---it can be beneficial to substitute a less
costly multiplication for an expensive division.
  Currently, the remainder of the division by a constant is computed from the
quotient by a multiplication and a subtraction. But if just the remainder is
desired and the quotient is unneeded, this may be suboptimal. We present a
generally applicable algorithm to compute the remainder more directly.
Specifically, we use the fractional portion of the product of the numerator and
the inverse of the divisor. On this basis, we also present a new, simpler
divisibility algorithm to detect nonzero remainders.
  We also derive new tight bounds on the precision required when representing
the inverse of the divisor. Furthermore, we present simple C implementations
that beat the optimized code produced by state-of-art C compilers on recent x64
processors (e.g., Intel Skylake and AMD Ryzen), sometimes by more than 25%. On
all tested platforms including 64-bit ARM and POWER8, our divisibility-test
functions are faster than state-of-the-art Granlund-Montgomery
divisibility-test functions, sometimes by more than 50%.
","['\nDaniel Lemire\n', '\nOwen Kaser\n', '\nNathan Kurz\n']",,"Software: Practice and Experience 49 (6), 2019",http://dx.doi.org/10.1002/spe.2689,cs.MS,"['cs.MS', 'cs.PF']",10.1002/spe.2689,,[]
Fast Strassen-based $A^t A$ Parallel Multiplication,http://arxiv.org/abs/1902.02104v1,2019-02-06T10:46:03Z,2019-02-06T10:46:03Z,"  Matrix multiplication $A^t A$ appears as intermediate operation during the
solution of a wide set of problems. In this paper, we propose a new
cache-oblivious algorithm for the $A^t A$ multiplication. Our algorithm,
A$\scriptstyle \mathsf{T}$A, calls classical Strassen's algorithm as
sub-routine, decreasing the computational cost %(expressed in number of
performed products) of the conventional $A^t A$ multiplication to
$\frac{2}{7}n^{\log_2 7}$. It works for generic rectangular matrices and
exploits the peculiar symmetry of the resulting product matrix for sparing
memory. We used the MPI paradigm to implement A$\scriptstyle \mathsf{T}$A in
parallel, and we tested its performances on a small subset of nodes of the
Galileo cluster. Experiments highlight good scalability and speed-up, also
thanks to minimal number of exchanged messages in the designed communication
system. Parallel overhead and inherently sequential time fraction are
negligible in the tested configurations.
","['\nViviana Arrigoni\n', '\nAnnalisa Massini\n']",,,http://arxiv.org/abs/1902.02104v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Supporting mixed-datatype matrix multiplication within the BLIS
  framework",http://arxiv.org/abs/1901.06015v2,2019-01-17T21:53:24Z,2019-05-02T00:21:38Z,"  We approach the problem of implementing mixed-datatype support within the
general matrix multiplication (GEMM) operation of the BLIS framework, whereby
each matrix operand A, B, and C may be stored as single- or double-precision
real or complex values. Another factor of complexity, whereby the computation
is allowed to take place in a precision different from the storage precisions
of either A or B, is also included in the discussion. We first break the
problem into mostly orthogonal dimensions, considering the mixing of domains
separately from mixing precisions. Support for all combinations of matrix
operands stored in either the real or complex domain is mapped out by
enumerating the cases and describing an implementation approach for each.
Supporting all combinations of storage and computation precisions is handled by
typecasting the matrices at key stages of the computation---during packing
and/or accumulation, as needed. Several optional optimizations are also
documented. Performance results gathered on a 56-core Marvell ThunderX2 and a
52-core Intel Xeon Platinum demonstrate that high performance is mostly
preserved, with modest slowdowns incurred from unavoidable typecast
instructions. The mixed-datatype implementation confirms that combinatoric
intractability is avoided, with the framework relying on only two assembly
microkernels to implement 128 datatype combinations.
","['\nField G. Van Zee\n', '\nDevangi N. Parikh\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1901.06015v2,cs.MS,['cs.MS'],,,[]
"TuckerMPI: A Parallel C++/MPI Software Package for Large-scale Data
  Compression via the Tucker Tensor Decomposition",http://arxiv.org/abs/1901.06043v2,2019-01-18T00:38:44Z,2019-08-21T23:45:27Z,"  Our goal is compression of massive-scale grid-structured data, such as the
multi-terabyte output of a high-fidelity computational simulation. For such
data sets, we have developed a new software package called TuckerMPI, a
parallel C++/MPI software package for compressing distributed data. The
approach is based on treating the data as a tensor, i.e., a multidimensional
array, and computing its truncated Tucker decomposition, a higher-order
analogue to the truncated singular value decomposition of a matrix. The result
is a low-rank approximation of the original tensor-structured data. Compression
efficiency is achieved by detecting latent global structure within the data,
which we contrast to most compression methods that are focused on local
structure. In this work, we describe TuckerMPI, our implementation of the
truncated Tucker decomposition, including details of the data distribution and
in-memory layouts, the parallel and serial implementations of the key kernels,
and analysis of the storage, communication, and computational costs. We test
the software on 4.5 terabyte and 6.7 terabyte data sets distributed across 100s
of nodes (1000s of MPI processes), achieving compression rates between
100-200,000$\times$ which equates to 99-99.999% compression (depending on the
desired accuracy) in substantially less time than it would take to even read
the same dataset from a parallel filesystem. Moreover, we show that our method
also allows for reconstruction of partial or down-sampled data on a single
node, without a parallel computer so long as the reconstructed portion is small
enough to fit on a single machine, e.g., in the instance of
reconstructing/visualizing a single down-sampled time step or computing summary
statistics.
","['\nGrey Ballard\n', '\nAlicia Klinvex\n', '\nTamara G. Kolda\n']",,"ACM Transactions on Mathematical Software, Vol. 46, No. 2, Article
  13, June 2020",http://dx.doi.org/10.1145/3378445,cs.MS,['cs.MS'],10.1145/3378445,,[]
ODE Test Problems: a MATLAB suite of initial value problems,http://arxiv.org/abs/1901.04098v1,2019-01-14T01:04:05Z,2019-01-14T01:04:05Z,"  ODE Test Problems (OTP) is an object-oriented MATLAB package offering a broad
range of initial value problems which can be used to test numerical methods
such as time integration methods and data assimilation (DA) methods. It
includes problems that are linear and nonlinear, homogeneous and
nonhomogeneous, autonomous and nonautonomous, scalar and high-dimensional,
stiff and nonstiff, and chaotic and nonchaotic. Many are real-world problems
from fields such as chemistry, astrophysics, meteorology, and electrical
engineering. OTP also supports partitioned ODEs for testing IMEX methods,
multirate methods, and other multimethods. Functions for plotting solutions and
creating movies are available for all problems, and exact solutions are
provided when available. OTP is desgined for ease of use-meaning that working
with and modifying problems is simple and intuitive.
","['\nSteven Roberts\n', '\nAndrey A. Popov\n', '\nAdrian Sandu\n']",,,http://arxiv.org/abs/1901.04098v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
Faster arbitrary-precision dot product and matrix multiplication,http://arxiv.org/abs/1901.04289v2,2019-01-14T13:25:49Z,2019-05-10T13:26:16Z,"  We present algorithms for real and complex dot product and matrix
multiplication in arbitrary-precision floating-point and ball arithmetic. A
low-overhead dot product is implemented on the level of GMP limb arrays; it is
about twice as fast as previous code in MPFR and Arb at precision up to several
hundred bits. Up to 128 bits, it is 3-4 times as fast, costing 20-30 cycles per
term for floating-point evaluation and 40-50 cycles per term for balls. We
handle large matrix multiplications even more efficiently via blocks of scaled
integer matrices. The new methods are implemented in Arb and significantly
speed up polynomial operations and linear algebra.
",['\nFredrik Johansson\nLFANT\n'],,"26th IEEE Symposium on Computer Arithmetic (ARITH26), Jun 2019,
  Kyoto, Japan",http://arxiv.org/abs/1901.04289v2,cs.MS,"['cs.MS', 'cs.NA']",,,['LFANT']
Sundials/ML: Connecting OCaml to the Sundials Numeric Solvers,http://arxiv.org/abs/1812.11668v1,2018-12-31T02:10:13Z,2018-12-31T02:10:13Z,"  This paper describes the design and implementation of a comprehensive OCaml
interface to the Sundials library of numeric solvers for ordinary differential
equations, differential algebraic equations, and non-linear equations. The
interface provides a convenient and memory-safe alternative to using Sundials
directly from C and facilitates application development by integrating with
higher-level language features, like garbage-collected memory management,
algebraic data types, and exceptions. Our benchmark results suggest that the
interface overhead is acceptable: the standard examples are rarely twice as
slow in OCaml than in C, and often less than 50% slower. The challenges in
interfacing with Sundials are to efficiently and safely share data structures
between OCaml and C, to support multiple implementations of vector operations
and linear solvers through a common interface, and to manage calls and error
signalling to and from OCaml. We explain how we overcame these difficulties
using a combination of standard techniques such as phantom types and
polymorphic variants, and carefully crafted data representations.
","['\nTimothy Bourke\nInria Paris & École normale supérieure, PSL University\n', '\nJun Inoue\nNational Institute of Advanced Industrial Science and Technology\n', '\nMarc Pouzet\nSorbonne Universités, UPMC Univ Paris 06 & École normale supérieure, PSL University & Inria Paris\n']","In Proceedings ML/OCAML 2016, arXiv:1812.10891","EPTCS 285, 2018, pp. 101-130",http://dx.doi.org/10.4204/EPTCS.285.4,cs.PL,"['cs.PL', 'cs.MS']",10.4204/EPTCS.285.4,,"['Inria Paris & École normale supérieure, PSL University', 'National Institute of Advanced Industrial Science and Technology', 'Sorbonne Universités, UPMC Univ Paris 06 & École normale supérieure, PSL University & Inria Paris']"
"DUNEuro -- A software toolbox for forward modeling in
  bioelectromagnetism",http://arxiv.org/abs/1901.02874v4,2019-01-09T18:52:01Z,2021-01-14T17:46:20Z,"  Accurate and efficient source analysis in electro- and magnetoencephalography
using sophisticated realistic head geometries requires advanced numerical
approaches. This paper presents DUNEuro, a free and open source C++ software
toolbox for forward modeling in bioelectromagnetism. Building upon the DUNE
framework, it provides implementations of modern fitted and unfitted finite
element methods to efficiently solve the forward problems in electro- and
magnetoencephalography. The user can choose between a variety of different
source models that are implemented. The software's aim is to provide interfaces
that are extendible and easy-to-use. In order to enable a closer integration
into existing analysis pipelines, interfaces to Python and Matlab are provided.
The practical use is demonstrated by a source analysis example of somatosensory
evoked potentials using a realistic six compartment head model.
","['\nSophie Schrader\n', '\nAndreas Westhoff\n', '\nMaria Carla Piastra\n', '\nTuuli Miinalainen\n', '\nSampsa Pursiainen\n', '\nJohannes Vorwerk\n', '\nHeinrich Brinck\n', '\nCarsten H. Wolters\n', '\nChristian Engwer\n']",,PLoS ONE 16.6 (2021): e0252431,http://dx.doi.org/10.1371/journal.pone.0252431,cs.MS,"['cs.MS', 'q-bio.NC']",10.1371/journal.pone.0252431,,[]
"Efficient and scalable data structures and algorithms for goal-oriented
  adaptivity of space-time FEM codes",http://arxiv.org/abs/1812.08558v1,2018-12-20T13:43:20Z,2018-12-20T13:43:20Z,"  The cost- and memory-efficient numerical simulation of coupled volume-based
multi-physics problems like flow, transport, wave propagation and others
remains a challenging task with finite element method (FEM) approaches.
Goal-oriented space and time adaptive methods derived from the dual weighted
residual (DWR) method appear to be a shiny key technology to generate optimal
space-time meshes to minimise costs. Current implementations for challenging
problems of numerical screening tools including the DWR technology broadly
suffer in their extensibility to other problems, in high memory consumption or
in missing system solver technologies. This work contributes to the efficient
embedding of DWR space-time adaptive methods into numerical screening tools for
challenging problems of physically relevance with a new approach of flexible
data structures and algorithms on them, a modularised and complete
implementation as well as illustrative examples to show the performance and
efficiency.
","['\nUwe Köcher\n', '\nMarius Paul Bruchhäuser\n', '\nMarkus Bause\n']",,,http://dx.doi.org/10.1016/j.softx.2019.100239,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1016/j.softx.2019.100239,,[]
Open source software in quantum computing,http://arxiv.org/abs/1812.09167v1,2018-12-21T14:56:18Z,2018-12-21T14:56:18Z,"  Open source software is becoming crucial in the design and testing of quantum
algorithms. Many of the tools are backed by major commercial vendors with the
goal to make it easier to develop quantum software: this mirrors how
well-funded open machine learning frameworks enabled the development of complex
models and their execution on equally complex hardware. We review a wide range
of open source software for quantum computing, covering all stages of the
quantum toolchain from quantum hardware interfaces through quantum compilers to
implementations of quantum algorithms, as well as all quantum computing
paradigms, including quantum annealing, and discrete and continuous-variable
gate-model quantum computing. The evaluation of each project covers
characteristics such as documentation, licence, the choice of programming
language, compliance with norms of software engineering, and the culture of the
project. We find that while the diversity of projects is mesmerizing, only a
few attract external developers and even many commercially backed frameworks
have shortcomings in software engineering. Based on these observations, we
highlight the best practices that could foster a more active community around
quantum computing software that welcomes newcomers to the field, but also
ensures high-quality, well-documented code.
","['\nMark Fingerhuth\n', '\nTomáš Babej\n', '\nPeter Wittek\n']","22 pages, 4 figures","Fingerhuth M, Babej T, Wittek P (2018) Open source software in
  quantum computing. PLoS ONE 13(12): e0208561",http://dx.doi.org/10.1371/journal.pone.0208561,quant-ph,"['quant-ph', 'cs.MS', 'cs.PL']",10.1371/journal.pone.0208561,,[]
Probabilistic Inference on Noisy Time Series (PINTS),http://arxiv.org/abs/1812.07388v1,2018-12-18T14:36:17Z,2018-12-18T14:36:17Z,"  Time series models are ubiquitous in science, arising in any situation where
researchers seek to understand how a system's behaviour changes over time. A
key problem in time series modelling is \emph{inference}; determining
properties of the underlying system based on observed time series. For both
statistical and mechanistic models, inference involves finding parameter
values, or distributions of parameters values, for which model outputs are
consistent with observations. A wide variety of inference techniques are
available and different approaches are suitable for different classes of
problems. This variety presents a challenge for researchers, who may not have
the resources or expertise to implement and experiment with these methods.
PINTS (Probabilistic Inference on Noisy Time Series -
https://github.com/pints-team/pints is an open-source (BSD 3-clause license)
Python library that provides researchers with a broad suite of non-linear
optimisation and sampling methods. It allows users to wrap a model and data in
a transparent and straightforward interface, which can then be used with custom
or pre-defined error measures for optimisation, or with likelihood functions
for Bayesian inference or maximum-likelihood estimation. Derivative-free
optimisation algorithms - which work without harder-to-obtain gradient
information - are included, as well as inference algorithms such as adaptive
Markov chain Monte Carlo and nested sampling which estimate distributions over
parameter values. By making these statistical techniques available in an open
and easy-to-use framework, PINTS brings the power of modern statistical
techniques to a wider scientific audience.
","['\nMichael Clerx\n', '\nMartin Robinson\n', '\nBen Lambert\n', '\nChon Lok Lei\n', '\nSanmitra Ghosh\n', '\nGary R. Mirams\n', '\nDavid J. Gavaghan\n']",,,http://dx.doi.org/10.5334/jors.252,cs.MS,['cs.MS'],10.5334/jors.252,,[]
Functional Design of Computation Graph,http://arxiv.org/abs/1812.03770v1,2018-12-10T12:52:03Z,2018-12-10T12:52:03Z,"  Representing the control flow of a computer program as a computation graph
can bring many benefits in a broad variety of domains where performance is
critical. This technique is a core component of most major numerical libraries
(TensorFlow, PyTorch, Theano, MXNet,...) and is successfully used to speed up
and optimise many computationally-intensive tasks. However, different design
choices in each of these libraries lead to noticeable differences in efficiency
and in the way an end user writes efficient code. In this report, we detail the
implementation and features of the computation graph support in OCaml's
numerical library Owl, a recent entry in the world of scientific computing.
",['\nPierre Vandenhove\n'],,,http://arxiv.org/abs/1812.03770v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
Disciplined Geometric Programming,http://arxiv.org/abs/1812.04074v2,2018-12-10T20:43:14Z,2019-03-20T23:50:14Z,"  We introduce log-log convex programs, which are optimization problems with
positive variables that become convex when the variables, objective functions,
and constraint functions are replaced with their logs, which we refer to as a
log-log transformation. This class of problems generalizes traditional
geometric programming and generalized geometric programming, and it includes
interesting problems involving nonnegative matrices. We give examples of
log-log convex functions, some well-known and some less so, and we develop an
analog of disciplined convex programming, which we call disciplined geometric
programming. Disciplined geometric programming is a subclass of log-log convex
programming generated by a composition rule and a set of functions with known
curvature under the log-log transformation. Finally, we describe an
implementation of disciplined geometric programming as a reduction in CVXPY
1.0.
","['\nAkshay Agrawal\n', '\nSteven Diamond\n', '\nStephen Boyd\n']","Fix typos: p2, changed ""g_i log-log concave"" to ""g_i log-log affine"";
  p6, max of log-log convex functions is log-log convex, not concave",,http://arxiv.org/abs/1812.04074v2,math.OC,"['math.OC', 'cs.MS']",,,[]
"Javelin: A Scalable Implementation for Sparse Incomplete LU
  Factorization",http://arxiv.org/abs/1812.06160v3,2018-12-13T15:20:41Z,2019-05-02T22:34:10Z,"  In this work, we present a new scalable incomplete LU factorization framework
called Javelin to be used as a preconditioner for solving sparse linear systems
with iterative methods. Javelin allows for improved parallel factorization on
shared-memory many-core systems by packaging the coefficient matrix into a
format that allows for high performance sparse matrix-vector multiplication and
sparse triangular solves with minimal overheads. The framework achieves these
goals by using a collection of traditional permutations, point-to-point thread
synchronizations, tasking, and segmented prefix scans in a conventional
compressed sparse row format. Moreover, this framework stresses the importance
of co-designing dependent tasks, such as sparse factorization and triangular
solves, on highly-threaded architectures. Using these changes, traditional
fill-in and drop tolerance methods can be used, while still being able to have
observed speedups of up to ~42x on 68 Intel Knights Landing cores and ~12x on
14 Intel Haswell cores.
","['\nJoshua Dennis Booth\n', '\nGregory Bolet\n']",,,http://arxiv.org/abs/1812.06160v3,cs.MS,"['cs.MS', 'cs.DC']",,,[]
A note on solving nonlinear optimization problems in variable precision,http://arxiv.org/abs/1812.03467v3,2018-12-09T12:16:33Z,2019-04-12T18:49:20Z,"  This short note considers an efficient variant of the trust-region algorithm
with dynamic accuracy proposed Carter (1993) and Conn, Gould and Toint (2000)
as a tool for very high-performance computing, an area where it is critical to
allow multi-precision computations for keeping the energy dissipation under
control. Numerical experiments are presented indicating that the use of the
considered method can bring substantial savings in objective function's and
gradient's evaluation ""energy costs"" by efficiently exploiting multi-precision
computations.
","['\nS. Gratton\n', '\nPh. L. Toint\n']","11 pages, 2 figures",,http://arxiv.org/abs/1812.03467v3,cs.NA,"['cs.NA', 'cs.LG', 'cs.MS', 'math.OC', '90C26, 90C30, 65K05', 'G.1.6; F.2.1; B.2.3; B.2.4; I.2.5']",,,[]
"Efficient Distributed-Memory Parallel Matrix-Vector Multiplication with
  Wide or Tall Unstructured Sparse Matrices",http://arxiv.org/abs/1812.00904v1,2018-12-03T17:03:15Z,2018-12-03T17:03:15Z,"  This paper presents an efficient technique for matrix-vector and
vector-transpose-matrix multiplication in distributed-memory parallel computing
environments, where the matrices are unstructured, sparse, and have a
substantially larger number of columns than rows or vice versa. Our method
allows for parallel I/O, does not require extensive preprocessing, and has the
same communication complexity as matrix-vector multiplies with column or row
partitioning. Our implementation of the method uses MPI. We partition the
matrix by individual nonzero elements, rather than by row or column, and use an
""overlapped"" vector representation that is matched to the matrix. The transpose
multiplies use matrix-specific MPI communicators and reductions that we show
can be set up in an efficient manner. The proposed technique achieves a good
work per processor balance even if some of the columns are dense, while keeping
communication costs relatively low.
","['\nJonathan Eckstein\n', '\nGyorgy Matyasfalvi\n']","8 pages, IEEE format",,http://arxiv.org/abs/1812.00904v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
Towards new solutions for scientific computing: the case of Julia,http://arxiv.org/abs/1812.01219v1,2018-12-04T05:07:20Z,2018-12-04T05:07:20Z,"  This year marks the consolidation of Julia (https://julialang.org/), a
programming language designed for scientific computing, as the first stable
version (1.0) has been released, in August 2018. Among its main features,
expressiveness and high execution speeds are the most prominent: the
performance of Julia code is similar to statically compiled languages, yet
Julia provides a nice interactive shell and fully supports Jupyter; moreover,
it can transparently call external codes written in C, Fortran, and even Python
and R without the need of wrappers. The usage of Julia in the astronomical
community is growing, and a GitHub organization named JuliaAstro takes care of
coordinating the development of packages. In this paper, we present the
features and shortcomings of this language and discuss its application in
astronomy and astrophysics.
","['\nMaurizio Tomasi\n', '\nMosè Giordano\n']",To appear in the Proceedings of ADASS2018,,http://arxiv.org/abs/1812.01219v1,astro-ph.IM,"['astro-ph.IM', 'cs.MS']",,,[]
"Practical Sparse Matrices in C++ with Hybrid Storage and Template-Based
  Expression Optimisation",http://arxiv.org/abs/1811.08768v3,2018-11-20T06:47:37Z,2019-07-22T06:10:51Z,"  Despite the importance of sparse matrices in numerous fields of science,
software implementations remain difficult to use for non-expert users,
generally requiring the understanding of underlying details of the chosen
sparse matrix storage format. In addition, to achieve good performance, several
formats may need to be used in one program, requiring explicit selection and
conversion between the formats. This can be both tedious and error-prone,
especially for non-expert users. Motivated by these issues, we present a
user-friendly and open-source sparse matrix class for the C++ language, with a
high-level application programming interface deliberately similar to the widely
used MATLAB language. This facilitates prototyping directly in C++ and aids the
conversion of research code into production environments. The class internally
uses two main approaches to achieve efficient execution: (i) a hybrid storage
framework, which automatically and seamlessly switches between three underlying
storage formats (compressed sparse column, Red-Black tree, coordinate list)
depending on which format is best suited and/or available for specific
operations, and (ii) a template-based meta-programming framework to
automatically detect and optimise execution of common expression patterns.
Empirical evaluations on large sparse matrices with various densities of
non-zero elements demonstrate the advantages of the hybrid storage framework
and the expression optimisation mechanism.
","['\nConrad Sanderson\n', '\nRyan Curtin\n']","extended and revised version of an earlier conference paper
  arXiv:1805.03380",,http://dx.doi.org/10.3390/mca24030070,cs.MS,"['cs.MS', '68N99, 65Y04, 65Y15, 65F50', 'G.4; G.1.3; H.3.4; E.1']",10.3390/mca24030070,,[]
Modeling Deep Learning Accelerator Enabled GPUs,http://arxiv.org/abs/1811.08309v2,2018-11-19T00:07:34Z,2019-02-21T02:11:33Z,"  The efficacy of deep learning has resulted in its use in a growing number of
applications. The Volta graphics processor unit (GPU) architecture from NVIDIA
introduced a specialized functional unit, the ""tensor core"", that helps meet
the growing demand for higher performance for deep learning. In this paper we
study the design of the tensor cores in NVIDIA's Volta and Turing
architectures. We further propose an architectural model for the tensor cores
in Volta. When implemented a GPU simulator, GPGPU-Sim, our tensor core model
achieves 99.6\% correlation versus an NVIDIA Titan~V GPU in terms of average
instructions per cycle when running tensor core enabled GEMM workloads. We also
describe support added to enable GPGPU-Sim to run CUTLASS, an open-source CUDA
C++ template library providing customizable GEMM templates that utilize tensor
cores.
","['\nMd Aamir Raihan\n', '\nNegar Goli\n', '\nTor Aamodt\n']",,,http://arxiv.org/abs/1811.08309v2,cs.MS,"['cs.MS', 'cs.AR']",,,[]
"Zeffiro user interface for electromagnetic brain imaging: a GPU
  accelerated FEM tool for forward and inverse computations in Matlab",http://arxiv.org/abs/1811.07717v4,2018-11-19T14:26:14Z,2019-09-03T08:56:03Z,"  This article introduces the Zeffiro interface (ZI) version 2.2 for brain
imaging. ZI aims to provide a simple, accessible and multimodal open source
platform for finite element method (FEM) based and graphics processing unit
(GPU) accelerated forward and inverse computations in the Matlab environment.
It allows one to (1) generate a given multi-compartment head model, (2) to
evaluate a lead field matrix as well as (3) to invert and analyze a given set
of measurements. GPU acceleration is applied in each of the processing stages
(1)-(3). In its current configuration, ZI includes forward solvers for
electro-/magnetoencephalography (EEG) and linearized electrical impedance
tomography (EIT) as well as a set of inverse solvers based on the hierarchical
Bayesian model (HBM). We report the results of EEG and EIT inversion tests
performed with real and synthetic data, respectively, and demonstrate
numerically how the inversion parameters affect the EEG inversion outcome in
HBM. The GPU acceleration was found to be essential in the generation of the FE
mesh and the LF matrix in order to achieve a reasonable computing time. The
code package can be extended in the future based on the directions given in
this article.
","['\nQin He\n', '\nAtena Rezaei\n', '\nSampsa Pursiainen\n']",,,http://arxiv.org/abs/1811.07717v4,cs.MS,"['cs.MS', 'cs.CE', 'math.AP', '65L60, 65N30, 34A55, 34M50, 92C50', 'G.1.8']",,,[]
Sound Approximation of Programs with Elementary Functions,http://arxiv.org/abs/1811.10274v1,2018-11-26T10:30:04Z,2018-11-26T10:30:04Z,"  Elementary function calls are a common feature in numerical programs. While
their implementions in library functions are highly optimized, their
computation is nonetheless very expensive compared to plain arithmetic. Full
accuracy is, however, not always needed. Unlike arithmetic, where the
performance difference between for example single and double precision
floating-point arithmetic is relatively small, elementary function calls
provide a much richer tradeoff space between accuracy and efficiency.
Navigating this space is challenging. First, generating approximations of
elementary function calls which are guaranteed to satisfy accuracy error bounds
is highly nontrivial. Second, the performance of such approximations generally
depends on several parameters which are unintuitive to choose manually,
especially for non-experts.
  We present a fully automated approach and tool which approximates elementary
function calls inside small programs while guaranteeing overall user provided
error bounds. Our tool leverages existing techniques for roundoff error
computation and approximation of individual elementary function calls, and
provides automated selection of many parameters. Our experiments show that
significant efficiency improvements are possible in exchange for reduced, but
guaranteed, accuracy.
","['\nEva Darulova\n', '\nAnastasia Volkova\n']",,,http://arxiv.org/abs/1811.10274v1,cs.NA,"['cs.NA', 'cs.MS', 'cs.PL']",,,[]
A Review of automatic differentiation and its efficient implementation,http://arxiv.org/abs/1811.05031v2,2018-11-12T22:52:46Z,2019-01-14T11:37:12Z,"  Derivatives play a critical role in computational statistics, examples being
Bayesian inference using Hamiltonian Monte Carlo sampling and the training of
neural networks. Automatic differentiation is a powerful tool to automate the
calculation of derivatives and is preferable to more traditional methods,
especially when differentiating complex algorithms and mathematical functions.
The implementation of automatic differentiation however requires some care to
insure efficiency. Modern differentiation packages deploy a broad range of
computational techniques to improve applicability, run time, and memory
management. Among these techniques are operation overloading, region based
memory, and expression templates. There also exist several mathematical
techniques which can yield high performance gains when applied to complex
algorithms. For example, semi-analytical derivatives can reduce by orders of
magnitude the runtime required to numerically solve and differentiate an
algebraic equation. Open problems include the extension of current packages to
provide more specialized routines, and efficient methods to perform
higher-order differentiation.
",['\nCharles C. Margossian\n'],"32 pages, 5 figures, submitted for publication. WIREs Data Mining
  Knowl Discov, March 2019",,http://dx.doi.org/10.1002/WIDM.1305,cs.MS,"['cs.MS', 'stat.CO']",10.1002/WIDM.1305,,[]
"FusionStitching: Deep Fusion and Code Generation for Tensorflow
  Computations on GPUs",http://arxiv.org/abs/1811.05213v1,2018-11-13T11:03:16Z,2018-11-13T11:03:16Z,"  In recent years, there is a surge on machine learning applications in
industry. Many of them are based on popular AI frameworks like Tensorflow,
Torch, Caffe, or MxNet, etc, and are enpowered by accelerator platforms such as
GPUs. One important challenge of running Tensorflow computations on GPUs is the
fine granularity problem, namely, FLOPS of individual ops are far from enough
to fully exploit the computing power of underlying accelerators. The XLA
framework provides a solid foundation to explore this problem further. In this
paper, we propose FusionStitching, a novel, comprehensive Op fusion and code
generation system to stitch computations into large GPU kernels. Experimental
results on four public models and two of our large inhouse applications show
another 55% (geometric mean) reduction of GPU kernel launches, compared to the
XLA fusion baseline. This increases the E2E performance of both of our latency
critical inhouse applications up to 20%.
","['\nGuoping Long\n', '\nJun Yang\n', '\nKai Zhu\n', '\nWei Lin\n']","11 pages, 8 figures",,http://arxiv.org/abs/1811.05213v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"AMGCL: an Efficient, Flexible, and Extensible Algebraic Multigrid
  Implementation",http://arxiv.org/abs/1811.05704v1,2018-11-14T09:56:30Z,2018-11-14T09:56:30Z,"  The paper presents AMGCL -- an opensource C++ library implementing the
algebraic multigrid method (AMG) for solution of large sparse linear systems of
equations, usually arising from discretization of partial differential
equations on an unstructured grid. The library supports both shared and
distributed memory computation, allows to utilize modern massively parallel
processors via OpenMP, OpenCL, or CUDA technologies, has minimal dependencies,
and is easily extensible. The design principles behind AMGCL are discussed and
it is shown that the code performance is on par with alternative
implementations.
",['\nDenis Demidov\n'],,,http://dx.doi.org/10.1134/S1995080219050056,cs.MS,"['cs.MS', 'cs.DC', '35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80']",10.1134/S1995080219050056,,[]
Gravitational octree code performance evaluation on Volta GPU,http://arxiv.org/abs/1811.02761v1,2018-11-07T05:00:23Z,2018-11-07T05:00:23Z,"  In this study, the gravitational octree code originally optimized for the
Fermi, Kepler, and Maxwell GPU architectures is adapted to the Volta
architecture. The Volta architecture introduces independent thread scheduling
requiring either the insertion of the explicit synchronizations at appropriate
locations or the enforcement of the same implicit synchronizations as do the
Pascal or earlier architectures by specifying \texttt{-gencode
arch=compute\_60,code=sm\_70}. The performance measurements on Tesla V100, the
current flagship GPU by NVIDIA, revealed that the $N$-body simulations of the
Andromeda galaxy model with $2^{23} = 8388608$ particles took $3.8 \times
10^{-2}$~s or $3.3 \times 10^{-2}$~s per step for each case. Tesla V100
achieves a 1.4 to 2.2-fold acceleration in comparison with Tesla P100, the
flagship GPU in the previous generation. The observed speed-up of 2.2 is
greater than 1.5, which is the ratio of the theoretical peak performance of the
two GPUs. The independence of the units for integer operations from those for
floating-point number operations enables the overlapped execution of integer
and floating-point number operations. It hides the execution time of the
integer operations leading to the speed-up rate above the theoretical peak
performance ratio. Tesla V100 can execute $N$-body simulation with up to $25
\times 2^{20} = 26214400$ particles, and it took $2.0 \times 10^{-1}$~s per
step. It corresponds to $3.5$~TFlop/s, which is 22\% of the single-precision
theoretical peak performance.
",['\nYohei Miki\n'],"10 pages, 10 figures, 2 tables, submitted to Computer Physics
  Communications",,http://arxiv.org/abs/1811.02761v1,cs.MS,"['cs.MS', 'astro-ph.IM', 'cs.PF', 'physics.comp-ph']",,,[]
A Feature Complete SPIKE Banded Algorithm and Solver,http://arxiv.org/abs/1811.03559v1,2018-11-08T17:28:23Z,2018-11-08T17:28:23Z,"  New features and enhancements for the SPIKE banded solver are presented.
Among all the SPIKE algorithm versions, we focus our attention on the recursive
SPIKE technique which provides the best trade-off between generality and
parallel efficiency, but was known for its lack of flexibility. Its application
was essentially limited to power of two number of cores/processors. This
limitation is successfully addressed in this paper. In addition, we present a
new transpose solve option, a standard feature of most numerical solver
libraries which has never been addressed by the SPIKE algorithm so far. A
pivoting recursive SPIKE strategy is finally presented as an alternative to
non-pivoting scheme for systems with large condition numbers. All these new
enhancements participate to create a feature complete SPIKE algorithm and a new
black-box SPIKE-OpenMP package that significantly outperforms the performance
and scalability obtained with other state-of-the-art banded solvers.
","['\nBraegan S. Spring\n', '\nEric Polizzi\n', '\nAhmed H. Sameh\n']",,,http://arxiv.org/abs/1811.03559v1,cs.NA,"['cs.NA', 'cs.CE', 'cs.MS']",,,[]
"Applying the swept rule for solving explicit partial differential
  equations on heterogeneous computing systems",http://arxiv.org/abs/1811.08282v2,2018-11-14T20:22:04Z,2020-05-13T18:43:27Z,"  Applications that exploit the architectural details of high-performance
computing (HPC) systems have become increasingly invaluable in academia and
industry over the past two decades. The most important hardware development of
the last decade in HPC has been the General Purpose Graphics Processing Unit
(GPGPU), a class of massively parallel devices that now contributes the
majority of computational power in the top 500 supercomputers. As these systems
grow, small costs such as latency---due to the fixed cost of memory accesses
and communication---accumulate in a large simulation and become a significant
barrier to performance. The swept time-space decomposition rule is a
communication-avoiding technique for time-stepping stencil update formulas that
attempts to reduce latency costs. This work extends the swept rule by targeting
heterogeneous, CPU/GPU architectures representing current and future HPC
systems. We compare our approach to a naive decomposition scheme with two test
equations using an MPI+CUDA pattern on 40 processes over two nodes containing
one GPU. The swept rule produces a factor of 1.9 to 23 speedup for the heat
equation and a factor of 1.1 to 2.0 speedup for the Euler equations, using the
same processors and work distribution, and with the best possible
configurations. These results show the potential effectiveness of the swept
rule for different equations and numerical schemes on massively parallel
computing systems that incur substantial latency costs.
","['\nDaniel J. Magee\n', '\nAnthony S. Walker\n', '\nKyle E. Niemeyer\n']","24 pages, 9 figures. Accepted for publication by the Journal of
  Supercomputing",,http://arxiv.org/abs/1811.08282v2,cs.MS,"['cs.MS', 'cs.DC', 'physics.comp-ph']",,,[]
Optimizations of the Eigensolvers in the ELPA Library,http://arxiv.org/abs/1811.01277v1,2018-11-03T20:07:06Z,2018-11-03T20:07:06Z,"  The solution of (generalized) eigenvalue problems for symmetric or Hermitian
matrices is a common subtask of many numerical calculations in electronic
structure theory or materials science. Solving the eigenvalue problem can
easily amount to a sizeable fraction of the whole numerical calculation. For
researchers in the field of computational materials science, an efficient and
scalable solution of the eigenvalue problem is thus of major importance. The
ELPA-library is a well-established dense direct eigenvalue solver library,
which has proven to be very efficient and scalable up to very large core
counts. In this paper, we describe the latest optimizations of the ELPA-library
for new HPC architectures of the Intel Skylake processor family with an AVX-512
SIMD instruction set, or for HPC systems accelerated with recent GPUs. We also
describe a complete redesign of the API in a modern modular way, which, apart
from a much simpler and more flexible usability, leads to a new path to access
system-specific performance optimizations. In order to ensure optimal
performance for a particular scientific setting or a specific HPC system, the
new API allows the user to influence in straightforward way the internal
details of the algorithms and of performance-critical parameters used in the
ELPA-library. On top of that, we introduced an autotuning functionality, which
allows for finding the best settings in a self-contained automated way. In
situations where many eigenvalue problems with similar settings have to be
solved consecutively, the autotuning process of the ELPA-library can be done
""on-the-fly"". Practical applications from materials science which rely on
so-called self-consistency iterations can profit from the autotuning. On some
examples of scientific interest, simulated with the FHI-aims application, the
advantages of the latest optimizations of the ELPA-library are demonstrated.
","['\nP. Kus\n', '\nA. Marek\n', '\nS. S. Koecher\n', '\nH. -H. Kowalski\n', '\nC. Carbogno\n', '\nCh. Scheurer\n', '\nK. Reuter\n', '\nM. Scheffler\n', '\nH. Lederer\n']",,"Parallel Computing 85, pp 167-177 (2019)",http://dx.doi.org/10.1016/j.parco.2019.04.003,cs.MS,['cs.MS'],10.1016/j.parco.2019.04.003,,[]
"Issues in the software implementation of stochastic numerical
  Runge-Kutta",http://arxiv.org/abs/1811.01719v1,2018-11-01T08:20:49Z,2018-11-01T08:20:49Z,"  This paper discusses stochastic numerical methods of Runge-Kutta type with
weak and strong convergences for systems of stochastic differential equations
in It\^o form. At the beginning we give a brief overview of the stochastic
numerical methods and information from the theory of stochastic differential
equations. Then we motivate the approach to the implementation of these methods
using source code generation. We discuss the implementation details and the
used programming languages and libraries
","['\nMigran N. Gevorkyan\n', '\nAnastasia V. Demidova\n', '\nAnna V. Korolkova\n', '\nDmitry S. Kulyabov\n']","in English, in Russian",,http://dx.doi.org/10.1007/978-3-319-99447-5_46,cs.NA,"['cs.NA', 'cs.MS']",10.1007/978-3-319-99447-5_46,,[]
"A Search for Good Pseudo-random Number Generators : Survey and Empirical
  Studies",http://arxiv.org/abs/1811.04035v1,2018-11-03T07:32:23Z,2018-11-03T07:32:23Z,"  In today's world, several applications demand numbers which appear random but
are generated by a background algorithm; that is, pseudo-random numbers. Since
late $19^{th}$ century, researchers have been working on pseudo-random number
generators (PRNGs). Several PRNGs continue to develop, each one demanding to be
better than the previous ones. In this scenario, this paper targets to verify
the claim of so-called good generators and rank the existing generators based
on strong empirical tests in same platforms. To do this, the genre of PRNGs
developed so far has been explored and classified into three groups -- linear
congruential generator based, linear feedback shift register based and cellular
automata based. From each group, well-known generators have been chosen for
empirical testing. Two types of empirical testing has been done on each PRNG --
blind statistical tests with Diehard battery of tests, TestU01 library and NIST
statistical test-suite and graphical tests (lattice test and space-time diagram
test). Finally, the selected $29$ PRNGs are divided into $24$ groups and are
ranked according to their overall performance in all empirical tests.
","['\nKamalika Bhattacharjee\n', '\nKrishnendu Maity\n', '\nSukanta Das\n']",,"Computer Science Review Volume 45, August 2022, 100471",http://dx.doi.org/10.1016/j.cosrev.2022.100471,cs.CR,"['cs.CR', 'cs.MS']",10.1016/j.cosrev.2022.100471,,[]
Dynamic Automatic Differentiation of GPU Broadcast Kernels,http://arxiv.org/abs/1810.08297v3,2018-10-18T22:52:52Z,2018-10-24T21:05:28Z,"  We show how forward-mode automatic differentiation (AD) can be employed
within larger reverse-mode computations to dynamically differentiate broadcast
operations in a GPU-friendly manner. Our technique fully exploits the broadcast
Jacobian's inherent sparsity structure, and unlike a pure reverse-mode
approach, this ""mixed-mode"" approach does not require a backwards pass over the
broadcasted operation's subgraph, obviating the need for several
reverse-mode-specific programmability restrictions on user-authored broadcast
operations. Most notably, this approach allows broadcast fusion in primal code
despite the presence of data-dependent control flow. We discuss an experiment
in which a Julia implementation of our technique outperformed pure reverse-mode
TensorFlow and Julia implementations for differentiating through broadcast
operations within an HM-LSTM cell update calculation.
","['\nJarrett Revels\n', '\nTim Besard\n', '\nValentin Churavy\n', '\nBjorn De Sutter\n', '\nJuan Pablo Vielma\n']",,,http://arxiv.org/abs/1810.08297v3,cs.MS,['cs.MS'],,,[]
Nonequispaced Fast Fourier Transform (NFFT) Interface for Julia,http://arxiv.org/abs/1810.09891v1,2018-10-23T14:46:09Z,2018-10-23T14:46:09Z,"  This report describes the newly added Julia interface to the NFFT3 library.
We explain the multidimensional NFFT algorithm and basics of the interface.
Furthermore, we go into detail about the different parameters and how to adjust
them properly.
",['\nMichael Schmischke\n'],"19 pages, 12 figures",,http://arxiv.org/abs/1810.09891v1,cs.MS,['cs.MS'],,,[]
The Ocean Tensor Package,http://arxiv.org/abs/1810.08723v1,2018-10-20T00:56:12Z,2018-10-20T00:56:12Z,"  Matrix and tensor operations form the basis of a wide range of fields and
applications, and in many cases constitute a substantial part of the overall
computational complexity. The ability of general-purpose GPUs to speed up many
of these operations and enable others has resulted in a widespread adaptation
of these devices. In order for tensor operations to take full advantage of the
computational power, specialized software is required, and currently there
exist several packages (predominantly in the area of deep learning) that
incorporate tensor operations on both CPU and GPU. Nevertheless, a stand-alone
framework that supports general tensor operations is still missing. In this
paper we fill this gap and propose the Ocean Tensor Library: a modular
tensor-support package that is designed to serve as a foundational layer for
applications that require dense tensor operations on a variety of device types.
The API is carefully designed to be powerful, extensible, and at the same time
easy to use. The package is available as open source.
",['\nEwout van den Berg\n'],,,http://arxiv.org/abs/1810.08723v1,cs.MS,"['cs.MS', 'cs.LG', 'G.4']",,,[]
"Optimizing AIREBO: Navigating the Journey from Complex Legacy Code to
  High Performance",http://arxiv.org/abs/1810.07026v1,2018-10-16T14:21:18Z,2018-10-16T14:21:18Z,"  Despite initiatives to improve the quality of scientific codes, there still
is a large presence of legacy code. Such code often needs to implement a lot of
functionality under time constrains, sacrificing quality. Additionally, quality
is rarely improved by optimizations for new architectures. This development
model leads to code that is increasingly difficult to work with. Our suggested
solution includes complexity-reducing refactoring and hardware abstraction. We
focus on the AIREBO potential from LAMMPS, where the challenge is that any
potential kernel is rather large and complex, hindering systematic
optimization. This issue is common to codes that model multiple physical
phenomena. We present our journey from the C++ port of a previous Fortran code
to performance-portable, KNC-hybrid, vectorized, scalable, optimized code
supporting full and reduced precision. The journey includes extensive testing
that fixed bugs in the original code. Large-scale, full-precision runs sustain
speedups of more than 4x (KNL) and 3x (Skylake).
","['\nMarkus Höhnerbach\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1810.07026v1,cs.CE,"['cs.CE', 'cs.DC', 'cs.MS']",,,[]
ensmallen: a flexible C++ library for efficient function optimization,http://arxiv.org/abs/1810.09361v2,2018-10-22T15:26:35Z,2018-12-10T04:37:09Z,"  We present ensmallen, a fast and flexible C++ library for mathematical
optimization of arbitrary user-supplied functions, which can be applied to many
machine learning problems. Several types of optimizations are supported,
including differentiable, separable, constrained, and categorical objective
functions. The library provides many pre-built optimizers (including numerous
variants of SGD and Quasi-Newton optimizers) as well as a flexible framework
for implementing new optimizers and objective functions. Implementation of a
new optimizer requires only one method and a new objective function requires
typically one or two C++ functions. This can aid in the quick implementation
and prototyping of new machine learning algorithms. Due to the use of C++
template metaprogramming, ensmallen is able to support compiler optimizations
that provide fast runtimes. Empirical comparisons show that ensmallen is able
to outperform other optimization frameworks (like Julia and SciPy), sometimes
by large margins. The library is distributed under the BSD license and is ready
for use in production environments.
","['\nShikhar Bhardwaj\n', '\nRyan R. Curtin\n', '\nMarcus Edel\n', '\nYannis Mentekidis\n', '\nConrad Sanderson\n']","Workshop on Systems for ML and Open Source Software at NIPS /
  NeurIPS, 2018",,http://dx.doi.org/10.5281/zenodo.2008650,cs.MS,"['cs.MS', 'cs.LG', 'math.OC', '65K10, 68N99, 68W99, 90C53', 'G.1.6, G.4']",10.5281/zenodo.2008650,,[]
CatBoost: gradient boosting with categorical features support,http://arxiv.org/abs/1810.11363v1,2018-10-24T13:08:24Z,2018-10-24T13:08:24Z,"  In this paper we present CatBoost, a new open-sourced gradient boosting
library that successfully handles categorical features and outperforms existing
publicly available implementations of gradient boosting in terms of quality on
a set of popular publicly available datasets. The library has a GPU
implementation of learning algorithm and a CPU implementation of scoring
algorithm, which are significantly faster than other gradient boosting
libraries on ensembles of similar sizes.
","['\nAnna Veronika Dorogush\n', '\nVasily Ershov\n', '\nAndrey Gulin\n']",,,http://arxiv.org/abs/1810.11363v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
"Studies on the energy and deep memory behaviour of a cache-oblivious,
  task-based hyperbolic PDE solver",http://arxiv.org/abs/1810.03940v4,2018-10-09T12:37:46Z,2019-03-25T14:22:14Z,"  We study the performance behaviour of a seismic simulation using the ExaHyPE
engine with a specific focus on memory characteristics and energy needs.
ExaHyPE combines dynamically adaptive mesh refinement (AMR) with ADER-DG. It is
parallelized using tasks, and it is cache efficient. AMR plus ADER-DG yields a
task graph which is highly dynamic in nature and comprises both arithmetically
expensive tasks and tasks which challenge the memory's latency. The expensive
tasks and thus the whole code benefit from AVX vectorization, though we suffer
from memory access bursts. A frequency reduction of the chip improves the
code's energy-to-solution. Yet, it does not mitigate burst effects. The bursts'
latency penalty becomes worse once we add Intel Optane technology, increase the
core count significantly, or make individual, computationally heavy tasks fall
out of close caches. Thread overbooking to hide away these latency penalties
contra-productive with non-inclusive caches as it destroys the cache and
vectorization character. In cases where memory-intense and computationally
expensive tasks overlap, ExaHyPE's cache-oblivious implementation can exploit
deep, non-inclusive, heterogeneous memory effectively, as main memory misses
arise infrequently and slow down only few cores. We thus propose that upcoming
supercomputing simulation codes with dynamic, inhomogeneous task graphs are
actively supported by thread runtimes in intermixing tasks of different compute
character, and we propose that future hardware actively allows codes to
downclock the cores running particular task types.
","['\nDominic E. Charrier\n', '\nBenjamin Hazelwood\n', '\nEkaterina Tutlyaeva\n', '\nMichael Bader\n', '\nMichael Dumbser\n', '\nAndrey Kudryavtsev\n', '\nAlexander Moskovsky\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1177/1094342019842645,cs.MS,['cs.MS'],10.1177/1094342019842645,,[]
Coloured and task-based stencil codes,http://arxiv.org/abs/1810.04033v1,2018-10-09T14:37:52Z,2018-10-09T14:37:52Z,"  Simple stencil codes are and remain an important building block in scientific
computing. On shared memory nodes, they are traditionally parallelised through
colouring or (recursive) tiling. New OpenMP versions alternatively allow users
to specify data dependencies explicitly and to outsource the decision how to
distribute the work to the runtime system. We evaluate traditional
multithreading strategies on both Broadwell and KNL, study the arising
assignment of tasks to threads and, from there, derive two efficient ways to
parallelise stencil codes on regular Cartesian grids that fuse colouring and
task-based approaches.
","['\nBenjamin Hazelwood\n', '\nTobias Weinzierl\n']",10 pages,,http://arxiv.org/abs/1810.04033v1,cs.MS,['cs.MS'],,,[]
"GPdoemd: a Python package for design of experiments for model
  discrimination",http://arxiv.org/abs/1810.02561v3,2018-10-05T08:02:28Z,2019-03-08T15:24:29Z,"  Model discrimination identifies a mathematical model that usefully explains
and predicts a given system's behaviour. Researchers will often have several
models, i.e. hypotheses, about an underlying system mechanism, but insufficient
experimental data to discriminate between the models, i.e. discard inaccurate
models. Given rival mathematical models and an initial experimental data set,
optimal design of experiments suggests maximally informative experimental
observations that maximise a design criterion weighted by prediction
uncertainty. The model uncertainty requires gradients, which may not be readily
available for black-box models. This paper (i) proposes a new design criterion
using the Jensen-R\'enyi divergence, and (ii) develops a novel method replacing
black-box models with Gaussian process surrogates. Using the surrogates, we
marginalise out the model parameters with approximate inference. Results show
these contributions working well for both classical and new test instances. We
also (iii) introduce and discuss GPdoemd, the open-source implementation of the
Gaussian process surrogate method.
","['\nSimon Olofsson\n', '\nLukas Hebing\n', '\nSebastian Niedenführ\n', '\nMarc Peter Deisenroth\n', '\nRuth Misener\n']",,"Computers & Chemical Engineering, Volume 125, 2019, Pages 54-70",http://dx.doi.org/10.1016/j.compchemeng.2019.03.010,cs.MS,"['cs.MS', 'stat.ML']",10.1016/j.compchemeng.2019.03.010,,[]
"Matrix-free construction of HSS representation using adaptive randomized
  sampling",http://arxiv.org/abs/1810.04125v2,2018-10-09T16:50:10Z,2018-10-11T18:55:38Z,"  We present new algorithms for the randomized construction of hierarchically
semi-separable matrices, addressing several practical issues. The HSS
construction algorithms use a partially matrix-free, adaptive randomized
projection scheme to determine the maximum off-diagonal block rank. We develop
both relative and absolute stopping criteria to determine the minimum dimension
of the random projection matrix that is sufficient for the desired accuracy.
Two strategies are discussed to adaptively enlarge the random sample matrix:
repeated doubling of the number of random vectors, and iteratively incrementing
the number of random vectors by a fixed number. The relative and absolute
stopping criteria are based on probabilistic bounds for the Frobenius norm of
the random projection of the Hankel blocks of the input matrix. We discuss
parallel implementation and computation and communication cost of both
variants. Parallel numerical results for a range of applications, including
boundary element method matrices and quantum chemistry Toeplitz matrices, show
the effectiveness, scalability and numerical robustness of the proposed
algorithms.
","['\nChristopher Gorman\n', '\nGustavo Chávez\n', '\nPieter Ghysels\n', '\nThéo Mary\n', '\nFrançois-Henry Rouet\n', '\nXiaoye Sherry Li\n']","24 pages, 4 figures, 20 references",,http://arxiv.org/abs/1810.04125v2,cs.NA,"['cs.NA', 'cs.MS']",,,[]
"Expressing Sparse Matrix Computations for Productive Performance on
  Spatial Architectures",http://arxiv.org/abs/1810.07517v1,2018-10-12T18:37:06Z,2018-10-12T18:37:06Z,"  This paper addresses spatial programming of sparse matrix computations for
productive performance. The challenge is how to express an irregular
computation and its optimizations in a regular way.
  A sparse matrix has (non-zero) values and a structure. In this paper, we
propose to classify the implementations of a computation on a sparse matrix
into two categories: (1) structure-driven, or top-down, approach, which
traverses the structure with given row and column indices and locates the
corresponding values, and (2) values-driven, or bottom-up, approach, which
loads and processes the values in parallel streams, and decodes the structure
for the values' corresponding row and column indices.
  On a spatial architecture like FPGAs, the values-driven approach is the norm.
We show how to express a sparse matrix computation and its optimizations for a
values-driven implementation. A compiler automatically synthesizes a code to
decode the structure. In this way, programmers focus on optimizing the
processing of the values, using familiar optimizations for dense matrices,
while leaving the complex, irregular structure traversal to an automatic
compiler. We also attempt to regularize the optimizations of the reduction for
a dynamic number of values, which is common in a sparse matrix computation.
",['\nHongbo Rong\n'],,,http://arxiv.org/abs/1810.07517v1,cs.MS,"['cs.MS', 'cs.PL']",,,[]
"Software for Sparse Tensor Decomposition on Emerging Computing
  Architectures",http://arxiv.org/abs/1809.09175v2,2018-09-24T19:19:05Z,2019-01-22T00:34:29Z,"  In this paper, we develop software for decomposing sparse tensors that is
portable to and performant on a variety of multicore, manycore, and GPU
computing architectures. The result is a single code whose performance matches
optimized architecture-specific implementations. The key to a portable approach
is to determine multiple levels of parallelism that can be mapped in different
ways to different architectures, and we explain how to do this for the
matricized tensor times Khatri-Rao product (MTTKRP) which is the key kernel in
canonical polyadic tensor decomposition. Our implementation leverages the
Kokkos framework, which enables a single code to achieve high performance
across multiple architectures that differ in how they approach fine-grained
parallelism. We also introduce a new construct for portable thread-local
arrays, which we call compile-time polymorphic arrays. Not only are the
specifics of our approaches and implementation interesting for tuning tensor
computations, but they also provide a roadmap for developing other portable
high-performance codes. As a last step in optimizing performance, we modify the
MTTKRP algorithm itself to do a permuted traversal of tensor nonzeros to reduce
atomic-write contention. We test the performance of our implementation on 16-
and 68-core Intel CPUs and the K80 and P100 NVIDIA GPUs, showing that we are
competitive with state-of-the-art architecture-specific codes while having the
advantage of being able to run on a variety of architectures.
","['\nEric Phipps\n', '\nTamara G. Kolda\n']",,"SIAM Journal on Scientific Computing, Vol. 41, No. 3, pp.
  C269-C290, 22 pages, 2019",http://dx.doi.org/10.1137/18M1210691,cs.MS,['cs.MS'],10.1137/18M1210691,,[]
FDBB: Fluid Dynamics Building Blocks,http://arxiv.org/abs/1809.09851v1,2018-09-26T08:50:08Z,2018-09-26T08:50:08Z,"  High-performance computing platforms are becoming more and more
heterogeneous, which makes it very difficult for researchers and scientific
software developers to keep up with the rapid changes on the hardware market.
In this paper, the open-source project FDBB (Fluid Dynamics Building Blocks) is
presented, which eases the development of fluid dynamics applications for
heterogeneous systems. It consists of a low-level API that provides a unified
interface to many different linear algebra back-ends and a lightweight and
extendible high-level expression template library, which provides largely
customizable fluid dynamics building blocks, like transformations between
primary and secondary variables as well as expressions for Riemann invariants,
equations of state, inviscid fluxes and their flux-Jacobians. The performance
of the developed approach is assessed both for synthetic micro-benchmarks and
within mini-applications.
","['\nMatthias Möller\n', '\nAndrzej Jaeschke\n']",,,http://arxiv.org/abs/1809.09851v1,cs.MS,['cs.MS'],,,[]
Multiscale finite element calculations in Python using SfePy,http://arxiv.org/abs/1810.00674v1,2018-10-01T12:41:29Z,2018-10-01T12:41:29Z,"  SfePy (Simple finite elements in Python) is a software for solving various
kinds of problems described by partial differential equations in one, two or
three spatial dimensions by the finite element method. Its source code is
mostly (85\%) Python and relies on fast vectorized operations provided by the
NumPy package. For a particular problem two interfaces can be used: a
declarative application programming interface (API), where problem
description/definition files (Python modules) are used to define a calculation,
and an imperative API, that can be used for interactive commands, or in scripts
and libraries. After outlining the SfePy package development, the paper
introduces its implementation, structure and general features. The components
for defining a partial differential equation are described using an example of
a simple heat conduction problem. Specifically, the declarative API of SfePy is
presented in the example. To illustrate one of SfePy's main assets, the
framework for implementing complex multiscale models based on the theory of
homogenization, an example of a two-scale piezoelastic model is presented,
showing both the mathematical description of the problem and the corresponding
code.
","['\nRobert Cimrman\n', '\nVladimír Lukeš\n', '\nEduard Rohan\n']","This manuscript version is made available under the CC-BY-NC-ND 4.0
  license","Advances in Computational Mathematics, 45(4): 1897-1921 (2019)",http://dx.doi.org/10.1007/s10444-019-09666-0,cs.MS,"['cs.MS', '35Qxx, 65N30, 65M60, 65Y05, 74S05']",10.1007/s10444-019-09666-0,,[]
"Validation of a PETSc based software implementing a 4DVAR Data
  Assimilation algorithm: a case study related with an Oceanic Model based on
  Shallow Water equation",http://arxiv.org/abs/1810.01361v2,2018-10-02T16:38:07Z,2018-10-03T09:40:53Z,"  In this work are presented and discussed some results related to the
validation process of a software module based on PETSc which implements a Data
Assimilation algorithm.
","['\nLuisa Carracciuolo\n', '\nEmil M. Constantinescu\n', ""\nLuisa D'Amore\n""]",,,http://arxiv.org/abs/1810.01361v2,cs.MS,"['cs.MS', 'cs.CE']",,,[]
"Scalar Arithmetic Multiple Data: Customizable Precision for Deep Neural
  Networks",http://arxiv.org/abs/1809.10572v2,2018-09-27T15:25:02Z,2019-12-12T15:39:59Z,"  Quantization of weights and activations in Deep Neural Networks (DNNs) is a
powerful technique for network compression, and has enjoyed significant
attention and success. However, much of the inference-time benefit of
quantization is accessible only through the use of customized hardware
accelerators or by providing an FPGA implementation of quantized arithmetic.
  Building on prior work, we show how to construct arbitrary bit-precise signed
and unsigned integer operations using a software technique which logically
\emph{embeds} a vector architecture with custom bit-width lanes in universally
available fixed-width scalar arithmetic.
  We evaluate our approach on a high-end Intel Haswell processor, and an
embedded ARM processor. Our approach yields very fast implementations of
bit-precise custom DNN operations, which often match or exceed the performance
of operations quantized to the sizes supported in native arithmetic. At the
strongest level of quantization, our approach yields a maximum speedup of
$\thicksim6\times$ on the Intel platform, and $\thicksim10\times$ on the ARM
platform versus quantization to native 8-bit integers.
","['\nAndrew Anderson\n', '\nDavid Gregg\n']",,,http://dx.doi.org/10.1109/ARITH.2019.00018,cs.PF,"['cs.PF', 'cs.CV', 'cs.MS']",10.1109/ARITH.2019.00018,,[]
When Lift-and-Project Cuts are Different,http://arxiv.org/abs/1809.05794v2,2018-09-16T02:03:24Z,2020-01-24T11:39:11Z,"  In this paper, we present a method to determine if a lift-and-project cut for
a mixed-integer linear program is irregular, in which case the cut is not
equivalent to any intersection cut from the bases of the linear relaxation.
This is an important question due to the intense research activity for the past
decade on cuts from multiple rows of simplex tableau as well as on
lift-and-project cuts from non-split disjunctions. While it is known since
Balas and Perregaard (2003) that lift-and-project cuts from split disjunctions
are always equivalent to intersection cuts and consequently to such multi-row
cuts, Balas and Kis (2016) have recently shown that there is a necessary and
sufficient condition in the case of arbitrary disjunctions: a lift-and-project
cut is regular if, and only if, it corresponds to a regular basic solution of
the Cut Generating Linear Program (CGLP). This paper has four contributions.
First, we state a result that simplifies the verification of regularity for
basic CGLP solutions from Balas and Kis (2016). Second, we provide a
mixed-integer formulation that checks whether there is a regular CGLP solution
for a given cut that is regular in a broader sense, which also encompasses
irregular cuts that are implied by the regular cut closure. Third, we describe
a numerical procedure based on such formulation that identifies irregular
lift-and-project cuts. Finally, we use this method to evaluate how often
lift-and-project cuts from simple $t$-branch split disjunctions are irregular,
and thus not equivalent to multi-row cuts, on 74 instances of the MIPLIB
benchmarks.
","['\nEgon Balas\n', '\nThiago Serra\n']",INFORMS Journal on Computing (to appear),,http://arxiv.org/abs/1809.05794v2,math.OC,"['math.OC', 'cs.MS']",,,[]
Random problems with R,http://arxiv.org/abs/1809.06520v3,2018-09-18T03:46:47Z,2018-11-13T17:25:07Z,"  R (Version 3.5.1 patched) has an issue with its random sampling
functionality. R generates random integers between $1$ and $m$ by multiplying
random floats by $m$, taking the floor, and adding $1$ to the result.
Well-known quantization effects in this approach result in a non-uniform
distribution on $\{ 1, \ldots, m\}$. The difference, which depends on $m$, can
be substantial. Because the sample function in R relies on generating random
integers, random sampling in R is biased. There is an easy fix: construct
random integers directly from random bits, rather than multiplying a random
float by $m$. That is the strategy taken in Python's numpy.random.randint()
function, among others. Example source code in Python is available at
https://github.com/statlab/cryptorandom/blob/master/cryptorandom/cryptorandom.py
(see functions getrandbits() and randbelow_from_randbits()).
","['\nKellie Ottoboni\n', '\nPhilip B. Stark\n']",,,http://arxiv.org/abs/1809.06520v3,cs.MS,"['cs.MS', 'stat.CO']",,,[]
"auditor: an R Package for Model-Agnostic Visual Validation and
  Diagnostics",http://arxiv.org/abs/1809.07763v4,2018-09-19T19:14:46Z,2020-05-26T15:15:19Z,"  Machine learning models have spread to almost every area of life. They are
successfully applied in biology, medicine, finance, physics, and other fields.
With modern software it is easy to train even a~complex model that fits the
training data and results in high accuracy on the test set. The problem arises
when models fail confronted with real-world data.
  This paper describes methodology and tools for model-agnostic audit.
Introduced techniques facilitate assessing and comparing the goodness of fit
and performance of models. In~addition, they may be used for the analysis of
the similarity of residuals and for identification of~outliers and influential
observations. The examination is carried out by diagnostic scores and visual
verification.
  Presented methods were implemented in the auditor package for R. Due to
flexible and~consistent grammar, it is simple to validate models of any
classes.
","['\nAlicja Gosiewska\n', '\nPrzemyslaw Biecek\n']",,,http://arxiv.org/abs/1809.07763v4,stat.CO,"['stat.CO', 'cs.LG', 'cs.MS', 'stat.ML']",,,[]
Tuning the Performance of a Computational Persistent Homology Package,http://arxiv.org/abs/1809.04424v1,2018-09-09T01:51:45Z,2018-09-09T01:51:45Z,"  In recent years, persistent homology has become an attractive method for data
analysis. It captures topological features, such as connected components,
holes, and voids from point cloud data and summarizes the way in which these
features appear and disappear in a filtration sequence. In this project, we
focus on improving the performance of Eirene, a computational package for
persistent homology. Eirene is a 5000-line open-source software library
implemented in the dynamic programming language Julia. We use the Julia
profiling tools to identify performance bottlenecks and develop novel methods
to manage them, including the parallelization of some time-consuming functions
on multicore/manycore hardware. Empirical results show that performance can be
greatly improved.
","['\nAlan Hylton\n', '\nGregory Henselman-Petrusek\n', '\nJanche Sang\n', '\nRobert Short\n']","29 pages, 10 figures",,http://arxiv.org/abs/1809.04424v1,cs.MS,['cs.MS'],,,[]
"A general-purpose hierarchical mesh partitioning method with node
  balancing strategies for large-scale numerical simulations",http://arxiv.org/abs/1809.02666v2,2018-09-07T20:40:26Z,2018-10-10T16:00:08Z,"  Large-scale parallel numerical simulations are essential for a wide range of
engineering problems that involve complex, coupled physical processes
interacting across a broad range of spatial and temporal scales. The data
structures involved in such simulations (meshes, sparse matrices, etc.) are
frequently represented as graphs, and these graphs must be optimally
partitioned across the available computational resources in order for the
underlying calculations to scale efficiently. Partitions which minimize the
number of graph edges that are cut (edge-cuts) while simultaneously maintaining
a balance in the amount of work (i.e. graph nodes) assigned to each processor
core are desirable, and the performance of most existing partitioning software
begins to degrade in this metric for partitions with more than than $O(10^3)$
processor cores. In this work, we consider a general-purpose hierarchical
partitioner which takes into account the existence of multiple processor cores
and shared memory in a compute node while partitioning a graph into an
arbitrary number of subgraphs. We demonstrate that our algorithms significantly
improve the preconditioning efficiency and overall performance of realistic
numerical simulations running on up to 32,768 processor cores with nearly
$10^9$ unknowns.
","['\nFande Kong\n', '\nRoy H. Stogner\n', '\nDerek R. Gaston\n', '\nJohn W. Peterson\n', '\nCody J. Permann\n', '\nAndrew E. Slaughter\n', '\nRichard C. Martineau\n']","9 pages. Accepted by 2018 IEEE/ACM 9th Workshop on Latest Advances in
  Scalable Algorithms for Large-Scale Systems (scalA)",,http://arxiv.org/abs/1809.02666v2,cs.MS,"['cs.MS', 'cs.DC']",,,[]
Implementing Strassen's Algorithm with CUTLASS on NVIDIA Volta GPUs,http://arxiv.org/abs/1808.07984v1,2018-08-24T02:28:51Z,2018-08-24T02:28:51Z,"  Conventional GPU implementations of Strassen's algorithm (Strassen) typically
rely on the existing high-performance matrix multiplication (GEMM), trading
space for time. As a result, such approaches can only achieve practical speedup
for relatively large, ""squarish"" matrices due to the extra memory overhead, and
their usages are limited due to the considerable workspace. We present novel
Strassen primitives for GPUs that can be composed to generate a family of
Strassen algorithms. Our algorithms utilize both the memory and thread
hierarchies on GPUs, reusing shared memory and register files inherited from
GEMM, fusing additional operations, and avoiding extra workspace. We further
exploit intra- and inter-kernel parallelism by batching, streaming, and
employing atomic operations. We also develop a performance model for NVIDIA
Volta GPUs to select the appropriate blocking parameters and predict the
performance for GEMM and Strassen. Overall, our 1-level Strassen can achieve up
to 1.11x speedup with a crossover point as small as 1,536 compared to
cublasSgemm on a NVIDIA Tesla V100 GPU. With additional workspace, our 2-level
Strassen can achieve 1.19x speedup with a crossover point at 7,680.
","['\nJianyu Huang\n', '\nChenhan D. Yu\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1808.07984v1,cs.MS,['cs.MS'],,,[]
"A parallel non-uniform fast Fourier transform library based on an
  ""exponential of semicircle"" kernel",http://arxiv.org/abs/1808.06736v2,2018-08-21T01:55:35Z,2019-04-08T20:26:13Z,"  The nonuniform fast Fourier transform (NUFFT) generalizes the FFT to off-grid
data. Its many applications include image reconstruction, data analysis, and
the numerical solution of differential equations. We present FINUFFT, an
efficient parallel library for type 1 (nonuiform to uniform), type 2 (uniform
to nonuniform), or type 3 (nonuniform to nonuniform) transforms, in dimensions
1, 2, or 3. It uses minimal RAM, requires no precomputation or plan steps, and
has a simple interface to several languages. We perform the expensive
spreading/interpolation between nonuniform points and the fine grid via a
simple new kernel---the `exponential of semicircle' $e^{\beta \sqrt{1-x^2}}$ in
$x\in[-1,1]$---in a cache-aware load-balanced multithreaded implementation. The
deconvolution step requires the Fourier transform of the kernel, for which we
propose efficient numerical quadrature. For types 1 and 2, rigorous error
bounds asymptotic in the kernel width approach the fastest known exponential
rate, namely that of the Kaiser--Bessel kernel. We benchmark against several
popular CPU-based libraries, showing favorable speed and memory footprint,
especially in three dimensions when high accuracy and/or clustered point
distributions are desired.
","['\nAlex H. Barnett\n', '\nJeremy F. Magland\n', '\nLudvig af Klinteberg\n']","25 pages, 9 figures",,http://arxiv.org/abs/1808.06736v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65T50, 65T40, 65Y05, 68N01']",,,[]
"An Experimental Comparison of SONC and SOS Certificates for
  Unconstrained Optimization",http://arxiv.org/abs/1808.08431v1,2018-08-25T14:17:59Z,2018-08-25T14:17:59Z,"  Finding the minimum of a multivariate real polynomial is a well-known hard
problem with various applications. We present a polynomial time algorithm to
approximate such lower bounds via sums of nonnegative circuit polynomials
(SONC). As a main result, we carry out the first large-scale comparison of
SONC, using this algorithm and different geometric programming (GP) solvers,
with the classical sums of squares (SOS) approach, using several of the most
common semidefinite programming (SDP) solvers. SONC yields bounds competitive
to SOS in several cases, but using significantly less time and memory. In
particular, SONC/GP can handle much larger problem instances than SOS/SDP.
","['\nHenning Seidler\n', '\nTimo de Wolff\n']","25 pages, 3 figures, 8 tables",,http://arxiv.org/abs/1808.08431v1,math.OC,"['math.OC', 'cs.MS', 'math.AG', 'Primary: 14P99, 90-04, 90C22, 90C26, Secondary: 14Q20, 52B20, 68Q25', 'G.4']",,,[]
Linguistic Relativity and Programming Languages,http://arxiv.org/abs/1808.03916v1,2018-08-12T09:38:34Z,2018-08-12T09:38:34Z,"  The use of programming languages can wax and wane across the decades. We
examine the split-apply- combine pattern that is common in statistical
computing, and consider how its invocation or implementation in languages like
MATLAB and APL differ from R/dplyr. The differences in spelling illustrate how
the concept of linguistic relativity applies to programming languages in ways
that are analogous to human languages. Finally, we discuss how Julia, by being
a high performance yet general purpose dynamic language, allows its users to
express different abstractions to suit individual preferences.
",['\nJiahao Chen\n'],"10 pages, repo at
  https://github.com/jiahao/statistical-computing-linguistics, Published in
  Proceedings of the 2016 Joint Statistical Meetings, Chicago, IL, USA",,http://arxiv.org/abs/1808.03916v1,cs.PL,"['cs.PL', 'cs.MS', 'stat.CO', '68N15', 'D.3.0']",,,[]
"Bringing Together Dynamic Geometry Software and the Graphics Processing
  Unit",http://arxiv.org/abs/1808.04579v1,2018-08-14T08:20:36Z,2018-08-14T08:20:36Z,"  We equip dynamic geometry software (DGS) with a user-friendly method that
enables massively parallel calculations on the graphics processing unit (GPU).
This interplay of DGS and GPU opens up various applications in education and
mathematical research. The GPU-aided discovery of mathematical properties,
interactive visualizations of algebraic surfaces (raycasting), the mathematical
deformation of images and footage in real-time, and computationally demanding
numerical simulations of PDEs are examples from the long and versatile list of
new domains that our approach makes accessible within a DGS. We ease the
development of complex (mathematical) visualizations and provide a
rapid-prototyping scheme for general-purpose computations (GPGPU).
  The possibility to program both CPU and GPU with the use of only one
high-level (scripting) programming language is a crucial aspect of our concept.
We embed shader programming seamlessly within a high-level (scripting)
programming environment. The aforementioned requires the symbolic process of
the transcompilation of a high-level programming language into shader
programming language for GPU and, in this article, we address the challenge of
the automatic translation of a high-level programming language to a shader
language of the GPU. To maintain platform independence and the possibility to
use our technology on modern devices, we focus on a realization through WebGL.
","['\nAaron Montag\n', '\nJürgen Richter-Gebert\n']",,,http://arxiv.org/abs/1808.04579v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.SC', 'math.AG', '68U05, 68W30, 68W10, 97R60, 14Q05, 14Q10, 68N20', 'G.4; D.3.3; D.3.4; I.3.1; I.6.8; K.3.1']",,,[]
Code generation for generally mapped finite elements,http://arxiv.org/abs/1808.05513v2,2018-08-16T14:30:14Z,2019-09-06T10:30:57Z,"  Many classical finite elements such as the Argyris and Bell elements have
long been absent from high-level PDE software. Building on recent theoretical
work, we describe how to implement very general finite element transformations
in FInAT and hence into the Firedrake finite element system. Numerical results
evaluate the new elements, comparing them to existing methods for classical
problems. For a second order model problem, we find that new elements give
smooth solutions at a mild increase in cost over standard Lagrange elements.
For fourth-order problems, however, the newly-enabled methods significantly
outperform interior penalty formulations. We also give some advanced use cases,
solving the nonlinear Cahn-Hilliard equation and some biharmonic eigenvalue
problems (including Chladni plates) using $C^1$ discretizations.
","['\nRobert C. Kirby\n', '\nLawrence Mitchell\n']",23 pages,ACM Transactions on Mathematical Software 45(41):1-23 (2019),http://dx.doi.org/10.1145/3361745,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1145/3361745,,[]
pySDC - Prototyping spectral deferred corrections,http://arxiv.org/abs/1808.02731v1,2018-08-08T11:44:27Z,2018-08-08T11:44:27Z,"  In this paper we present the Python framework pySDC for solving collocation
problems with spectral deferred correction methods (SDC) and their
time-parallel variant PFASST, the parallel full approximation scheme in space
and time. pySDC features many implementations of SDC and PFASST, from simple
implicit time-stepping to high-order implicit-explicit or multi-implicit
splitting and multi-level spectral deferred corrections. It comes with many
different, pre-implemented examples and has seven tutorials to help new users
with their first steps. Time-parallelism is implemented either in an emulated
way for debugging and prototyping as well as using MPI for benchmarking. The
code is fully documented and tested using continuous integration, including
most results of previous publications. Here, we describe the structure of the
code by taking two different perspectives: the user's and the developer's
perspective. While the first sheds light on the front-end, the examples and the
tutorials, the second is used to describe the underlying implementation and the
data structures. We show three different examples to highlight various aspects
of the implementation, the capabilities and the usage of pySDC. Also, couplings
to the FEniCS framework and PETSc, the latter including spatial parallelism
with MPI, are described.
",['\nRobert Speck\n'],,,http://arxiv.org/abs/1808.02731v1,cs.MS,['cs.MS'],,,[]
GuiTeNet: A graphical user interface for tensor networks,http://arxiv.org/abs/1808.00532v1,2018-07-30T18:09:13Z,2018-07-30T18:09:13Z,"  We introduce a graphical user interface for constructing arbitrary tensor
networks and specifying common operations like contractions or splitting,
denoted GuiTeNet. Tensors are represented as nodes with attached legs,
corresponding to the ordered dimensions of the tensor. GuiTeNet visualizes the
current network, and instantly generates Python/NumPy source code for the
hitherto sequence of user actions. Support for additional programming languages
is planned for the future. We discuss the elementary operations on tensor
networks used by GuiTeNet, together with high-level optimization strategies.
The software runs directly in web browsers and is available online at
http://guitenet.org.
","['\nLisa Sahlmann\n', '\nChristian B. Mendl\n']","7 pages, 4 figures","J. Open Res. Softw. 8(1), 29 (2020)",http://dx.doi.org/10.5334/jors.304,cs.MS,"['cs.MS', 'cond-mat.str-el', 'physics.comp-ph']",10.5334/jors.304,,[]
"Accelerating wave-propagation algorithms with adaptive mesh refinement
  using the Graphics Processing Unit (GPU)",http://arxiv.org/abs/1808.02638v1,2018-08-08T06:21:56Z,2018-08-08T06:21:56Z,"  Clawpack is a library for solving nonlinear hyperbolic partial differential
equations using high-resolution finite volume methods based on Riemann solvers
and limiters. It supports Adaptive Mesh Refinement (AMR), which is essential in
solving multi-scale problems. Recently, we added capabilities to accelerate the
code by using the Graphics Process Unit (GPU). Routines that manage CPU and GPU
AMR data and facilitate the execution of GPU kernels are added. Customized and
CPU thread-safe memory managers are designed to manage GPU and CPU memory
pools, which is essential in eliminating the overhead of memory allocation and
de-allocation. A global reduction is conducted every time step for dynamically
adjusting the time step based on Courant number restrictions. Some small GPU
kernels are merged into bigger kernels, which greatly reduces kernel launching
overhead. A speed-up between $2$ and $3$ for the total running time is observed
in an acoustics benchmark problem.
","['\nXinsheng Qin\n', '\nRandall J. LeVeque\n', '\nMichael R. Motley\n']",,,http://arxiv.org/abs/1808.02638v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",,,[]
"A Benchmark of Selected Algorithmic Differentiation Tools on Some
  Problems in Computer Vision and Machine Learning",http://arxiv.org/abs/1807.10129v1,2018-07-26T13:42:30Z,2018-07-26T13:42:30Z,"  Algorithmic differentiation (AD) allows exact computation of derivatives
given only an implementation of an objective function. Although many AD tools
are available, a proper and efficient implementation of AD methods is not
straightforward. The existing tools are often too different to allow for a
general test suite. In this paper, we compare fifteen ways of computing
derivatives including eleven automatic differentiation tools implementing
various methods and written in various languages (C++, F#, MATLAB, Julia and
Python), two symbolic differentiation tools, finite differences, and
hand-derived computation.
  We look at three objective functions from computer vision and machine
learning. These objectives are for the most part simple, in the sense that no
iterative loops are involved, and conditional statements are encapsulated in
functions such as {\tt abs} or {\tt logsumexp}. However, it is important for
the success of algorithmic differentiation that such `simple' objective
functions are handled efficiently, as so many problems in computer vision and
machine learning are of this form.
  Of course, our results depend on programmer skill, and familiarity with the
tools. However, we contend that this paper presents an important datapoint: a
skilled programmer devoting roughly a week to each tool produced the timings we
present. We have made our implementations available as open source to allow the
community to replicate and update these benchmarks.
","['\nFilip Šrajer\n', '\nZuzana Kukelova\n', '\nAndrew Fitzgibbon\n']","Previous versions of this article appeared at AD2016---7th
  International Conference on Algorithmic Differentiation, and in Optimization
  Methods and Software, Taylor and Francis, Feb 2018 (online)",,http://arxiv.org/abs/1807.10129v1,cs.MS,"['cs.MS', 'cs.CV', 'cs.LG']",,,[]
"Architecture and performance of Devito, a system for automated stencil
  computation",http://arxiv.org/abs/1807.03032v3,2018-07-09T10:32:50Z,2020-02-07T11:30:42Z,"  Stencil computations are a key part of many high-performance computing
applications, such as image processing, convolutional neural networks, and
finite-difference solvers for partial differential equations. Devito is a
framework capable of generating highly-optimized code given symbolic equations
expressed in Python, specialized in, but not limited to, affine (stencil)
codes. The lowering process---from mathematical equations down to C++ code---is
performed by the Devito compiler through a series of intermediate
representations. Several performance optimizations are introduced, including
advanced common sub-expressions elimination, tiling and parallelization. Some
of these are obtained through well-established stencil optimizers, integrated
in the back-end of the Devito compiler. The architecture of the Devito
compiler, as well as the performance optimizations that are applied when
generating code, are presented. The effectiveness of such performance
optimizations is demonstrated using operators drawn from seismic imaging
applications.
","['\nFabio Luporini\n', '\nMichael Lange\n', '\nMathias Louboutin\n', '\nNavjot Kukreja\n', '\nJan Hückelheim\n', '\nCharles Yount\n', '\nPhilipp Witte\n', '\nPaul H. J. Kelly\n', '\nFelix J. Herrmann\n', '\nGerard J. Gorman\n']",Submitted to ACM Transactions on Mathematical Software,,http://arxiv.org/abs/1807.03032v3,cs.MS,"['cs.MS', '65N06, 68N20']",,,[]
The Dune Python Module,http://arxiv.org/abs/1807.05252v1,2018-07-13T19:17:48Z,2018-07-13T19:17:48Z,"  In this paper we present the new Dune-Python module which provides Python
bindings for the Dune core, which is a C++ environment for solving partial
differential equations. The aim of this new module is to firstly provide the
general infrastructure for exporting realizations of statically polymorphic
interfaces based on just-in-time compilation and secondly to provide bindings
for the central interfaces of the dune core modules. In the first release we
focus on the grid interface. Our aim is to only introduce a thin layer when
passing objects into Python which can be removed when the object is passed back
into a C++ algorithm. Thus no efficiency is lost and little additional code
maintenance cost is incurred. To make the transition for Dune users to the
Python environment straightforward the Python classes provide a very similar
interface to their C++ counterparts. In addition, vectorized versions of many
interfaces allow for more efficient code on the Python side. The infrastructure
for exporting these interfaces and the resulting bindings for a Dune grid are
explained in detail in this paper for both experienced Dune users and others
interested in a flexible Python environment for implementing grid based schemes
for solving partial differential equations.
","['\nAndreas Dedner\n', '\nMartin Nolte\n']",,,http://arxiv.org/abs/1807.05252v1,cs.MS,['cs.MS'],,,[]
Physical-type correctness in scientific Python,http://arxiv.org/abs/1807.07643v3,2018-07-17T13:12:32Z,2018-08-03T04:28:40Z,"  The representation of units and dimensions in informatics systems is barely
codified and often ignored. For instance, the major languages used in
scientific computing (Fortran, C and Python), have no type for dimension or
unit, and so physical quantities are represented in a program by variables of
type real, resulting in the possibility of unit or dimensional errors. In view
of this danger, many authors have proposed language schemes for unit-checking
and conversion. However, since many physical quantities have the same units, it
is possible for a block of code to be unit-compatible, but still physically
meaningless. We demonstrate the limitations of three Python unit-libraries and
present a justification and method for checking kind-of-quantity.
","['\nMarcus Foster\n', '\nSean Tregeagle\n']","6 pages. v2 expanded Abstract only. v3 added reference to/description
  of/code example for recent units library unyt arXiv:1806.02417; fixed typos",,http://arxiv.org/abs/1807.07643v3,cs.MS,['cs.MS'],,,[]
"Confederated Modular Differential Equation APIs for Accelerated
  Algorithm Development and Benchmarking",http://arxiv.org/abs/1807.06430v1,2018-07-17T13:46:23Z,2018-07-17T13:46:23Z,"  Performant numerical solving of differential equations is required for
large-scale scientific modeling. In this manuscript we focus on two questions:
(1) how can researchers empirically verify theoretical advances and
consistently compare methods in production software settings and (2) how can
users (scientific domain experts) keep up with the state-of-the-art methods to
select those which are most appropriate? Here we describe how the confederated
modular API of DifferentialEquations.jl addresses these concerns. We detail the
package-free API which allows numerical methods researchers to readily utilize
and benchmark any compatible method directly in full-scale scientific
applications. In addition, we describe how the complexity of the method choices
is abstracted via a polyalgorithm. We show how scientific tooling built on top
of DifferentialEquations.jl, such as packages for dynamical systems
quantification and quantum optics simulation, both benefit from this structure
and provide themselves as convenient benchmarking tools.
","['\nChristopher Rackauckas\n', '\nQing Nie\n']","4 figures, 3 algorithms",,http://arxiv.org/abs/1807.06430v1,cs.SE,"['cs.SE', 'cs.MS']",,,[]
"Computational and applied topology, tutorial",http://arxiv.org/abs/1807.08607v2,2018-07-11T09:19:41Z,2018-08-23T09:56:59Z,"  This is a tutorial in applied and computational topology and topological data
analysis. It is illustrated with numerous computational examples that utilize
Gudhi library. It is under constant development, so please do not consider this
version as final.
",['\nPaweł Dłotko\n'],,,http://arxiv.org/abs/1807.08607v2,cs.MS,"['cs.MS', 'math.AT']",,,[]
Implementation of a Near-Optimal Complex Root Clustering Algorithm,http://arxiv.org/abs/1806.10584v3,2018-06-27T17:31:48Z,2018-08-01T18:50:36Z,"  We describe Ccluster, a software for computing natural $\epsilon$-clusters of
complex roots in a given box of the complex plane. This algorithm from Becker
et al.~(2016) is near-optimal when applied to the benchmark problem of
isolating all complex roots of an integer polynomial. It is one of the first
implementations of a near-optimal algorithm for complex roots. We describe some
low level techniques for speeding up the algorithm. Its performance is compared
with the well-known MPSolve library and Maple.
","['\nRémi Imbach\n', '\nVictor Y. Pan\n', '\nChee Yap\n']",,,http://arxiv.org/abs/1806.10584v3,cs.MS,"['cs.MS', 'cs.SC']",,,[]
"The Implementation of the Colored Abstract Simplicial Complex and its
  Application to Mesh Generation",http://arxiv.org/abs/1807.01417v2,2018-07-04T01:04:27Z,2019-03-27T21:09:34Z,"  We introduce CASC: a new, modern, and header-only C++ library which provides
a data structure to represent arbitrary dimension abstract simplicial complexes
(ASC) with user-defined classes stored directly on the simplices at each
dimension. This is accomplished by using the latest C++ language features
including variadic template parameters introduced in C++11 and automatic
function return type deduction from C++14. Effectively CASC decouples the
representation of the topology from the interactions of user data. We present
the innovations and design principles of the data structure and related
algorithms. This includes a metadata aware decimation algorithm which is
general for collapsing simplices of any dimension. We also present an example
application of this library to represent an orientable surface mesh.
","['\nC. T. Lee\n', '\nJ. B. Moody\n', '\nR. E. Amaro\n', '\nJ. A. McCammon\n', '\nM. Holst\n']","24 pages, 6 figures","ACM Trans. Math. Softw. 45, 3, Article 28 (August 2019)",http://dx.doi.org/10.1145/3321515,cs.MS,"['cs.MS', 'math.NA']",10.1145/3321515,,[]
"FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC
  libraries",http://arxiv.org/abs/1807.01775v1,2018-07-03T09:52:57Z,2018-07-03T09:52:57Z,"  The Python package fluidfft provides a common Python API for performing Fast
Fourier Transforms (FFT) in sequential, in parallel and on GPU with different
FFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT
framework which allows Python users to easily and efficiently perform FFT and
the associated tasks, such as as computing linear operators and energy spectra.
We describe the architecture of the package composed of C++ and Cython FFT
classes, Python ""operator"" classes and Pythran functions. The package supplies
utilities to easily test itself and benchmark the different FFT solutions for a
particular case and on a particular machine. We present a performance scaling
analysis on three different computing clusters and a microbenchmark showing
that fluidfft is an interesting solution to write efficient Python applications
using FFT.
","['\nAshwin Vishnu Mohanan\n', '\nCyrille Bonamy\n', '\nPierre Augier\n']",,,http://dx.doi.org/10.5334/jors.238,cs.MS,"['cs.MS', 'physics.flu-dyn']",10.5334/jors.238,,[]
A GPU-enabled finite volume solver for large shallow water simulations,http://arxiv.org/abs/1807.00672v1,2018-06-28T08:11:29Z,2018-06-28T08:11:29Z,"  This paper presents the implementation of a HLLC finite volume solver using
GPU technology for the solution of shallow water problems in two dimensions. It
compares both CPU and GPU approaches for implementing all the solver's steps.
The technology of graphics and central processors is highlighted with a
particular emphasis on the CUDA architecture of NVIDIA. The simple and
well-documented Application Programming Interface (CUDA API) facilitates the
use of the display card workstation as an additional computer unit to the
central processor. Four professional solutions of the NVIDIA Quadro line are
tested. Comparison tests between CPU and GPU are carried out on unstructured
grids of small sizes (up to 10,000 elements), medium and large sizes (up to
10,000,000 elements). For all test cases, the accuracy of results is of the
same order of magnitude for both approaches. Furthermore, the obtained speed
gains with the GPU strongly depend on the model of the graphics card, the size
of the problem and the simulation time.
",['\nFabrice Zaoui\nEDF R\\&D STEP\n'],,,http://arxiv.org/abs/1807.00672v1,cs.CE,"['cs.CE', 'cs.MS', 'physics.comp-ph', 'physics.med-ph']",,,['EDF R\\&D STEP']
"Numerical Evaluation of Elliptic Functions, Elliptic Integrals and
  Modular Forms",http://arxiv.org/abs/1806.06725v1,2018-06-18T14:19:18Z,2018-06-18T14:19:18Z,"  We describe algorithms to compute elliptic functions and their relatives
(Jacobi theta functions, modular forms, elliptic integrals, and the
arithmetic-geometric mean) numerically to arbitrary precision with rigorous
error bounds for arbitrary complex variables. Implementations in ball
arithmetic are available in the open source Arb library. We discuss the
algorithms from a concrete implementation point of view, with focus on
performance at tens to thousands of digits of precision.
",['\nFredrik Johansson\nLFANT\n'],,,http://arxiv.org/abs/1806.06725v1,cs.NA,"['cs.NA', 'cs.MS']",,,['LFANT']
"Enclave Tasking for Discontinuous Galerkin Methods on Dynamically
  Adaptive Meshes",http://arxiv.org/abs/1806.07984v3,2018-06-19T14:09:42Z,2020-02-24T08:17:01Z,"  High-order Discontinuous Galerkin (DG) methods promise to be an excellent
discretisation paradigm for partial differential equation solvers by combining
high arithmetic intensity with localised data access. They also facilitate
dynamic adaptivity without the need for conformal meshes. A parallel evaluation
of DG's weak formulation within a mesh traversal is non-trivial, as dependency
graphs over dynamically adaptive meshes change, as causal constraints along
resolution transitions have to be preserved, and as data sends along MPI domain
boundaries have to be triggered in the correct order. We propose to process
mesh elements subject to constraints with high priority or, where needed,
serially throughout a traversal. The remaining cells form enclaves and are
spawned into a task system. This introduces concurrency, mixes memory-intensive
DG integrations with compute-bound Riemann solves, and overlaps computation and
communication. We discuss implications on MPI and show that MPI parallelisation
improves by a factor of three through enclave tasking, while we obtain an
additional factor of two from shared memory if grids are dynamically adaptive.
","['\nDominic E. Charrier\n', '\nBenjamin Hazelwood\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1137/19M1276194,cs.MS,"['cs.MS', 'cs.DC']",10.1137/19M1276194,,[]
"Optimising finite-difference methods for PDEs through parameterised
  time-tiling in Devito",http://arxiv.org/abs/1806.08299v1,2018-06-21T15:50:20Z,2018-06-21T15:50:20Z,"  Finite-difference methods are widely used in solving partial differential
equations. In a large problem set, approximations can take days or weeks to
evaluate, yet the bulk of computation may occur within a single loop nest. The
modelling process for researchers is not straightforward either, requiring
models with differential equations to be translated into stencil kernels, then
optimised separately. One tool that seeks to speed up and eliminate mistakes
from this tedious procedure is Devito, used to efficiently employ
finite-difference methods.
  In this work, we implement time-tiling, a loop nest optimisation, in Devito
yielding a decrease in runtime of up to 45%, and at least 20% across stencils
from the acoustic wave equation family, widely used in Devito's target domain
of seismic imaging. We present an estimator for arithmetic intensity under
time-tiling and a model to predict runtime improvements in stencil
computations. We also consider generalisation of time-tiling to imperfect loop
nests, a less widely studied problem.
",['\nNicholas Sim\n'],,,http://arxiv.org/abs/1806.08299v1,cs.PF,"['cs.PF', 'cs.MS']",,,[]
Function space bases in the dune-functions module,http://arxiv.org/abs/1806.09545v1,2018-06-25T15:58:53Z,2018-06-25T15:58:53Z,"  The dune-functions Dune module provides interfaces for functions and function
space bases. It forms one abstraction level above grids, shape functions, and
linear algebra, and provides infrastructure for full discretization frameworks
like dune-pdelab and dune-fem. This document describes the function space bases
provided by dune-functions. These are based on an abstract description of bases
for product spaces as trees of simpler bases. From this description, many
different numberings of degrees of freedom by multi-indices can be derived in a
natural way. We describe the abstract concepts, document the programmer
interface, and give a complete example program that solves the stationary
Stokes equation using Taylor-Hood elements.
","['\nChristian Engwer\n', '\nCarsten Gräser\n', '\nSteffen Müthing\n', '\nOliver Sander\n']",,,http://arxiv.org/abs/1806.09545v1,cs.MS,"['cs.MS', 'cs.NA', '68N99']",,,[]
Probabilistic Inference Using Generators - The Statues Algorithm,http://arxiv.org/abs/1806.09997v2,2018-06-24T23:00:29Z,2018-08-02T07:19:02Z,"  We present here a new probabilistic inference algorithm that gives exact
results in the domain of discrete probability distributions. This algorithm,
named the Statues algorithm, calculates the marginal probability distribution
on probabilistic models defined as direct acyclic graphs. These models are made
up of well-defined primitives that allow to express, in particular, joint
probability distributions, Bayesian networks, discrete Markov chains,
conditioning and probabilistic arithmetic. The Statues algorithm relies on a
variable binding mechanism based on the generator construct, a special form of
coroutine; being related to the enumeration algorithm, this new algorithm
brings important improvements in terms of efficiency, which makes it valuable
in regard to other exact marginalization algorithms. After introduction of
several definitions, primitives and compositional rules, we present in details
the Statues algorithm. Then, we briefly discuss the interest of this algorithm
compared to others and we present possible extensions. Finally, we introduce
Lea and MicroLea, two Python libraries implementing the Statues algorithm,
along with several use cases. A proof of the correctness of the algorithm is
provided in appendix.
",['\nPierre Denis\n'],"50 pages, incl. 3 appendices (v2: typos and minor corrections, added
  appendix C with proof of correctness)",,http://dx.doi.org/10.1007/978-3-030-52246-9_10,cs.AI,"['cs.AI', 'cs.MS']",10.1007/978-3-030-52246-9_10,,[]
A model-driven approach for a new generation of adaptive libraries,http://arxiv.org/abs/1806.07060v1,2018-06-19T06:17:38Z,2018-06-19T06:17:38Z,"  Efficient high-performance libraries often expose multiple tunable parameters
to provide highly optimized routines. These can range from simple loop unroll
factors or vector sizes all the way to algorithmic changes, given that some
implementations can be more suitable for certain devices by exploiting hardware
characteristics such as local memories and vector units. Traditionally, such
parameters and algorithmic choices are tuned and then hard-coded for a specific
architecture and for certain characteristics of the inputs. However, emerging
applications are often data-driven, thus traditional approaches are not
effective across the wide range of inputs and architectures used in practice.
In this paper, we present a new adaptive framework for data-driven applications
which uses a predictive model to select the optimal algorithmic parameters by
training with synthetic and real datasets. We demonstrate the effectiveness of
a BLAS library and specifically on its matrix multiplication routine. We
present experimental results for two GPU architectures and show significant
performance gains of up to 3x (on a high-end NVIDIA Pascal GPU) and 2.5x (on an
embedded ARM Mali GPU) when compared to a traditionally optimized library.
","['\nMarco Cianfriglia\n', '\nFlavio Vella\n', '\nCedric Nugteren\n', '\nAnton Lokhmotov\n', '\nGrigori Fursin\n']",New detailed analysis will be provided,ACM Transactions on Architecture and Code Optimization 2021,http://dx.doi.org/10.1145/3434402,cs.PF,"['cs.PF', 'cs.DC', 'cs.MS', 'cs.SE']",10.1145/3434402,,[]
Parallel Nonnegative CP Decomposition of Dense Tensors,http://arxiv.org/abs/1806.07985v1,2018-06-19T13:52:12Z,2018-06-19T13:52:12Z,"  The CP tensor decomposition is a low-rank approximation of a tensor. We
present a distributed-memory parallel algorithm and implementation of an
alternating optimization method for computing a CP decomposition of dense
tensor data that can enforce nonnegativity of the computed low-rank factors.
The principal task is to parallelize the matricized-tensor times Khatri-Rao
product (MTTKRP) bottleneck subcomputation. The algorithm is computation
efficient, using dimension trees to avoid redundant computation across MTTKRPs
within the alternating method. Our approach is also communication efficient,
using a data distribution and parallel algorithm across a multidimensional
processor grid that can be tuned to minimize communication. We benchmark our
software on synthetic as well as hyperspectral image and neuroscience dynamic
functional connectivity data, demonstrating that our algorithm scales well to
100s of nodes (up to 4096 cores) and is faster and more general than the
currently available parallel software.
","['\nGrey Ballard\n', '\nKoby Hayashi\n', '\nRamakrishnan Kannan\n']",,,http://arxiv.org/abs/1806.07985v1,cs.NA,"['cs.NA', 'cs.DC', 'cs.MS']",,,[]
"A scalable H-matrix approach for the solution of boundary integral
  equations on multi-GPU clusters",http://arxiv.org/abs/1806.11558v1,2018-06-20T07:39:20Z,2018-06-20T07:39:20Z,"  In this work, we consider the solution of boundary integral equations by
means of a scalable hierarchical matrix approach on clusters equipped with
graphics hardware, i.e. graphics processing units (GPUs). To this end, we
extend our existing single-GPU hierarchical matrix library hmglib such that it
is able to scale on many GPUs and such that it can be coupled to arbitrary
application codes. Using a model GPU implementation of a boundary element
method (BEM) solver, we are able to achieve more than 67 percent relative
parallel speed-up going from 128 to 1024 GPUs for a model geometry test case
with 1.5 million unknowns and a real-world geometry test case with almost 1.2
million unknowns. On 1024 GPUs of the cluster Titan, it takes less than 6
minutes to solve the 1.5 million unknowns problem, with 5.7 minutes for the
setup phase and 20 seconds for the iterative solver. To the best of the
authors' knowledge, we here discuss the first fully GPU-based
distributed-memory parallel hierarchical matrix Open Source library using the
traditional H-matrix format and adaptive cross approximation with an
application to BEM problems.
","['\nHelmut Harbrecht\n', '\nPeter Zaspel\n']",,,http://arxiv.org/abs/1806.11558v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA']",,,[]
Tensor-Tensor Product Toolbox,http://arxiv.org/abs/1806.07247v2,2018-06-17T08:14:42Z,2018-06-20T03:23:18Z,"  The tensor-tensor product (t-product) [M. E. Kilmer and C. D. Martin, 2011]
is a natural generalization of matrix multiplication. Based on t-product, many
operations on matrix can be extended to tensor cases, including tensor SVD,
tensor spectral norm, tensor nuclear norm [C. Lu, et al., 2018] and many
others. The linear algebraic structure of tensors are similar to the matrix
cases. We develop a Matlab toolbox to implement several basic operations on
tensors based on t-product. The toolbox is available at
https://github.com/canyilu/tproduct.
",['\nCanyi Lu\n'],"arXiv admin note: substantial text overlap with arXiv:1804.03728.
  Carnegie Mellon University",,http://arxiv.org/abs/1806.07247v2,stat.ML,"['stat.ML', 'cs.AI', 'cs.CV', 'cs.LG', 'cs.MS']",,,[]
Generalized Polylogarithms in Maple,http://arxiv.org/abs/1806.02883v1,2018-06-07T19:42:58Z,2018-06-07T19:42:58Z,"  This paper describes generalized polylogarithms, multiple polylogarithms, and
multiple zeta values, along with their implementation in Maple 2018. This set
of related functions is of interest in high energy physics as well as in number
theory. Algorithms for the analytical manipulation and numerical evaluation of
these functions are described, along with the way these features are
implemented in Maple.
",['\nHjalte Frellesvig\n'],28 pages,,http://arxiv.org/abs/1806.02883v1,hep-th,"['hep-th', 'cs.MS']",,,[]
"SIMD Vectorization for the Lennard-Jones Potential with AVX2 and AVX-512
  instructions",http://arxiv.org/abs/1806.05713v2,2018-06-13T08:53:58Z,2018-10-22T09:53:05Z,"  This work describes the SIMD vectorization of the force calculation of the
Lennard-Jones potential with Intel AVX2 and AVX-512 instruction sets. Since the
force-calculation kernel of the molecular dynamics method involves indirect
access to memory, the data layout is one of the most important factors in
vectorization. We find that the Array of Structures (AoS) with padding exhibits
better performance than Structure of Arrays (SoA) with appropriate
vectorization and optimizations. In particular, AoS with 512-bit width exhibits
the best performance among the architectures. While the difference in
performance between AoS and SoA is significant for the vectorization with AVX2,
that with AVX-512 is minor. The effect of other optimization techniques, such
as software pipelining together with vectorization, is also discussed. We
present results for benchmarks on three CPU architectures: Intel Haswell (HSW),
Knights Landing (KNL), and Skylake (SKL). The performance gains by
vectorization are about 42\% on HSW compared with the code optimized without
vectorization. On KNL, the hand-vectorized codes exhibit 34\% better
performance than the codes vectorized automatically by the Intel compiler. On
SKL, the code vectorized with AVX2 exhibits slightly better performance than
that with vectorized AVX-512.
","['\nHiroshi Watanabe\n', '\nKoh M. Nakagawa\n']","9 pages, 12 figures",,http://dx.doi.org/10.1016/j.cpc.2018.10.028,cs.MS,"['cs.MS', 'cs.CE']",10.1016/j.cpc.2018.10.028,,[]
"Far-HO: A Bilevel Programming Package for Hyperparameter Optimization
  and Meta-Learning",http://arxiv.org/abs/1806.04941v1,2018-06-13T10:46:32Z,2018-06-13T10:46:32Z,"  In (Franceschi et al., 2018) we proposed a unified mathematical framework,
grounded on bilevel programming, that encompasses gradient-based hyperparameter
optimization and meta-learning. We formulated an approximate version of the
problem where the inner objective is solved iteratively, and gave sufficient
conditions ensuring convergence to the exact problem. In this work we show how
to optimize learning rates, automatically weight the loss of single examples
and learn hyper-representations with Far-HO, a software package based on the
popular deep learning framework TensorFlow that allows to seamlessly tackle
both HO and ML problems.
","['\nLuca Franceschi\n', '\nRiccardo Grazzi\n', '\nMassimiliano Pontil\n', '\nSaverio Salzo\n', '\nPaolo Frasconi\n']","This submission is a reduced version of (Franceschi et al.,
  arXiv:1806.04910) which has been accepted at the main ICML 2018 conference.
  In this paper we illustrate the software framework, material that could not
  be included in the conference paper",,http://arxiv.org/abs/1806.04941v1,cs.MS,"['cs.MS', 'cs.LG', 'stat.ML']",,,[]
"Efficient Differentiable Programming in a Functional Array-Processing
  Language",http://arxiv.org/abs/1806.02136v1,2018-06-06T11:54:34Z,2018-06-06T11:54:34Z,"  We present a system for the automatic differentiation of a higher-order
functional array-processing language. The core functional language underlying
this system simultaneously supports both source-to-source automatic
differentiation and global optimizations such as loop transformations. Thanks
to this feature, we demonstrate how for some real-world machine learning and
computer vision benchmarks, the system outperforms the state-of-the-art
automatic differentiation tools.
","['\nAmir Shaikhha\n', '\nAndrew Fitzgibbon\n', '\nDimitrios Vytiniotis\n', '\nSimon Peyton Jones\n', '\nChristoph Koch\n']",,,http://arxiv.org/abs/1806.02136v1,cs.MS,"['cs.MS', 'cs.LG', 'cs.PL', 'cs.SC', 'stat.ML']",,,[]
"Optimizing Sparse Matrix-Vector Multiplication on Emerging Many-Core
  Architectures",http://arxiv.org/abs/1805.11938v1,2018-05-29T15:29:30Z,2018-05-29T15:29:30Z,"  Sparse matrix vector multiplication (SpMV) is one of the most common
operations in scientific and high-performance applications, and is often
responsible for the application performance bottleneck. While the sparse matrix
representation has a significant impact on the resulting application
performance, choosing the right representation typically relies on expert
knowledge and trial and error. This paper provides the first comprehensive
study on the impact of sparse matrix representations on two emerging many-core
architectures: the Intel's Knights Landing (KNL) XeonPhi and the ARM-based
FT-2000Plus (FTP). Our large-scale experiments involved over 9,500 distinct
profiling runs performed on 956 sparse datasets and five mainstream SpMV
representations. We show that the best sparse matrix representation depends on
the underlying architecture and the program input. To help developers to choose
the optimal matrix representation, we employ machine learning to develop a
predictive model. Our model is first trained offline using a set of training
examples. The learned model can be used to predict the best matrix
representation for any unseen input for a given architecture. We show that our
model delivers on average 95% and 91% of the best available performance on KNL
and FTP respectively, and it achieves this with no runtime profiling overhead.
","['\nShizhao Chen\n', '\nJianbin Fang\n', '\nDonglin Chen\n', '\nChuanfu Xu\n', '\nZheng Wang\n']",Accepted to be published at HPCC 2018,,http://arxiv.org/abs/1805.11938v1,cs.MS,['cs.MS'],,,[]
"A Scalable and Modular Software Architecture for Finite Elements on
  Hierarchical Hybrid Grids",http://arxiv.org/abs/1805.10167v1,2018-05-25T14:10:59Z,2018-05-25T14:10:59Z,"  In this article, a new generic higher-order finite-element framework for
massively parallel simulations is presented. The modular software architecture
is carefully designed to exploit the resources of modern and future
supercomputers. Combining an unstructured topology with structured grid
refinement facilitates high geometric adaptability and matrix-free multigrid
implementations with excellent performance. Different abstraction levels and
fully distributed data structures additionally ensure high flexibility,
extensibility, and scalability. The software concepts support sophisticated
load balancing and flexibly combining finite element spaces. Example scenarios
with coupled systems of PDEs show the applicability of the concepts to
performing geophysical simulations.
","['\nNils Kohl\n', '\nDominik Thönnes\n', '\nDaniel Drzisga\n', '\nDominik Bartuschat\n', '\nUlrich Rüde\n']","Preprint of an article submitted to International Journal of
  Parallel, Emergent and Distributed Systems (Taylor & Francis)",,http://arxiv.org/abs/1805.10167v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"ChASE: Chebyshev Accelerated Subspace iteration Eigensolver for
  sequences of Hermitian eigenvalue problems",http://arxiv.org/abs/1805.10121v1,2018-05-25T12:56:18Z,2018-05-25T12:56:18Z,"  Solving dense Hermitian eigenproblems arranged in a sequence with direct
solvers fails to take advantage of those spectral properties which are
pertinent to the entire sequence, and not just to the single problem. When such
features take the form of correlations between the eigenvectors of consecutive
problems, as is the case in many real-world applications, the potential benefit
of exploiting them can be substantial. We present ChASE, a modern algorithm and
library based on subspace iteration with polynomial acceleration. Novel to
ChASE is the computation of the spectral estimates that enter in the filter and
an optimization of the polynomial degree which further reduces the necessary
FLOPs. ChASE is written in C++ using the modern software engineering concepts
which favor a simple integration in application codes and a straightforward
portability over heterogeneous platforms. When solving sequences of Hermitian
eigenproblems for a portion of their extremal spectrum, ChASE greatly benefits
from the sequence's spectral properties and outperforms direct solvers in many
scenarios. The library ships with two distinct parallelization schemes,
supports execution over distributed GPUs, and it is easily extensible to other
parallel computing architectures.
","['\nJan Winkelmann\nAICES, RWTH Aachen University\n', '\nPaul Springer\nAICES, RWTH Aachen University\n', '\nEdoardo Di Napoli\nAICES, RWTH Aachen University\nJSC, Forschungszentrum Jülich\n']",33 pages. Submitted to ACM TOMS,,http://arxiv.org/abs/1805.10121v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.DS']",,,"['AICES, RWTH Aachen University', 'AICES, RWTH Aachen University', 'AICES, RWTH Aachen University', 'JSC, Forschungszentrum Jülich']"
"COREclust: a new package for a robust and scalable analysis of complex
  data",http://arxiv.org/abs/1805.10211v1,2018-05-25T15:50:15Z,2018-05-25T15:50:15Z,"  In this paper, we present a new R package COREclust dedicated to the
detection of representative variables in high dimensional spaces with a
potentially limited number of observations. Variable sets detection is based on
an original graph clustering strategy denoted CORE-clustering algorithm that
detects CORE-clusters, i.e. variable sets having a user defined size range and
in which each variable is very similar to at least another variable.
Representative variables are then robustely estimate as the CORE-cluster
centers. This strategy is entirely coded in C++ and wrapped by R using the Rcpp
package. A particular effort has been dedicated to keep its algorithmic cost
reasonable so that it can be used on large datasets. After motivating our work,
we will explain the CORE-clustering algorithm as well as a greedy extension of
this algorithm. We will then present how to use it and results obtained on
synthetic and real data.
","['\nCamille Champion\nIMT\n', '\nAnne-Claire Brunet\nIMT\n', '\nJean-Michel Loubes\nIMT\n', '\nLaurent Risser\nIMT\n']",,,http://arxiv.org/abs/1805.10211v1,cs.MS,"['cs.MS', 'stat.CO', 'stat.ML']",,,"['IMT', 'IMT', 'IMT', 'IMT']"
Particle-based simulations of reaction-diffusion processes with Aboria,http://arxiv.org/abs/1805.11007v1,2018-05-28T16:07:30Z,2018-05-28T16:07:30Z,"  Mathematical models of transport and reactions in biological systems have
been traditionally written in terms of partial differential equations (PDEs)
that describe the time evolution of population-level variables. In recent
years, the use of stochastic particle-based models, which keep track of the
evolution of each organism in the system, has become widespread. These models
provide a lot more detail than the population-based PDE models, for example by
explicitly modelling particle-particle interactions, but bring with them many
computational challenges. In this paper we overview Aboria, a powerful and
flexible C++ library for the implementation of numerical methods for
particle-based models. We demonstrate the use of Aboria with a commonly used
model in mathematical biology, namely cell chemotaxis. Cells interact with each
other and diffuse, biased by extracellular chemicals, that can be altered by
the cells themselves. We use a hybrid approach where particle-based models of
cells are coupled with a PDE for the concentration of the extracellular
chemical.
","['\nMaria Bruna\n', '\nPhilip K. Maini\n', '\nMartin Robinson\n']",,,http://arxiv.org/abs/1805.11007v1,cs.CE,"['cs.CE', 'cs.MS', 'q-bio.QM']",,,[]
The EPFL Logic Synthesis Libraries,http://arxiv.org/abs/1805.05121v3,2018-05-14T11:34:47Z,2022-06-03T09:33:52Z,"  We present a collection of modular open source C++ libraries for the
development of logic synthesis applications. These libraries can be used to
develop applications for the design of classical and emerging technologies, as
well as for the implementation of quantum compilers. All libraries are well
documented and well tested. Furthermore, being header-only, the libraries can
be readily used as core components in complex logic synthesis systems.
","['\nMathias Soeken\n', '\nHeinz Riener\n', '\nWinston Haaswijk\n', '\nEleonora Testa\n', '\nBruno Schmitt\n', '\nGiulia Meuli\n', '\nFereshte Mozafari\n', '\nSiang-Yun Lee\n', '\nAlessandro Tempia Calvino\n', '\nDewmini Sudara Marakkalage\n', '\nGiovanni De Micheli\n']","13 pages, originally accepted at Int'l Workshop on Logic & Synthesis
  2018, extended for Workshop on Open-Source EDA Technology 2019",,http://arxiv.org/abs/1805.05121v3,cs.LO,"['cs.LO', 'cs.MS']",,,[]
geomstats: a Python Package for Riemannian Geometry in Machine Learning,http://arxiv.org/abs/1805.08308v2,2018-05-21T22:24:14Z,2018-11-06T01:28:54Z,"  We introduce geomstats, a python package that performs computations on
manifolds such as hyperspheres, hyperbolic spaces, spaces of symmetric positive
definite matrices and Lie groups of transformations. We provide efficient and
extensively unit-tested implementations of these manifolds, together with
useful Riemannian metrics and associated Exponential and Logarithm maps. The
corresponding geodesic distances provide a range of intuitive choices of
Machine Learning loss functions. We also give the corresponding Riemannian
gradients. The operations implemented in geomstats are available with different
computing backends such as numpy, tensorflow and keras. We have enabled GPU
implementation and integrated geomstats manifold computations into keras deep
learning framework. This paper also presents a review of manifolds in machine
learning and an overview of the geomstats package with examples demonstrating
its use for efficient and user-friendly Riemannian geometry.
","['\nNina Miolane\n', '\nJohan Mathe\n', '\nClaire Donnat\n', '\nMikael Jorda\n', '\nXavier Pennec\n']",Preprint NIPS2018,,http://arxiv.org/abs/1805.08308v2,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML']",,,[]
"CUDACLAW: A high-performance programmable GPU framework for the solution
  of hyperbolic PDEs",http://arxiv.org/abs/1805.08846v1,2018-05-21T14:21:51Z,2018-05-21T14:21:51Z,"  We present cudaclaw, a CUDA-based high performance data-parallel framework
for the solution of multidimensional hyperbolic partial differential equation
(PDE) systems, equations describing wave motion. cudaclaw allows computational
scientists to solve such systems on GPUs without being burdened by the need to
write CUDA code, worry about thread and block details, data layout, and data
movement between the different levels of the memory hierarchy. The user defines
the set of PDEs to be solved via a CUDA- independent serial Riemann solver and
the framework takes care of orchestrating the computations and data transfers
to maximize arithmetic throughput. cudaclaw treats the different spatial
dimensions separately to allow suitable block sizes and dimensions to be used
in the different directions, and includes a number of optimizations to minimize
access to global memory.
","['\nH. Gorune Ohannessian\n', '\nGeorge Turkiyyah\n', '\nAron Ahmadia\n', '\nDavid Ketcheson\n']",,,http://arxiv.org/abs/1805.08846v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
A User-Friendly Hybrid Sparse Matrix Class in C++,http://arxiv.org/abs/1805.03380v3,2018-05-09T05:49:05Z,2019-10-21T08:27:42Z,"  When implementing functionality which requires sparse matrices, there are
numerous storage formats to choose from, each with advantages and
disadvantages. To achieve good performance, several formats may need to be used
in one program, requiring explicit selection and conversion between the
formats. This can be both tedious and error-prone, especially for non-expert
users. Motivated by this issue, we present a user-friendly sparse matrix class
for the C++ language, with a high-level application programming interface
deliberately similar to the widely used MATLAB language. The class internally
uses two main approaches to achieve efficient execution: (i) a hybrid storage
framework, which automatically and seamlessly switches between three underlying
storage formats (compressed sparse column, coordinate list, Red-Black tree)
depending on which format is best suited for specific operations, and (ii)
template-based meta-programming to automatically detect and optimise execution
of common expression patterns. To facilitate relatively quick conversion of
research code into production environments, the class and its associated
functions provide a suite of essential sparse linear algebra functionality
(eg., arithmetic operations, submatrix manipulation) as well as high-level
functions for sparse eigendecompositions and linear equation solvers. The
latter are achieved by providing easy-to-use abstractions of the low-level
ARPACK and SuperLU libraries. The source code is open and provided under the
permissive Apache 2.0 license, allowing unencumbered use in commercial
products.
","['\nConrad Sanderson\n', '\nRyan Curtin\n']",,"Lecture Notes in Computer Science (LNCS), Vol. 10931, pp. 422-430,
  2018",http://dx.doi.org/10.1007/978-3-319-96418-8_50,cs.MS,"['cs.MS', '65F50, 97H60, 68N99, 68P05, 97N80', 'G.4; G.1.3; H.3.4; E.1']",10.1007/978-3-319-96418-8_50,,[]
RealCertify: a Maple package for certifying non-negativity,http://arxiv.org/abs/1805.02201v1,2018-05-06T12:31:55Z,2018-05-06T12:31:55Z,"  Let $\mathbb{Q}$ (resp. $\mathbb{R}$) be the field of rational (resp. real)
numbers and $X = (X_1, \ldots, X_n)$ be variables. Deciding the non-negativity
of polynomials in $\mathbb{Q}[X]$ over $\mathbb{R}^n$ or over semi-algebraic
domains defined by polynomial constraints in $\mathbb{Q}[X]$ is a classical
algorithmic problem for symbolic computation.
  The Maple package \textsc{RealCertify} tackles this decision problem by
computing sum of squares certificates of non-negativity for inputs where such
certificates hold over the rational numbers. It can be applied to numerous
problems coming from engineering sciences, program verification and
cyber-physical systems. It is based on hybrid symbolic-numeric algorithms based
on semi-definite programming.
","['\nVictor Magron\n', '\nMohab Safey El Din\n']","4 pages, 2 tables",,http://arxiv.org/abs/1805.02201v1,cs.SC,"['cs.SC', 'cs.MS']",,,[]
Program Generation for Small-Scale Linear Algebra Applications,http://arxiv.org/abs/1805.04775v1,2018-05-12T20:21:40Z,2018-05-12T20:21:40Z,"  We present SLinGen, a program generation system for linear algebra. The input
to SLinGen is an application expressed mathematically in a
linear-algebra-inspired language (LA) that we define. LA provides basic
scalar/vector/matrix additions/multiplications and higher level operations
including linear systems solvers, Cholesky and LU factorizations. The output of
SLinGen is performance-optimized single-source C code, optionally vectorized
with intrinsics. The target of SLinGen are small-scale computations on
fixed-size operands, for which a straightforward implementation using optimized
libraries (e.g., BLAS or LAPACK) is known to yield suboptimal performance
(besides increasing code size and introducing dependencies), but which are
crucial in control, signal processing, computer vision, and other domains.
Internally, SLinGen uses synthesis and DSL-based techniques to optimize at a
high level of abstraction. We benchmark our program generator on three
prototypical applications: the Kalman filter, Gaussian process regression, and
an L1-analysis convex solver, as well as basic routines including Cholesky
factorization and solvers for the continuous-time Lyapunov and Sylvester
equations. The results show significant speed-ups compared to straightforward C
with Intel icc and clang with a polyhedral optimizer, as well as library-based
and template-based implementations.
","['\nDaniele G. Spampinato\nETH Zurich\n', '\nDiego Fabregat-Traver\nRWTH Aachen University\n', '\nPaolo Bientinesi\nRWTH Aachen University\n', '\nMarkus Pueschel\nETH Zurich\n']",CGO 2018,,http://arxiv.org/abs/1805.04775v1,cs.PL,"['cs.PL', 'cs.MS']",,,"['ETH Zurich', 'RWTH Aachen University', 'RWTH Aachen University', 'ETH Zurich']"
Scrambled Linear Pseudorandom Number Generators,http://arxiv.org/abs/1805.01407v3,2018-05-03T16:22:23Z,2022-03-28T14:45:50Z,"  $\mathbf F_2$-linear pseudorandom number generators are very popular due to
their high speed, to the ease with which generators with a sizable state space
can be created, and to their provable theoretical properties. However, they
suffer from linear artifacts that show as failures in linearity-related
statistical tests such as the binary-rank and the linear-complexity test. In
this paper, we give two new contributions. First, we introduce two new $\mathbf
F_2$-linear transformations that have been handcrafted to have good statistical
properties and at the same time to be programmable very efficiently on
superscalar processors, or even directly in hardware. Then, we describe some
scramblers, that is, nonlinear functions applied to the state array that reduce
or delete the linear artifacts, and propose combinations of linear
transformations and scramblers that give extremely fast pseudorandom number
generators of high quality. A novelty in our approach is that we use ideas from
the theory of filtered linear-feedback shift registers to prove some properties
of our scramblers, rather than relying purely on heuristics. In the end, we
provide simple, extremely fast generators that use a few hundred bits of
memory, have provable properties, and pass strong statistical tests.
","['\nDavid Blackman\n', '\nSebastiano Vigna\n']",,,http://arxiv.org/abs/1805.01407v3,cs.DS,"['cs.DS', 'cs.CR', 'cs.MS']",,,[]
"MPI+X: task-based parallelization and dynamic load balance of finite
  element assembly",http://arxiv.org/abs/1805.03949v1,2018-05-09T16:01:01Z,2018-05-09T16:01:01Z,"  The main computing tasks of a finite element code(FE) for solving partial
differential equations (PDE's) are the algebraic system assembly and the
iterative solver. This work focuses on the first task, in the context of a
hybrid MPI+X paradigm. Although we will describe algorithms in the FE context,
a similar strategy can be straightforwardly applied to other discretization
methods, like the finite volume method. The matrix assembly consists of a loop
over the elements of the MPI partition to compute element matrices and
right-hand sides and their assemblies in the local system to each MPI
partition. In a MPI+X hybrid parallelism context, X has consisted traditionally
of loop parallelism using OpenMP. Several strategies have been proposed in the
literature to implement this loop parallelism, like coloring or substructuring
techniques to circumvent the race condition that appears when assembling the
element system into the local system. The main drawback of the first technique
is the decrease of the IPC due to bad spatial locality. The second technique
avoids this issue but requires extensive changes in the implementation, which
can be cumbersome when several element loops should be treated. We propose an
alternative, based on the task parallelism of the element loop using some
extensions to the OpenMP programming model. The taskification of the assembly
solves both aforementioned problems. In addition, dynamic load balance will be
applied using the DLB library, especially efficient in the presence of hybrid
meshes, where the relative costs of the different elements is impossible to
estimate a priori. This paper presents the proposed methodology, its
implementation and its validation through the solution of large computational
mechanics problems up to 16k cores.
","['\nMarta Garcia-Gasulla\n', '\nGuillaume Houzeaux\n', '\nRoger Ferrer\n', '\nAntoni Artigues\n', '\nVictor López\n', '\nJesús Labarta\n', '\nMariano Vázquez\n']",,,http://dx.doi.org/10.1080/10618562.2019.1617856,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF', 'cs.PL']",10.1080/10618562.2019.1617856,,[]
Fast parallel multidimensional FFT using advanced MPI,http://arxiv.org/abs/1804.09536v1,2018-04-25T13:20:53Z,2018-04-25T13:20:53Z,"  We present a new method for performing global redistributions of
multidimensional arrays essential to parallel fast Fourier (or similar)
transforms. Traditional methods use standard all-to-all collective
communication of contiguous memory buffers, thus necessary requiring local data
realignment steps intermixed in-between redistribution and transform steps.
Instead, our method takes advantage of subarray datatypes and generalized
all-to-all scatter/gather from the MPI-2 standard to communicate discontiguous
memory buffers, effectively eliminating the need for local data realignments.
Despite generalized all-to-all communication of discontiguous data being
generally slower, our proposal economizes in local work. For a range of strong
and weak scaling tests, we found the overall performance of our method to be on
par and often better than well-established libraries like MPI-FFTW, P3DFFT, and
2DECOMP&FFT. We provide compact routines implemented at the highest possible
level using the MPI bindings for the C programming language. These routines
apply to any global redistribution, over any two directions of a
multidimensional array, decomposed on arbitrary Cartesian processor grids (1D
slabs, 2D pencils, or even higher-dimensional decompositions). The high level
implementation makes the code easy to read, maintain, and eventually extend.
Our approach enables for future speedups from optimizations in the internal
datatype handling engines within MPI implementations.
","['\nLisandro Dalcin\n', '\nMikael Mortensen\n', '\nDavid E Keyes\n']",,,http://arxiv.org/abs/1804.09536v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Format Abstraction for Sparse Tensor Algebra Compilers,http://arxiv.org/abs/1804.10112v2,2018-04-23T20:57:59Z,2018-11-12T02:16:20Z,"  This paper shows how to build a sparse tensor algebra compiler that is
agnostic to tensor formats (data layouts). We develop an interface that
describes formats in terms of their capabilities and properties, and show how
to build a modular code generator where new formats can be added as plugins. We
then describe six implementations of the interface that compose to form the
dense, CSR/CSF, COO, DIA, ELL, and HASH tensor formats and countless variants
thereof. With these implementations at hand, our code generator can generate
code to compute any tensor algebra expression on any combination of the
aforementioned formats.
  To demonstrate our technique, we have implemented it in the taco tensor
algebra compiler. Our modular code generator design makes it simple to add
support for new tensor formats, and the performance of the generated code is
competitive with hand-optimized implementations. Furthermore, by extending taco
to support a wider range of formats specialized for different application and
data characteristics, we can improve end-user application performance. For
example, if input data is provided in the COO format, our technique allows
computing a single matrix-vector multiplication directly with the data in COO,
which is up to 3.6$\times$ faster than by first converting the data to CSR.
","['\nStephen Chou\n', '\nFredrik Kjolstad\n', '\nSaman Amarasinghe\n']",Presented at OOPSLA 2018,"Proc. ACM Program. Lang. 2, OOPSLA, Article 123 (November 2018)",http://dx.doi.org/10.1145/3276493,cs.MS,"['cs.MS', 'cs.PL']",10.1145/3276493,,[]
"Automatic generation of CUDA code performing tensor manipulations using
  C++ expression templates",http://arxiv.org/abs/1804.10120v1,2018-04-24T15:54:12Z,2018-04-24T15:54:12Z,"  We present a C++ library, TLoops, which uses a hierarchy of expression
templates to represent operations upon tensorial quantities in single lines of
C++ code that resemble analytic equations. These expressions may be run as-is,
but may also be used to emit equivalent low-level C or CUDA code, which either
performs the operations more quickly on the CPU, or allows them to be rapidly
ported to run on NVIDIA GPUs. We detail the expression template and C++-class
hierarchy that represents the expressions and which makes automatic
code-generation possible. We then present benchmarks of the expression-template
code, the automatically generated C code, and the automatically generated CUDA
code running on several generations of NVIDIA GPU.
","['\nAdam G. M. Lewis\n', '\nHarald P. Pfeiffer\n']","46 pages, 5 figures",,http://arxiv.org/abs/1804.10120v1,cs.MS,"['cs.MS', 'gr-qc']",,,[]
Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code,http://arxiv.org/abs/1804.10694v5,2018-04-27T21:28:44Z,2018-12-20T16:25:40Z,"  This paper introduces Tiramisu, a polyhedral framework designed to generate
high performance code for multiple platforms including multicores, GPUs, and
distributed machines. Tiramisu introduces a scheduling language with novel
extensions to explicitly manage the complexities that arise when targeting
these systems. The framework is designed for the areas of image processing,
stencils, linear algebra and deep learning. Tiramisu has two main features: it
relies on a flexible representation based on the polyhedral model and it has a
rich scheduling language allowing fine-grained control of optimizations.
Tiramisu uses a four-level intermediate representation that allows full
separation between the algorithms, loop transformations, data layouts, and
communication. This separation simplifies targeting multiple hardware
architectures with the same algorithm. We evaluate Tiramisu by writing a set of
image processing, deep learning, and linear algebra benchmarks and compare them
with state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu
matches or outperforms existing compilers and libraries on different hardware
architectures, including multicore CPUs, GPUs, and distributed machines.
","['\nRiyadh Baghdadi\n', '\nJessica Ray\n', '\nMalek Ben Romdhane\n', '\nEmanuele Del Sozzo\n', '\nAbdurrahman Akkas\n', '\nYunming Zhang\n', '\nPatricia Suriana\n', '\nShoaib Kamil\n', '\nSaman Amarasinghe\n']",arXiv admin note: substantial text overlap with arXiv:1803.00419,,http://arxiv.org/abs/1804.10694v5,cs.PL,"['cs.PL', 'cs.DC', 'cs.MS', 'cs.NE', 'cs.PF']",,,[]
Adaptive control in rollforward recovery for extreme scale multigrid,http://arxiv.org/abs/1804.06373v1,2018-04-17T16:58:50Z,2018-04-17T16:58:50Z,"  With the increasing number of compute components, failures in future
exa-scale computer systems are expected to become more frequent. This motivates
the study of novel resilience techniques. Here, we extend a recently proposed
algorithm-based recovery method for multigrid iterations by introducing an
adaptive control. After a fault, the healthy part of the system continues the
iterative solution process, while the solution in the faulty domain is
re-constructed by an asynchronous on-line recovery. The computations in both
the faulty and healthy subdomains must be coordinated in a sensitive way, in
particular, both under and over-solving must be avoided. Both of these waste
computational resources and will therefore increase the overall
time-to-solution. To control the local recovery and guarantee an optimal
re-coupling, we introduce a stopping criterion based on a mathematical error
estimator. It involves hierarchical weighted sums of residuals within the
context of uniformly refined meshes and is well-suited in the context of
parallel high-performance computing. The re-coupling process is steered by
local contributions of the error estimator. We propose and compare two criteria
which differ in their weights. Failure scenarios when solving up to
$6.9\cdot10^{11}$ unknowns on more than 245\,766 parallel processes will be
reported on a state-of-the-art peta-scale supercomputer demonstrating the
robustness of the method.
","['\nMarkus Huber\n', '\nUlrich Rüde\n', '\nBarbara Wohlmuth\n']",,,http://arxiv.org/abs/1804.06373v1,cs.MS,['cs.MS'],,,[]
"A Scalable Shared-Memory Parallel Simplex for Large-Scale Linear
  Programming",http://arxiv.org/abs/1804.04737v2,2018-04-12T21:59:40Z,2019-05-27T19:52:48Z,"  The Simplex tableau has been broadly used and investigated in the industry
and academia. With the advent of the big data era, ever larger problems are
posed to be solved in ever larger machines whose architecture type did not
exist in the conception of this algorithm. In this paper, we present a
shared-memory parallel implementation of the Simplex tableau algorithm for
dense large-scale Linear Programming (LP) problems for use in modern multi-core
architectures. We present the general scheme and explain the strategies taken
to parallelize each step of the standard simplex algorithm, emphasizing the
solutions found to solve performance bottlenecks. We analyzed the speedup and
the parallel efficiency for the proposed implementation relative to the
standard Simplex algorithm using a shared-memory system with 64 processing
cores. The experiments were performed for several different problems, with up
to 8192 variables and constraints, in their primal and dual formulations. The
results show that the performance is mostly much better when we use the
formulation with more variables than inequality constraints. Also, they show
that the parallelization strategies applied to avoid bottlenecks lead the
implementation to scale well with the problem size and the core count up to a
certain limit of problem size. Further analysis showed that this scaling limit
was an effect of resource limitation. Even though, our implementation was able
to reach speedups in the order of 19x.
","['\nDemetrios Coutinho\n', '\nFelipe O. Lins e Silva\n', '\nDaniel Aloise\n', '\n Samuel\n', '\n Xavier-de-Souza\n']",,,http://arxiv.org/abs/1804.04737v2,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Programming Parallel Dense Matrix Factorizations with Look-Ahead and
  OpenMP",http://arxiv.org/abs/1804.07017v1,2018-04-19T07:14:36Z,2018-04-19T07:14:36Z,"  We investigate a parallelization strategy for dense matrix factorization
(DMF) algorithms, using OpenMP, that departs from the legacy (or conventional)
solution, which simply extracts concurrency from a multithreaded version of
BLAS. This approach is also different from the more sophisticated
runtime-assisted implementations, which decompose the operation into tasks and
identify dependencies via directives and runtime support. Instead, our strategy
attains high performance by explicitly embedding a static look-ahead technique
into the DMF code, in order to overcome the performance bottleneck of the panel
factorization, and realizing the trailing update via a cache-aware
multi-threaded implementation of the BLAS. Although the parallel algorithms are
specified with a highlevel of abstraction, the actual implementation can be
easily derived from them, paving the road to deriving a high performance
implementation of a considerable fraction of LAPACK functionality on any
multicore platform with an OpenMP-like runtime.
","['\nSandra Catalán\n', '\nAdrián Castelló\n', '\nFrancisco D. Igual\n', '\nRafael Rodríguez-Sánchez\n', '\nEnrique S. Quintana-Ortí\n']",28 pages,,http://arxiv.org/abs/1804.07017v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Multiprecision Arithmetic for Cryptology in C++ - Compile-Time
  Computations and Beating the Performance of Hand-Optimized Assembly at
  Run-Time",http://arxiv.org/abs/1804.07236v1,2018-04-19T15:36:15Z,2018-04-19T15:36:15Z,"  We describe a new C++ library for multiprecision arithmetic for numbers in
the order of 100--500 bits, i.e., representable with just a few limbs. The
library is written in ""optimizing-compiler-friendly"" C++, with an emphasis on
the use of fixed-size arrays and particular function-argument-passing styles
(including the avoidance of naked pointers) to allow the limbs to be allocated
on the stack or even in registers. Depending on the particular functionality,
we get close to, or significantly beat the performance of existing libraries
for multiprecision arithmetic that employ hand-optimized assembly code.
  Most functions in the library are constant-time, which is a necessity for
secure implementations of cryptographic protocols.
  Beyond the favorable runtime performance, our library is, to the best of the
author's knowledge, the first library that offers big-integer computations
during compile-time. For example, when implementing finite-field arithmetic
with a fixed modulus, this feature enables the automatic precomputation (at
compile time) of the special modulus-dependent constants required for Barrett
and Montgomery reduction. Another application is to parse (at compile-time) a
base-10-encoded big-integer literal.
",['\nNiek J. Bouman\n'],9 pages (14 pages including references and appendices),,http://arxiv.org/abs/1804.07236v1,cs.CR,"['cs.CR', 'cs.MS']",,,[]
"OpenFPM: A scalable open framework for particle and particle-mesh codes
  on parallel computers",http://arxiv.org/abs/1804.07598v1,2018-04-20T13:18:50Z,2018-04-20T13:18:50Z,"  Scalable and efficient numerical simulations continue to gain importance, as
computation is firmly established as the third pillar of discovery, alongside
theory and experiment. Meanwhile, the performance of computing hardware grows
through increasing heterogeneous parallelism, enabling simulations of ever more
complex models. However, efficiently implementing scalable codes on
heterogeneous, distributed hardware systems becomes the bottleneck. This
bottleneck can be alleviated by intermediate software layers that provide
higher-level abstractions closer to the problem domain, hence allowing the
computational scientist to focus on the simulation. Here, we present OpenFPM,
an open and scalable framework that provides an abstraction layer for numerical
simulations using particles and/or meshes. OpenFPM provides transparent and
scalable infrastructure for shared-memory and distributed-memory
implementations of particles-only and hybrid particle-mesh simulations of both
discrete and continuous models, as well as non-simulation codes. This
infrastructure is complemented with portable implementations of frequently used
numerical routines, as well as interfaces to third-party libraries. We present
the architecture and design of OpenFPM, detail the underlying abstractions, and
benchmark the framework in applications ranging from Smoothed-Particle
Hydrodynamics (SPH) to Molecular Dynamics (MD), Discrete Element Methods (DEM),
Vortex Methods, stencil codes, high-dimensional Monte Carlo sampling (CMA-ES),
and Reaction-Diffusion solvers, comparing it to the current state of the art
and existing software frameworks.
","['\nPietro Incardona\n', '\nAntonio Leo\n', '\nYaroslav Zaluzhnyi\n', '\nRajesh Ramaswamy\n', '\nIvo F. Sbalzarini\n']","32 pages, 12 figures",,http://dx.doi.org/10.1016/j.cpc.2019.03.007,cs.DC,"['cs.DC', 'cs.MS', 'cs.SE', 'physics.comp-ph']",10.1016/j.cpc.2019.03.007,,[]
A Blackbox Polynomial System Solver on Parallel Shared Memory Computers,http://arxiv.org/abs/1804.03807v2,2018-04-11T04:41:49Z,2018-06-17T19:57:36Z,"  A numerical irreducible decomposition for a polynomial system provides
representations for the irreducible factors of all positive dimensional
solution sets of the system, separated from its isolated solutions. Homotopy
continuation methods are applied to compute a numerical irreducible
decomposition. Load balancing and pipelining are techniques in a parallel
implementation on a computer with multicore processors. The application of the
parallel algorithms is illustrated on solving the cyclic $n$-roots problems, in
particular for $n = 8, 9$, and~12.
",['\nJan Verschelde\n'],Accepted for publication in the proceedings of CASC 2018,,http://arxiv.org/abs/1804.03807v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.SC', 'math.AG', 'math.NA']",,,[]
μ-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching,http://arxiv.org/abs/1804.04806v1,2018-04-13T07:20:44Z,2018-04-13T07:20:44Z,"  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used
in deep learning. Specifically, cuDNN implements several equivalent convolution
algorithms, whose performance and memory footprint may vary considerably,
depending on the layer dimensions. When an algorithm is automatically selected
by cuDNN, the decision is performed on a per-layer basis, and thus it often
resorts to slower algorithms that fit the workspace size constraints. We
present {\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides
layers' mini-batch computation into several micro-batches. Based on Dynamic
Programming and Integer Linear Programming, {\mu}-cuDNN enables faster
algorithms by decreasing the workspace requirements. At the same time,
{\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples
statistical efficiency from the hardware efficiency safely. We demonstrate the
effectiveness of {\mu}-cuDNN over two frameworks, Caffe and TensorFlow,
achieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2
GPU. These results indicate that using micro-batches can seamlessly increase
the performance of deep learning, while maintaining the same memory footprint.
","['\nYosuke Oyama\n', '\nTal Ben-Nun\n', '\nTorsten Hoefler\n', '\nSatoshi Matsuoka\n']","11 pages, 14 figures. Part of the content have been published in IPSJ
  SIG Technical Report, Vol. 2017-HPC-162, No. 22, pp. 1-9, 2017. (DOI:
  http://id.nii.ac.jp/1001/00184814)",,http://arxiv.org/abs/1804.04806v1,cs.LG,"['cs.LG', 'cs.DC', 'cs.MS', 'cs.NE', 'stat.ML', 'I.2.6']",,,[]
"Automatic symbolic computation for discontinuous Galerkin finite element
  methods",http://arxiv.org/abs/1804.02338v1,2018-04-06T16:09:06Z,2018-04-06T16:09:06Z,"  The implementation of discontinuous Galerkin finite element methods (DGFEMs)
represents a very challenging computational task, particularly for systems of
coupled nonlinear PDEs, including multiphysics problems, whose parameters may
consist of power series or functionals of the solution variables. Thereby, the
exploitation of symbolic algebra to express a given DGFEM approximation of a
PDE problem within a high level language, whose syntax closely resembles the
mathematical definition, is an invaluable tool. Indeed, this then facilitates
the automatic assembly of the resulting system of (nonlinear) equations, as
well as the computation of Fr\'echet derivative(s) of the DGFEM scheme, needed,
for example, within a Newton-type solver. However, even exploiting symbolic
algebra, the discretisation of coupled systems of PDEs can still be extremely
verbose and hard to debug. Thereby, in this article we develop a further layer
of abstraction by designing a class structure for the automatic computation of
DGFEM formulations. This work has been implemented within the FEniCS package,
based on exploiting the Unified Form Language. Numerical examples are presented
which highlight the simplicity of implementation of DGFEMs for the numerical
approximation of a range of PDE problems.
","['\nPaul Houston\n', '\nNathan Sime\n']",,,http://arxiv.org/abs/1804.02338v1,cs.NA,"['cs.NA', 'cs.MS', '65N30']",,,[]
"Extreme Scale FMM-Accelerated Boundary Integral Equation Solver for Wave
  Scattering",http://arxiv.org/abs/1803.09948v1,2018-03-27T08:12:13Z,2018-03-27T08:12:13Z,"  Algorithmic and architecture-oriented optimizations are essential for
achieving performance worthy of anticipated energy-austere exascale systems. In
this paper, we present an extreme scale FMM-accelerated boundary integral
equation solver for wave scattering, which uses FMM as a matrix-vector
multiplication inside the GMRES iterative method. Our FMM Helmholtz kernels
treat nontrivial singular and near-field integration points. We implement
highly optimized kernels for both shared and distributed memory, targeting
emerging Intel extreme performance HPC architectures. We extract the potential
thread- and data-level parallelism of the key Helmholtz kernels of FMM. Our
application code is well optimized to exploit the AVX-512 SIMD units of Intel
Skylake and Knights Landing architectures. We provide different performance
models for tuning the task-based tree traversal implementation of FMM, and
develop optimal architecture-specific and algorithm aware partitioning, load
balancing, and communication reducing mechanisms to scale up to 6,144 compute
nodes of a Cray XC40 with 196,608 hardware cores. With shared memory
optimizations, we achieve roughly 77% of peak single precision floating point
performance of a 56-core Skylake processor, and on average 60% of peak single
precision floating point performance of a 72-core KNL. These numbers represent
nearly 5.4x and 10x speedup on Skylake and KNL, respectively, compared to the
baseline scalar code. With distributed memory optimizations, on the other hand,
we report near-optimal efficiency in the weak scalability study with respect to
both the logarithmic communication complexity as well as the theoretical
scaling complexity of FMM. In addition, we exhibit up to 85% efficiency in
strong scaling. We compute in excess of 2 billion DoF on the full-scale of the
Cray XC40 supercomputer.
","['\nMustafa Abduljabbar\n', '\nMohammed Al Farhan\n', '\nNoha Al-Harthi\n', '\nRui Chen\n', '\nRio Yokota\n', '\nHakan Bagci\n', '\nDavid Keyes\n']",,,http://arxiv.org/abs/1803.09948v1,cs.PF,"['cs.PF', 'cs.CE', 'cs.MS']",,,[]
Algorithmic Differentiation for Domain Specific Languages,http://arxiv.org/abs/1803.04154v1,2018-03-12T08:39:30Z,2018-03-12T08:39:30Z,"  Algorithmic Differentiation (AD) can be used to automate the generation of
derivatives in arbitrary software projects. This will generate maintainable
derivatives, that are always consistent with the computation of the software.
If a domain specific language (DSL) is used in a software the state of the art
approach is to differentiate the DSL library with the same AD tool. The
drawback of this solution is the reduced performance since the compiler is no
longer able to optimize the e.g. SIMD operations. The new approach in this
paper integrates the types and operations of the DSL into the AD tool. It will
be an operator overloading tool that is generated from an abstract definition
of a DSL. This approach enables the compiler to optimize again e.g. for SIMD
operation since all calculations are still performed with the original data
types. This will also reduce the required memory for AD since the statements
inside the DLS implementation are no longer seen by the AD tool. The
implementation is presented in the paper and first results for the performance
of the solution are presented.
","['\nMax Sagebaum\n', '\nNicolas R. Gauger\n']","6 pages, 4 figures",,http://arxiv.org/abs/1803.04154v1,cs.MS,"['cs.MS', '65D25 (Primary), 68N30 (Secondary)', 'G.1.4; G.4; D.2.2; D.2.11']",,,[]
"Efficient Realization of Givens Rotation through Algorithm-Architecture
  Co-design for Acceleration of QR Factorization",http://arxiv.org/abs/1803.05320v2,2018-03-14T14:41:52Z,2018-03-23T08:41:53Z,"  We present efficient realization of Generalized Givens Rotation (GGR) based
QR factorization that achieves 3-100x better performance in terms of
Gflops/watt over state-of-the-art realizations on multicore, and General
Purpose Graphics Processing Units (GPGPUs). GGR is an improvement over
classical Givens Rotation (GR) operation that can annihilate multiple elements
of rows and columns of an input matrix simultaneously. GGR takes 33% lesser
multiplications compared to GR. For custom implementation of GGR, we identify
macro operations in GGR and realize them on a Reconfigurable Data-path (RDP)
tightly coupled to pipeline of a Processing Element (PE). In PE, GGR attains
speed-up of 1.1x over Modified Householder Transform (MHT) presented in the
literature. For parallel realization of GGR, we use REDEFINE, a scalable
massively parallel Coarse-grained Reconfigurable Architecture, and show that
the speed-up attained is commensurate with the hardware resources in REDEFINE.
GGR also outperforms General Matrix Multiplication (gemm) by 10% in-terms of
Gflops/watt which is counter-intuitive.
","['\nFarhad Merchant\n', '\nTarun Vatwani\n', '\nAnupam Chattopadhyay\n', '\nSoumyendu Raha\n', '\nS K Nandy\n', '\nRanjani Narayan\n', '\nRainer Leupers\n']",,,http://arxiv.org/abs/1803.05320v2,cs.DC,"['cs.DC', 'cs.AR', 'cs.MS']",,,[]
Glyph: Symbolic Regression Tools,http://arxiv.org/abs/1803.06226v2,2018-03-13T21:57:49Z,2018-03-21T10:06:54Z,"  We present Glyph - a Python package for genetic programming based symbolic
regression. Glyph is designed for usage let by numerical simulations let by
real world experiments. For experimentalists, glyph-remote provides a
separation of tasks: a ZeroMQ interface splits the genetic programming
optimization task from the evaluation of an experimental (or numerical) run.
Glyph can be accessed at http://github.com/ambrosys/glyph . Domain experts are
be able to employ symbolic regression in their experiments with ease, even if
they are not expert programmers. The reuse potential is kept high by a generic
interface design. Glyph is available on PyPI and Github.
","['\nMarkus Quade\n', '\nJulien Gout\n', '\nMarkus Abel\n']","Submitted to JOSR. arXiv admin note: text overlap with
  arXiv:1612.05276",,http://arxiv.org/abs/1803.06226v2,cs.MS,"['cs.MS', 'cs.NE', 'math.OC', 'physics.data-an']",,,[]
Sparse Tensor Algebra Optimizations with Workspaces,http://arxiv.org/abs/1802.10574v2,2018-02-28T18:28:10Z,2018-04-24T17:55:16Z,"  This paper shows how to optimize sparse tensor algebraic expressions by
introducing temporary tensors, called workspaces, into the resulting loop
nests. We develop a new intermediate language for tensor operations called
concrete index notation that extends tensor index notation. Concrete index
notation expresses when and where sub-computations occur and what tensor they
are stored into. We then describe the workspace optimization in this language,
and how to compile it to sparse code by building on prior work in the
literature.
  We demonstrate the importance of the optimization on several important sparse
tensor kernels, including sparse matrix-matrix multiplication (SpMM), sparse
tensor addition (SpAdd), and the matricized tensor times Khatri-Rao product
(MTTKRP) used to factorize tensors. Our results show improvements over prior
work on tensor algebra compilation and brings the performance of these kernels
on par with state-of-the-art hand-optimized implementations. For example, SpMM
was not supported by prior tensor algebra compilers, the performance of MTTKRP
on the nell-2 data set improves by 35%, and MTTKRP can for the first time have
sparse results.
","['\nFredrik Kjolstad\n', '\nWillow Ahrens\n', '\nShoaib Kamil\n', '\nSaman Amarasinghe\n']",25 pages,,http://arxiv.org/abs/1802.10574v2,cs.MS,"['cs.MS', 'cs.PL']",,,[]
OpenMath and SMT-LIB,http://arxiv.org/abs/1803.01592v1,2018-03-05T10:33:50Z,2018-03-05T10:33:50Z,"  OpenMath and SMT-LIB are languages with very different origins, but both
""represent mathematics"". We describe SMT-LIB for the OpenMath community and
consider adaptations for both languages to support the growing SC-Square
initiative.
","['\nJames H. Davenport\n', '\nMatthew England\n', '\nRoberto Sebastiani\n', '\nPatrick Trentin\n']","Presented in the OpenMath 2017 Workshop, at CICM 2017, Edinburgh, UK",,http://arxiv.org/abs/1803.01592v1,cs.SC,"['cs.SC', 'cs.MS', 'H.3.5']",,,[]
"Chebyshev Filter Diagonalization on Modern Manycore Processors and
  GPGPUs",http://arxiv.org/abs/1803.02156v1,2018-03-06T13:13:23Z,2018-03-06T13:13:23Z,"  Chebyshev filter diagonalization is well established in quantum chemistry and
quantum physics to compute bulks of eigenvalues of large sparse matrices.
Choosing a block vector implementation, we investigate optimization
opportunities on the new class of high-performance compute devices featuring
both high-bandwidth and low-bandwidth memory. We focus on the transparent
access to the full address space supported by both architectures under
consideration: Intel Xeon Phi ""Knights Landing"" and Nvidia ""Pascal.""
  We propose two optimizations: (1) Subspace blocking is applied for improved
performance and data access efficiency. We also show that it allows
transparently handling problems much larger than the high-bandwidth memory
without significant performance penalties. (2) Pipelining of communication and
computation phases of successive subspaces is implemented to hide communication
costs without extra memory traffic.
  As an application scenario we use filter diagonalization studies on
topological insulator materials. Performance numbers on up to 512 nodes of the
OakForest-PACS and Piz Daint supercomputers are presented, achieving beyond 100
Tflop/s for computing 100 inner eigenvalues of sparse matrices of dimension one
billion.
","['\nMoritz Kreutzer\n', '\nGeorg Hager\n', '\nDominik Ernst\n', '\nHolger Fehske\n', '\nAlan R. Bishop\n', '\nGerhard Wellein\n']","18 pages, 8 figures",,http://dx.doi.org/10.1007/978-3-319-92040-5_17,cs.MS,"['cs.MS', 'cs.PF', 'physics.comp-ph']",10.1007/978-3-319-92040-5_17,,[]
"Scaling Structured Multigrid to 500K+ Cores through Coarse-Grid
  Redistribution",http://arxiv.org/abs/1803.02481v1,2018-03-06T23:57:38Z,2018-03-06T23:57:38Z,"  The efficient solution of sparse, linear systems resulting from the
discretization of partial differential equations is crucial to the performance
of many physics-based simulations. The algorithmic optimality of multilevel
approaches for common discretizations makes them a good candidate for an
efficient parallel solver. Yet, modern architectures for high-performance
computing systems continue to challenge the parallel scalability of multilevel
solvers. While algebraic multigrid methods are robust for solving a variety of
problems, the increasing importance of data locality and cost of data movement
in modern architectures motivates the need to carefully exploit structure in
the problem.
  Robust logically structured variational multigrid methods, such as Black Box
Multigrid (BoxMG), maintain structure throughout the multigrid hierarchy. This
avoids indirection and increased coarse-grid communication costs typical in
parallel algebraic multigrid. Nevertheless, the parallel scalability of
structured multigrid is challenged by coarse-grid problems where the overhead
in communication dominates computation. In this paper, an algorithm is
introduced for redistributing coarse-grid problems through incremental
agglomeration. Guided by a predictive performance model, this algorithm
provides robust redistribution decisions for structured multilevel solvers.
  A two-dimensional diffusion problem is used to demonstrate the significant
gain in performance of this algorithm over the previous approach that used
agglomeration to one processor. In addition, the parallel scalability of this
approach is demonstrated on two large-scale computing systems, with solves on
up to 500K+ cores.
","['\nAndrew Reisner\n', '\nLuke N. Olson\n', '\nJ. David Moulton\n']",21 pages,,http://arxiv.org/abs/1803.02481v1,cs.MS,"['cs.MS', 'cs.NA', 'cs.PF', 'physics.comp-ph']",,,[]
Compiling Diderot: From Tensor Calculus to C,http://arxiv.org/abs/1802.06504v1,2018-02-19T02:38:51Z,2018-02-19T02:38:51Z,"  Diderot is a parallel domain-specific language for analysis and visualization
of multidimensional scientific images, such as those produced by CT and MRI
scanners. In particular, it supports algorithms where tensor fields (i.e.,
functions from 3D points to tensor values) are used to represent the underlying
physical objects that were scanned by the imaging device. Diderot supports
higher-order programming where tensor fields are first-class values and where
differential operators and lifted linear-algebra operators can be used to
express mathematical reasoning directly in the language. While such lifted
field operations are central to the definition and computation of many
scientific visualization algorithms, to date they have required extensive
manual derivations and laborious implementation.
  The challenge for the Diderot compiler is to effectively translate the
high-level mathematical concepts that are expressible in the surface language
to a low-level and efficient implementation in C. This paper describes our
approach to this challenge, which is based around the careful design of an
intermediate representation (IR), called EIN, and a number of compiler
transformations that lower the program from tensor calculus to C while avoiding
combinatorial explosion in the size of the IR. We describe the challenges in
compiling a language like Diderot, the design of EIN, and the transformation
used by the compiler. We also present an evaluation of EIN with respect to both
compiler efficiency and quality of generated code.
","['\nCharisee Chiw\n', '\nGordon L. Kindlmann\n', '\nJohn Reppy\n']",,,http://arxiv.org/abs/1802.06504v1,cs.PL,"['cs.PL', 'cs.MS']",,,[]
"Comparative study of finite element methods using the Time-Accuracy-Size
  (TAS) spectrum analysis",http://arxiv.org/abs/1802.07832v1,2018-02-21T22:11:58Z,2018-02-21T22:11:58Z,"  We present a performance analysis appropriate for comparing algorithms using
different numerical discretizations. By taking into account the total
time-to-solution, numerical accuracy with respect to an error norm, and the
computation rate, a cost-benefit analysis can be performed to determine which
algorithm and discretization are particularly suited for an application. This
work extends the performance spectrum model in Chang et. al. 2017 for
interpretation of hardware and algorithmic tradeoffs in numerical PDE
simulation. As a proof-of-concept, popular finite element software packages are
used to illustrate this analysis for Poisson's equation.
","['\nJustin Chang\n', '\nMaurice S. Fabien\n', '\nMatthew G. Knepley\n', '\nRichard T. Mills\n']",,,http://arxiv.org/abs/1802.07832v1,cs.MS,"['cs.MS', 'cs.PF', '65Y05, 65Y20, 68N99']",,,[]
Numerical integration in arbitrary-precision ball arithmetic,http://arxiv.org/abs/1802.07942v1,2018-02-22T08:46:14Z,2018-02-22T08:46:14Z,"  We present an implementation of arbitrary-precision numerical integration
with rigorous error bounds in the Arb library. Rapid convergence is ensured for
piecewise complex analytic integrals by use of the Petras algorithm, which
combines adaptive bisection with adaptive Gaussian quadrature where error
bounds are determined via complex magnitudes without evaluating derivatives.
The code is general, easy to use, and efficient, often outperforming existing
non-rigorous software.
",['\nFredrik Johansson\n'],"8 pages, 1 figure",,http://arxiv.org/abs/1802.07942v1,cs.MS,"['cs.MS', 'cs.NA', '65G20']",,,[]
Moore: Interval Arithmetic in C++20,http://arxiv.org/abs/1802.08558v1,2018-02-21T19:02:45Z,2018-02-21T19:02:45Z,"  This article presents the Moore library for interval arithmetic in C++20. It
gives examples of how the library can be used, and explains the basic
principles underlying its design.
",['\nWalter F. Mascarenhas\n'],"arXiv admin note: text overlap with arXiv:1611.09567""",,http://arxiv.org/abs/1802.08558v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"The iisignature library: efficient calculation of iterated-integral
  signatures and log signatures",http://arxiv.org/abs/1802.08252v1,2018-02-22T14:29:30Z,2018-02-22T14:29:30Z,"  Iterated-integral signatures and log signatures are vectors calculated from a
path that characterise its shape. They come from the theory of differential
equations driven by rough paths, and also have applications in statistics and
machine learning. We present algorithms for efficiently calculating these
signatures, and benchmark their performance. We release the methods as a Python
package.
","['\nJeremy Reizenstein\n', '\nBenjamin Graham\n']",18 pages,,http://arxiv.org/abs/1802.08252v1,cs.DS,"['cs.DS', 'cs.MS', 'math.RA']",,,[]
Automatic differentiation of ODE integration,http://arxiv.org/abs/1802.02247v1,2018-02-06T22:13:26Z,2018-02-06T22:13:26Z,"  We discuss the calculation of the derivatives of ODE systems with the
automatic differentiation tool ADiMat. Using the well-known Lotka-Volterra
equations and the ode23 ODE solver as examples we show the analytic derivatives
and detail how to differentiate a top-level function that calls ode23 somewhere
with ADiMat. This involves the manual construction of substitution function to
propagate the derivatives in forward and reverse mode. We also show how to use
the reverse mode code to evaluate the Hessian in forward-over-reverse mode.
",['\nJohannes Willkomm\n'],"13 pages, 7 figure, 4 tables",,http://arxiv.org/abs/1802.02247v1,cs.MS,['cs.MS'],,,[]
"High Performance Rearrangement and Multiplication Routines for Sparse
  Tensor Arithmetic",http://arxiv.org/abs/1802.02619v1,2018-02-07T20:01:45Z,2018-02-07T20:01:45Z,"  Researchers are increasingly incorporating numeric high-order data, i.e.,
numeric tensors, within their practice. Just like the matrix/vector (MV)
paradigm, the development of multi-purpose, but high-performance, sparse data
structures and algorithms for arithmetic calculations, e.g., those found in
Einstein-like notation, is crucial for the continued adoption of tensors. We
use the example of high-order differential operators to illustrate this need.
As sparse tensor arithmetic is an emerging research topic, with challenges
distinct from the MV paradigm, many aspects require further articulation. We
focus on three core facets. First, aligning with prominent voices in the field,
we emphasise the importance of data structures able to accommodate the
operational complexity of tensor arithmetic. However, we describe a linearised
coordinate (LCO) data structure that provides faster and more memory-efficient
sorting performance. Second, flexible data structures, like the LCO, rely
heavily on sorts and permutations. We introduce an innovative permutation
algorithm, based on radix sort, that is tailored to rearrange already-sorted
sparse data, producing significant performance gains. Third, we introduce a
novel poly-algorithm for sparse tensor products, where hyper-sparsity is a
possibility. Different manifestations of hyper-sparsity demand their own
approach, which our poly-algorithm is the first to provide. These developments
are incorporated within our LibNT and NTToolbox software libraries. Benchmarks,
frequently drawn from the high-order differential operators example,
demonstrate the practical impact of our routines, with speed-ups of 40% or
higher compared to alternative high-performance implementations. Comparisons
against the MATLAB Tensor Toolbox show over 10 times speed improvements. Thus,
these advancements produce significant practical improvements for sparse tensor
arithmetic.
","['\nAdam P. Harrison\n', '\nDileepan Joseph\n']",To appear in SIAM Journal on Scientific Computing,,http://arxiv.org/abs/1802.02619v1,cs.MS,['cs.MS'],,,[]
GPU Accelerated Finite Element Assembly with Runtime Compilation,http://arxiv.org/abs/1802.03433v1,2018-02-09T19:56:16Z,2018-02-09T19:56:16Z,"  In recent years, high performance scientific computing on graphics processing
units (GPUs) have gained widespread acceptance. These devices are designed to
offer massively parallel threads for running code with general purpose. There
are many researches focus on finite element method with GPUs. However, most of
the works are specific to certain problems and applications. Some works propose
methods for finite element assembly that is general for a wide range of finite
element models. But the development of finite element code is dependent on the
hardware architectures. It is usually complicated and error prone using the
libraries provided by the hardware vendors. In this paper, we present
architecture and implementation of finite element assembly for partial
differential equations (PDEs) based on symbolic computation and runtime
compilation technique on GPU. User friendly programming interface with symbolic
computation is provided. At the same time, high computational efficiency is
achieved by using runtime compilation technique. As far as we know, it is the
first work using this technique to accelerate finite element assembly for
solving PDEs. Experiments show that a one to two orders of speedup is achieved
for the problems studied in the paper.
","['\nTao Cui\n', '\nXiaohu Guo\n', '\nHui Liu\n']","6 pages, 8 figures, conference",,http://arxiv.org/abs/1802.03433v1,cs.MS,"['cs.MS', 'math.NA']",,,[]
"Achieving Efficient Realization of Kalman Filter on CGRA through
  Algorithm-Architecture Co-design",http://arxiv.org/abs/1802.03650v1,2018-02-10T20:51:30Z,2018-02-10T20:51:30Z,"  In this paper, we present efficient realization of Kalman Filter (KF) that
can achieve up to 65% of the theoretical peak performance of underlying
architecture platform. KF is realized using Modified Faddeeva Algorithm (MFA)
as a basic building block due to its versatility and REDEFINE Coarse Grained
Reconfigurable Architecture (CGRA) is used as a platform for experiments since
REDEFINE is capable of supporting realization of a set algorithmic compute
structures at run-time on a Reconfigurable Data-path (RDP). We perform several
hardware and software based optimizations in the realization of KF to achieve
116% improvement in terms of Gflops over the first realization of KF. Overall,
with the presented approach for KF, 4-105x performance improvement in terms of
Gflops/watt over several academically and commercially available realizations
of KF is attained. In REDEFINE, we show that our implementation is scalable and
the performance attained is commensurate with the underlying hardware resources
","['\nFarhad Merchant\n', '\nTarun Vatwani\n', '\nAnupam Chattopadhyay\n', '\nSoumyendu Raha\n', '\nS K Nandy\n', '\nRanjani Narayan\n']",Accepted in ARC 2018,,http://arxiv.org/abs/1802.03650v1,cs.MS,"['cs.MS', 'cs.AR']",,,[]
Locality Optimized Unstructured Mesh Algorithms on GPUs,http://arxiv.org/abs/1802.03749v4,2018-02-11T14:59:49Z,2019-07-27T12:40:28Z,"  Unstructured-mesh based numerical algorithms such as finite volume and finite
element algorithms form an important class of applications for many scientific
and engineering domains. The key difficulty in achieving higher performance
from these applications is the indirect accesses that lead to data-races when
parallelized. Current methods for handling such data-races lead to reduced
parallelism and suboptimal performance. Particularly on modern many-core
architectures, such as GPUs, that has increasing core/thread counts, reducing
data movement and exploiting memory locality is vital for gaining good
performance.
  In this work we present novel locality-exploiting optimizations for the
efficient execution of unstructured-mesh algorithms on GPUs. Building on a
two-layered coloring strategy for handling data races, we introduce novel
reordering and partitioning techniques to further improve efficient execution.
The new optimizations are then applied to several well established
unstructured-mesh applications, investigating their performance on NVIDIA's
latest P100 and V100 GPUs. We demonstrate significant speedups
($1.1\text{--}1.75\times$) compared to the state-of-the-art. A range of
performance metrics are benchmarked including runtime, memory transactions,
achieved bandwidth performance, GPU occupancy and data reuse factors and are
used to understand and explain the key factors impacting performance. The
optimized algorithms are implemented as an open-source software library and we
illustrate its use for improving performance of existing or new
unstructured-mesh applications.
","['\nAndrás Attila Sulyok\n', '\nGábor Dániel Balogh\n', '\nIstván Zoltán Reguly\n', '\nGihan R. Mudalige\n']",Number of pages: 36 Number of figures: 21 Submitted to JPDC,,http://arxiv.org/abs/1802.03749v4,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"QRkit: Sparse, Composable QR Decompositions for Efficient and Stable
  Solutions to Problems in Computer Vision",http://arxiv.org/abs/1802.03773v1,2018-02-11T17:18:18Z,2018-02-11T17:18:18Z,"  Embedded computer vision applications increasingly require the speed and
power benefits of single-precision (32 bit) floating point. However,
applications which make use of Levenberg-like optimization can lose significant
accuracy when reducing to single precision, sometimes unrecoverably so. This
accuracy can be regained using solvers based on QR rather than Cholesky
decomposition, but the absence of sparse QR solvers for common sparsity
patterns found in computer vision means that many applications cannot benefit.
We introduce an open-source suite of solvers for Eigen, which efficiently
compute the QR decomposition for matrices with some common sparsity patterns
(block diagonal, horizontal and vertical concatenation, and banded). For
problems with very particular sparsity structures, these elements can be
composed together in 'kit' form, hence the name QRkit. We apply our methods to
several computer vision problems, showing competitive performance and
suitability especially in single precision arithmetic.
","['\nJan Svoboda\n', '\nThomas Cashman\n', '\nAndrew Fitzgibbon\n']",,,http://arxiv.org/abs/1802.03773v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
"Fast and rigorous arbitrary-precision computation of Gauss-Legendre
  quadrature nodes and weights",http://arxiv.org/abs/1802.03948v2,2018-02-12T09:47:05Z,2018-10-17T07:33:50Z,"  We describe a strategy for rigorous arbitrary-precision evaluation of
Legendre polynomials on the unit interval and its application in the generation
of Gauss-Legendre quadrature rules. Our focus is on making the evaluation
practical for a wide range of realistic parameters, corresponding to the
requirements of numerical integration to an accuracy of about 100 to 100 000
bits. Our algorithm combines the summation by rectangular splitting of several
types of expansions in terms of hypergeometric series with a fixed-point
implementation of Bonnet's three-term recurrence relation. We then compute
rigorous enclosures of the Gauss-Legendre nodes and weights using the interval
Newton method. We provide rigorous error bounds for all steps of the algorithm.
The approach is validated by an implementation in the Arb library, which
achieves order-of-magnitude speedups over previous code for computing
Gauss-Legendre rules with simultaneous high degree and precision.
","['\nFredrik Johansson\nLFANT\n', '\nMarc Mezzarobba\nARIC\n']",,,http://arxiv.org/abs/1802.03948v2,cs.NA,"['cs.NA', 'cs.MS']",,,"['LFANT', 'ARIC']"
"GPU implementation of algorithm SIMPLE-TS for calculation of unsteady,
  viscous, compressible and heat-conductive gas flows",http://arxiv.org/abs/1802.04243v1,2018-02-12T18:45:13Z,2018-02-12T18:45:13Z,"  The recent trend of using Graphics Processing Units (GPU's) for high
performance computations is driven by the high ratio of price performance for
these units, complemented by their cost effectiveness. At first glance,
computational fluid dynamics (CFD) solvers match perfectly to GPU resources
because these solvers make intensive calculations and use relatively little
memory. Nevertheless, there are scarce results about the practical use of this
serious advantage of GPU over CPU, especially for calculations of viscous,
compressible, heat-conductive gas flows with double precision accuracy. In this
paper, two GPU algorithms according to time approximation of convective terms
were presented: explicit and implicit scheme. To decrease data transfers
between device memories and increase the arithmetic intensity of a GPU code we
minimize the number of kernels. The GPU algorithm was implemented in one kernel
for the implicit scheme and two kernels for the explicit scheme. The numerical
equations were put together using macros and optimization, data copy from
global to private memory, and data reuse were left to the compiler. Thus keeps
the code simpler with excellent maintenance. As a test case, we model the flow
past squares in a microchannel at supersonic speed. The tests show that overall
speedup of AMD Radeon R9 280X is up to 102x compared to Intel Core i5-4690 core
and up to 184x compared to Intel Core i7-920 core, while speedup of NVIDIA
Tesla M2090 is up to 11x compared to Intel Core i5-4690 core and up to 20x
compared to Intel Core i7-920 core. Memory requirements of GPU code are
improved compared to CPU one. It requires 1[GB] global memory for 5.9 million
finite volumes that are two times less compared to C++ CPU code. After all the
code is simple, portable (written in OpenCL), memory efficient and easily
modifiable moreover demonstrates excellent performance.
",['\nKiril S. Shterev\n'],49 pages,,http://arxiv.org/abs/1802.04243v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
"Certified Roundoff Error Bounds using Bernstein Expansions and Sparse
  Krivine-Stengle Representations",http://arxiv.org/abs/1802.04385v1,2018-02-12T22:56:20Z,2018-02-12T22:56:20Z,"  Floating point error is a drawback of embedded systems implementation that is
difficult to avoid. Computing rigorous upper bounds of roundoff errors is
absolutely necessary for the validation of critical software. This problem of
computing rigorous upper bounds is even more challenging when addressing
non-linear programs. In this paper, we propose and compare two new algorithms
based on Bernstein expansions and sparse Krivine-Stengle representations,
adapted from the field of the global optimization, to compute upper bounds of
roundoff errors for programs implementing polynomial and rational functions. We
also provide the convergence rate of these two algorithms. We release two
related software package FPBern and FPKriSten, and compare them with the
state-of-the-art tools. We show that these two methods achieve competitive
performance, while providing accurate upper bounds by comparison with the other
tools.
","['\nVictor Magron\n', '\nAlexandre Rocca\n', '\nThao Dang\n']","14 pages, 2 figures, 2 tables. Extension of the work in
  arXiv:1610.07038",,http://arxiv.org/abs/1802.04385v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
"A High Performance Implementation of Spectral Clustering on CPU-GPU
  Platforms",http://arxiv.org/abs/1802.04450v1,2018-02-13T03:08:22Z,2018-02-13T03:08:22Z,"  Spectral clustering is one of the most popular graph clustering algorithms,
which achieves the best performance for many scientific and engineering
applications. However, existing implementations in commonly used software
platforms such as Matlab and Python do not scale well for many of the emerging
Big Data applications. In this paper, we present a fast implementation of the
spectral clustering algorithm on a CPU-GPU heterogeneous platform. Our
implementation takes advantage of the computational power of the multi-core CPU
and the massive multithreading and SIMD capabilities of GPUs. Given the input
as data points in high dimensional space, we propose a parallel scheme to build
a sparse similarity graph represented in a standard sparse representation
format. Then we compute the smallest $k$ eigenvectors of the Laplacian matrix
by utilizing the reverse communication interfaces of ARPACK software and
cuSPARSE library, where $k$ is typically very large. Moreover, we implement a
very fast parallelized $k$-means algorithm on GPUs. Our implementation is shown
to be significantly faster compared to the best known Matlab and Python
implementations for each step. In addition, our algorithm scales to problems
with a very large number of clusters.
","['\nYu Jin\n', '\nJoseph F. JaJa\n']","2016 IEEE International Parallel and Distributed Processing Symposium
  Workshops (Parallel Computing and Optimization (PCO) workshop). Codes are
  available on https://github.com/yuj-umd/fastsc",,http://dx.doi.org/10.1109/IPDPSW.2016.79,cs.DC,"['cs.DC', 'cs.MS']",10.1109/IPDPSW.2016.79,,[]
"Slate: extending Firedrake's domain-specific abstraction to hybridized
  solvers for geoscience and beyond",http://arxiv.org/abs/1802.00303v4,2018-02-01T14:37:13Z,2019-04-01T19:34:09Z,"  Within the finite element community, discontinuous Galerkin (DG) and mixed
finite element methods have become increasingly popular in simulating
geophysical flows. However, robust and efficient solvers for the resulting
saddle-point and elliptic systems arising from these discretizations continue
to be an on-going challenge. One possible approach for addressing this issue is
to employ a method known as hybridization, where the discrete equations are
transformed such that classic static condensation and local post-processing
methods can be employed. However, it is challenging to implement hybridization
as performant parallel code within complex models, whilst maintaining
separation of concerns between applications scientists and software experts. In
this paper, we introduce a domain-specific abstraction within the Firedrake
finite element library that permits the rapid execution of these hybridization
techniques within a code-generating framework. The resulting framework composes
naturally with Firedrake's solver environment, allowing for the implementation
of hybridization and static condensation as runtime-configurable
preconditioners via the Python interface to PETSc, petsc4py. We provide
examples derived from second order elliptic problems and geophysical fluid
dynamics. In addition, we demonstrate that hybridization shows great promise
for improving the performance of solvers for mixed finite element
discretizations of equations related to large-scale geophysical flows.
","['\nThomas H. Gibson\n', '\nLawrence Mitchell\n', '\nDavid A. Ham\n', '\nColin J. Cotter\n']",Revisions for submission to GMD,Geoscientific Model Development 13:735-761 (2020),http://dx.doi.org/10.5194/gmd-13-735-2020,cs.MS,"['cs.MS', 'G.4; G.1.8; I.1']",10.5194/gmd-13-735-2020,,[]
Stop talking to me -- a communication-avoiding ADER-DG realisation,http://arxiv.org/abs/1801.08682v1,2018-01-26T05:56:11Z,2018-01-26T05:56:11Z,"  We present a communication- and data-sensitive formulation of ADER-DG for
hyperbolic differential equation systems. Sensitive here has multiple flavours:
First, the formulation reduces the persistent memory footprint. This reduces
pressure on the memory subsystem. Second, the formulation realises the
underlying predictor-corrector scheme with single-touch semantics, i.e., each
degree of freedom is read on average only once per time step from the main
memory. This reduces communication through the memory controllers. Third, the
formulation breaks up the tight coupling of the explicit time stepping's
algorithmic steps to mesh traversals. This averages out data access peaks.
Different operations and algorithmic steps are ran on different grid entities.
Finally, the formulation hides distributed memory data transfer behind the
computation aligned with the mesh traversal. This reduces pressure on the
machine interconnects. All techniques applied by our formulation are elaborated
by means of a rigorous task formalism. They break up ADER-DG's tight causal
coupling of compute steps and can be generalised to other predictor-corrector
schemes.
","['\nDominic E. Charrier\n', '\nTobias Weinzierl\n']",,,http://arxiv.org/abs/1801.08682v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"GraphCombEx: A Software Tool for Exploration of Combinatorial
  Optimisation Properties of Large Graphs",http://arxiv.org/abs/1801.09229v1,2018-01-28T13:43:50Z,2018-01-28T13:43:50Z,"  We present a prototype of a software tool for exploration of multiple
combinatorial optimisation problems in large real-world and synthetic complex
networks. Our tool, called GraphCombEx (an acronym of Graph Combinatorial
Explorer), provides a unified framework for scalable computation and
presentation of high-quality suboptimal solutions and bounds for a number of
widely studied combinatorial optimisation problems. Efficient representation
and applicability to large-scale graphs and complex networks are particularly
considered in its design. The problems currently supported include maximum
clique, graph colouring, maximum independent set, minimum vertex clique
covering, minimum dominating set, as well as the longest simple cycle problem.
Suboptimal solutions and intervals for optimal objective values are estimated
using scalable heuristics. The tool is designed with extensibility in mind,
with the view of further problems and both new fast and high-performance
heuristics to be added in the future. GraphCombEx has already been successfully
used as a support tool in a number of recent research studies using
combinatorial optimisation to analyse complex networks, indicating its promise
as a research software tool.
","['\nDavid Chalupa\n', '\nKen A Hawick\n']",,,http://dx.doi.org/10.1007/s00500-018-3230-x,cs.SI,"['cs.SI', 'cs.MS']",10.1007/s00500-018-3230-x,,[]
HOL Light QE,http://arxiv.org/abs/1802.00405v2,2018-02-01T17:31:06Z,2018-05-12T18:05:54Z,"  We are interested in algorithms that manipulate mathematical expressions in
mathematically meaningful ways. Expressions are syntactic, but most logics do
not allow one to discuss syntax. ${\rm CTT}_{\rm qe}$ is a version of Church's
type theory that includes quotation and evaluation operators, akin to quote and
eval in the Lisp programming language. Since the HOL logic is also a version of
Church's type theory, we decided to add quotation and evaluation to HOL Light
to demonstrate the implementability of ${\rm CTT}_{\rm qe}$ and the benefits of
having quotation and evaluation in a proof assistant. The resulting system is
called HOL Light QE. Here we document the design of HOL Light QE and the
challenges that needed to be overcome. The resulting implementation is freely
available.
","['\nJacques Carette\n', '\nWilliam M. Farmer\n', '\nPatrick Laskowski\n']",20 pages. arXiv admin note: text overlap with arXiv:1612.02785,,http://arxiv.org/abs/1802.00405v2,cs.LO,"['cs.LO', 'cs.MS', '68T30 (Primary), 03B15, 03B35 (Secondary)', 'F.4.1; I.2.4']",,,[]
rlsm: R package for least squares Monte Carlo,http://arxiv.org/abs/1801.05554v1,2018-01-17T05:19:49Z,2018-01-17T05:19:49Z,"  This short paper briefly describes the implementation of the least squares
Monte Carlo method in the rlsm package. This package provides users with an
easy manner to experiment with the large amount of R regression tools on any
regression basis and reward functions. This package also computes lower and
upper bounds for the true value function via duality methods.
",['\nJeremy Yee\n'],9 pages,,http://arxiv.org/abs/1801.05554v1,cs.MS,['cs.MS'],,,[]
rcss: Subgradient and duality approach for dynamic programming,http://arxiv.org/abs/1801.06029v1,2018-01-18T14:19:36Z,2018-01-18T14:19:36Z,"  This short paper gives an introduction to the \emph{rcss} package. The R
package \emph{rcss} provides users with a tool to approximate the value
functions in the Bellman recursion using convex piecewise linear functions
formed using operations on tangents. A pathwise method is then used to gauge
the quality of the numerical results.
","['\nJuri Hinz\n', '\nJeremy Yee\n']",13 pages,,http://arxiv.org/abs/1801.06029v1,cs.MS,['cs.MS'],,,[]
Distributed dynamic load balancing for task parallel programming,http://arxiv.org/abs/1801.04582v1,2018-01-14T16:47:52Z,2018-01-14T16:47:52Z,"  In this paper, we derive and investigate approaches to dynamically load
balance a distributed task parallel application software. The load balancing
strategy is based on task migration. Busy processes export parts of their ready
task queue to idle processes. Idle--busy pairs of processes find each other
through a random search process that succeeds within a few steps with high
probability. We evaluate the load balancing approach for a block Cholesky
factorization implementation and observe a reduction in execution time on the
order of 5\% in the selected test cases.
","['\nAfshin Zafari\n', '\nElisabeth Larsson\n']",,,http://arxiv.org/abs/1801.04582v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs,http://arxiv.org/abs/1801.06601v1,2018-01-19T23:39:15Z,2018-01-19T23:39:15Z,"  Deep Neural Networks are becoming increasingly popular in always-on IoT edge
devices performing data analytics right at the source, reducing latency as well
as energy consumption for data communication. This paper presents CMSIS-NN,
efficient kernels developed to maximize the performance and minimize the memory
footprint of neural network (NN) applications on Arm Cortex-M processors
targeted for intelligent IoT edge devices. Neural network inference based on
CMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X
improvement in energy efficiency.
","['\nLiangzhen Lai\n', '\nNaveen Suda\n', '\nVikas Chandra\n']",,,http://arxiv.org/abs/1801.06601v1,cs.NE,"['cs.NE', 'cs.LG', 'cs.MS']",,,[]
"Review of theory and implementation of hyper-dual numbers for first and
  second order automatic differentiation",http://arxiv.org/abs/1801.03614v2,2018-01-11T02:16:35Z,2018-01-14T19:12:21Z,"  In this review we present hyper-dual numbers as a tool for the automatic
differentiation of computer programs via operator overloading.
  We start with a motivational introduction into the ideas of algorithmic
differentiation. Then we illuminate the concepts behind operator overloading
and dual numbers.
  Afterwards, we present hyper-dual numbers (and vectors) as an extension of
dual numbers for the computation of the Jacobian and the Hessian matrices of a
computer program. We review a mathematical theorem that proves the correctness
of the derivative information that is obtained from hyper-dual numbers.
  Finally, we refer to a freely available implementation of a hyper-dual number
class in Matlab. We explain an interface that can be called with a function as
argument such that the Jacobian and Hessian of this function are returned.
",['\nMartin Neuenhofen\n'],9 pages,,http://arxiv.org/abs/1801.03614v2,cs.MS,['cs.MS'],,,[]
ruptures: change point detection in Python,http://arxiv.org/abs/1801.00826v1,2018-01-02T20:35:23Z,2018-01-02T20:35:23Z,"  ruptures is a Python library for offline change point detection. This package
provides methods for the analysis and segmentation of non-stationary signals.
Implemented algorithms include exact and approximate detection for various
parametric and non-parametric models. ruptures focuses on ease of use by
providing a well-documented and consistent interface. In addition, thanks to
its modular structure, different algorithms and models can be connected and
extended within this package.
","['\nCharles Truong\n', '\nLaurent Oudre\n', '\nNicolas Vayatis\n']",,,http://arxiv.org/abs/1801.00826v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
Tensor Train decomposition on TensorFlow (T3F),http://arxiv.org/abs/1801.01928v2,2018-01-05T21:58:01Z,2020-03-02T21:51:20Z,"  Tensor Train decomposition is used across many branches of machine learning.
We present T3F -- a library for Tensor Train decomposition based on TensorFlow.
T3F supports GPU execution, batch processing, automatic differentiation, and
versatile functionality for the Riemannian optimization framework, which takes
into account the underlying manifold structure to construct efficient
optimization methods. The library makes it easier to implement machine learning
papers that rely on the Tensor Train decomposition. T3F includes documentation,
examples and 94% test coverage.
","['\nAlexander Novikov\n', '\nPavel Izmailov\n', '\nValentin Khrulkov\n', '\nMichael Figurnov\n', '\nIvan Oseledets\n']",,,http://arxiv.org/abs/1801.01928v2,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"Computing the sparse matrix vector product using block-based kernels
  without zero padding on processors with AVX-512 instructions",http://arxiv.org/abs/1801.01134v2,2018-01-03T19:00:06Z,2018-05-11T10:05:38Z,"  The sparse matrix-vector product (SpMV) is a fundamental operation in many
scientific applications from various fields. The High Performance Computing
(HPC) community has therefore continuously invested a lot of effort to provide
an efficient SpMV kernel on modern CPU architectures. Although it has been
shown that block-based kernels help to achieve high performance, they are
difficult to use in practice because of the zero padding they require. In the
current paper, we propose new kernels using the AVX-512 instruction set, which
makes it possible to use a blocking scheme without any zero padding in the
matrix memory storage. We describe mask-based sparse matrix formats and their
corresponding SpMV kernels highly optimized in assembly language. Considering
that the optimal blocking size depends on the matrix, we also provide a method
to predict the best kernel to be used utilizing a simple interpolation of
results from previous executions. We compare the performance of our approach to
that of the Intel MKL CSR kernel and the CSR5 open-source package on a set of
standard benchmark matrices. We show that we can achieve significant
improvements in many cases, both for sequential and for parallel executions.
Finally, we provide the corresponding code in an open source library, called
SPC5.
","['\nBerenger Bramas\n', '\nPavel Kus\n']",Published in Peer J CS,,http://arxiv.org/abs/1801.01134v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
"On quality of implementation of Fortran 2008 complex intrinsic functions
  on branch cuts",http://arxiv.org/abs/1712.10230v1,2017-12-29T13:53:03Z,2017-12-29T13:53:03Z,"  Branch cuts in complex functions in combination with signed zero and signed
infinity have important uses in fracture mechanics, jet flow and aerofoil
analysis. We present benchmarks for validating Fortran 2008 complex functions -
LOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with
arguments of all 3 IEEE floating point binary formats: binary32, binary64 and
binary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,
Cray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,
e.g. wrong signs of results or unexpected overflow, underflow, or NaN. We
conclude that the quality of implementation of these Fortran 2008 intrinsics in
many compilers is not yet sufficient to remove the need for special code for
branch cuts. The test results are complemented by conformal maps of the branch
cuts and detailed derivations of the values of these functions on branch cuts,
to be used as a reference. The benchmarks are freely available from
cmplx.sf.net. This work will be of interest to engineers who use complex
functions, as well as to compiler and maths library developers.
",['\nAnton Shterenlikht\n'],"28 pages, 10 figures, 13 tables, original work",,http://arxiv.org/abs/1712.10230v1,cs.MS,"['cs.MS', 'cs.NA', '30-04']",,,[]
"CameraTransform: a Scientific Python Package for Perspective Camera
  Corrections",http://arxiv.org/abs/1712.07438v1,2017-12-20T12:13:44Z,2017-12-20T12:13:44Z,"  Scientific applications often require an exact reconstruction of object
positions and distances from digital images. Therefore, the images need to be
corrected for perspective distortions. We present \textit{CameraTransform}, a
python package that performs a perspective image correction whereby the height,
tilt/roll angle and heading of the camera can be automatically obtained from
the images if additional information such as GPS coordinates or object sizes
are provided. We present examples of images of penguin colonies that are
recorded with stationary cameras and from a helicopter.
","['\nRichard Gerum\n', '\nSebastian Richter\n', '\nAlexander Winterl\n', '\nBen Fabry\n', '\nDaniel Zitterbart\n']","8 pages, 5 figures",,http://dx.doi.org/10.1016/j.softx.2019.100333,cs.MS,['cs.MS'],10.1016/j.softx.2019.100333,,[]
In a Nutshell -- The Sequential Parameter Optimization Toolbox,http://arxiv.org/abs/1712.04076v2,2017-12-12T00:03:45Z,2021-03-04T18:55:44Z,"  The performance of optimization algorithms relies crucially on their
parameterizations. Finding good parameter settings is called algorithm tuning.
The sequential parameter optimization (SPOT) package for R is a toolbox for
tuning and understanding simulation and optimization algorithms. Model-based
investigations are common approaches in simulation and optimization. Sequential
parameter optimization has been developed, because there is a strong need for
sound statistical analysis of simulation and optimization algorithms. SPOT
includes methods for tuning based on classical regression and analysis of
variance techniques; tree-based models such as CART and random forest; Gaussian
process models (Kriging), and combinations of different meta-modeling
approaches. Using a simple simulated annealing algorithm, we will demonstrate
how optimization algorithms can be tuned using SPOT. The underling concepts of
the SPOT approach are explained. This includes key techniques such as
exploratory fitness landscape analysis and sensititvity analysis. Many examples
illustrate how SPOT can be used for understanding the performance of algorithms
and gaining insight into algorithm's behavior. Furthermore, we demonstrate how
SPOT can be used as an optimizer and how a sophisticated ensemble approach is
able to combine several meta models via stacking. This article exemplifies how
SPOT can be used for automatic and interactive tuning.
","['\nThomas Bartz-Beielstein\n', '\nMartin Zaefferer\n', '\nFrederik Rehbach\n']",For SPOT Version >= 2.2.24,,http://arxiv.org/abs/1712.04076v2,cs.MS,"['cs.MS', 'cs.AI', 'math.OC', '68W50', 'A.1; B.8.0; G.1.6; G.4; I.2.8']",,,[]
"Accelerating the computation of FLAPW methods on heterogeneous
  architectures",http://arxiv.org/abs/1712.07206v1,2017-12-19T20:58:08Z,2017-12-19T20:58:08Z,"  Legacy codes in computational science and engineering have been very
successful in providing essential functionality to researchers. However, they
are not capable of exploiting the massive parallelism provided by emerging
heterogeneous architectures. The lack of portable performance and scalability
puts them at high risk: either they evolve or they are doomed to disappear. One
example of legacy code which would heavily benefit from a modern design is
FLEUR, a software for electronic structure calculations. In previous work, the
computational bottleneck of FLEUR was partially re-engineered to have a modular
design that relies on standard building blocks, namely BLAS and LAPACK. In this
paper, we demonstrate how the initial redesign enables the portability to
heterogeneous architectures. More specifically, we study different approaches
to port the code to architectures consisting of multi-core CPUs equipped with
one or more coprocessors such as Nvidia GPUs and Intel Xeon Phis. Our final
code attains over 70\% of the architectures' peak performance, and outperforms
Nvidia's and Intel's libraries. Finally, on JURECA, the supercomputer where
FLEUR is often executed, the code takes advantage of the full power of the
computing nodes, attaining $5\times$ speedup over the sole use of the CPUs.
","['\nDavor Davidović\n', '\nDiego Fabregat-Traver\n', '\nMarkus Höhnerbach\n', '\nEdoardo di Napoli\n']","22 pages, submitted to special issue of CCPE",,http://dx.doi.org/10.1002/cpe.4905,cs.DC,"['cs.DC', 'cs.CE', 'cs.MS']",10.1002/cpe.4905,,[]
"A distributed-memory hierarchical solver for general sparse linear
  systems",http://arxiv.org/abs/1712.07297v1,2017-12-20T02:54:20Z,2017-12-20T02:54:20Z,"  We present a parallel hierarchical solver for general sparse linear systems
on distributed-memory machines. For large-scale problems, this fully algebraic
algorithm is faster and more memory-efficient than sparse direct solvers
because it exploits the low-rank structure of fill-in blocks. Depending on the
accuracy of low-rank approximations, the hierarchical solver can be used either
as a direct solver or as a preconditioner. The parallel algorithm is based on
data decomposition and requires only local communication for updating boundary
data on every processor. Moreover, the computation-to-communication ratio of
the parallel algorithm is approximately the volume-to-surface-area ratio of the
subdomain owned by every processor. We present various numerical results to
demonstrate the versatility and scalability of the parallel algorithm.
","['\nChao Chen\n', '\nHadi Pouransari\n', '\nSivasankaran Rajamanickam\n', '\nErik G. Boman\n', '\nEric Darve\n']",,,http://arxiv.org/abs/1712.07297v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F50']",,,[]
Constructive Arithmetics in Ore Localizations of Domains,http://arxiv.org/abs/1712.01773v1,2017-12-05T17:26:19Z,2017-12-05T17:26:19Z,"  For a non-commutative domain $R$ and a multiplicatively closed set $S$ the
(left) Ore localization of $R$ at $S$ exists if and only if $S$ satisfies the
(left) Ore property. Since the concept has been introduced by Ore back in the
1930's, Ore localizations have been widely used in theory and in applications.
We investigate the arithmetics of the localized ring $S^{-1}R$ from both
theoretical and practical points of view. We show that the key component of the
arithmetics is the computation of the intersection of a left ideal with a
submonoid $S$ of $R$. It is not known yet, whether there exists an algorithmic
solution of this problem in general. Still, we provide such solutions for cases
where $S$ is equipped with additional structure by distilling three most
frequently occurring types of Ore sets. We introduce the notion of the (left)
saturation closure and prove that it is a canonical form for (left) Ore sets in
$R$. We provide an implementation of arithmetics over the ubiquitous
$G$-algebras in \textsc{Singular:Plural} and discuss questions arising in this
context. Numerous examples illustrate the effectiveness of the proposed
approach.
","['\nJohannes Hoffmann\n', '\nViktor Levandovskyy\n']",24 pages,Journal of Symbolic Computation 98 (2020) 23-46,http://dx.doi.org/10.1016/j.jsc.2019.07.005,math.RA,"['math.RA', 'cs.MS', 'cs.SC', '16U20, 16Z05, 68W30']",10.1016/j.jsc.2019.07.005,,[]
Rings: an efficient Java/Scala library for polynomial rings,http://arxiv.org/abs/1712.02329v3,2017-12-06T18:52:14Z,2018-09-21T19:32:48Z,"  In this paper we briefly discuss \Rings --- an efficient lightweight library
for commutative algebra. Polynomial arithmetic, GCDs, polynomial factorization
and Gr\""obner bases are implemented with the use of modern asymptotically fast
algorithms. \Rings can be easily interacted or embedded in applications in
high-energy physics and other research areas via a simple API with fully typed
hierarchy of algebraic structures and algorithms for commutative algebra. The
use of the Scala language brings a quite novel powerful, strongly typed
functional programming model allowing to write short, expressive, and fast code
for applications. At the same time Rings shows one of the best performances
among existing software for algebraic calculations. \Rings is available from
http://github.com/PoslavskySV/rings
",['\nStanislav Poslavsky\n'],Computer Physics Communications (2018),,http://dx.doi.org/10.1016/j.cpc.2018.09.005,cs.SC,"['cs.SC', 'cs.MS', 'hep-ph', 'math.AC', 'math.RA']",10.1016/j.cpc.2018.09.005,,[]
Abaqus2Matlab: A suitable tool for finite element post-processing,http://arxiv.org/abs/1711.10188v1,2017-11-28T09:06:44Z,2017-11-28T09:06:44Z,"  A suitable piece of software is presented to connect Abaqus, a sophisticated
finite element package, with Matlab, the most comprehensive program for
mathematical analysis. This interface between these well-known codes not only
benefits from the image processing and the integrated graph-plotting features
of Matlab but also opens up new opportunities in results post-processing,
statistical analysis and mathematical optimization, among many other
possibilities. The software architecture and usage are appropriately described
and two problems of particular engineering significance are addressed to
demonstrate its capabilities. Firstly, the software is employed to assess
cleavage fracture through a novel 3-parameter Weibull probabilistic framework.
Then, its potential to create and train neural networks is used to identify
damage parameters through a hybrid experimental-numerical scheme, and model
crack propagation in structural materials by means of a cohesive zone approach.
The source code, detailed documentation and a large number of tutorials can be
freely downloaded from www.abaqus2matlab.com.
","['\nGeorge Papazafeiropoulos\n', '\nMiguel Muñiz-Calvente\n', '\nEmilio Martínez-Pañeda\n']",,"Advances in Engineering Software 105, pp. 9-16 (2017)",http://dx.doi.org/10.1016/j.advengsoft.2017.01.006,cs.MS,['cs.MS'],10.1016/j.advengsoft.2017.01.006,,[]
TLib: A Flexible C++ Tensor Framework for Numerical Tensor Calculus,http://arxiv.org/abs/1711.10912v1,2017-11-28T14:36:59Z,2017-11-28T14:36:59Z,"  Numerical tensor calculus comprise basic tensor operations such as the
entrywise addition and contraction of higher-order tensors. We present, TLib,
flexible tensor framework with generic tensor functions and tensor classes that
assists users to implement generic and flexible tensor algorithms in C++. The
number of dimensions, the extents of the dimensions of the tensors and the
contraction modes of the tensor operations can be runtime variable. Our
framework provides tensor classes that simplify the management of
multidimensional data and utilization of tensor operations using
object-oriented and generic programming techniques. Additional stream classes
help the user to verify and compare of numerical results with MATLAB. Tensor
operations are implemented with generic tensor functions and in terms of
multidimensional iterator types only, decoupling data storage representation
and computation. The user can combine tensor functions with different tensor
types and extend the framework without further modification of the classes or
functions. We discuss the design and implementation of the framework and
demonstrate its usage with examples that have been discussed in the literature.
",['\nCem Bassoy\n'],29 pages,,http://arxiv.org/abs/1711.10912v1,cs.MS,"['cs.MS', 'G.4']",,,[]
HomotopyContinuation.jl: A package for homotopy continuation in Julia,http://arxiv.org/abs/1711.10911v2,2017-11-28T15:53:22Z,2018-05-30T09:14:53Z,"  We present the Julia package HomotopyContinuation.jl, which provides an
algorithmic framework for solving polynomial systems by numerical homotopy
continuation. We introduce the basic capabilities of the package and
demonstrate the software on an illustrative example. We motivate our choice of
Julia and how its features allow us to improve upon existing software packages
with respect to usability, modularity and performance. Furthermore, we compare
the performance of HomotopyContinuation.jl to the existing packages Bertini and
PHCpack.
","['\nPaul Breiding\n', '\nSascha Timme\n']",8 pages,,http://arxiv.org/abs/1711.10911v2,cs.MS,"['cs.MS', 'math.AG']",,,[]
PhasePack User Guide,http://arxiv.org/abs/1711.09777v3,2017-11-24T09:36:13Z,2017-11-29T22:58:07Z,"  ""Phase retrieval"" refers to the recovery of signals from the magnitudes (and
not the phases) of linear measurements. While there has been a recent explosion
in development of phase retrieval methods, the lack of a common interface has
made it difficult to compare new methods against the current state-of-the-art.
PhasePack is a software library that creates a common interface for a wide
range of phase retrieval schemes. PhasePack also provides a test bed for phase
retrieval methods using both synthetic data and publicly available empirical
datasets.
","['\nRohan Chandra\n', '\nZiyuan Zhong\n', '\nJustin Hontz\n', '\nVal McCulloch\n', '\nChristoph Studer\n', '\nTom Goldstein\n']",,,http://arxiv.org/abs/1711.09777v3,cs.MS,"['cs.MS', 'cs.IT', 'math.IT']",,,[]
"Efficiently and easily integrating differential equations with JiTCODE,
  JiTCDDE, and JiTCSDE",http://arxiv.org/abs/1711.09886v2,2017-11-25T18:25:44Z,2018-03-22T13:52:09Z,"  We present a family of Python modules for the numerical integration of
ordinary, delay, or stochastic differential equations. The key features are
that the user enters the derivative symbolically and it is
just-in-time-compiled, allowing the user to efficiently integrate differential
equations from a higher-level interpreted language. The presented modules are
particularly suited for large systems of differential equations such as used to
describe dynamics on complex networks. Through the selected method of input,
the presented modules also allow to almost completely automatize the process of
estimating regular as well as transversal Lyapunov exponents for ordinary and
delay differential equations. We conceptually discuss the modules' design,
analyze their performance, and demonstrate their capabilities by application to
timely problems.
",['\nGerrit Ansmann\n'],,"Chaos 28, 043116 (2018)",http://dx.doi.org/10.1063/1.5019320,cs.MS,"['cs.MS', 'math.DS', 'physics.comp-ph']",10.1063/1.5019320,,[]
"TRPL+K: Thick-Restart Preconditioned Lanczos+K Method for Large
  Symmetric Eigenvalue Problems",http://arxiv.org/abs/1711.10128v2,2017-11-28T05:33:14Z,2018-07-16T03:36:36Z,"  The Lanczos method is one of the standard approaches for computing a few
eigenpairs of a large, sparse, symmetric matrix. It is typically used with
restarting to avoid unbounded growth of memory and computational requirements.
Thick-restart Lanczos is a popular restarted variant because of its simplicity
and numerically robustness. However, convergence can be slow for highly
clustered eigenvalues so more effective restarting techniques and the use of
preconditioning is needed. In this paper, we present a thick-restart
preconditioned Lanczos method, TRPL+K, that combines the power of locally
optimal restarting (+K) and preconditioning techniques with the efficiency of
the thick-restart Lanczos method. TRPL+K employs an inner-outer scheme where
the inner loop applies Lanczos on a preconditioned operator while the outer
loop augments the resulting Lanczos subspace with certain vectors from the
previous restart cycle to obtain eigenvector approximations with which it thick
restarts the outer subspace. We first identify the differences from various
relevant methods in the literature. Then, based on an optimization perspective,
we show an asymptotic global quasi-optimality of a simplified TRPL+K method
compared to an unrestarted global optimal method. Finally, we present extensive
experiments showing that TRPL+K either outperforms or matches other
state-of-the-art eigenmethods in both matrix-vector multiplications and
computational time.
","['\nLingfei Wu\n', '\nFei Xue\n', '\nAndreas Stathopoulos\n']","27 pages, 6 figures, 7 tables. Submitted to SIAM Journal on
  Scientific Computing, Minor Revision",,http://arxiv.org/abs/1711.10128v2,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
PQSER: A Matlab package for spectral seriation,http://arxiv.org/abs/1711.05677v2,2017-11-15T17:13:36Z,2017-11-23T10:09:02Z,"  The seriation problem is an important ordering issue which consists of
finding the best ordering of a set of units whose interrelationship is defined
by a bipartite graph. It has important applications in, e.g., archaeology,
anthropology, psychology, and biology. This paper presents a Matlab
implementation of an algorithm for spectral seriation by Atkins et al., based
on the use of the Fiedler vector of the Laplacian matrix associated to the
problem, which encodes the set of admissible solutions into a PQ-tree. We
introduce some numerical technicalities in the original algorithm to improve
its performance, and point out that the presence of a multiple Fiedler value
may have a substantial influence on the computation of an approximated
solution, in the presence of inconsistent data sets. Practical examples and
numerical experiments show how to use the toolbox to process data sets deriving
from real-world applications.
","['\nAnna Concas\n', '\nCaterina Fenu\n', '\nGiuseppe Rodriguez\n']","20 pages, 9 figures",,http://arxiv.org/abs/1711.05677v2,cs.MS,"['cs.MS', '65F15, 65F50, 05C82, 91D30']",,,[]
"Performance Analysis and Optimization of Sparse Matrix-Vector
  Multiplication on Modern Multi- and Many-Core Processors",http://arxiv.org/abs/1711.05487v1,2017-11-15T10:22:53Z,2017-11-15T10:22:53Z,"  This paper presents a low-overhead optimizer for the ubiquitous sparse
matrix-vector multiplication (SpMV) kernel. Architectural diversity among
different processors together with structural diversity among different sparse
matrices lead to bottleneck diversity. This justifies an SpMV optimizer that is
both matrix- and architecture-adaptive through runtime specialization. To this
direction, we present an approach that first identifies the performance
bottlenecks of SpMV for a given sparse matrix on the target platform either
through profiling or by matrix property inspection, and then selects suitable
optimizations to tackle those bottlenecks. Our optimization pool is based on
the widely used Compressed Sparse Row (CSR) sparse matrix storage format and
has low preprocessing overheads, making our overall approach practical even in
cases where fast decision making and optimization setup is required. We
evaluate our optimizer on three x86-based computing platforms and demonstrate
that it is able to distinguish and appropriately optimize SpMV for the majority
of matrices in a representative test suite, leading to significant speedups
over the CSR and Inspector-Executor CSR SpMV kernels available in the latest
release of the Intel MKL library.
","['\nAthena Elafrou\n', '\nGeorgios Goumas\n', '\nNektarios Koziris\n']","10 pages, 7 figures, ICPP 2017",,http://dx.doi.org/10.1109/ICPP.2017.38,cs.PF,"['cs.PF', 'cs.MS']",10.1109/ICPP.2017.38,,[]
Python Implementation and Construction of Finite Abelian Groups,http://arxiv.org/abs/1711.05814v1,2017-11-15T21:26:09Z,2017-11-15T21:26:09Z,"  Here we present a working framework to establish finite abelian groups in
python. The primary aim is to allow new A-level students to work with examples
of finite abelian groups using open source software. We include the code used
in the implementation of the framework. We also prove some useful results
regarding finite abelian groups which are used to establish the functions and
help show how number theoretic results can blend with computational power when
studying algebra. The groups established are based modular multiplication and
addition. We include direct products of cyclic groups meaning the user has
access to all finite abelian groups.
","['\nPaul Bradley\n', '\nJohn Smethurst\n']",20 pages,,http://arxiv.org/abs/1711.05814v1,math.GR,"['math.GR', 'cs.MS', '60-04, 20-04']",,,[]
Solving Poisson's Equation on the Microsoft HoloLens,http://arxiv.org/abs/1711.07790v1,2017-11-17T13:44:33Z,2017-11-17T13:44:33Z,"  We present a mixed reality application (HoloFEM) for the Microsoft HoloLens.
The application lets a user define and solve a physical problem governed by
Poisson's equation with the surrounding real world geometry as input data.
Holograms are used to visualise both the problem and the solution. The finite
element method is used to solve Poisson's equation. Solving and visualising
partial differential equations in mixed reality could have potential usage in
areas such as building planning and safety engineering.
","['\nAnders Logg\n', '\nCarl Lundholm\n', '\nMagne Nordaas\n']","2 pages, 9 figures","In Proceedings of the 23rd ACM Symposium on Virtual Reality
  Software and Technology (VRST 2017). ACM, New York, NY, USA, Article 87",http://dx.doi.org/10.1145/3139131.3141777,cs.GR,"['cs.GR', 'cs.MS']",10.1145/3139131.3141777,,[]
DLVM: A modern compiler infrastructure for deep learning systems,http://arxiv.org/abs/1711.03016v5,2017-11-08T15:33:23Z,2018-02-02T21:07:25Z,"  Deep learning software demands reliability and performance. However, many of
the existing deep learning frameworks are software libraries that act as an
unsafe DSL in Python and a computation graph interpreter. We present DLVM, a
design and implementation of a compiler infrastructure with a linear algebra
intermediate representation, algorithmic differentiation by adjoint code
generation, domain-specific optimizations and a code generator targeting GPU
via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM
is more modular and more generic than existing deep learning compiler
frameworks, and supports tensor DSLs with high expressivity. With our
prototypical staged DSL embedded in Swift, we argue that the DLVM system
enables a form of modular, safe and performant frameworks for deep learning.
","['\nRichard Wei\n', '\nLane Schwartz\n', '\nVikram Adve\n']",,,http://arxiv.org/abs/1711.03016v5,cs.PL,"['cs.PL', 'cs.LG', 'cs.MS']",,,[]
"Fast matrix-free evaluation of discontinuous Galerkin finite element
  operators",http://arxiv.org/abs/1711.03590v1,2017-11-09T20:36:06Z,2017-11-09T20:36:06Z,"  We present an algorithmic framework for matrix-free evaluation of
discontinuous Galerkin finite element operators based on sum factorization on
quadrilateral and hexahedral meshes. We identify a set of kernels for fast
quadrature on cells and faces targeting a wide class of weak forms originating
from linear and nonlinear partial differential equations. Different algorithms
and data structures for the implementation of operator evaluation are compared
in an in-depth performance analysis. The sum factorization kernels are
optimized by vectorization over several cells and faces and an even-odd
decomposition of the one-dimensional compute kernels. In isolation our
implementation then reaches up to 60\% of arithmetic peak on Intel Haswell and
Broadwell processors and up to 50\% of arithmetic peak on Intel Knights
Landing. The full operator evaluation reaches only about half that throughput
due to memory bandwidth limitations from loading the input and output vectors,
MPI ghost exchange, as well as handling variable coefficients and the geometry.
Our performance analysis shows that the results are often within 10\% of the
available memory bandwidth for the proposed implementation, with the exception
of the Cartesian mesh case where the cost of gather operations and MPI
communication are more substantial.
","['\nMartin Kronbichler\n', '\nKatharina Kormann\n']",,"ACM Transactions on Mathematical Software 45(3), 29/1-29/40, 2019",http://dx.doi.org/10.1145/3325864,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",10.1145/3325864,,[]
"Domain-Specific Acceleration and Auto-Parallelization of Legacy
  Scientific Code in FORTRAN 77 using Source-to-Source Compilation",http://arxiv.org/abs/1711.04471v1,2017-11-13T08:56:43Z,2017-11-13T08:56:43Z,"  Massively parallel accelerators such as GPGPUs, manycores and FPGAs represent
a powerful and affordable tool for scientists who look to speed up simulations
of complex systems. However, porting code to such devices requires a detailed
understanding of heterogeneous programming tools and effective strategies for
parallelization. In this paper we present a source to source compilation
approach with whole-program analysis to automatically transform single-threaded
FORTRAN 77 legacy code into OpenCL-accelerated programs with parallelized
kernels.
  The main contributions of our work are: (1) whole-source refactoring to allow
any subroutine in the code to be offloaded to an accelerator. (2) Minimization
of the data transfer between the host and the accelerator by eliminating
redundant transfers. (3) Pragmatic auto-parallelization of the code to be
offloaded to the accelerator by identification of parallelizable maps and
reductions.
  We have validated the code transformation performance of the compiler on the
NIST FORTRAN 78 test suite and several real-world codes: the Large Eddy
Simulator for Urban Flows, a high-resolution turbulent flow model; the shallow
water component of the ocean model Gmodel; the Linear Baroclinic Model, an
atmospheric climate model and Flexpart-WRF, a particle dispersion simulator.
  The automatic parallelization component has been tested on as 2-D Shallow
Water model (2DSW) and on the Large Eddy Simulator for Urban Flows (UFLES) and
produces a complete OpenCL-enabled code base. The fully OpenCL-accelerated
versions of the 2DSW and the UFLES are resp. 9x and 20x faster on GPU than the
original code on CPU, in both cases this is the same performance as manually
ported code.
","['\nWim Vanderbauwhede\n', '\nGavin Davidson\n']","12 pages, 5 figures, submitted to ""Computers and Fluids"" as full
  paper from ParCFD conference entry",,http://arxiv.org/abs/1711.04471v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA']",,,[]
"Hydra: a C++11 framework for data analysis in massively parallel
  platforms",http://arxiv.org/abs/1711.05683v2,2017-11-15T17:19:29Z,2017-11-16T01:44:12Z,"  Hydra is a header-only, templated and C++11-compliant framework designed to
perform the typical bottleneck calculations found in common HEP data analyses
on massively parallel platforms. The framework is implemented on top of the
C++11 Standard Library and a variadic version of the Thrust library and is
designed to run on Linux systems, using OpenMP, CUDA and TBB enabled devices.
This contribution summarizes the main features of Hydra. A basic description of
the overall design, functionality and user interface is provided, along with
some code examples and measurements of performance.
","['\nA. A. Alves Jr\n', '\nM. D. Sokoloff\n']",ACAT 2017 Proceedings,,http://arxiv.org/abs/1711.05683v2,cs.MS,"['cs.MS', 'hep-ex', 'physics.comp-ph', 'physics.data-an']",,,[]
A generic and fast C++ optimization framework,http://arxiv.org/abs/1711.06581v1,2017-11-17T15:10:25Z,2017-11-17T15:10:25Z,"  The development of the mlpack C++ machine learning library
(http://www.mlpack.org/) has required the design and implementation of a
flexible, robust optimization system that is able to solve the types of
arbitrary optimization problems that may arise all throughout machine learning
problems. In this paper, we present the generic optimization framework that we
have designed for mlpack. A key priority in the design was ease of
implementation of both new optimizers and new objective functions to be
optimized; therefore, implementation of a new optimizer requires only one
method and implementation of a new objective function requires at most four
functions. This leads to simple and intuitive code, which, for fast prototyping
and experimentation, is of paramount importance. When compared to optimization
frameworks of other libraries, we find that mlpack's supports more types of
objective functions, is able to make optimizations that other frameworks do
not, and seamlessly supports user-defined objective functions and optimizers.
","['\nRyan R. Curtin\n', '\nShikhar Bhardwaj\n', '\nMarcus Edel\n', '\nYannis Mentekidis\n']",6 pages + references submitted to MLSYS 2017 workshop,,http://arxiv.org/abs/1711.06581v1,cs.MS,"['cs.MS', 'cs.LG', 'cs.SE']",,,[]
CGAlgebra: a Mathematica package for conformal geometric algebra. v.2.0,http://arxiv.org/abs/1711.02513v3,2017-11-03T23:29:00Z,2022-06-29T22:52:58Z,"  A tutorial of the Mathematica package CGAlgebra, for conformal geometric
algebra calculations is presented. Using rule-based programming, the
5-dimensional conformal geometric algebra is implemented and defined functions
simplify the calculations of geometric, outer and inner products, as well as
many other calculations related with geometric transformations. CGAlgebra is
available from https://github.com/jlaragonvera/Geometric-Algebra
","['\nE. Alejandra Ortiz-Duran\n', '\nJose L. Aragon\n']","Improved version, one figure",,http://arxiv.org/abs/1711.02513v3,cs.MS,['cs.MS'],,,[]
"A Massively Parallel Algorithm for the Approximate Calculation of
  Inverse p-th Roots of Large Sparse Matrices",http://arxiv.org/abs/1710.10899v3,2017-10-30T12:33:35Z,2018-04-12T13:50:40Z,"  We present the submatrix method, a highly parallelizable method for the
approximate calculation of inverse p-th roots of large sparse symmetric
matrices which are required in different scientific applications. We follow the
idea of Approximate Computing, allowing imprecision in the final result in
order to be able to utilize the sparsity of the input matrix and to allow
massively parallel execution. For an n x n matrix, the proposed algorithm
allows to distribute the calculations over n nodes with only little
communication overhead. The approximate result matrix exhibits the same
sparsity pattern as the input matrix, allowing for efficient reuse of allocated
data structures.
  We evaluate the algorithm with respect to the error that it introduces into
calculated results, as well as its performance and scalability. We demonstrate
that the error is relatively limited for well-conditioned matrices and that
results are still valuable for error-resilient applications like
preconditioning even for ill-conditioned matrices. We discuss the execution
time and scaling of the algorithm on a theoretical level and present a
distributed implementation of the algorithm using MPI and OpenMP. We
demonstrate the scalability of this implementation by running it on a
high-performance compute cluster comprised of 1024 CPU cores, showing a speedup
of 665x compared to single-threaded execution.
","['\nMichael Lass\n', '\nStephan Mohr\n', '\nHendrik Wiebeler\n', '\nThomas D. Kühne\n', '\nChristian Plessl\n']",,,http://dx.doi.org/10.1145/3218176.3218231,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA']",10.1145/3218176.3218231,,[]
"Performance Optimization and Parallelization of a Parabolic Equation
  Solver in Computational Ocean Acoustics on Modern Many-core Computer",http://arxiv.org/abs/1711.00005v2,2017-10-31T13:58:48Z,2017-11-11T08:52:52Z,"  As one of open-source codes widely used in computational ocean acoustics,
FOR3D can provide a very good estimate for underwater acoustic propagation. In
this paper, we propose a performance optimization and parallelization to speed
up the running of FOR3D. We utilized a variety of methods to enhance the entire
performance, such as using a multi-threaded programming model to exploit the
potential capability of the many-core node of high-performance computing (HPC)
system, tuning compile options, using efficient tuned mathematical library and
utilizing vectorization optimization instruction. In addition, we extended the
application from single-frequency calculation to multi-frequency calculation
successfully by using OpenMP+MPI hybrid programming techniques on the
mainstream HPC platform. A detailed performance evaluation was performed and
the results showed that the proposed parallelization obtained good accelerated
effect of 25.77X when testing a typical three-dimensional medium-sized case on
Tianhe-2 supercomputer. It also showed that the tuned parallel version has a
weak-scalability. The speed of calculation of underwater sound field can be
greatly improved by the strategy mentioned in this paper. The method used in
this paper is not only applicable to other similar computing models in
computational ocean acoustics but also a guideline of performance enhancement
for scientific and engineering application running on modern
many-core-computing platform.
","['\nMin Xu\n', '\nYongxian Wang\n', '\nAnthony Theodore Chronopoulos\n', '\nHao Yue\n']","9 pages, 8 figures, 3 tables. preprint for the International
  Conference on Computer Science and Application Engineering (CSAE2017).
  2017.10.21-23, Shanghai, China",,http://dx.doi.org/10.12783/dtcse/csae2017/17546,cs.MS,"['cs.MS', 'cs.CE', 'cs.PF']",10.12783/dtcse/csae2017/17546,,[]
"Acceleration of tensor-product operations for high-order finite element
  methods",http://arxiv.org/abs/1711.00903v2,2017-11-02T19:45:33Z,2017-11-13T15:18:19Z,"  This paper is devoted to GPU kernel optimization and performance analysis of
three tensor-product operators arising in finite element methods. We provide a
mathematical background to these operations and implementation details.
Achieving close-to-the-peak performance for these operators requires extensive
optimization because of the operators' properties: low arithmetic intensity,
tiered structure, and the need to store intermediate results inside the kernel.
We give a guided overview of optimization strategies and we present a
performance model that allows us to compare the efficacy of these optimizations
against an empirically calibrated roofline.
","['\nKasia Świrydowicz\n', '\nNoel Chalmers\n', '\nAli Karakus\n', '\nTimothy Warburton\n']","31 pages, 11 figures",,http://arxiv.org/abs/1711.00903v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'cs.PF', 'math.NA']",,,[]
Fast Linear Transformations in Python,http://arxiv.org/abs/1710.09578v2,2017-10-26T08:16:04Z,2021-11-29T14:10:54Z,"  Scientific computing requires handling large linear models, which are often
composed of structured matrices. With increasing model size, dense
representations quickly become infeasible to compute or store. Matrix-free
implementations are suited to mitigate this problem but usually complicate
research and development effort by months, when applied to practical research
problems.
  Fastmat is a framework for handling large composed or structured matrices by
offering an easy-to-use abstraction model. It allows expressing and using
linear operators in a mathematically intuitive way, while maintaining a strong
focus on efficient computation and memory storage. The implemented user
interface allows for very readable code implementation with very close
relationship to the actual mathematical notation of a given problem. Further it
provides means for quickly testing new implementations and also allows for
run-time execution path optimization.
  Summarizing, fastmat provides a flexible and extensible framework for
handling matrix-free linear structured operators efficiently, while being
intuitive and generating easy-to-reuse results.
","['\nChristoph Wilfried Wagner\n', '\nSebastian Semper\n', '\nJan Kirchhof\n']",,,http://arxiv.org/abs/1710.09578v2,cs.MS,['cs.MS'],,,[]
Wilson and Domainwall Kernels on Oakforest-PACS,http://arxiv.org/abs/1710.07226v1,2017-10-18T06:24:50Z,2017-10-18T06:24:50Z,"  We report the performance of Wilson and Domainwall Kernels on a new Intel
Xeon Phi Knights Landing based machine named Oakforest-PACS, which is co-hosted
by University of Tokyo and Tsukuba University and is currently fastest in
Japan. This machine uses Intel Omni-Path for the internode network. We compare
performance with several types of implementation including that makes use of
the Grid library. The code is incorporated with the code set Bridge++.
","['\nIssaku Kanamori\n', '\nHideo Matsufuru\n']","8 pages, 9 figures, Proceedings for the 35th International Symposium
  on Lattice Field Theory (Lattice 2017)",,http://dx.doi.org/10.1051/epjconf/201817509002,hep-lat,"['hep-lat', 'cs.MS']",10.1051/epjconf/201817509002,,[]
"Geometric Computing with Chain Complexes: Design and Features of a Julia
  Package",http://arxiv.org/abs/1710.07819v2,2017-10-21T16:03:17Z,2017-11-06T09:00:54Z,"  Geometric computing with chain complexes allows for the computation of the
whole chain of linear spaces and (co)boundary operators generated by a space
decomposition into a cell complex. The space decomposition is stored and
handled with LAR (Linear Algebraic Representation), i.e. with sparse integer
arrays, and allows for using cells of a very general type, even non convex and
with internal holes. In this paper we discuss the features and the merits of
this approach, and describe the goals and the implementation of a software
package aiming at providing for simple and efficient computational support of
geometric computing with any kind of meshes, using linear algebra tools with
sparse matrices. The library is being written in Julia, the novel efficient and
parallel language for scientific computing. This software, that is being ported
on hybrid architectures (CPU+GPU) of last generation, is yet under development.
","['\nFrancesco Furiani\n', '\nGiulio Martella\n', '\nAlberto Paoluzzi\n']",Submitted paper,,http://arxiv.org/abs/1710.07819v2,cs.CG,"['cs.CG', 'cs.MS']",,,[]
Nauticle: a general-purpose particle-based simulation tool,http://arxiv.org/abs/1710.08259v2,2017-10-23T13:27:36Z,2018-04-14T16:41:41Z,"  Nauticle is a general-purpose simulation tool for the flexible and highly
configurable application of particle-based methods of either discrete or
continuum phenomena. It is presented that Nauticle has three distinct layers
for users and developers, then the top two layers are discussed in detail. The
paper introduces the Symbolic Form Language (SFL) of Nauticle, which
facilitates the formulation of user-defined numerical models at the top level
in text-based configuration files and provides simple application examples of
use. On the other hand, at the intermediate level, it is shown that the SFL can
be intuitively extended with new particle methods without tedious recoding or
even the knowledge of the bottom level. Finally, the efficiency of the code is
also tested through a performance benchmark.
",['\nBalazs Toth\n'],Submitted manuscript,,http://arxiv.org/abs/1710.08259v2,cs.MS,"['cs.MS', 'physics.comp-ph']",,,[]
Communication-avoiding Cholesky-QR2 for rectangular matrices,http://arxiv.org/abs/1710.08471v6,2017-10-23T19:35:07Z,2019-06-15T18:52:13Z,"  Scalable QR factorization algorithms for solving least squares and eigenvalue
problems are critical given the increasing parallelism within modern machines.
We introduce a more general parallelization of the CholeskyQR2 algorithm and
show its effectiveness for a wide range of matrix sizes. Our algorithm executes
over a 3D processor grid, the dimensions of which can be tuned to trade-off
costs in synchronization, interprocessor communication, computational work, and
memory footprint. We implement this algorithm, yielding a code that can achieve
a factor of $\Theta(P^{1/6})$ less interprocessor communication on $P$
processors than any previous parallel QR implementation. Our performance study
on Intel Knights-Landing and Cray XE supercomputers demonstrates the
effectiveness of this CholeskyQR2 parallelization on a large number of nodes.
Specifically, relative to ScaLAPACK's QR, on 1024 nodes of Stampede2, our
CholeskyQR2 implementation is faster by 2.6x-3.3x in strong scaling tests and
by 1.1x-1.9x in weak scaling tests.
","['\nEdward Hutter\n', '\nEdgar Solomonik\n']",,,http://arxiv.org/abs/1710.08471v6,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"Implicit Low-Order Unstructured Finite-Element Multiple Simulation
  Enhanced by Dense Computation using OpenACC",http://arxiv.org/abs/1710.08679v1,2017-10-24T09:51:31Z,2017-10-24T09:51:31Z,"  In this paper, we develop a low-order three-dimensional finite-element solver
for fast multiple-case crust deformation analysis on GPU-based systems. Based
on a high-performance solver designed for massively parallel CPU based systems,
we modify the algorithm to reduce random data access, and then insert OpenACC
directives. The developed solver on ten Reedbush-H nodes (20 P100 GPUs)
attained speedup of 14.2 times from 20 K computer nodes, which is high
considering the peak memory bandwidth ratio of 11.4 between the two systems. On
the newest Volta generation V100 GPUs, the solver attained a further 2.45 times
speedup from P100 GPUs. As a demonstrative example, we computed 368 cases of
crustal deformation analyses of northeast Japan with 400 million degrees of
freedom. The total procedure of algorithm modification and porting
implementation took only two weeks; we can see that high performance
improvement was achieved with low development cost. With the developed solver,
we can expect improvement in reliability of crust-deformation analyses by
many-case analyses on a wide range of GPU-based systems.
","['\nTakuma Yamaguchi\nEarthquake Research Institute and Department of Civil Engineering, The University of Tokyo\n', '\nKohei Fujita\nEarthquake Research Institute and Department of Civil Engineering, The University of Tokyo\nAdvanced Institute for Computational Science, RIKEN\n', '\nTsuyoshi Ichimura\nEarthquake Research Institute and Department of Civil Engineering, The University of Tokyo\nAdvanced Institute for Computational Science, RIKEN\n', '\nMuneo Hori\nEarthquake Research Institute and Department of Civil Engineering, The University of Tokyo\nAdvanced Institute for Computational Science, RIKEN\n', '\nMaddegedara Lalith\nEarthquake Research Institute and Department of Civil Engineering, The University of Tokyo\nAdvanced Institute for Computational Science, RIKEN\n', '\nKengo Nakajima\nInformation Technology Center, The University of Tokyo\n']","18 pages, 10 figures, accepted for WACCPD2017",,http://arxiv.org/abs/1710.08679v1,cs.DC,"['cs.DC', 'cs.MS']",,,"['Earthquake Research Institute and Department of Civil Engineering, The University of Tokyo', 'Earthquake Research Institute and Department of Civil Engineering, The University of Tokyo', 'Advanced Institute for Computational Science, RIKEN', 'Earthquake Research Institute and Department of Civil Engineering, The University of Tokyo', 'Advanced Institute for Computational Science, RIKEN', 'Earthquake Research Institute and Department of Civil Engineering, The University of Tokyo', 'Advanced Institute for Computational Science, RIKEN', 'Earthquake Research Institute and Department of Civil Engineering, The University of Tokyo', 'Advanced Institute for Computational Science, RIKEN', 'Information Technology Center, The University of Tokyo']"
Performance Portability Strategies for Grid C++ Expression Templates,http://arxiv.org/abs/1710.09409v1,2017-10-25T18:23:19Z,2017-10-25T18:23:19Z,"  One of the key requirements for the Lattice QCD Application Development as
part of the US Exascale Computing Project is performance portability across
multiple architectures. Using the Grid C++ expression template as a starting
point, we report on the progress made with regards to the Grid GPU offloading
strategies. We present both the successes and issues encountered in using CUDA,
OpenACC and Just-In-Time compilation. Experimentation and performance on GPUs
with a SU(3)$\times$SU(3) streaming test will be reported. We will also report
on the challenges of using current OpenMP 4.x for GPU offloading in the same
code.
","['\nPeter A. Boyle\n', '\nM. A. Clark\n', '\nCarleton DeTar\n', '\nMeifeng Lin\n', '\nVerinder Rana\n', '\nAlejandro Vaquero Avilés-Casco\n']","8 pages, 4 figures. Talk presented at the 35th International
  Symposium on Lattice Field Theory, 18-24 June 2017, Granada, Spain",,http://dx.doi.org/10.1051/epjconf/201817509006,hep-lat,"['hep-lat', 'cs.MS']",10.1051/epjconf/201817509006,,[]
Auto-Differentiating Linear Algebra,http://arxiv.org/abs/1710.08717v5,2017-10-24T11:58:45Z,2019-08-14T13:08:25Z,"  Development systems for deep learning (DL), such as Theano, Torch,
TensorFlow, or MXNet, are easy-to-use tools for creating complex neural network
models. Since gradient computations are automatically baked in, and execution
is mapped to high performance hardware, these models can be trained end-to-end
on large amounts of data. However, it is currently not easy to implement many
basic machine learning primitives in these systems (such as Gaussian processes,
least squares estimation, principal components analysis, Kalman smoothing),
mainly because they lack efficient support of linear algebra primitives as
differentiable operators. We detail how a number of matrix decompositions
(Cholesky, LQ, symmetric eigen) can be implemented as differentiable operators.
We have implemented these primitives in MXNet, running on CPU and GPU in single
and double precision. We sketch use cases of these new operators, learning
Gaussian process and Bayesian linear regression models, where we demonstrate
very substantial reductions in implementation complexity and running time
compared to previous codes. Our MXNet extension allows end-to-end learning of
hybrid models, which combine deep neural networks (DNNs) with Bayesian
concepts, with applications in advanced Gaussian process models, scalable
Bayesian optimization, and Bayesian active learning.
","['\nMatthias Seeger\n', '\nAsmus Hetzel\n', '\nZhenwen Dai\n', '\nEric Meissner\n', '\nNeil D. Lawrence\n']",,,http://arxiv.org/abs/1710.08717v5,cs.MS,"['cs.MS', 'cs.LG', 'stat.ML']",,,[]
GooFit 2.0,http://arxiv.org/abs/1710.08826v1,2017-10-21T11:43:33Z,2017-10-21T11:43:33Z,"  The GooFit package provides physicists a simple, familiar syntax for
manipulating probability density functions and performing fits, and is highly
optimized for data analysis on NVIDIA GPUs and multithreaded CPU backends.
GooFit was updated to version 2.0, bringing a host of new features. A
completely revamped and redesigned build system makes GooFit easier to install,
develop with, and run on virtually any system. Unit testing, continuous
integration, and advanced logging options are improving the stability and
reliability of the system. Developing new PDFs now uses standard CUDA
terminology and provides a lower barrier for new users. The system now has
built-in support for multiple graphics cards or nodes using MPI, and is being
tested on a wide range of different systems. GooFit also has significant
improvements in performance on some GPU architectures due to optimized memory
access. Support for time-dependent four-body amplitude analyses has also been
added.
","['\nHenry Schreiner\n', '\nChristoph Hasse\n', '\nBradley Hittle\n', '\nHimadri Pandey\n', '\nMichael Sokoloff\n', '\nKaren Tomko\n']","Submitted to the ACAT 2017 proceedings, 6 pages",,http://arxiv.org/abs/1710.08826v1,cs.MS,"['cs.MS', 'hep-ex', 'physics.data-an']",,,[]
Deriving Correct High-Performance Algorithms,http://arxiv.org/abs/1710.04286v1,2017-10-11T20:04:43Z,2017-10-11T20:04:43Z,"  Dijkstra observed that verifying correctness of a program is difficult and
conjectured that derivation of a program hand-in-hand with its proof of
correctness was the answer. We illustrate this goal-oriented approach by
applying it to the domain of dense linear algebra libraries for distributed
memory parallel computers. We show that algorithms that underlie the
implementation of most functionality for this domain can be systematically
derived to be correct. The benefit is that an entire family of algorithms for
an operation is discovered so that the best algorithm for a given architecture
can be chosen. This approach is very practical: Ideas inspired by it have been
used to rewrite the dense linear algebra software stack starting below the
Basic Linear Algebra Subprograms (BLAS) and reaching up through the Elemental
distributed memory library, and every level in between. The paper demonstrates
how formal methods and rigorous mathematical techniques for correctness impact
HPC.
","['\nDevangi N. Parikh\n', '\nMaggie E. Myers\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1710.04286v1,cs.MS,['cs.MS'],,,[]
On Parallel Solution of Sparse Triangular Linear Systems in CUDA,http://arxiv.org/abs/1710.04985v1,2017-10-13T16:15:41Z,2017-10-13T16:15:41Z,"  The acceleration of sparse matrix computations on modern many-core
processors, such as the graphics processing units (GPUs), has been recognized
and studied over a decade. Significant performance enhancements have been
achieved for many sparse matrix computational kernels such as sparse
matrix-vector products and sparse matrix-matrix products. Solving linear
systems with sparse triangular structured matrices is another important sparse
kernel as demanded by a variety of scientific and engineering applications such
as sparse linear solvers. However, the development of efficient parallel
algorithms in CUDA for solving sparse triangular linear systems remains a
challenging task due to the inherently sequential nature of the computation. In
this paper, we will revisit this problem by reviewing the existing
level-scheduling methods and proposing algorithms with self-scheduling
techniques. Numerical results have indicated that the CUDA implementations of
the proposed algorithms can outperform the state-of-the-art solvers in cuSPARSE
by a factor of up to $2.6$ for structured model problems and general sparse
matrices.
",['\nRuipeng Li\n'],,,http://arxiv.org/abs/1710.04985v1,cs.MS,['cs.MS'],,,[]
"SoAx: A generic C++ Structure of Arrays for handling Particles in HPC
  Codes",http://arxiv.org/abs/1710.03462v1,2017-10-10T09:13:54Z,2017-10-10T09:13:54Z,"  The numerical study of physical problems often require integrating the
dynamics of a large number of particles evolving according to a given set of
equations. Particles are characterized by the information they are carrying
such as an identity, a position other. There are generally speaking two
different possibilities for handling particles in high performance computing
(HPC) codes. The concept of an Array of Structures (AoS) is in the spirit of
the object-oriented programming (OOP) paradigm in that the particle information
is implemented as a structure. Here, an object (realization of the structure)
represents one particle and a set of many particles is stored in an array. In
contrast, using the concept of a Structure of Arrays (SoA), a single structure
holds several arrays each representing one property (such as the identity) of
the whole set of particles.
  The AoS approach is often implemented in HPC codes due to its handiness and
flexibility. For a class of problems, however, it is know that the performance
of SoA is much better than that of AoS. We confirm this observation for our
particle problem. Using a benchmark we show that on modern Intel Xeon
processors the SoA implementation is typically several times faster than the
AoS one. On Intel's MIC co-processors the performance gap even attains a factor
of ten. The same is true for GPU computing, using both computational and
multi-purpose GPUs.
  Combining performance and handiness, we present the library SoAx that has
optimal performance (on CPUs, MICs, and GPUs) while providing the same
handiness as AoS. For this, SoAx uses modern C++ design techniques such
template meta programming that allows to automatically generate code for user
defined heterogeneous data structures.
","['\nHolger Homann\n', '\nFrancois Laenen\n']",,,http://dx.doi.org/10.1016/j.cpc.2017.11.015,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1016/j.cpc.2017.11.015,,[]
"Subdomain Deflation Combined with Local AMG: a Case Study Using AMGCL
  Library",http://arxiv.org/abs/1710.03940v4,2017-10-11T07:25:16Z,2018-10-26T06:20:18Z,"  The paper proposes a combination of the subdomain deflation method and local
algebraic multigrid as a scalable distributed memory preconditioner that is
able to solve large linear systems of equations. The implementation of the
algorithm is made available for the community as part of an open source AMGCL
library. The solution targets both homogeneous (CPU-only) and heterogeneous
(CPU/GPU) systems, employing hybrid MPI/OpenMP approach in the former and a
combination of MPI, OpenMP, and CUDA in the latter cases. The use of OpenMP
minimizes the number of MPI processes, thus reducing the communication overhead
of the deflation method and improving both weak and strong scalability of the
preconditioner. The examples of scalar, Poisson-like, systems as well as
non-scalar problems, stemming out of the discretization of the Navier-Stokes
equations, are considered in order to estimate performance of the implemented
algorithm. A comparison with a traditional global AMG preconditioner based on a
well-established Trilinos ML package is provided.
","['\nDenis Demidov\n', '\nRiccardo Rossi\n']","21 pages, 7 figures",,http://dx.doi.org/10.1134/S1995080220040071,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'D.1.3; G.1.0; G.1.8']",10.1134/S1995080220040071,,[]
Tensors Come of Age: Why the AI Revolution will help HPC,http://arxiv.org/abs/1709.09108v1,2017-09-26T16:11:43Z,2017-09-26T16:11:43Z,"  This article discusses how the automation of tensor algorithms, based on A
Mathematics of Arrays and Psi Calculus, and a new way to represent numbers,
Unum Arithmetic, enables mechanically provable, scalable, portable, and more
numerically accurate software.
","['\nJohn L. Gustafson\n', '\nLenore M. Mullin\n']",To be published in this years 30th anniversary edition of HPCwire,,http://arxiv.org/abs/1709.09108v1,cs.AI,"['cs.AI', 'cs.MS', 'cs.PF']",,,[]
"Energy efficiency of finite difference algorithms on multicore CPUs,
  GPUs, and Intel Xeon Phi processors",http://arxiv.org/abs/1709.09713v1,2017-09-27T19:52:03Z,2017-09-27T19:52:03Z,"  In addition to hardware wall-time restrictions commonly seen in
high-performance computing systems, it is likely that future systems will also
be constrained by energy budgets. In the present work, finite difference
algorithms of varying computational and memory intensity are evaluated with
respect to both energy efficiency and runtime on an Intel Ivy Bridge CPU node,
an Intel Xeon Phi Knights Landing processor, and an NVIDIA Tesla K40c GPU. The
conventional way of storing the discretised derivatives to global arrays for
solution advancement is found to be inefficient in terms of energy consumption
and runtime. In contrast, a class of algorithms in which the discretised
derivatives are evaluated on-the-fly or stored as thread-/process-local
variables (yielding high compute intensity) is optimal both with respect to
energy consumption and runtime. On all three hardware architectures considered,
a speed-up of ~2 and an energy saving of ~2 are observed for the high compute
intensive algorithms compared to the memory intensive algorithm. The energy
consumption is found to be proportional to runtime, irrespective of the power
consumed and the GPU has an energy saving of ~5 compared to the same algorithm
on a CPU node.
","['\nSatya P. Jammy\n', '\nChristian T. Jacobs\n', '\nDavid J. Lusher\n', '\nNeil D. Sandham\n']",Submitted to Computers and Fluids,,http://arxiv.org/abs/1709.09713v1,cs.MS,"['cs.MS', 'cs.PF', 'physics.comp-ph', 'physics.flu-dyn']",,,[]
"HPC optimal parallel communication algorithm for the simulation of
  fractional-order systems",http://arxiv.org/abs/1710.01133v1,2017-09-28T14:36:55Z,2017-09-28T14:36:55Z,"  A parallel numerical simulation algorithm is presented for fractional-order
systems involving Caputo-type derivatives, based on the Adams-Bashforth-Moulton
(ABM) predictor-corrector scheme. The parallel algorithm is implemented using
several different approaches: a pure MPI version, a combination of MPI with
OpenMP optimization and a memory saving speedup approach. All tests run on a
BlueGene/P cluster, and comparative improvement results for the running time
are provided. As an applied experiment, the solutions of a fractional-order
version of a system describing a forced series LCR circuit are numerically
computed, depicting cascades of period-doubling bifurcations which lead to the
onset of chaotic behavior.
","['\nCosmin Bonchis\n', '\nEva Kaslik\n', '\nFlorin Rosu\n']",,,http://arxiv.org/abs/1710.01133v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '37']",,,[]
High-Performance Derivative Computations using CoDiPack,http://arxiv.org/abs/1709.07229v1,2017-09-21T09:28:36Z,2017-09-21T09:28:36Z,"  There are several AD tools available, which all implement different
strategies for the reverse mode of AD. The major strategies are primal value
taping (implemented e.g. by ADOL-c) and Jacobi taping (implemented e.g. by
adept and dco/c++). Especially for Jacobi taping, recent advances by using
expression templates make this approach very attractive for large scale
software. The current implementations are either closed source or miss
essential features and flexibility. Therefore, we present the new AD tool
CoDiPack (Code Differentiation Package) in this paper. It is specifically
designed for a minimal memory consumption and optimal runtime, such that it can
be used for the differentiation of large scale software. An essential part of
the design of CoDiPack is the modular layout and the recursive data structures,
which do not only allow the efficient implementation of the Jacobi taping
approach, but will also enable other approaches like the primal value taping or
new research ideas. We will also present the performance value of CoDiPack on a
generic PDE example and on the SU2 code.
","['\nMax Sagebaum\n', '\nTim Albring\n', '\nNicolas R. Gauger\n']","21 pages, 11 figures, 6 tables, CoDiPack:
  https://github.com/SciCompKL/CoDiPack",,http://arxiv.org/abs/1709.07229v1,cs.MS,"['cs.MS', '68N30', 'G.1.4; G.4; D.2.2']",,,[]
A new indexed approach to render the attractors of Kleinian groups,http://arxiv.org/abs/1709.08018v1,2017-09-23T08:00:31Z,2017-09-23T08:00:31Z,"  One widespread procedure to render the attractor of Kleinian groups,
published in the renown book ""Indra's Pearls"" and based upon a combinatorial
tree model, wants huge memory resources to compute and store all the words
required. We will present here a new faster and lighter version which drops the
original words array and pulls out words from integer numbers.
",['\nAlessandro Rosa\n'],"9 pages, 15 figures",,http://arxiv.org/abs/1709.08018v1,cs.FL,"['cs.FL', 'cs.MS']",,,[]
Magnus integrators on multicore CPUs and GPUs,http://arxiv.org/abs/1709.06483v2,2017-09-19T15:13:04Z,2018-03-28T13:19:03Z,"  In the present paper we consider numerical methods to solve the discrete
Schr\""odinger equation with a time dependent Hamiltonian (motivated by problems
encountered in the study of spin systems). We will consider both short-range
interactions, which lead to evolution equations involving sparse matrices, and
long-range interactions, which lead to dense matrices. Both of these settings
show very different computational characteristics. We use Magnus integrators
for time integration and employ a framework based on Leja interpolation to
compute the resulting action of the matrix exponential. We consider both
traditional Magnus integrators (which are extensively used for these types of
problems in the literature) as well as the recently developed commutator-free
Magnus integrators and implement them on modern CPU and GPU (graphics
processing unit) based systems.
  We find that GPUs can yield a significant speed-up (up to a factor of $10$ in
the dense case) for these types of problems. In the sparse case GPUs are only
advantageous for large problem sizes and the achieved speed-ups are more
modest. In most cases the commutator-free variant is superior but especially on
the GPU this advantage is rather small. In fact, none of the advantage of
commutator-free methods on GPUs (and on multi-core CPUs) is due to the
elimination of commutators. This has important consequences for the design of
more efficient numerical methods.
","['\nN. Auer\n', '\nL. Einkemmer\n', '\nP. Kandolf\n', '\nA. Ostermann\n']",,"Computer Physics Communications, Volume 228, Pages 115-122, 2018",http://dx.doi.org/10.1016/j.cpc.2018.02.019,physics.comp-ph,"['physics.comp-ph', 'cs.CE', 'cs.MS', 'math.NA']",10.1016/j.cpc.2018.02.019,,[]
"From MPI to MPI+OpenACC: Conversion of a legacy FORTRAN PCG solver for
  the spherical Laplace equation",http://arxiv.org/abs/1709.01126v2,2017-09-04T19:26:03Z,2017-12-29T21:49:27Z,"  A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned
Conjugate Gradient code is described, and timing results for multi-node
multi-GPU runs are shown. The code is used to obtain three-dimensional
spherical solutions to the Laplace equation. Its application is finding
potential field solutions of the solar corona, a useful tool in space weather
modeling. We highlight key tips, strategies, and challenges faced when adding
OpenACC. Performance results are shown for running the code with MPI-only on
multiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.
","['\nRonald M. Caplan\n', '\nZoran Mikic\n', '\nJon A. Linker\n']","18 pages, 4 figures. Work presented at the 2017 NVIDIA GPU Technology
  Conference",,http://arxiv.org/abs/1709.01126v2,cs.MS,"['cs.MS', 'G.4']",,,[]
qTorch: The Quantum Tensor Contraction Handler,http://arxiv.org/abs/1709.03636v2,2017-09-12T00:56:22Z,2018-12-22T17:43:10Z,"  Classical simulation of quantum computation is necessary for studying the
numerical behavior of quantum algorithms, as there does not yet exist a large
viable quantum computer on which to perform numerical tests. Tensor network
(TN) contraction is an algorithmic method that can efficiently simulate some
quantum circuits, often greatly reducing the computational cost over methods
that simulate the full Hilbert space. In this study we implement a tensor
network contraction program for simulating quantum circuits using multi-core
compute nodes. We show simulation results for the Max-Cut problem on 3- through
7-regular graphs using the quantum approximate optimization algorithm (QAOA),
successfully simulating up to 100 qubits. We test two different methods for
generating the ordering of tensor index contractions: one is based on the tree
decomposition of the line graph, while the other generates ordering using a
straight-forward stochastic scheme. Through studying instances of QAOA
circuits, we show the expected result that as the treewidth of the quantum
circuit's line graph decreases, TN contraction becomes significantly more
efficient than simulating the whole Hilbert space. The results in this work
suggest that tensor contraction methods are superior only when simulating
Max-Cut/QAOA with graphs of regularities approximately five and below. Insight
into this point of equal computational cost helps one determine which
simulation method will be more efficient for a given quantum circuit. The
stochastic contraction method outperforms the line graph based method only when
the time to calculate a reasonable tree decomposition is prohibitively
expensive. Finally, we release our software package, qTorch (Quantum TensOR
Contraction Handler), intended for general quantum circuit simulation.
","['\nE. Schuyler Fried\n', '\nNicolas P. D. Sawaya\n', '\nYudong Cao\n', '\nIan D. Kivlichan\n', '\nJhonathan Romero\n', '\nAlán Aspuru-Guzik\n']","21 pages, 8 figures",PLoS ONE 13(12): e0208510. (2018),http://dx.doi.org/10.1371/journal.pone.0208510,quant-ph,"['quant-ph', 'cs.MS']",10.1371/journal.pone.0208510,,[]
"Look-Ahead in the Two-Sided Reduction to Compact Band Forms for
  Symmetric Eigenvalue Problems and the SVD",http://arxiv.org/abs/1709.00302v2,2017-09-01T13:34:32Z,2017-11-06T12:52:00Z,"  We address the reduction to compact band forms, via unitary similarity
transformations, for the solution of symmetric eigenvalue problems and the
computation of the singular value decomposition (SVD). Concretely, in the first
case we revisit the reduction to symmetric band form while, for the second
case, we propose a similar alternative, which transforms the original matrix to
(unsymmetric) band form, replacing the conventional reduction method that
produces a triangular--band output. In both cases, we describe algorithmic
variants of the standard Level-3 BLAS-based procedures, enhanced with
look-ahead, to overcome the performance bottleneck imposed by the panel
factorization. Furthermore, our solutions employ an algorithmic block size that
differs from the target bandwidth, illustrating the important performance
benefits of this decision. Finally, we show that our alternative compact band
form for the SVD is key to introduce an effective look-ahead strategy into the
corresponding reduction procedure.
","['\nRafael Rodríguez-Sánchez\n', '\nSandra Catalán\n', '\nJosé R. Herrero\n', '\nEnrique S. Quintana-Ortí\n', '\nAndrés E. Tomás\n']",,,http://arxiv.org/abs/1709.00302v2,cs.MS,"['cs.MS', 'cs.DC']",,,[]
Algorithmic patterns for $\mathcal{H}$-matrices on many-core processors,http://arxiv.org/abs/1708.09707v1,2017-08-31T13:50:42Z,2017-08-31T13:50:42Z,"  In this work, we consider the reformulation of hierarchical ($\mathcal{H}$)
matrix algorithms for many-core processors with a model implementation on
graphics processing units (GPUs). $\mathcal{H}$ matrices approximate specific
dense matrices, e.g., from discretized integral equations or kernel ridge
regression, leading to log-linear time complexity in dense matrix-vector
products. The parallelization of $\mathcal{H}$ matrix operations on many-core
processors is difficult due to the complex nature of the underlying algorithms.
While previous algorithmic advances for many-core hardware focused on
accelerating existing $\mathcal{H}$ matrix CPU implementations by many-core
processors, we here aim at totally relying on that processor type. As main
contribution, we introduce the necessary parallel algorithmic patterns allowing
to map the full $\mathcal{H}$ matrix construction and the fast matrix-vector
product to many-core hardware. Here, crucial ingredients are space filling
curves, parallel tree traversal and batching of linear algebra operations. The
resulting model GPU implementation hmglib is the, to the best of the authors
knowledge, first entirely GPU-based Open Source $\mathcal{H}$ matrix library of
this kind. We conclude this work by an in-depth performance analysis and a
comparative performance study against a standard $\mathcal{H}$ matrix library,
highlighting profound speedups of our many-core parallel approach.
",['\nPeter Zaspel\n'],,,http://arxiv.org/abs/1708.09707v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA', '65Y05, 68T05, 65Y10, 68W10, 65Y20, 65F30, 65F10, 15A06, 015-04,\n  65N38']",,,[]
"The basic principles and the structure and algorithmically software of
  computing by hypercomplex number",http://arxiv.org/abs/1708.04021v1,2017-08-14T07:13:39Z,2017-08-14T07:13:39Z,"  In article the basic principles put in a basis of algorithmicallysoftware of
hypercomplex number calculations, structure of a software, structure of
functional subsystems are considered. The most important procedures included in
subsystems are considered, program listings and examples of their application
are given.
","['\nYa. Kalinovsky\n', '\nYu. Boyarinova\n', '\nA. Sukalo\n', '\nYa. Hitsko\n']",,,http://arxiv.org/abs/1708.04021v1,cs.MS,"['cs.MS', 'cs.SE']",,,[]
"PSelInv - A Distributed Memory Parallel Algorithm for Selected
  Inversion: the non-symmetric Case",http://arxiv.org/abs/1708.04539v1,2017-08-14T00:18:41Z,2017-08-14T00:18:41Z,"  This paper generalizes the parallel selected inversion algorithm called
PSelInv to sparse non- symmetric matrices. We assume a general sparse matrix A
has been decomposed as PAQ = LU on a distributed memory parallel machine, where
L, U are lower and upper triangular matrices, and P, Q are permutation
matrices, respectively. The PSelInv method computes selected elements of A-1.
The selection is confined by the sparsity pattern of the matrix AT . Our
algorithm does not assume any symmetry properties of A, and our parallel
implementation is memory efficient, in the sense that the computed elements of
A-T overwrites the sparse matrix L+U in situ. PSelInv involves a large number
of collective data communication activities within different processor groups
of various sizes. In order to minimize idle time and improve load balancing,
tree-based asynchronous communication is used to coordinate all such collective
communication. Numerical results demonstrate that PSelInv can scale efficiently
to 6,400 cores for a variety of matrices.
","['\nMathias Jacquelin\n', '\nLin Lin\n', '\nChao Yang\n']",arXiv admin note: text overlap with arXiv:1404.0447,,http://arxiv.org/abs/1708.04539v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
Computer Algebra for Microhydrodynamics,http://arxiv.org/abs/1708.05788v1,2017-08-19T00:43:04Z,2017-08-19T00:43:04Z,"  I describe a method for computer algebra that helps with laborious
calculations typically encountered in theoretical microhydrodynamics. The
program mimics how humans calculate by matching patterns and making
replacements according to the rules of algebra and calculus. This note gives an
overview and walks through an example, while the accompanying code repository
contains the implementation details, a tutorial, and more examples. The code
repository is attached as supplementary material to this note, and maintained
at https://github.com/jeinarsson/matte
",['\nJonas Einarsson\n'],,,http://arxiv.org/abs/1708.05788v1,physics.flu-dyn,"['physics.flu-dyn', 'cs.MS']",,,[]
Parallel solver for shifted systems in a hybrid CPU-GPU framework,http://arxiv.org/abs/1708.06290v1,2017-08-21T15:39:14Z,2017-08-21T15:39:14Z,"  This paper proposes a combination of a hybrid CPU--GPU and a pure GPU
software implementation of a direct algorithm for solving shifted linear
systems $(A - \sigma I)X = B$ with large number of complex shifts $\sigma$ and
multiple right-hand sides. Such problems often appear e.g. in control theory
when evaluating the transfer function, or as a part of an algorithm performing
interpolatory model reduction, as well as when computing pseudospectra and
structured pseudospectra, or solving large linear systems of ordinary
differential equations. The proposed algorithm first jointly reduces the
general full $n\times n$ matrix $A$ and the $n\times m$ full right-hand side
matrix $B$ to the controller Hessenberg canonical form that facilitates
efficient solution: $A$ is transformed to a so-called $m$-Hessenberg form and
$B$ is made upper-triangular. This is implemented as blocked highly parallel
CPU--GPU hybrid algorithm; individual blocks are reduced by the CPU, and the
necessary updates of the rest of the matrix are split among the cores of the
CPU and the GPU. To enhance parallelization, the reduction and the updates are
overlapped. In the next phase, the reduced $m$-Hessenberg--triangular systems
are solved entirely on the GPU, with shifts divided into batches. The benefits
of such load distribution are demonstrated by numerical experiments. In
particular, we show that our proposed implementation provides an excellent
basis for efficient implementations of computational methods in systems and
control theory, from evaluation of transfer function to the interpolatory model
reduction.
","['\nNela Bosner\n', '\nZvonimir Bujanović\n', '\nZlatko Drmač\n']",,,http://arxiv.org/abs/1708.06290v1,cs.MS,"['cs.MS', 'cs.NA', '65F05, 65Y05, 93A15, 93B40, 93C05, 93C80']",,,[]
Distributed Triangle Counting in the Graphulo Matrix Math Library,http://arxiv.org/abs/1709.01054v2,2017-08-20T06:03:31Z,2017-09-05T04:37:43Z,"  Triangle counting is a key algorithm for large graph analysis. The Graphulo
library provides a framework for implementing graph algorithms on the Apache
Accumulo distributed database. In this work we adapt two algorithms for
counting triangles, one that uses the adjacency matrix and another that also
uses the incidence matrix, to the Graphulo library for server-side processing
inside Accumulo. Cloud-based experiments show a similar performance profile for
these different approaches on the family of power law Graph500 graphs, for
which data skew increasingly bottlenecks. These results motivate the design of
skew-aware hybrid algorithms that we propose for future work.
",['\nDylan Hutchison\n'],Honorable mention in the 2017 IEEE HPEC's Graph Challenge,,http://dx.doi.org/10.1109/HPEC.2017.8091041,cs.DC,"['cs.DC', 'cs.MS']",10.1109/HPEC.2017.8091041,,[]
"An OpenGL and C++ based function library for curve and surface modeling
  in a large class of extended Chebyshev spaces",http://arxiv.org/abs/1708.04440v3,2017-08-15T09:09:48Z,2018-10-14T08:14:09Z,"  We propose a platform-independent multi-threaded function library that
provides data structures to generate, differentiate and render both the
ordinary basis and the normalized B-basis of a user-specified extended
Chebyshev (EC) space that comprises the constants and can be identified with
the solution space of a constant-coefficient homogeneous linear differential
equation defined on a sufficiently small interval. Using the obtained
normalized B-bases, our library can also generate, (partially) differentiate,
modify and visualize a large family of so-called B-curves and tensor product
B-surfaces. Moreover, the library also implements methods that can be used to
perform dimension elevation, to subdivide B-curves and B-surfaces by means of
de Casteljau-like B-algorithms, and to generate basis transformations for the
B-representation of arbitrary integral curves and surfaces that are described
in traditional parametric form by means of the ordinary bases of the underlying
EC spaces. Independently of the algebraic, exponential, trigonometric or mixed
type of the applied EC space, the proposed library is numerically stable and
efficient up to a reasonable dimension number and may be useful for academics
and engineers in the fields of Approximation Theory, Computer Aided Geometric
Design, Computer Graphics, Isogeometric and Numerical Analysis.
",['\nÁgoston Róth\n'],"29 pages, 20 figures, 2 tables, additional references have been
  included, some cross-references have been updated",,http://arxiv.org/abs/1708.04440v3,cs.MS,"['cs.MS', 'cs.GR', 'math.NA', '65D17, 68U07']",,,[]
Designing and building the mlpack open-source machine learning library,http://arxiv.org/abs/1708.05279v2,2017-08-17T13:59:48Z,2017-08-30T15:41:17Z,"  mlpack is an open-source C++ machine learning library with an emphasis on
speed and flexibility. Since its original inception in 2007, it has grown to be
a large project implementing a wide variety of machine learning algorithms,
from standard techniques such as decision trees and logistic regression to
modern techniques such as deep neural networks as well as other
recently-published cutting-edge techniques not found in any other library.
mlpack is quite fast, with benchmarks showing mlpack outperforming other
libraries' implementations of the same methods. mlpack has an active community,
with contributors from around the world---including some from PUST. This short
paper describes the goals and design of mlpack, discusses how the open-source
community functions, and shows an example usage of mlpack for a simple data
science problem.
","['\nRyan R. Curtin\n', '\nMarcus Edel\n']",submitted to ICOPUST 2017,,http://arxiv.org/abs/1708.05279v2,cs.MS,"['cs.MS', 'cs.LG', 'cs.SE']",,,[]
"Preconditioned Spectral Clustering for Stochastic Block Partition
  Streaming Graph Challenge",http://arxiv.org/abs/1708.07481v1,2017-08-21T14:09:05Z,2017-08-21T14:09:05Z,"  Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) is
demonstrated to efficiently solve eigenvalue problems for graph Laplacians that
appear in spectral clustering. For static graph partitioning, 10-20 iterations
of LOBPCG without preconditioning result in ~10x error reduction, enough to
achieve 100% correctness for all Challenge datasets with known truth
partitions, e.g., for graphs with 5K/.1M (50K/1M) Vertices/Edges in 2 (7)
seconds, compared to over 5,000 (30,000) seconds needed by the baseline Python
code. Our Python code 100% correctly determines 98 (160) clusters from the
Challenge static graphs with 0.5M (2M) vertices in 270 (1,700) seconds using
10GB (50GB) of memory. Our single-precision MATLAB code calculates the same
clusters at half time and memory. For streaming graph partitioning, LOBPCG is
initiated with approximate eigenvectors of the graph Laplacian already computed
for the previous graph, in many cases reducing 2-3 times the number of required
LOBPCG iterations, compared to the static case. Our spectral clustering is
generic, i.e. assuming nothing specific of the block model or streaming, used
to generate the graphs for the Challenge, in contrast to the base code.
Nevertheless, in 10-stage streaming comparison with the base code for the 5K
graph, the quality of our clusters is similar or better starting at stage 4 (7)
for emerging edging (snowballing) streaming, while the computations are over
100-1000 faster.
","['\nDavid Zhuzhunashvili\n', '\nAndrew Knyazev\n']","6 pages. To appear in Proceedings of the 2017 IEEE High Performance
  Extreme Computing Conference. Student Innovation Award Streaming Graph
  Challenge: Stochastic Block Partition, see
  http://graphchallenge.mit.edu/champions","2017 IEEE High Performance Extreme Computing Conference (HPEC),
  Waltham, MA, USA, 2017, pp. 1-6",http://dx.doi.org/10.1109/HPEC.2017.8091045,cs.MS,"['cs.MS', 'cs.DC', 'cs.DS', 'stat.CO', 'stat.ML', '05C50, 05C70, 15A18, 58C40, 65F15, 65N25, 62H30, 91C20', 'H.3.3; I.5.3']",10.1109/HPEC.2017.8091045,,[]
"Practically efficient methods for performing bit-reversed permutation in
  C++11 on the x86-64 architecture",http://arxiv.org/abs/1708.01873v1,2017-08-02T19:12:50Z,2017-08-02T19:12:50Z,"  The bit-reversed permutation is a famous task in signal processing and is key
to efficient implementation of the fast Fourier transform. This paper presents
optimized C++11 implementations of five extant methods for computing the
bit-reversed permutation: Stockham auto-sort, naive bitwise swapping, swapping
via a table of reversed bytes, local pairwise swapping of bits, and swapping
via a cache-localized matrix buffer. Three new strategies for performing the
bit-reversed permutation in C++11 are proposed: an inductive method using the
bitwise XOR operation, a template-recursive closed form, and a cache-oblivious
template-recursive approach, which reduces the bit-reversed permutation to
smaller bit-reversed permutations and a square matrix transposition. These new
methods are compared to the extant approaches in terms of theoretical runtime,
empirical compile time, and empirical runtime. The template-recursive
cache-oblivious method is shown to be competitive with the fastest known
method; however, we demonstrate that the cache-oblivious method can more
readily benefit from parallelization on multiple cores and on the GPU.
","['\nChristian Knauth\n', '\nBoran Adas\n', '\nDaniel Whitfield\n', '\nXuesong Wang\n', '\nLydia Ickler\n', '\nTim Conrad\n', '\nOliver Serang\n']",,,http://arxiv.org/abs/1708.01873v1,cs.MS,['cs.MS'],,,[]
FEMPAR: An object-oriented parallel finite element framework,http://arxiv.org/abs/1708.01773v3,2017-08-05T14:47:00Z,2017-09-19T13:15:02Z,"  FEMPAR is an open source object oriented Fortran200X scientific software
library for the high-performance scalable simulation of complex multiphysics
problems governed by partial differential equations at large scales, by
exploiting state-of-the-art supercomputing resources. It is a highly
modularized, flexible, and extensible library, that provides a set of modules
that can be combined to carry out the different steps of the simulation
pipeline. FEMPAR includes a rich set of algorithms for the discretization step,
namely (arbitrary-order) grad, div, and curl-conforming finite element methods,
discontinuous Galerkin methods, B-splines, and unfitted finite element
techniques on cut cells, combined with $h$-adaptivity. The linear solver module
relies on state-of-the-art bulk-asynchronous implementations of multilevel
domain decomposition solvers for the different discretization alternatives and
block-preconditioning techniques for multiphysics problems. FEMPAR is a
framework that provides users with out-of-the-box state-of-the-art
discretization techniques and highly scalable solvers for the simulation of
complex applications, hiding the dramatic complexity of the underlying
algorithms. But it is also a framework for researchers that want to experience
with new algorithms and solvers, by providing a highly extensible framework. In
this work, the first one in a series of articles about FEMPAR, we provide a
detailed introduction to the software abstractions used in the discretization
module and the related geometrical module. We also provide some ingredients
about the assembly of linear systems arising from finite element
discretizations, but the software design of complex scalable multilevel solvers
is postponed to a subsequent work.
","['\nSantiago Badia\n', '\nAlberto F. Martín\n', '\nJavier Principe\n']",,,http://arxiv.org/abs/1708.01773v3,cs.CE,"['cs.CE', 'cs.MS']",,,[]
ELFI: Engine for Likelihood-Free Inference,http://arxiv.org/abs/1708.00707v3,2017-08-02T11:39:11Z,2018-07-05T08:34:27Z,"  Engine for Likelihood-Free Inference (ELFI) is a Python software library for
performing likelihood-free inference (LFI). ELFI provides a convenient syntax
for arranging components in LFI, such as priors, simulators, summaries or
distances, to a network called ELFI graph. The components can be implemented in
a wide variety of languages. The stand-alone ELFI graph can be used with any of
the available inference methods without modifications. A central method
implemented in ELFI is Bayesian Optimization for Likelihood-Free Inference
(BOLFI), which has recently been shown to accelerate likelihood-free inference
up to several orders of magnitude by surrogate-modelling the distance. ELFI
also has an inbuilt support for output data storing for reuse and analysis, and
supports parallelization of computation from multiple cores up to a cluster
environment. ELFI is designed to be extensible and provides interfaces for
widening its functionality. This makes the adding of new inference methods to
ELFI straightforward and automatically compatible with the inbuilt features.
","['\nJarno Lintusaari\n', '\nHenri Vuollekoski\n', '\nAntti Kangasrääsiö\n', '\nKusti Skytén\n', '\nMarko Järvenpää\n', '\nPekka Marttinen\n', '\nMichael U. Gutmann\n', '\nAki Vehtari\n', '\nJukka Corander\n', '\nSamuel Kaski\n']",,"Journal of Machine Learning Research, 19(16):1-7, 2018.
  http://jmlr.org/papers/v19/17-374.html",http://arxiv.org/abs/1708.00707v3,stat.ML,"['stat.ML', 'cs.MS', 'stat.CO']",,,[]
"Example Setups of Navier-Stokes Equations with Control and Observation:
  Spatial Discretization and Representation via Linear-quadratic Matrix
  Coefficients",http://arxiv.org/abs/1707.08711v1,2017-07-27T05:42:54Z,2017-07-27T05:42:54Z,"  We provide spatial discretizations of nonlinear incompressible Navier-Stokes
equations with inputs and outputs in the form of matrices ready to use in any
numerical linear algebra package. We discuss the assembling of the system
operators and the realization of boundary conditions and inputs and outputs. We
describe the two benchmark problems - the driven cavity and the cylinder wake -
and provide the corresponding data. The use of the data is illustrated by
numerous example setups. The test cases are provided as plain PYTHON or
OCTAVE/MATLAB script files for immediate replication.
","['\nMaximilian Behr\n', '\nPeter Benner\n', '\nJan Heiland\n']",,,http://arxiv.org/abs/1707.08711v1,cs.MS,"['cs.MS', 'math.DS', '68U20']",,,[]
"An Open Source C++ Implementation of Multi-Threaded Gaussian Mixture
  Models, k-Means and Expectation Maximisation",http://arxiv.org/abs/1707.09094v1,2017-07-28T03:15:22Z,2017-07-28T03:15:22Z,"  Modelling of multivariate densities is a core component in many signal
processing, pattern recognition and machine learning applications. The
modelling is often done via Gaussian mixture models (GMMs), which use
computationally expensive and potentially unstable training algorithms. We
provide an overview of a fast and robust implementation of GMMs in the C++
language, employing multi-threaded versions of the Expectation Maximisation
(EM) and k-means training algorithms. Multi-threading is achieved through
reformulation of the EM and k-means algorithms into a MapReduce-like framework.
Furthermore, the implementation uses several techniques to improve numerical
stability and modelling accuracy. We demonstrate that the multi-threaded
implementation achieves a speedup of an order of magnitude on a recent 16 core
machine, and that it can achieve higher modelling accuracy than a previously
well-established publically accessible implementation. The multi-threaded
implementation is included as a user-friendly class in recent releases of the
open source Armadillo C++ linear algebra library. The library is provided under
the permissive Apache~2.0 license, allowing unencumbered use in commercial
products.
","['\nConrad Sanderson\n', '\nRyan Curtin\n']",,"International Conference on Signal Processing and Communication
  Systems, 2017",http://dx.doi.org/10.1109/ICSPCS.2017.8270510,cs.MS,"['cs.MS', 'cs.LG', '65Y05, 68N99', 'G.4; G.1; J.2; J.4']",10.1109/ICSPCS.2017.8270510,,[]
"Dragon: A Computation Graph Virtual Machine Based Deep Learning
  Framework",http://arxiv.org/abs/1707.08265v1,2017-07-26T01:16:29Z,2017-07-26T01:16:29Z,"  Deep Learning has made a great progress for these years. However, it is still
difficult to master the implement of various models because different
researchers may release their code based on different frameworks or interfaces.
In this paper, we proposed a computation graph based framework which only aims
to introduce well-known interfaces. It will help a lot when reproducing a newly
model or transplanting models that were implemented by other frameworks.
Additionally, we implement numerous recent models covering both Computer Vision
and Nature Language Processing. We demonstrate that our framework will not
suffer from model-starving because it is much easier to make full use of the
works that are already done.
",['\nTing Pan\n'],,,http://arxiv.org/abs/1707.08265v1,cs.SE,"['cs.SE', 'cs.LG', 'cs.MS', 'cs.NE']",,,[]
Owl: A General-Purpose Numerical Library in OCaml,http://arxiv.org/abs/1707.09616v3,2017-07-30T13:18:06Z,2018-08-28T06:42:48Z,"  Owl is a new numerical library developed in the OCaml language. It focuses on
providing a comprehensive set of high-level numerical functions so that
developers can quickly build up data analytical applications. In this abstract,
we will present Owl's design, core components, and its key functionality.
",['\nLiang Wang\n'],,,http://arxiv.org/abs/1707.09616v3,cs.MS,"['cs.MS', 'cs.DC', 'cs.LO']",,,[]
Optimised finite difference computation from symbolic equations,http://arxiv.org/abs/1707.03776v1,2017-07-12T15:51:35Z,2017-07-12T15:51:35Z,"  Domain-specific high-productivity environments are playing an increasingly
important role in scientific computing due to the levels of abstraction and
automation they provide. In this paper we introduce Devito, an open-source
domain-specific framework for solving partial differential equations from
symbolic problem definitions by the finite difference method. We highlight the
generation and automated execution of highly optimized stencil code from only a
few lines of high-level symbolic Python for a set of scientific equations,
before exploring the use of Devito operators in seismic inversion problems.
","['\nMichael Lange\n', '\nNavjot Kukreja\n', '\nFabio Luporini\n', '\nMathias Louboutin\n', '\nCharles Yount\n', '\nJan Hückelheim\n', '\nGerard J. Gorman\n']","Accepted for publication in Proceedings of the 16th Python in Science
  Conference (SciPy 2017)",,http://arxiv.org/abs/1707.03776v1,cs.MS,['cs.MS'],,,[]
Language-based Abstractions for Dynamical Systems,http://arxiv.org/abs/1707.04254v1,2017-07-13T13:51:26Z,2017-07-13T13:51:26Z,"  Ordinary differential equations (ODEs) are the primary means to modelling
dynamical systems in many natural and engineering sciences. The number of
equations required to describe a system with high heterogeneity limits our
capability of effectively performing analyses. This has motivated a large body
of research, across many disciplines, into abstraction techniques that provide
smaller ODE systems while preserving the original dynamics in some appropriate
sense. In this paper we give an overview of a recently proposed
computer-science perspective to this problem, where ODE reduction is recast to
finding an appropriate equivalence relation over ODE variables, akin to
classical models of computation based on labelled transition systems.
",['\nAndrea Vandin\nIMT School for Advanced Studies Lucca\n'],"In Proceedings QAPL 2017, arXiv:1707.03668","EPTCS 250, 2017, pp. 15-24",http://dx.doi.org/10.4204/EPTCS.250.2,cs.MS,"['cs.MS', 'cs.PF', 'F.1.1']",10.4204/EPTCS.250.2,,['IMT School for Advanced Studies Lucca']
"Batched QR and SVD Algorithms on GPUs with Applications in Hierarchical
  Matrix Compression",http://arxiv.org/abs/1707.05141v1,2017-07-13T12:25:52Z,2017-07-13T12:25:52Z,"  We present high performance implementations of the QR and the singular value
decomposition of a batch of small matrices hosted on the GPU with applications
in the compression of hierarchical matrices. The one-sided Jacobi algorithm is
used for its simplicity and inherent parallelism as a building block for the
SVD of low rank blocks using randomized methods. We implement multiple kernels
based on the level of the GPU memory hierarchy in which the matrices can reside
and show substantial speedups against streamed cuSOLVER SVDs. The resulting
batched routine is a key component of hierarchical matrix compression, opening
up opportunities to perform H-matrix arithmetic efficiently on GPUs.
","['\nWajih Halim Boukaram\n', '\nGeorge Turkiyyah\n', '\nHatem Ltaief\n', '\nDavid E. Keyes\n']",,,http://arxiv.org/abs/1707.05141v1,cs.MS,"['cs.MS', 'cs.DS', 'cs.NA']",,,[]
FDTD: solving 1+1D delay PDE in parallel,http://arxiv.org/abs/1707.05943v2,2017-07-19T06:06:13Z,2018-09-04T02:51:39Z,"  We present a proof of concept for solving a 1+1D complex-valued, delay
partial differential equation (PDE) that emerges in the study of waveguide
quantum electrodynamics (QED) by adapting the finite-difference time-domain
(FDTD) method. The delay term is spatially non-local, rendering conventional
approaches such as the method of lines inapplicable. We show that by properly
designing the grid and by supplying the (partial) exact solution as the
boundary condition, the delay PDE can be numerically solved. In addition, we
demonstrate that while the delay imposes strong data dependency, multi-thread
parallelization can nevertheless be applied to such a problem. Our code
provides a numerically exact solution to the time-dependent multi-photon
scattering problem in waveguide QED.
",['\nYao-Lung L. Fang\n'],"Introduced two parallelization approaches along with other
  improvements in the presentation. Code open sourced at
  https://github.com/leofang/FDTD. To appear in Computer Physics Communications","Computer Physics Communications 235, 422 (2019)",http://dx.doi.org/10.1016/j.cpc.2018.08.018,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'physics.comp-ph', 'quant-ph']",10.1016/j.cpc.2018.08.018,,[]
Geometry-Oblivious FMM for Compressing Dense SPD Matrices,http://arxiv.org/abs/1707.00164v1,2017-07-01T14:57:20Z,2017-07-01T14:57:20Z,"  We present GOFMM (geometry-oblivious FMM), a novel method that creates a
hierarchical low-rank approximation, ""compression,"" of an arbitrary dense
symmetric positive definite (SPD) matrix. For many applications, GOFMM enables
an approximate matrix-vector multiplication in $N \log N$ or even $N$ time,
where $N$ is the matrix size. Compression requires $N \log N$ storage and work.
In general, our scheme belongs to the family of hierarchical matrix
approximation methods. In particular, it generalizes the fast multipole method
(FMM) to a purely algebraic setting by only requiring the ability to sample
matrix entries. Neither geometric information (i.e., point coordinates) nor
knowledge of how the matrix entries have been generated is required, thus the
term ""geometry-oblivious."" Also, we introduce a shared-memory parallel scheme
for hierarchical matrix computations that reduces synchronization barriers. We
present results on the Intel Knights Landing and Haswell architectures, and on
the NVIDIA Pascal architecture for a variety of matrices.
","['\nChenhan D. Yu\n', '\nJames Levitt\n', '\nSeverin Reiz\n', '\nGeorge Biros\n']","13 pages, accepted by SC'17",,http://arxiv.org/abs/1707.00164v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
Compiling LATEX to computer algebra-enabled HTML5,http://arxiv.org/abs/1707.01271v1,2017-07-05T09:24:46Z,2017-07-05T09:24:46Z,"  This document explains how to create or modify an existing LATEX document
with commands enabling computations in the HTML5 output: when the reader opens
the HTML5 output, he can run a computation in his browser, or modify the
command to be executed and run it. This is done by combining different
softwares: hevea for compilation to HTML5, giac.js for the CAS computing kernel
(itself compiled from the C++ Giac library with emscripten), and a modified
version of itex2MML for fast and nice rendering in MathML in browsers that
support MathML.
",['\nBernard Parisse\n'],"The interactive HTML5/MathML version of the document is available at
  https://www-fourier.ujf-grenoble.fr/~parisse/giac/castex.htmlThe LaTeX source
  will not compile properly to PDF without installing the software described in
  the document",,http://arxiv.org/abs/1707.01271v1,cs.SC,"['cs.SC', 'cs.MS']",,,[]
Adaptive Modular Exponentiation Methods v.s. Python's Power Function,http://arxiv.org/abs/1707.01898v1,2017-07-06T04:12:25Z,2017-07-06T04:12:25Z,"  In this paper we use Python to implement two efficient modular exponentiation
methods: the adaptive m-ary method and the adaptive sliding-window method of
window size k, where both m's are adaptively chosen based on the length of
exponent. We also conduct the benchmark for both methods. Evaluation results
show that compared to the industry-standard efficient implementations of
modular power function in CPython and Pypy, our algorithms can reduce 1-5%
computing time for exponents with more than 3072 bits.
","['\nShiyu Ji\n', '\nKun Wan\n']",4 pages,,http://arxiv.org/abs/1707.01898v1,cs.DS,"['cs.DS', 'cs.MS']",,,[]
Applying the Polyhedral Model to Tile Time Loops in Devito,http://arxiv.org/abs/1707.02347v1,2017-06-30T14:51:26Z,2017-06-30T14:51:26Z,"  The run time of many scientific computation applications for numerical
methods is heavily dependent on just a few multi-dimensional loop nests. Since
these applications are often limited by memory bandwidth rather than
computational resources they can benefit greatly from any optimizations which
decrease the run time of their loops by improving data reuse and thus reducing
the total memory traffic. Some of the most effective of these optimizations are
not suitable for development by hand or require advanced software engineering
knowledge which is beyond the level of many researchers who are not specialists
in code optimization. Several tools exist to automate the generation of
high-performance code for numerical methods, such as Devito which produces code
for finite-difference approximations typically used in the seismic imaging
domain. We present a loop-tiling optimization which can be applied to
Devito-generated loops and improves run time by up to 27.5%, and options for
automating this optimization in the Devito framework.
",['\nDylan McCormick\n'],,,http://arxiv.org/abs/1707.02347v1,cs.PL,"['cs.PL', 'cs.MS']",,,[]
Parareal Algorithm Implementation and Simulation in Julia,http://arxiv.org/abs/1706.08569v2,2017-06-26T19:27:58Z,2018-12-13T20:21:25Z,"  We present a full implementation of the parareal algorithm---an integration
technique to solve differential equations in parallel---in the Julia
programming language for a fully general, first-order, initial-value problem.
We provide a brief overview of Julia---a concurrent programming language for
scientific computing. Our implementation of the parareal algorithm accepts both
coarse and fine integrators as functional arguments. We use Euler's method and
another Runge-Kutta integration technique as the integrators in our
experiments. We also present a simulation of the algorithm for purposes of
pedagogy and as a tool for investigating the performance of the algorithm.
","['\nTyler M. Masthay\n', '\nSaverio Perugini\n']","6 pages, 2 figures, 2 listings",,http://arxiv.org/abs/1706.08569v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA']",,,[]
A randomized Halton algorithm in R,http://arxiv.org/abs/1706.02808v2,2017-06-09T01:44:03Z,2017-06-22T22:04:44Z,"  Randomized quasi-Monte Carlo (RQMC) sampling can bring orders of magnitude
reduction in variance compared to plain Monte Carlo (MC) sampling. The extent
of the efficiency gain varies from problem to problem and can be hard to
predict. This article presents an R function rhalton that produces scrambled
versions of Halton sequences. On some problems it brings efficiency gains of
several thousand fold. On other problems, the efficiency gain is minor. The
code is designed to make it easy to determine whether a given integrand will
benefit from RQMC sampling. An RQMC sample of n points in $[0,1]^d$ can be
extended later to a larger n and/or d.
",['\nArt B. Owen\n'],,,http://arxiv.org/abs/1706.02808v2,stat.CO,"['stat.CO', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
A Unified Optimization Approach for Sparse Tensor Operations on GPUs,http://arxiv.org/abs/1705.09905v1,2017-05-28T07:41:22Z,2017-05-28T07:41:22Z,"  Sparse tensors appear in many large-scale applications with multidimensional
and sparse data. While multidimensional sparse data often need to be processed
on manycore processors, attempts to develop highly-optimized GPU-based
implementations of sparse tensor operations are rare. The irregular computation
patterns and sparsity structures as well as the large memory footprints of
sparse tensor operations make such implementations challenging. We leverage the
fact that sparse tensor operations share similar computation patterns to
propose a unified tensor representation called F-COO. Combined with
GPU-specific optimizations, F-COO provides highly-optimized implementations of
sparse tensor computations on GPUs. The performance of the proposed unified
approach is demonstrated for tensor-based kernels such as the Sparse Matricized
Tensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix
Multiply (SpTTM) and is used in tensor decomposition algorithms. Compared to
state-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to
3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a
CANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using
the unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs.
","['\nBangtian Liu\n', '\nChengyao Wen\n', '\nAnand D. Sarwate\n', '\nMaryam Mehri Dehnavi\n']",,,http://dx.doi.org/10.1109/CLUSTER.2017.75,cs.MS,"['cs.MS', 'cs.DC']",10.1109/CLUSTER.2017.75,,[]
"Increasing the Efficiency of Sparse Matrix-Matrix Multiplication with a
  2.5D Algorithm and One-Sided MPI",http://arxiv.org/abs/1705.10218v1,2017-05-29T14:42:14Z,2017-05-29T14:42:14Z,"  Matrix-matrix multiplication is a basic operation in linear algebra and an
essential building block for a wide range of algorithms in various scientific
fields. Theory and implementation for the dense, square matrix case are
well-developed. If matrices are sparse, with application-specific sparsity
patterns, the optimal implementation remains an open question. Here, we explore
the performance of communication reducing 2.5D algorithms and one-sided MPI
communication in the context of linear scaling electronic structure theory. In
particular, we extend the DBCSR sparse matrix library, which is the basic
building block for linear scaling electronic structure theory and low scaling
correlated methods in CP2K. The library is specifically designed to efficiently
perform block-sparse matrix-matrix multiplication of matrices with a relatively
large occupation. Here, we compare the performance of the original
implementation based on Cannon's algorithm and MPI point-to-point
communication, with an implementation based on MPI one-sided communications
(RMA), in both a 2D and a 2.5D approach. The 2.5D approach trades memory and
auxiliary operations for reduced communication, which can lead to a speedup if
communication is dominant. The 2.5D algorithm is somewhat easier to implement
with one-sided communications. A detailed description of the implementation is
provided, also for non ideal processor topologies, since this is important for
actual applications. Given the importance of the precise sparsity pattern, and
even the actual matrix data, which decides the effective fill-in upon
multiplication, the tests are performed within the CP2K package with
application benchmarks. Results show a substantial boost in performance for the
RMA based 2.5D algorithm, up to 1.80x, which is observed to increase with the
number of involved processes in the parallelization.
","['\nAlfio Lazzaro\n', '\nJoost VandeVondele\n', '\nJuerg Hutter\n', '\nOle Schuett\n']","In Proceedings of PASC '17, Lugano, Switzerland, June 26-28, 2017, 10
  pages, 4 figures",,http://dx.doi.org/10.1145/3093172.3093228,cs.DC,"['cs.DC', 'cs.MS']",10.1145/3093172.3093228,,[]
Automatic Differentiation using Constraint Handling Rules in Prolog,http://arxiv.org/abs/1706.00231v1,2017-06-01T09:55:10Z,2017-06-01T09:55:10Z,"  Automatic differentiation is a technique which allows a programmer to define
a numerical computation via compositions of a broad range of numeric and
computational primitives and have the underlying system support the computation
of partial derivatives of the result with respect to any of its inputs, without
making any finite difference approximations, and without manipulating large
symbolic expressions representing the computation. This note describes a novel
approach to reverse mode automatic differentiation using constraint logic
programmming, specifically, the constraint handling rules (CHR) library of SWI
Prolog, resulting in a very small (50 lines of code) implementation. When
applied to a differentiation-based implementation of the inside-outside
algorithm for parameter learning in probabilistic grammars, the CHR based
implementations outperformed two well-known frameworks for optimising
differentiable functions, Theano and TensorFlow, by a large margin.
",['\nSamer Abdallah\n'],,,http://arxiv.org/abs/1706.00231v1,cs.MS,"['cs.MS', 'cs.PL', 'cs.SC']",,,[]
Solver composition across the PDE/linear algebra barrier,http://arxiv.org/abs/1706.01346v3,2017-06-05T14:25:39Z,2017-11-08T11:04:49Z,"  The efficient solution of discretisations of coupled systems of partial
differential equations (PDEs) is at the core of much of numerical simulation.
Significant effort has been expended on scalable algorithms to precondition
Krylov iterations for the linear systems that arise. With few exceptions, the
reported numerical implementation of such solution strategies is specific to a
particular model setup, and intimately ties the solver strategy to the
discretisation and PDE, especially when the preconditioner requires auxiliary
operators. In this paper, we present recent improvements in the Firedrake
finite element library that allow for straightforward development of the
building blocks of extensible, composable preconditioners that decouple the
solver from the model formulation. Our implementation extends the algebraic
composability of linear solvers offered by the PETSc library by augmenting
operators, and hence preconditioners, with the ability to provide any necessary
auxiliary operators. Rather than specifying up front the full solver
configuration, tied to the model, solvers can be developed independently of
model formulation and configured at runtime. We illustrate with examples from
incompressible fluids and temperature-driven convection.
","['\nRobert C. Kirby\n', '\nLawrence Mitchell\n']",23 pages. Fixed axis labelling in Fig 3,SIAM Journal on Scientific Computing 40(1):C76-C98 (2018),http://dx.doi.org/10.1137/17M1133208,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', '65N22, 65F08, 65F10']",10.1137/17M1133208,,[]
"Introducing Geometric Algebra to Geometric Computing Software
  Developers: A Computational Thinking Approach",http://arxiv.org/abs/1705.06668v1,2017-05-18T16:05:54Z,2017-05-18T16:05:54Z,"  Designing software systems for Geometric Computing applications can be a
challenging task. Software engineers typically use software abstractions to
hide and manage the high complexity of such systems. Without the presence of a
unifying algebraic system to describe geometric models, the use of software
abstractions alone can result in many design and maintenance problems.
Geometric Algebra (GA) can be a universal abstract algebraic language for
software engineering geometric computing applications. Few sources, however,
provide enough information about GA-based software implementations targeting
the software engineering community. In particular, successfully introducing GA
to software engineers requires quite different approaches from introducing GA
to mathematicians or physicists. This article provides a high-level
introduction to the abstract concepts and algebraic representations behind the
elegant GA mathematical structure. The article focuses on the conceptual and
representational abstraction levels behind GA mathematics with sufficient
references for more details. In addition, the article strongly recommends
applying the methods of Computational Thinking in both introducing GA to
software engineers, and in using GA as a mathematical language for developing
Geometric Computing software systems.
",['\nAhmad Hosny Eid\n'],"Tutorial, 43 pages, 3 figures",,http://arxiv.org/abs/1705.06668v1,cs.MS,['cs.MS'],,,[]
Sparse Matrix Multiplication On An Associative Processor,http://arxiv.org/abs/1705.07282v1,2017-05-20T09:07:04Z,2017-05-20T09:07:04Z,"  Sparse matrix multiplication is an important component of linear algebra
computations. Implementing sparse matrix multiplication on an associative
processor (AP) enables high level of parallelism, where a row of one matrix is
multiplied in parallel with the entire second matrix, and where the execution
time of vector dot product does not depend on the vector size. Four sparse
matrix multiplication algorithms are explored in this paper, combining AP and
baseline CPU processing to various levels. They are evaluated by simulation on
a large set of sparse matrices. The computational complexity of sparse matrix
multiplication on AP is shown to be an O(nnz) where nnz is the number of
nonzero elements. The AP is found to be especially efficient in binary sparse
matrix multiplication. AP outperforms conventional solutions in power
efficiency.
","['\nL. Yavits\n', '\nA. Morad\n', '\nR. Ginosar\n']",,,http://arxiv.org/abs/1705.07282v1,cs.MS,['cs.MS'],,,[]
"Nemo/Hecke: Computer Algebra and Number Theory Packages for the Julia
  Programming Language",http://arxiv.org/abs/1705.06134v1,2017-05-17T13:10:32Z,2017-05-17T13:10:32Z,"  We introduce two new packages, Nemo and Hecke, written in the Julia
programming language for computer algebra and number theory. We demonstrate
that high performance generic algorithms can be implemented in Julia, without
the need to resort to a low-level C implementation. For specialised algorithms,
we use Julia's efficient native C interface to wrap existing C/C++ libraries
such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke
and Nemo and discuss some algorithms that we have implemented to provide high
performance basic arithmetic.
","['\nClaus Fieker\n', '\nWilliam Hart\n', '\nTommy Hofmann\n', '\nFredrik Johansson\n']","ISSAC '17, Kaiserslautern, Germany, July 25-28, 2017, 8 pages",,http://dx.doi.org/10.1145/3087604.3087611,cs.MS,"['cs.MS', 'cs.SC']",10.1145/3087604.3087611,,[]
Spin Summations: A High-Performance Perspective,http://arxiv.org/abs/1705.06661v1,2017-05-18T15:48:46Z,2017-05-18T15:48:46Z,"  Besides tensor contractions, one of the most pronounced computational
bottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry
methods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and
CCSDT(Q)---are spin summations. At a first sight, spin summations are
operations similar to tensor transpositions; a closer look instead reveals
additional challenges to high-performance calculations, including temporal
locality as well as scattered memory accesses. This publication explores a
sequence of algorithmic solutions for spin summations, each exploiting
individual properties of either the underlying hardware (e.g. caches,
vectorization), or the problem itself (e.g. factorizability). The final
algorithm combines the advantages of all the solutions, while avoiding their
drawbacks; this algorithm, achieves high-performance through parallelization,
vectorization, and by exploiting the temporal locality inherent to spin
summations. Combined, these optimizations result in speedups between 2.4x and
5.5x over the NCC quantum chemistry software package. In addition to such a
performance boost, our algorithm can perform the spin summations in-place, thus
reducing the memory footprint by 2x over an out-of-place variant.
","['\nPaul Springer\n', '\nDevin Matthews\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1705.06661v1,cs.MS,"['cs.MS', 'cs.PF', 'G.4; D.1.3']",,,[]
ParMooN - a modernized program package based on mapped finite elements,http://arxiv.org/abs/1705.08784v2,2017-05-24T14:17:57Z,2017-05-31T16:40:58Z,"  {\sc ParMooN} is a program package for the numerical solution of elliptic and
parabolic partial differential equations. It inherits the distinct features of
its predecessor {\sc MooNMD} \cite{JM04}: strict decoupling of geometry and
finite element spaces, implementation of mapped finite elements as their
definition can be found in textbooks, and a geometric multigrid preconditioner
with the option to use different finite element spaces on different levels of
the multigrid hierarchy. After having presented some thoughts about in-house
research codes, this paper focuses on aspects of the parallelization for a
distributed memory environment, which is the main novelty of {\sc ParMooN}.
Numerical studies, performed on compute servers, assess the efficiency of the
parallelized geometric multigrid preconditioner in comparison with some
parallel solvers that are available in the library {\sc PETSc}. The results of
these studies give a first indication whether the cumbersome implementation of
the parallelized geometric multigrid method was worthwhile or not.
","['\nUlrich Wilbrandt\n', '\nClemens Bartsch\n', '\nNaveed Ahmed\n', '\nNajib Alia\n', '\nFelix Anker\n', '\nLaura Blank\n', '\nAlfonso Caiazzo\n', '\nSashikumaar Ganesan\n', '\nSwetlana Giere\n', '\nGunar Matthies\n', '\nRaviteja Meesala\n', '\nAbdus Shamim\n', '\nJagannath Venkatesan\n', '\nVolker John\n']","partly supported by European Union (EU), Horizon 2020, Marie
  Sk{\l}odowska-Curie Innovative Training Networks (ITN-EID), MIMESIS, grant
  number 675715","Comput. Math. Appl. 74(1), 74-88, 2017",http://dx.doi.org/10.1016/j.camwa.2016.12.020,math.NA,"['math.NA', 'cs.MS']",10.1016/j.camwa.2016.12.020,,[]
"Parallel Matrix-Free Implementation of Frequency-Domain Finite
  Difference Methods for Cluster Computing",http://arxiv.org/abs/1705.08849v1,2017-05-23T16:45:20Z,2017-05-23T16:45:20Z,"  Full-wave 3D electromagnetic simulations of complex planar devices,
multilayer interconnects, and chip packages are presented for wide-band
frequency-domain analysis using the finite difference integration technique
developed in the PETSc software package. Initial reordering of the index
assignment to the unknowns makes the resulting system matrix diagonally
dominant. The rearrangement also facilitates the decomposition of large domain
into slices for passing the mesh information to different machines. Matrix-free
methods are then exploited to minimize the number of element-wise
multiplications and memory requirements in the construction of the system of
linear equations. Besides, the recipes provide extreme ease of modifications in
the kernel of the code. The applicability of different Krylov subspace solvers
is investigated. The accuracy is checked through comparisons with CST MICROWAVE
STUDIO transient solver results. The parallel execution of the compiled code on
specific number of processors in multi-core distributed-memory architectures
demonstrate high scalability of the computational algorithm.
",['\nAmir Geranmayeh\n'],"7 pages, 10 figures including: Matrix-free 3D finite-difference
  frequency-domain (FDFD) methods, Simultaneous reduction in memory usage and
  computational costs of FDFD, Broadband impedance calculation of electrically
  large interconnects, Ease of solver modification for mutual field coupling
  simulation between many ports, Domain decomposition for passing the mesh
  information to parallel machines",,http://arxiv.org/abs/1705.08849v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
"Computing the Lambert W function in arbitrary-precision complex interval
  arithmetic",http://arxiv.org/abs/1705.03266v1,2017-05-09T10:45:42Z,2017-05-09T10:45:42Z,"  We describe an algorithm to evaluate all the complex branches of the Lambert
W function with rigorous error bounds in interval arithmetic, which has been
implemented in the Arb library. The classic 1996 paper on the Lambert W
function by Corless et al. provides a thorough but partly heuristic numerical
analysis which needs to be complemented with some explicit inequalities and
practical observations about managing precision and branch cuts.
",['\nFredrik Johansson\n'],"16 pages, 4 figures",,http://arxiv.org/abs/1705.03266v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"A performance spectrum for parallel computational frameworks that solve
  PDEs",http://arxiv.org/abs/1705.03625v2,2017-05-10T06:51:15Z,2017-09-15T00:00:52Z,"  Important computational physics problems are often large-scale in nature, and
it is highly desirable to have robust and high performing computational
frameworks that can quickly address these problems. However, it is no trivial
task to determine whether a computational framework is performing efficiently
or is scalable. The aim of this paper is to present various strategies for
better understanding the performance of any parallel computational frameworks
for solving PDEs. Important performance issues that negatively impact
time-to-solution are discussed, and we propose a performance spectrum analysis
that can enhance one's understanding of critical aforementioned performance
issues. As proof of concept, we examine commonly used finite element simulation
packages and software and apply the performance spectrum to quickly analyze the
performance and scalability across various hardware platforms, software
implementations, and numerical discretizations. It is shown that the proposed
performance spectrum is a versatile performance model that is not only
extendable to more complex PDEs such as hydrostatic ice sheet flow equations,
but also useful for understanding hardware performance in a massively parallel
computing environment. Potential applications and future extensions of this
work are also discussed.
","['\nJ. Chang\n', '\nK. B. Nakshatrala\n', '\nM. G. Knepley\n', '\nL. Johnsson\n']",,,http://arxiv.org/abs/1705.03625v2,cs.MS,"['cs.MS', 'cs.NA']",,,[]
TSFC: a structure-preserving form compiler,http://arxiv.org/abs/1705.03667v2,2017-05-10T09:21:24Z,2018-04-09T13:51:11Z,"  A form compiler takes a high-level description of the weak form of partial
differential equations and produces low-level code that carries out the finite
element assembly. In this paper we present the Two-Stage Form Compiler (TSFC),
a new form compiler with the main motivation to maintain the structure of the
input expression as long as possible. This facilitates the application of
optimizations at the highest possible level of abstraction. TSFC features a
novel, structure-preserving method for separating the contributions of a form
to the subblocks of the local tensor in discontinuous Galerkin problems. This
enables us to preserve the tensor structure of expressions longer through the
compilation process than other form compilers. This is also achieved in part by
a two-stage approach that cleanly separates the lowering of finite element
constructs to tensor algebra in the first stage, from the scheduling of those
tensor operations in the second stage. TSFC also efficiently traverses
complicated expressions, and experimental evaluation demonstrates good
compile-time performance even for highly complex forms.
","['\nMiklós Homolya\n', '\nLawrence Mitchell\n', '\nFabio Luporini\n', '\nDavid A. Ham\n']",Accepted version. 28 pages plus 5 pages supplement,"SIAM Journal on Scientific Computing, 40 (2018), pp. C401-C428",http://dx.doi.org/10.1137/17M1130642,cs.MS,"['cs.MS', 'cs.NA', '68N20, 65M60, 65N30']",10.1137/17M1130642,,[]
A revision of the subtract-with-borrow random number generators,http://arxiv.org/abs/1705.03123v1,2017-05-08T23:42:29Z,2017-05-08T23:42:29Z,"  The most popular and widely used subtract-with-borrow generator, also known
as RANLUX, is reimplemented as a linear congruential generator using large
integer arithmetic with the modulus size of 576 bits. Modern computers, as well
as the specific structure of the modulus inferred from RANLUX, allow for the
development of a fast modular multiplication -- the core of the procedure. This
was previously believed to be slow and have too high cost in terms of computing
resources. Our tests show a significant gain in generation speed which is
comparable with other fast, high quality random number generators. An
additional feature is the fast skipping of generator states leading to a
seeding scheme which guarantees the uniqueness of random number sequences.
",['\nAlexei Sibidanov\n'],13 pages,,http://dx.doi.org/10.1016/j.cpc.2017.09.005,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'hep-lat']",10.1016/j.cpc.2017.09.005,,[]
"Accelerating solutions of one-dimensional unsteady PDEs with GPU-based
  swept time-space decomposition",http://arxiv.org/abs/1705.03162v2,2017-05-09T03:25:24Z,2017-11-10T23:58:13Z,"  The expedient design of precision components in aerospace and other high-tech
industries requires simulations of physical phenomena often described by
partial differential equations (PDEs) without exact solutions. Modern design
problems require simulations with a level of resolution difficult to achieve in
reasonable amounts of time---even in effectively parallelized solvers. Though
the scale of the problem relative to available computing power is the greatest
impediment to accelerating these applications, significant performance gains
can be achieved through careful attention to the details of memory
communication and access. The swept time-space decomposition rule reduces
communication between sub-domains by exhausting the domain of influence before
communicating boundary values. Here we present a GPU implementation of the
swept rule, which modifies the algorithm for improved performance on this
processing architecture by prioritizing use of private (shared) memory,
avoiding interblock communication, and overwriting unnecessary values. It shows
significant improvement in the execution time of finite-difference solvers for
one-dimensional unsteady PDEs, producing speedups of 2--9$\times$ for a range
of problem sizes, respectively, compared with simple GPU versions and
7--300$\times$ compared with parallel CPU versions. However, for a more
sophisticated one-dimensional system of equations discretized with a
second-order finite-volume scheme, the swept rule performs 1.2--1.9$\times$
worse than a standard implementation for all problem sizes.
","['\nDaniel J Magee\n', '\nKyle E Niemeyer\n']","25 pages, 10 figures",J. Comput. Phys. 357 (2018) 338-352,http://dx.doi.org/10.1016/j.jcp.2017.12.028,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS', '65M55, 65N55, 68W10, 35Q35']",10.1016/j.jcp.2017.12.028,,[]
CLBlast: A Tuned OpenCL BLAS Library,http://arxiv.org/abs/1705.05249v2,2017-05-12T17:16:59Z,2018-04-27T09:10:16Z,"  This work introduces CLBlast, an open-source BLAS library providing optimized
OpenCL routines to accelerate dense linear algebra for a wide variety of
devices. It is targeted at machine learning and HPC applications and thus
provides a fast matrix-multiplication routine (GEMM) to accelerate the core of
many applications (e.g. deep learning, iterative solvers, astrophysics,
computational fluid dynamics, quantum chemistry). CLBlast has five main
advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested
on a large variety of OpenCL devices including less commonly used devices such
as embedded and low-power GPUs, 2) it can be explicitly tuned for specific
problem-sizes on specific hardware platforms, 3) it can perform operations in
half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has
an optional CUDA back-end, 5) and it can combine multiple operations in a
single batched routine, accelerating smaller problems significantly. This paper
describes the library and demonstrates the advantages of CLBlast experimentally
for different use-cases on a wide variety of OpenCL hardware.
",['\nCedric Nugteren\n'],"Conference paper in: IWOCL '18, the International Workshop on OpenCL",,http://dx.doi.org/10.1145/3204919.3204924,cs.MS,"['cs.MS', 'cs.AI', 'cs.DC']",10.1145/3204919.3204924,,[]
"A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel
  Skylake",http://arxiv.org/abs/1704.08579v2,2017-04-24T12:34:29Z,2018-03-12T11:39:00Z,"  The modern CPU's design, which is composed of hierarchical memory and
SIMD/vectorization capability, governs the potential for algorithms to be
transformed into efficient implementations. The release of the AVX-512 changed
things radically, and motivated us to search for an efficient sorting algorithm
that can take advantage of it. In this paper, we describe the best strategy we
have found, which is a novel two parts hybrid sort, based on the well-known
Quicksort algorithm. The central partitioning operation is performed by a new
algorithm, and small partitions/arrays are sorted using a branch-free
Bitonic-based sort. This study is also an illustration of how classical
algorithms can be adapted and enhanced by the AVX-512 extension. We evaluate
the performance of our approach on a modern Intel Xeon Skylake and assess the
different layers of our implementation by sorting/partitioning integers, double
floating-point numbers, and key/value pairs of integers. Our results
demonstrate that our approach is faster than two libraries of reference: the
GNU \emph{C++} sort algorithm by a speedup factor of 4, and the Intel IPP
library by a speedup factor of 1.4.
",['\nBerenger Bramas\n'],"8 pages, research paper","Article Published in International Journal of Advanced Computer
  Science and Applications(IJACSA), Volume 8 Issue 10, 2017",http://dx.doi.org/10.14569/IJACSA.2017.081044,cs.MS,['cs.MS'],10.14569/IJACSA.2017.081044,,[]
"cuTT: A High-Performance Tensor Transpose Library for CUDA Compatible
  GPUs",http://arxiv.org/abs/1705.01598v1,2017-05-03T19:58:00Z,2017-05-03T19:58:00Z,"  We introduce the CUDA Tensor Transpose (cuTT) library that implements
high-performance tensor transposes for NVIDIA GPUs with Kepler and above
architectures. cuTT achieves high performance by (a) utilizing two
GPU-optimized transpose algorithms that both use a shared memory buffer in
order to reduce global memory access scatter, and by (b) computing memory
positions of tensor elements using a thread-parallel algorithm. We evaluate the
performance of cuTT on a variety of benchmarks with tensor ranks ranging from 2
to 12 and show that cuTT performance is independent of the tensor rank and that
it performs no worse than an approach based on code generation. We develop a
heuristic scheme for choosing the optimal parameters for tensor transpose
algorithms by implementing an analytical GPU performance model that can be used
at runtime without need for performance measurements or profiling. Finally, by
integrating cuTT into the tensor algebra library TAL-SH, we significantly
reduce the tensor transpose overhead in tensor contractions, achieving as low
as just one percent overhead for arithmetically intensive tensor contractions.
","['\nAntti-Pekka Hynninen\n', '\nDmitry I. Lyakh\n']",,,http://arxiv.org/abs/1705.01598v1,cs.MS,['cs.MS'],,,[]
Particle-based and Meshless Methods with Aboria,http://arxiv.org/abs/1704.08907v2,2017-04-28T12:49:43Z,2017-10-11T20:50:12Z,"  Aboria is a powerful and flexible C++ library for the implementation of
particle-based numerical methods. The particles in such methods can represent
actual particles (e.g. Molecular Dynamics) or abstract particles used to
discretise a continuous function over a domain (e.g. Radial Basis Functions).
Aboria provides a particle container, compatible with the Standard Template
Library, spatial search data structures, and a Domain Specific Language to
specify non-linear operators on the particle set. This paper gives an overview
of Aboria's design, an example of use, and a performance benchmark.
","['\nMartin Robinson\n', '\nMaria Bruna\n']",,SoftwareX 6 (2017),http://dx.doi.org/10.1016/j.softx.2017.07.002,cs.MS,"['cs.MS', 'cond-mat.soft', 'q-bio.QM']",10.1016/j.softx.2017.07.002,,[]
Computing isomorphisms and embeddings of finite fields,http://arxiv.org/abs/1705.01221v1,2017-05-03T01:33:29Z,2017-05-03T01:33:29Z,"  Let $\mathbb{F}_q$ be a finite field. Given two irreducible polynomials $f,g$
over $\mathbb{F}_q$, with $\mathrm{deg} f$ dividing $\mathrm{deg} g$, the
finite field embedding problem asks to compute an explicit description of a
field embedding of $\mathbb{F}_q[X]/f(X)$ into $\mathbb{F}_q[Y]/g(Y)$. When
$\mathrm{deg} f = \mathrm{deg} g$, this is also known as the isomorphism
problem.
  This problem, a special instance of polynomial factorization, plays a central
role in computer algebra software. We review previous algorithms, due to
Lenstra, Allombert, Rains, and Narayanan, and propose improvements and
generalizations. Our detailed complexity analysis shows that our newly proposed
variants are at least as efficient as previously known algorithms, and in many
cases significantly better.
  We also implement most of the presented algorithms, compare them with the
state of the art computer algebra software, and make the code available as open
source. Our experiments show that our new variants consistently outperform
available software.
","['\nLudovic Brieulle\n', '\nLuca De Feo\n', '\nJavad Doliskani\n', '\nJean-Pierre Flori\n', '\nÉric Schost\n']",,,http://dx.doi.org/10.1090/mcom/3363,cs.SC,"['cs.SC', 'cs.MS', 'math.NT']",10.1090/mcom/3363,,[]
Computing Tropical Prevarieties in Parallel,http://arxiv.org/abs/1705.00720v2,2017-05-01T21:34:00Z,2017-07-01T23:04:37Z,"  The computation of the tropical prevariety is the first step in the
application of polyhedral methods to compute positive dimensional solution sets
of polynomial systems. In particular, pretropisms are candidate leading
exponents for the power series developments of the solutions. The computation
of the power series may start as soon as one pretropism is available, so our
parallel computation of the tropical prevariety has an application in a
pipelined solver.
  We present a parallel implementation of dynamic enumeration. Our first
distributed memory implementation with forked processes achieved good speedups,
but quite often resulted in large variations in the execution times of the
processes. The shared memory multithreaded version applies work stealing to
reduce the variability of the run time. Our implementation applies the thread
safe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU
Multiprecision Arithmetic Library (GMP), aided by the fast memory allocations
of TCMalloc.
  Our parallel implementation is capable of computing the tropical prevariety
of the cyclic 16-roots problem. We also report on computational experiments on
the $n$-body and $n$-vortex problems; our computational results compare
favorably with Gfan.
","['\nAnders Jensen\n', '\nJeff Sommars\n', '\nJan Verschelde\n']",Accepted for publication in the proceedings of PASCO 2017,,http://arxiv.org/abs/1705.00720v2,cs.MS,"['cs.MS', 'cs.CG', 'cs.DC', 'math.AG', 'math.CO']",,,[]
DATeS: A Highly-Extensible Data Assimilation Testing Suite v1.0,http://arxiv.org/abs/1704.05594v2,2017-04-19T02:58:23Z,2018-07-02T03:06:51Z,"  A flexible and highly-extensible data assimilation testing suite, named
DATeS, is described in this paper. DATeS aims to offer a unified testing
environment that allows researchers to compare different data assimilation
methodologies and understand their performance in various settings. The core of
DATeS is implemented in Python and takes advantage of its object-oriented
capabilities. The main components of the package (the numerical models, the
data assimilation algorithms, the linear algebra solvers, and the time
discretization routines) are independent of each other, which offers great
flexibility to configure data assimilation applications. DATeS can interface
easily with large third-party numerical models written in Fortran or in C, and
with a plethora of external solvers.
","['\nAhmed Attia\n', '\nAdrian Sandu\n']",,,http://arxiv.org/abs/1704.05594v2,cs.MS,['cs.MS'],,,[]
Two variants of the Froiduire-Pin Algorithm for finite semigroups,http://arxiv.org/abs/1704.04084v2,2017-04-13T12:05:37Z,2017-06-09T17:00:57Z,"  In this paper, we present two algorithms based on the Froidure-Pin Algorithm
for computing the structure of a finite semigroup from a generating set. As was
the case with the original algorithm of Froidure and Pin, the algorithms
presented here produce the left and right Cayley graphs, a confluent
terminating rewriting system, and a reduced word of the rewriting system for
every element of the semigroup.
  If $U$ is any semigroup, and $A$ is a subset of $U$, then we denote by
$\langle A\rangle$ the least subsemigroup of $U$ containing $A$. If $B$ is any
other subset of $U$, then, roughly speaking, the first algorithm we present
describes how to use any information about $\langle A\rangle$, that has been
found using the Froidure-Pin Algorithm, to compute the semigroup $\langle A\cup
B\rangle$. More precisely, we describe the data structure for a finite
semigroup $S$ given by Froidure and Pin, and how to obtain such a data
structure for $\langle A\cup B\rangle$ from that for $\langle A\rangle$. The
second algorithm is a lock-free concurrent version of the Froidure-Pin
Algorithm.
","['\nJ. Jonušas\n', '\nJ. D. Mitchell\n', '\nM. Pfeiffer\n']","19 pages, 7 figures (v2 revised according to referees comments to
  improve the readability, and add a further 1198 examples)",,http://arxiv.org/abs/1704.04084v2,math.GR,"['math.GR', 'cs.MS', '20M10']",,,[]
HPTT: A High-Performance Tensor Transposition C++ Library,http://arxiv.org/abs/1704.04374v2,2017-04-14T09:45:06Z,2017-05-10T21:34:51Z,"  Recently we presented TTC, a domain-specific compiler for tensor
transpositions. Despite the fact that the performance of the generated code is
nearly optimal, due to its offline nature, TTC cannot be utilized in all the
application codes in which the tensor sizes and the necessary tensor
permutations are determined at runtime. To overcome this limitation, we
introduce the open-source C++ library High-Performance Tensor Transposition
(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,
multi-threading, and explicit vectorization; furthermore it decomposes any
transposition into multiple loops around a so called micro-kernel. This modular
design---inspired by BLIS---makes HPTT easy to port to different architectures,
by only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).
HPTT also offers an optional autotuning framework---guided by a performance
model---that explores a vast search space of implementations at runtime
(similar to FFTW). Across a wide range of different tensor transpositions and
architectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM
Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields
remarkable speedups over Eigen's tensor transposition implementation. Most
importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)
improves the overall performance of tensor contractions by up to 3.1x.
","['\nPaul Springer\n', '\nTong Su\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1704.04374v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF', 'G.4; D.1.3']",,,[]
BLASFEO: basic linear algebra subroutines for embedded optimization,http://arxiv.org/abs/1704.02457v3,2017-04-08T09:00:22Z,2018-01-07T17:38:05Z,"  BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization. A key difference with respect to existing high-performance
implementations of BLAS is that the computational performance is optimized for
small to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO
comes with three different implementations: a high-performance implementation
aiming at providing the highest performance for matrices fitting in cache, a
reference implementation providing portability and embeddability and optimized
for very small matrices, and a wrapper to standard BLAS and LAPACK providing
high-performance on large matrices. The three implementations of BLASFEO
together provide high-performance dense linear algebra routines for matrices
ranging from very small to large. Compared to both open-source and proprietary
highly-tuned BLAS libraries, for matrices of size up to about one hundred the
high-performance implementation of BLASFEO is about 20-30% faster than the
corresponding level 3 BLAS routines and 2-3 times faster than the corresponding
LAPACK routines.
","['\nGianluca Frison\n', '\nDimitris Kouzoupis\n', '\nTommaso Sartor\n', '\nAndrea Zanelli\n', '\nMoritz Diehl\n']",,"ACM Transactions on Mathematical Software (TOMS): Volume 44 Issue
  4, August 2018",http://dx.doi.org/10.1145/3210754,cs.MS,['cs.MS'],10.1145/3210754,,[]
Strassen's Algorithm for Tensor Contraction,http://arxiv.org/abs/1704.03092v1,2017-04-11T00:37:59Z,2017-04-11T00:37:59Z,"  Tensor contraction (TC) is an important computational kernel widely used in
numerous applications. It is a multi-dimensional generalization of matrix
multiplication (GEMM). While Strassen's algorithm for GEMM is well studied in
theory and practice, extending it to accelerate TC has not been previously
pursued. Thus, we believe this to be the first paper to demonstrate how one can
in practice speed up tensor contraction with Strassen's algorithm. By adopting
a Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can
conceptually view TC as GEMM for a general stride storage, with an implicit
tensor-to-matrix transformation. This insight enables us to tailor a recent
state-of-the-art implementation of Strassen's algorithm to TC, avoiding
explicit transpositions (permutations) and extra workspace, and reducing the
overhead of memory movement that is incurred. Performance benefits are
demonstrated with a performance model as well as in practice on modern single
core, multicore, and distributed memory parallel architectures, achieving up to
1.3x speedup. The resulting implementations can serve as a drop-in replacement
for various applications with significant speedup.
","['\nJianyu Huang\n', '\nDevin A. Matthews\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1704.03092v1,cs.MS,['cs.MS'],,,[]
"Conical: an extended module for computing a numerically satisfactory
  pair of solutions of the differential equation for conical functions",http://arxiv.org/abs/1704.01145v1,2017-04-04T18:28:01Z,2017-04-04T18:28:01Z,"  Conical functions appear in a large number of applications in physics and
engineering. In this paper we describe an extension of our module CONICAL for
the computation of conical functions. Specifically, the module includes now a
routine for computing the function ${{\rm R}}^{m}_{-\frac{1}{2}+i\tau}(x)$, a
real-valued numerically satisfactory companion of the function ${\rm
P}^m_{-\tfrac12+i\tau}(x)$ for $x>1$. In this way, a natural basis for solving
Dirichlet problems bounded by conical domains is provided.
","['\nT. M. Dunster\n', '\nA. Gil\n', '\nJ. Segura\n', '\nN. M. Temme\n']",To appear in Computer Physics Communications,,http://dx.doi.org/10.1016/j.cpc.2017.04.007,cs.MS,"['cs.MS', 'math.CA']",10.1016/j.cpc.2017.04.007,,[]
Faster Base64 Encoding and Decoding Using AVX2 Instructions,http://arxiv.org/abs/1704.00605v5,2017-03-30T19:04:09Z,2018-06-14T21:02:13Z,"  Web developers use base64 formats to include images, fonts, sounds and other
resources directly inside HTML, JavaScript, JSON and XML files. We estimate
that billions of base64 messages are decoded every day. We are motivated to
improve the efficiency of base64 encoding and decoding. Compared to
state-of-the-art implementations, we multiply the speeds of both the encoding
(~10x) and the decoding (~7x). We achieve these good results by using the
single-instruction-multiple-data (SIMD) instructions available on recent Intel
processors (AVX2). Our accelerated software abides by the specification and
reports errors when encountering characters outside of the base64 set. It is
available online as free software under a liberal license.
","['\nWojciech Muła\n', '\nDaniel Lemire\n']",software at https://github.com/lemire/fastbase64,"ACM Transactions on the Web 12 (3), 2018",http://dx.doi.org/10.1145/3132709,cs.MS,"['cs.MS', 'cs.PF']",10.1145/3132709,,[]
"A Unified 2D/3D Large Scale Software Environment for Nonlinear Inverse
  Problems",http://arxiv.org/abs/1703.09268v2,2017-03-27T19:01:10Z,2017-04-04T00:19:08Z,"  Large scale parameter estimation problems are among some of the most
computationally demanding problems in numerical analysis. An academic
researcher's domain-specific knowledge often precludes that of software design,
which results in inversion frameworks that are technically correct, but not
scalable to realistically-sized problems. On the other hand, the computational
demands for realistic problems result in industrial codebases that are geared
solely for high performance, rather than comprehensibility or flexibility. We
propose a new software design for inverse problems constrained by partial
differential equations that bridges the gap between these two seemingly
disparate worlds. A hierarchical and modular design allows a user to delve into
as much detail as she desires, while exploiting high performance primitives at
the lower levels. Our code has the added benefit of actually reflecting the
underlying mathematics of the problem, which lowers the cognitive load on user
using it and reduces the initial startup period before a researcher can be
fully productive. We also introduce a new preconditioner for the 3D Helmholtz
equation that is suitable for fault-tolerant distributed systems. Numerical
experiments on a variety of 2D and 3D test problems demonstrate the
effectiveness of this approach on scaling algorithms from small to large scale
problems with minimal code changes.
","['\nCurt Da Silva\n', '\nFelix J. Herrmann\n']",,,http://arxiv.org/abs/1703.09268v2,cs.MS,"['cs.MS', 'cs.NA']",,,[]
A Domain-Specific Language and Editor for Parallel Particle Methods,http://arxiv.org/abs/1704.00032v2,2017-03-31T19:39:27Z,2017-09-17T13:50:08Z,"  Domain-specific languages (DSLs) are of increasing importance in scientific
high-performance computing to reduce development costs, raise the level of
abstraction and, thus, ease scientific programming. However, designing and
implementing DSLs is not an easy task, as it requires knowledge of the
application domain and experience in language engineering and compilers.
Consequently, many DSLs follow a weak approach using macros or text generators,
which lack many of the features that make a DSL a comfortable for programmers.
Some of these features---e.g., syntax highlighting, type inference, error
reporting, and code completion---are easily provided by language workbenches,
which combine language engineering techniques and tools in a common ecosystem.
In this paper, we present the Parallel Particle-Mesh Environment (PPME), a DSL
and development environment for numerical simulations based on particle methods
and hybrid particle-mesh methods. PPME uses the meta programming system (MPS),
a projectional language workbench. PPME is the successor of the Parallel
Particle-Mesh Language (PPML), a Fortran-based DSL that used conventional
implementation strategies. We analyze and compare both languages and
demonstrate how the programmer's experience can be improved using static
analyses and projectional editing. Furthermore, we present an explicit domain
model for particle abstractions and the first formal type system for particle
methods.
","['\nSven Karol\n', '\nTobias Nett\n', '\nJeronimo Castrillon\n', '\nIvo F. Sbalzarini\n']","Submitted to ACM Transactions on Mathematical Software on Dec. 25,
  2016",,http://arxiv.org/abs/1704.00032v2,cs.MS,"['cs.MS', 'cs.PL', 'cs.SE']",,,[]
A Java library to perform S-expansions of Lie algebras,http://arxiv.org/abs/1703.04036v2,2017-03-11T22:46:19Z,2017-04-11T22:45:00Z,"  The contraction method is a procedure that allows to establish non-trivial
relations between Lie algebras and has had succesful applications in both
mathematics and theoretical physics. This work deals with generalizations of
the contraction procedure with a main focus in the so called S-expansion method
as it includes most of the other generalized contractions. Basically, the
S-exansion combines a Lie algebra $\mathcal{G}$ with a finite abelian semigroup
$S$ in order to define new S-expanded algebras. After giving a description of
the main ingredients used in this paper, we present a Java library that
automatizes the S-expansion procedure. With this computational tool we are able
to represent Lie algebras and semigroups, so we can perform S-expansions of Lie
algebras using arbitrary semigroups. We explain how the library methods has
been constructed and how they work; then we give a set of example programs
aimed to solve different problems. They are presented so that any user can
easily modify them to perform his own calculations, without being necessarily
an expert in Java. Finally, some comments about further developements and
possible new applications are made.
","['\nC. Inostroza\n', '\nI. Kondrashuk\n', '\nN. Merino\n', '\nF. Nadal\n']","54 pages, 2 figures. The full Java library for S-Expansions is
  available at https://github.com/SemigroupExp/Sexpansion/releases/tag/v1.0.0.
  Revised version: three references are added, the code of the programs
  ""loadfile"" and ""loadfromfile"" is removed",,http://arxiv.org/abs/1703.04036v2,cs.MS,"['cs.MS', 'hep-th', 'math-ph', 'math.MP', '22E70, 17B99, 05E15, 83E50']",,,[]
"Coupling parallel adaptive mesh refinement with a nonoverlapping domain
  decomposition solver",http://arxiv.org/abs/1703.06494v1,2017-03-19T19:25:42Z,2017-03-19T19:25:42Z,"  We study the effect of adaptive mesh refinement on a parallel domain
decomposition solver of a linear system of algebraic equations. These concepts
need to be combined within a parallel adaptive finite element software. A
prototype implementation is presented for this purpose. It uses adaptive mesh
refinement with one level of hanging nodes. Two and three-level versions of the
Balancing Domain Decomposition based on Constraints (BDDC) method are used to
solve the arising system of algebraic equations. The basic concepts are
recalled and components necessary for the combination are studied in detail. Of
particular interest is the effect of disconnected subdomains, a typical output
of the employed mesh partitioning based on space-filling curves, on the
convergence and solution time of the BDDC method. It is demonstrated using a
large set of experiments that while both refined meshes and disconnected
subdomains have a negative effect on the convergence of BDDC, the number of
iterations remains acceptable. In addition, scalability of the three-level BDDC
solver remains good on up to a few thousands of processor cores. The largest
presented problem using adaptive mesh refinement has over 10^9 unknowns and is
solved on 2048 cores.
","['\nPavel Kůs\n', '\nJakub Šístek\n']",,"Advances in Engineering Software 110 (2017), 34-54",http://dx.doi.org/10.1016/j.advengsoft.2017.03.012,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65N55', 'G.1.8']",10.1016/j.advengsoft.2017.03.012,,[]
A GPU-based Multi-level Algorithm for Boundary Value Problems,http://arxiv.org/abs/1703.07206v1,2017-03-16T15:35:08Z,2017-03-16T15:35:08Z,"  A novel and scalable geometric multi-level algorithm is presented for the
numerical solution of elliptic partial differential equations, specially
designed to run with high occupancy of streaming processors inside Graphics
Processing Units(GPUs). The algorithm consists of iterative, superposed
operations on a single grid, and it is composed of two simple full-grid
routines: a restriction and a coarsened interpolation-relaxation. The
restriction is used to collect sources using recursive coarsened averages, and
the interpolation-relaxation simultaneously applies coarsened finite-difference
operators and interpolations. The routines are scheduled in a saw-like refining
cycle. Convergence to machine precision is achieved repeating the full cycle
using accumulated residuals and successively collecting the solution. Its total
number of operations scale linearly with the number of nodes. It provides an
attractive fast solver for Boundary Value Problems (BVPs), specially for
simulations running entirely in the GPU. Applications shown in this work
include the deformation of two-dimensional grids, the computation of
three-dimensional streamlines for a singular trifoil-knot vortex and the
calculation of three-dimensional electric potentials in heterogeneous
dielectric media.
","['\nJ. T. Becerra-Sagredo\n', '\nF. Mandujano\n', '\nC. Malaga\n']","14 pages, 7 figures",,http://arxiv.org/abs/1703.07206v1,cs.MS,"['cs.MS', 'cs.NA', 'physics.comp-ph']",,,[]
"ForestClaw: A parallel algorithm for patch-based adaptive mesh
  refinement on a forest of quadtrees",http://arxiv.org/abs/1703.03116v1,2017-03-09T03:01:31Z,2017-03-09T03:01:31Z,"  We describe a parallel, adaptive, multi-block algorithm for explicit
integration of time dependent partial differential equations on two-dimensional
Cartesian grids. The grid layout we consider consists of a nested hierarchy of
fixed size, non-overlapping, logically Cartesian grids stored as leaves in a
quadtree. Dynamic grid refinement and parallel partitioning of the grids is
done through the use of the highly scalable quadtree/octree library p4est.
Because our concept is multi-block, we are able to easily solve on a variety of
geometries including the cubed sphere. In this paper, we pay special attention
to providing details of the parallel ghost-filling algorithm needed to ensure
that both corner and edge ghost regions around each grid hold valid values.
  We have implemented this algorithm in the ForestClaw code using single-grid
solvers from ClawPack, a software package for solving hyperbolic PDEs using
finite volumes methods. We show weak and strong scalability results for scalar
advection problems on two-dimensional manifold domains on 1 to 64Ki MPI
processes, demonstrating neglible regridding overhead.
","['\nDonna Calhoun\n', '\nCarsten Burstedde\n']","26 pages, 12 figures",,http://arxiv.org/abs/1703.03116v1,cs.MS,"['cs.MS', '65M08, 65M50, 68W10, 65Y05']",,,[]
"Small Superposition Dimension and Active Set Construction for
  Multivariate Integration Under Modest Error Demand",http://arxiv.org/abs/1703.00985v1,2017-03-02T23:27:33Z,2017-03-02T23:27:33Z,"  Constructing active sets is a key part of the Multivariate Decomposition
Method. An algorithm for constructing optimal or quasi-optimal active sets is
proposed in the paper. By numerical experiments, it is shown that the new
method can provide sets that are significantly smaller than the sets
constructed by the already existing method. The experiments also show that the
superposition dimension could surprisingly be very small, at most 3, when the
error demand is not smaller than $10^{-3}$ and the weights decay sufficiently
fast.
","['\nAlexander D. Gilbert\n', '\nGreg W. Wasilkowski\n']",,,http://arxiv.org/abs/1703.00985v1,math.NA,"['math.NA', 'cs.MS']",,,[]
Decoupled Block-Wise ILU(k) Preconditioner on GPU,http://arxiv.org/abs/1703.01325v1,2017-03-03T20:08:02Z,2017-03-03T20:08:02Z,"  This research investigates the implementation mechanism of block-wise ILU(k)
preconditioner on GPU. The block-wise ILU(k) algorithm requires both the level
k and the block size to be designed as variables. A decoupled ILU(k) algorithm
consists of a symbolic phase and a factorization phase. In the symbolic phase,
a ILU(k) nonzero pattern is established from the point-wise structure extracted
from a block-wise matrix. In the factorization phase, the block-wise matrix
with a variable block size is factorized into a block lower triangular matrix
and a block upper triangular matrix. And a further diagonal factorization is
required to perform on the block upper triangular matrix for adapting a
parallel triangular solver on GPU.We also present the numerical experiments to
study the preconditioner actions on different k levels and block sizes.
","['\nBo Yang\n', '\nHui Liu\n', '\nHe Zhong\n', '\nZhangxin Chen\n']",14 pages,,http://arxiv.org/abs/1703.01325v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
"Scalar and Tensor Parameters for Importing Tensor Index Notation
  including Einstein Summation Notation",http://arxiv.org/abs/1702.06343v6,2017-02-21T12:05:59Z,2017-08-08T00:35:19Z,"  In this paper, we propose a method for importing tensor index notation,
including Einstein summation notation, into functional programming. This method
involves introducing two types of parameters, i.e, scalar and tensor
parameters, and simplified tensor index rules that do not handle expressions
that are valid only for the Cartesian coordinate system, in which the index can
move up and down freely. An example of such an expression is ""c = A_i B_i"". As
an ordinary function, when a tensor parameter obtains a tensor as an argument,
the function treats the tensor argument as a whole. In contrast, when a scalar
parameter obtains a tensor as an argument, the function is applied to each
component of the tensor. In this paper, we show that introducing these two
types of parameters and our simplified index rules enables us to apply
arbitrary user-defined functions to tensor arguments using index notation
including Einstein summation notation without requiring an additional
description to enable each function to handle tensors.
",['\nSatoshi Egi\n'],Scheme and Functional Programming Workshop 2017,,http://arxiv.org/abs/1702.06343v6,cs.PL,"['cs.PL', 'cs.MS']",,,[]
"General Semiparametric Shared Frailty Model Estimation and Simulation
  with frailtySurv",http://arxiv.org/abs/1702.06407v3,2017-02-21T14:40:29Z,2018-09-05T22:01:05Z,"  The R package frailtySurv for simulating and fitting semi-parametric shared
frailty models is introduced. Package frailtySurv implements semi-parametric
consistent estimators for a variety of frailty distributions, including gamma,
log-normal, inverse Gaussian and power variance function, and provides
consistent estimators of the standard errors of the parameters' estimators. The
parameters' estimators are asymptotically normally distributed, and therefore
statistical inference based on the results of this package, such as hypothesis
testing and confidence intervals, can be performed using the normal
distribution. Extensive simulations demonstrate the flexibility and correct
implementation of the estimator. Two case studies performed with publicly
available datasets demonstrate applicability of the package. In the Diabetic
Retinopathy Study, the onset of blindness is clustered by patient, and in a
large hard drive failure dataset, failure times are thought to be clustered by
the hard drive manufacturer and model.
","['\nJohn V. Monaco\n', '\nMalka Gorfine\n', '\nLi Hsu\n']",,"Monaco, J., Gorfine, M., & Hsu, L. (2018). General Semiparametric
  Shared Frailty Model: Estimation and Simulation with frailtySurv. Journal of
  Statistical Software, 86(4), 1 - 42.
  doi:http://dx.doi.org/10.18637/jss.v086.i04",http://arxiv.org/abs/1702.06407v3,stat.CO,"['stat.CO', 'cs.MS']",,,[]
Enhancing speed and scalability of the ParFlow simulation code,http://arxiv.org/abs/1702.06898v2,2017-02-22T17:12:49Z,2017-10-02T18:51:52Z,"  Regional hydrology studies are often supported by high resolution simulations
of subsurface flow that require expensive and extensive computations. Efficient
usage of the latest high performance parallel computing systems becomes a
necessity. The simulation software ParFlow has been demonstrated to meet this
requirement and shown to have excellent solver scalability for up to 16,384
processes. In the present work we show that the code requires further
enhancements in order to fully take advantage of current petascale machines. We
identify ParFlow's way of parallelization of the computational mesh as a
central bottleneck. We propose to reorganize this subsystem using fast mesh
partition algorithms provided by the parallel adaptive mesh refinement library
p4est. We realize this in a minimally invasive manner by modifying selected
parts of the code to reinterpret the existing mesh data structures. We evaluate
the scaling performance of the modified version of ParFlow, demonstrating good
weak and strong scaling up to 458k cores of the Juqueen supercomputer, and test
an example application at large scale.
","['\nCarsten Burstedde\n', '\nJose A. Fonseca\n', '\nStefan Kollet\n']",The final publication is available at link.springer.com,Computational Geosciences 2017,http://dx.doi.org/10.1007/s10596-017-9696-2,cs.MS,"['cs.MS', 'cs.DC', 'physics.flu-dyn']",10.1007/s10596-017-9696-2,,[]
Simflowny 2: An upgraded platform for scientific modeling and simulation,http://arxiv.org/abs/1702.04715v1,2017-02-14T20:49:22Z,2017-02-14T20:49:22Z,"  Simflowny is an open platform which automatically generates parallel code of
scientific dynamical models for different simulation frameworks. Here we
present major upgrades on this software to support an extended set of families
of models, in particular: i) a new generic family for partial differential
equations, which can include spatial derivatives of any order, ii) a new family
for agent based models to study complex phenomena --either on a spatial domain
or on a graph--. Additionally we introduce a flexible graphical user interface
(GUI) to accommodate these and future families of equations. This paper
describes the new GUI architecture and summarizes the formal representation and
implementation of these new families, providing several validation results.
","['\nA. Arbona\n', '\nB. Miñano\n', '\nA. Rigo\n', '\nC. Bona\n', '\nC. Palenzuela\n', '\nA. Artigues\n', '\nC. Bona-Casas\n', '\nJ. Massó\n']","26 pages, 21 figures",,http://dx.doi.org/10.1016/j.cpc.2018.03.015,cs.MS,['cs.MS'],10.1016/j.cpc.2018.03.015,,[]
gearshifft - The FFT Benchmark Suite for Heterogeneous Platforms,http://arxiv.org/abs/1702.00629v2,2017-02-02T11:41:32Z,2017-07-11T14:37:00Z,"  Fast Fourier Transforms (FFTs) are exploited in a wide variety of fields
ranging from computer science to natural sciences and engineering. With the
rising data production bandwidths of modern FFT applications, judging best
which algorithmic tool to apply, can be vital to any scientific endeavor. As
tailored FFT implementations exist for an ever increasing variety of high
performance computer hardware, choosing the best performing FFT implementation
has strong implications for future hardware purchase decisions, for resources
FFTs consume and for possibly decisive financial and time savings ahead of the
competition. This paper therefor presents gearshifft, which is an open-source
and vendor agnostic benchmark suite to process a wide variety of problem sizes
and types with state-of-the-art FFT implementations (fftw, clfft and cufft).
gearshifft provides a reproducible, unbiased and fair comparison on a wide
variety of hardware to explore which FFT variant is best for a given problem
size.
","['\nPeter Steinbach\n', '\nMatthias Werner\n']",,"High Performance Computing, Theoretical Computer Science and
  General Issues, Vol. 10266, Springer International Publishing. (ISC High
  Performance 2017)",http://dx.doi.org/10.1007/978-3-319-58667-0,cs.PF,"['cs.PF', 'cs.MS']",10.1007/978-3-319-58667-0,,[]
"Manyopt: An Extensible Tool for Mixed, Non-Linear Optimization Through
  SMT Solving",http://arxiv.org/abs/1702.01332v1,2017-02-04T19:49:06Z,2017-02-04T19:49:06Z,"  Optimization of Mixed-Integer Non-Linear Programming (MINLP) supports
important decisions in applications such as Chemical Process Engineering. But
current solvers have limited ability for deductive reasoning or the use of
domain-specific theories, and the management of integrality constraints does
not yet exploit automated reasoning tools such as SMT solvers. This seems to
limit both scalability and reach of such tools in practice. We therefore
present a tool, ManyOpt, for MINLP optimization that enables experimentation
with reduction techniques which transform a MINLP problem to feasibility
checking realized by an SMT solver. ManyOpt is similar to the SAT solver
ManySAT in that it runs a specified number of such reduction techniques in
parallel to get the strongest result on a given MINLP problem. The tool is
implemented in layers, which we may see as features and where reduction
techniques are feature vectors. Some of these features are inspired by known
MINLP techniques whereas others are novel and specific to SMT. Our experimental
results on standard benchmarks demonstrate the benefits of this approach. The
tool supports a variety of SMT solvers and is easily extensible with new
features, courtesy of its layered structure. For example, logical formulas for
deductive reasoning are easily added to constrain further the optimization of a
MINLP problem of interest.
","[""\nAndrea Callia D'Iddio\n"", '\nMichael Huth\n']","17 pages, 3 figures, link to open research data and code available",,http://arxiv.org/abs/1702.01332v1,cs.AI,"['cs.AI', 'cs.MS']",,,[]
"Scalable linear solvers for sparse linear systems from large-scale
  numerical simulations",http://arxiv.org/abs/1701.05913v1,2017-01-20T19:37:44Z,2017-01-20T19:37:44Z,"  This paper presents our work on designing scalable linear solvers for
large-scale reservoir simulations. The main objective is to support
implementation of parallel reservoir simulators on distributed-memory parallel
systems, where MPI (Message Passing Interface) is employed for communications
among computation nodes. Distributed matrix and vector modules are designed,
which are the base of our parallel linear systems. Commonly-used Krylov
subspace linear solvers are implemented, including the restarted GMRES method,
the LGMRES method, and the BiCGSTAB method. It also has an interface to a
parallel algebraic multigrid solver, BoomerAMG from HYPRE. Parallel
general-purpose preconditioners and special preconditioners for reservoir
simulations are also developed. The numerical experiments show that our linear
solvers have excellent scalability using thousands of CPU cores.
","['\nHui Liu\n', '\nZhangxin Chen\n']",arXiv admin note: substantial text overlap with arXiv:1602.05901,,http://arxiv.org/abs/1701.05913v1,cs.MS,['cs.MS'],,,[]
DyNet: The Dynamic Neural Network Toolkit,http://arxiv.org/abs/1701.03980v1,2017-01-15T01:53:23Z,2017-01-15T01:53:23Z,"  We describe DyNet, a toolkit for implementing neural network models based on
dynamic declaration of network structure. In the static declaration strategy
that is used in toolkits like Theano, CNTK, and TensorFlow, the user first
defines a computation graph (a symbolic representation of the computation), and
then examples are fed into an engine that executes this computation and
computes its derivatives. In DyNet's dynamic declaration strategy, computation
graph construction is mostly transparent, being implicitly constructed by
executing procedural code that computes the network outputs, and the user is
free to use different network structures for each input. Dynamic declaration
thus facilitates the implementation of more complicated network architectures,
and DyNet is specifically designed to allow users to implement their models in
a way that is idiomatic in their preferred programming language (C++ or
Python). One challenge with dynamic declaration is that because the symbolic
computation graph is defined anew for every training example, its construction
must have low overhead. To achieve this, DyNet has an optimized C++ backend and
lightweight graph representation. Experiments show that DyNet's speeds are
faster than or comparable with static declaration toolkits, and significantly
faster than Chainer, another dynamic declaration toolkit. DyNet is released
open-source under the Apache 2.0 license and available at
http://github.com/clab/dynet.
","['\nGraham Neubig\n', '\nChris Dyer\n', '\nYoav Goldberg\n', '\nAustin Matthews\n', '\nWaleed Ammar\n', '\nAntonios Anastasopoulos\n', '\nMiguel Ballesteros\n', '\nDavid Chiang\n', '\nDaniel Clothiaux\n', '\nTrevor Cohn\n', '\nKevin Duh\n', '\nManaal Faruqui\n', '\nCynthia Gan\n', '\nDan Garrette\n', '\nYangfeng Ji\n', '\nLingpeng Kong\n', '\nAdhiguna Kuncoro\n', '\nGaurav Kumar\n', '\nChaitanya Malaviya\n', '\nPaul Michel\n', '\nYusuke Oda\n', '\nMatthew Richardson\n', '\nNaomi Saphra\n', '\nSwabha Swayamdipta\n', '\nPengcheng Yin\n']",33 pages,,http://arxiv.org/abs/1701.03980v1,stat.ML,"['stat.ML', 'cs.CL', 'cs.MS']",,,[]
"A task-driven implementation of a simple numerical solver for hyperbolic
  conservation laws",http://arxiv.org/abs/1701.05431v1,2017-01-19T14:29:17Z,2017-01-19T14:29:17Z,"  This article describes the implementation of an all-in-one numerical
procedure within the runtime StarPU. In order to limit the complexity of the
method, for the sake of clarity of the presentation of the non-classical
task-driven programming environnement, we have limited the numerics to first
order in space and time. Results show that the task distribution is efficient
if the tasks are numerous and individually large enough so that the task heap
can be saturated by tasks which computational time covers the task management
overhead. Next, we also see that even though they are mostly faster on graphic
cards, not all the tasks are suitable for GPUs, which brings forward the
importance of the task scheduler. Finally, we look at a more realistic system
of conservation laws with an expensive source term, what allows us to conclude
and open on future works involving higher local arithmetic intensity, by
increasing the order of the numerical method or by enriching the model
(increased number of parameters and therefore equations).
","['\nMohamed Essadki\nIFPEN, FR3487, EM2C\n', '\nJonathan Jung\nLMAP\n', '\nAdam Larat\nFR3487, EM2C\n', '\nMilan Pelletier\nEM2C\n', '\nVincent Perrier\nLMAP\n']",,"ESAIM: Proceedings and Surveys, EDP Sciences, pp.1 - 10 (2017)",http://arxiv.org/abs/1701.05431v1,cs.DC,"['cs.DC', 'cs.MS', 'math.NA']",,,"['IFPEN, FR3487, EM2C', 'LMAP', 'FR3487, EM2C', 'EM2C', 'LMAP']"
"The Unum Number Format: Mathematical Foundations, Implementation and
  Comparison to IEEE 754 Floating-Point Numbers",http://arxiv.org/abs/1701.00722v1,2017-01-02T23:21:43Z,2017-01-02T23:21:43Z,"  This thesis examines a modern concept for machine numbers based on interval
arithmetic called 'Unums' and compares it to IEEE 754 floating-point
arithmetic, evaluating possible uses of this format where floating-point
numbers are inadequate. In the course of this examination, this thesis builds
theoretical foundations for IEEE 754 floating-point numbers, interval
arithmetic based on the projectively extended real numbers and Unums.
",['\nLaslo Hunhold\n'],"95 pages, 7 figures, 14 code listings",,http://arxiv.org/abs/1701.00722v1,cs.NA,"['cs.NA', 'cs.MS']",,,[]
"Efficient Realization of Householder Transform through
  Algorithm-Architecture Co-design for Acceleration of QR Factorization",http://arxiv.org/abs/1612.04470v1,2016-12-14T03:22:44Z,2016-12-14T03:22:44Z,"  We present efficient realization of Householder Transform (HT) based QR
factorization through algorithm-architecture co-design where we achieve
performance improvement of 3-90x in-terms of Gflops/watt over state-of-the-art
multicore, General Purpose Graphics Processing Units (GPGPUs), Field
Programmable Gate Arrays (FPGAs), and ClearSpeed CSX700. Theoretical and
experimental analysis of classical HT is performed for opportunities to exhibit
higher degree of parallelism where parallelism is quantified as a number of
parallel operations per level in the Directed Acyclic Graph (DAG) of the
transform. Based on theoretical analysis of classical HT, an opportunity
re-arrange computations in the classical HT is identified that results in
Modified HT (MHT) where it is shown that MHT exhibits 1.33x times higher
parallelism than classical HT. Experiments in off-the-shelf multicore and
General Purpose Graphics Processing Units (GPGPUs) for HT and MHT suggest that
MHT is capable of achieving slightly better or equal performance compared to
classical HT based QR factorization realizations in the optimized software
packages for Dense Linear Algebra (DLA). We implement MHT on a customized
platform for Dense Linear Algebra (DLA) and show that MHT achieves 1.3x better
performance than native implementation of classical HT on the same accelerator.
For custom realization of HT and MHT based QR factorization, we also identify
macro operations in the DAGs of HT and MHT that are realized on a
Reconfigurable Data-path (RDP). We also observe that due to re-arrangement in
the computations in MHT, custom realization of MHT is capable of achieving 12%
better performance improvement over multicore and GPGPUs than the performance
improvement reported by General Matrix Multiplication (GEMM) over highly tuned
DLA software packages for multicore and GPGPUs which is counter-intuitive.
","['\nFarhad Merchant\n', '\nTarun Vatwani\n', '\nAnupam Chattopadhyay\n', '\nSoumyendu Raha\n', '\nS K Nandy\n', '\nRanjani Narayan\n']",,,http://dx.doi.org/10.1109/TPDS.2018.2803820,cs.PF,"['cs.PF', 'cs.MS']",10.1109/TPDS.2018.2803820,,[]
Parallel Integer Polynomial Multiplication,http://arxiv.org/abs/1612.05778v1,2016-12-17T14:54:52Z,2016-12-17T14:54:52Z,"  We propose a new algorithm for multiplying dense polynomials with integer
coefficients in a parallel fashion, targeting multi-core processor
architectures. Complexity estimates and experimental comparisons demonstrate
the advantages of this new approach.
","['\nChangbo Chen\n', '\nSvyatoslav Covanov\n', '\nFarnam Mansouri\n', '\nMarc Moreno Maza\n', '\nNing Xie\n', '\nYuzhen Xie\n']",,,http://arxiv.org/abs/1612.05778v1,cs.SC,"['cs.SC', 'cs.MS']",,,[]
"The Method of Gauss-Newton to Compute Power Series Solutions of
  Polynomial Homotopies",http://arxiv.org/abs/1612.05313v4,2016-12-15T23:52:29Z,2017-10-26T00:54:59Z,"  We consider the extension of the method of Gauss-Newton from complex
floating-point arithmetic to the field of truncated power series with complex
floating-point coefficients. With linearization we formulate a linear system
where the coefficient matrix is a series with matrix coefficients, and provide
a characterization for when the matrix series is regular based on the algebraic
variety of an augmented system. The structure of the linear system leads to a
block triangular system. In the regular case, solving the linear system is
equivalent to solving a Hermite interpolation problem. We show that this
solution has cost cubic in the problem size. In general, at singular points, we
rely on methods of tropical algebraic geometry to compute Puiseux series. With
a few illustrative examples, we demonstrate the application to polynomial
homotopy continuation.
","['\nNathan Bliss\n', '\nJan Verschelde\n']","21 pages, 9 figures",,http://arxiv.org/abs/1612.05313v4,math.NA,"['math.NA', 'cs.MS', 'cs.SC', 'math.AG']",,,[]
"An efficient hybrid tridiagonal divide-and-conquer algorithm on
  distributed memory architectures",http://arxiv.org/abs/1612.07526v1,2016-12-22T10:19:09Z,2016-12-22T10:19:09Z,"  In this paper, an efficient divide-and-conquer (DC) algorithm is proposed for
the symmetric tridiagonal matrices based on ScaLAPACK and the hierarchically
semiseparable (HSS) matrices. HSS is an important type of rank-structured
matrices.Most time of the DC algorithm is cost by computing the eigenvectors
via the matrix-matrix multiplications (MMM). In our parallel hybrid DC (PHDC)
algorithm, MMM is accelerated by using the HSS matrix techniques when the
intermediate matrix is large. All the HSS algorithms are done via the package
STRUMPACK. PHDC has been tested by using many different matrices. Compared with
the DC implementation in MKL, PHDC can be faster for some matrices with few
deflations when using hundreds of processes. However, the gains decrease as the
number of processes increases. The comparisons of PHDC with ELPA (the
Eigenvalue soLvers for Petascale Applications library) are similar. PHDC is
usually slower than MKL and ELPA when using 300 or more processes on Tianhe-2
supercomputer.
","['\nShengguo Li\n', '\nFrancois-Henry Rouet\n', '\nJie Liu\n', '\nChun Huang\n', '\nXingyu Gao\n', '\nXuebin Chi\n']","20 pages, 7 figures",,http://arxiv.org/abs/1612.07526v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA']",,,[]
"Implementation and evaluation of data-compression algorithms for
  irregular-grid iterative methods on the PEZY-SC processor",http://arxiv.org/abs/1612.00530v1,2016-12-02T01:09:23Z,2016-12-02T01:09:23Z,"  Iterative methods on irregular grids have been used widely in all areas of
comptational science and engineering for solving partial differential equations
with complex geometry. They provide the flexibility to express complex shapes
with relatively low computational cost. However, the direction of the evolution
of high-performance processors in the last two decades have caused serious
degradation of the computational efficiency of iterative methods on irregular
grids, because of relatively low memory bandwidth. Data compression can in
principle reduce the necessary memory memory bandwidth of iterative methods and
thus improve the efficiency. We have implemented several data compression
algorithms on the PEZY-SC processor, using the matrix generated for the HPCG
benchmark as an example. For the SpMV (Sparse Matrix-Vector multiplication)
part of the HPCG benchmark, the best implementation without data compression
achieved 11.6Gflops/chip, close to the theoretical limit due to the memory
bandwidth. Our implementation with data compression has achieved 32.4Gflops.
This is of course rather extreme case, since the grid used in HPCG is
geometrically regular and thus its compression efficiency is very high.
However, in real applications, it is in many cases possible to make a large
part of the grid to have regular geometry, in particular when the resolution is
high. Note that we do not need to change the structure of the program, except
for the addition of the data compression/decompression subroutines. Thus, we
believe the data compression will be very useful way to improve the performance
of many applications which rely on the use of irregular grids.
","['\nNaoki Yoshifuji\n', '\nRyo Sakamoto\n', '\nKeigo Nitadori\n', '\nJun Makino\n']","Talk given at IA3 2016 Sixth Workshop on Irregular Applications:
  Architectures and Algorithms http://hpc.pnl.gov/IA3/IA3/Program.html",,http://arxiv.org/abs/1612.00530v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"An initial investigation of the performance of GPU-based swept
  time-space decomposition",http://arxiv.org/abs/1612.02495v2,2016-12-08T00:19:54Z,2017-01-03T21:27:02Z,"  Simulations of physical phenomena are essential to the expedient design of
precision components in aerospace and other high-tech industries. These
phenomena are often described by mathematical models involving partial
differential equations (PDEs) without exact solutions. Modern design problems
require simulations with a level of resolution that is difficult to achieve in
a reasonable amount of time even in effectively parallelized solvers. Though
the scale of the problem relative to available computing power is the greatest
impediment to accelerating these applications, significant performance gains
can be achieved through careful attention to the details of memory accesses.
Parallelized PDE solvers are subject to a trade-off in memory management: store
the solution for each timestep in abundant, global memory with high access
costs or in a limited, private memory with low access costs that must be passed
between nodes. The GPU implementation of swept time-space decomposition
presented here mitigates this dilemma by using private (shared) memory,
avoiding internode communication, and overwriting unnecessary values. It shows
significant improvement in the execution time of the PDE solvers in one
dimension achieving speedups of 6-2x for large and small problem sizes
respectively compared to naive GPU versions and 7-300x compared to parallel CPU
versions.
","['\nDaniel Magee\n', '\nKyle E Niemeyer\n']",14 pages; submitted to 2017 AIAA SciTech Forum,,http://arxiv.org/abs/1612.02495v2,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS', '65M55 (Primary), 35Q35 (Secondary)', 'G.1.8; G.4; J.2']",,,[]
SimTensor: A synthetic tensor data generator,http://arxiv.org/abs/1612.03772v1,2016-12-09T19:13:03Z,2016-12-09T19:13:03Z,"  SimTensor is a multi-platform, open-source software for generating artificial
tensor data (either with CP/PARAFAC or Tucker structure) for reproducible
research on tensor factorization algorithms. SimTensor is a stand-alone
application based on MATALB. It provides a wide range of facilities for
generating tensor data with various configurations. It comes with a
user-friendly graphical user interface, which enables the user to generate
tensors with complicated settings in an easy way. It also has this facility to
export generated data to universal formats such as CSV and HDF5, which can be
imported via a wide range of programming languages (C, C++, Java, R, Fortran,
MATLAB, Perl, Python, and many more). The most innovative part of SimTensor is
this that can generate temporal tensors with periodic waves, seasonal effects
and streaming structure. it can apply constraints such as non-negativity and
different kinds of sparsity to the data. SimTensor also provides this facility
to simulate different kinds of change-points and inject various types of
anomalies. The source code and binary versions of SimTensor is available for
download in http://www.simtensor.org.
","['\nHadi Fanaee-T\n', '\nJoao Gama\n']",,,http://arxiv.org/abs/1612.03772v1,cs.MS,"['cs.MS', 'math.NA', 'stat.ML']",,,[]
Automating the Last-Mile for High Performance Dense Linear Algebra,http://arxiv.org/abs/1611.08035v2,2016-11-24T00:01:07Z,2017-04-28T15:22:19Z,"  High performance dense linear algebra (DLA) libraries often rely on a general
matrix multiply (Gemm) kernel that is implemented using assembly or with vector
intrinsics. In particular, the real-valued Gemm kernels provide the
overwhelming fraction of performance for the complex-valued Gemm kernels, along
with the entire level-3 BLAS and many of the real and complex LAPACK routines.
Thus,achieving high performance for the Gemm kernel translates into a high
performance linear algebra stack above this kernel. However, it is a monumental
task for a domain expert to manually implement the kernel for every
library-supported architecture. This leads to the belief that the craft of a
Gemm kernel is more dark art than science. It is this premise that drives the
popularity of autotuning with code generation in the domain of DLA.
  This paper, instead, focuses on an analytical approach to code generation of
the Gemm kernel for different architecture, in order to shed light on the
details or voo-doo required for implementing a high performance Gemm kernel. We
distill the implementation of the kernel into an even smaller kernel, an
outer-product, and analytically determine how available SIMD instructions can
be used to compute the outer-product efficiently. We codify this approach into
a system to automatically generate a high performance SIMD implementation of
the Gemm kernel. Experimental results demonstrate that our approach yields
generated kernels with performance that is competitive with kernels implemented
manually or using empirical search.
","['\nRichard Michael Veras\n', '\nTze Meng Low\n', '\nTyler Michael Smith\n', '\nRobert van de Geijn\n', '\nFranz Franchetti\n']",,,http://arxiv.org/abs/1611.08035v2,cs.MS,['cs.MS'],,,[]
Moore: Interval Arithmetic in Modern C++,http://arxiv.org/abs/1611.09567v1,2016-11-29T11:12:06Z,2016-11-29T11:12:06Z,"  We present the library Moore, which implements Interval Arithmetic in modern
C++. This library is based on a new feature in the C++ language called
concepts, which reduces the problems caused by template meta programming, and
leads to a new approach for implementing interval arithmetic libraries in C++.
",['\nWalter F. Mascarenhas\n'],,,http://arxiv.org/abs/1611.09567v1,cs.MS,['cs.MS'],,,[]
"A Metaprogramming and Autotuning Framework for Deploying Deep Learning
  Applications",http://arxiv.org/abs/1611.06945v1,2016-11-21T18:49:23Z,2016-11-21T18:49:23Z,"  In recent years, deep neural networks (DNNs), have yielded strong results on
a wide range of applications. Graphics Processing Units (GPUs) have been one
key enabling factor leading to the current popularity of DNNs. However, despite
increasing hardware flexibility and software programming toolchain maturity,
high efficiency GPU programming remains difficult: it suffers from high
complexity, low productivity, and low portability. GPU vendors such as NVIDIA
have spent enormous effort to write special-purpose DNN libraries. However, on
other hardware targets, especially mobile GPUs, such vendor libraries are not
generally available. Thus, the development of portable, open, high-performance,
energy-efficient GPU code for DNN operations would enable broader deployment of
DNN-based algorithms. Toward this end, this work presents a framework to enable
productive, high-efficiency GPU programming for DNN computations across
hardware platforms and programming models. In particular, the framework
provides specific support for metaprogramming, autotuning, and DNN-tailored
data types. Using our framework, we explore implementing DNN operations on
three different hardware targets: NVIDIA, AMD, and Qualcomm GPUs. On NVIDIA
GPUs, we show both portability between OpenCL and CUDA as well competitive
performance compared to the vendor library. On Qualcomm GPUs, we show that our
framework enables productive development of target-specific optimizations, and
achieves reasonable absolute performance. Finally, On AMD GPUs, we show initial
results that indicate our framework can yield reasonable performance on a new
platform with minimal effort.
","['\nMatthew W. Moskewicz\n', '\nAli Jannesari\n', '\nKurt Keutzer\n']",,,http://arxiv.org/abs/1611.06945v1,cs.NE,"['cs.NE', 'cs.DC', 'cs.MS']",,,[]
Verifying Integer Programming Results,http://arxiv.org/abs/1611.08832v2,2016-11-27T12:27:03Z,2019-01-01T20:39:16Z,"  Software for mixed-integer linear programming can return incorrect results
for a number of reasons, one being the use of inexact floating-point
arithmetic. Even solvers that employ exact arithmetic may suffer from
programming or algorithmic errors, motivating the desire for a way to produce
independently verifiable certificates of claimed results. Due to the complex
nature of state-of-the-art MILP solution algorithms, the ideal form of such a
certificate is not entirely clear. This paper proposes such a certificate
format, illustrating its capabilities and structure through examples. The
certificate format is designed with simplicity in mind and is composed of a
list of statements that can be sequentially verified using a limited number of
simple yet powerful inference rules. We present a supplementary verification
tool for compressing and checking these certificates independently of how they
were created. We report computational results on a selection of mixed-integer
linear programming instances from the literature. To this end, we have extended
the exact rational version of the MIP solver SCIP to produce such certificates.
","['\nKevin K. H. Cheung\n', '\nAmbros Gleixner\n', '\nDaniel E. Steffy\n']","Zuse Institute Berlin, Takustr. 7, 14195 Berlin, November 2016,
  http://nbn-resolving.de/urn:nbn:de:0297-zib-61044","In F. Eisenbrand and J. Koenemann, eds., Integer Programming and
  Combinatorial Optimization: 19th International Conference, IPCO 2017, pages
  148-160, 2017",http://dx.doi.org/10.1007/978-3-319-59250-3_13,math.OC,"['math.OC', 'cs.DM', 'cs.MS', '90C11']",10.1007/978-3-319-59250-3_13,,[]
Efficient Implementation of a Higher-Order Language with Built-In AD,http://arxiv.org/abs/1611.03416v1,2016-11-10T17:40:53Z,2016-11-10T17:40:53Z,"  We show that Automatic Differentiation (AD) operators can be provided in a
dynamic language without sacrificing numeric performance. To achieve this,
general forward and reverse AD functions are added to a simple high-level
dynamic language, and support for them is included in an aggressive optimizing
compiler. Novel technical mechanisms are discussed, which have the ability to
migrate the AD transformations from run-time to compile-time. The resulting
system, although only a research prototype, exhibits startlingly good
performance. In fact, despite the potential inefficiencies entailed by support
of a functional-programming language and a first-class AD operator, performance
is competitive with the fastest available preprocessor-based Fortran AD
systems. On benchmarks involving nested use of the AD operators, it can even
dramatically exceed their performance.
","['\nJeffrey Mark Siskind\n', '\nBarak A. Pearlmutter\n']","Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK",,http://arxiv.org/abs/1611.03416v1,cs.PL,"['cs.PL', 'cs.MS']",,,[]
DiffSharp: An AD Library for .NET Languages,http://arxiv.org/abs/1611.03423v1,2016-11-10T17:50:06Z,2016-11-10T17:50:06Z,"  DiffSharp is an algorithmic differentiation or automatic differentiation (AD)
library for the .NET ecosystem, which is targeted by the C# and F# languages,
among others. The library has been designed with machine learning applications
in mind, allowing very succinct implementations of models and optimization
routines. DiffSharp is implemented in F# and exposes forward and reverse AD
operators as general nestable higher-order functions, usable by any .NET
language. It provides high-performance linear algebra primitives---scalars,
vectors, and matrices, with a generalization to tensors underway---that are
fully supported by all the AD operators, and which use a BLAS/LAPACK backend
via the highly optimized OpenBLAS library. DiffSharp currently uses operator
overloading, but we are developing a transformation-based version of the
library using F#'s ""code quotation"" metaprogramming facility. Work on a
CUDA-based GPU backend is also underway.
","['\nAtılım Güneş Baydin\n', '\nBarak A. Pearlmutter\n', '\nJeffrey Mark Siskind\n']","Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK",,http://arxiv.org/abs/1611.03423v1,cs.MS,"['cs.MS', 'cs.LG']",,,[]
Binomial Checkpointing for Arbitrary Programs with No User Annotation,http://arxiv.org/abs/1611.03410v1,2016-11-10T17:29:24Z,2016-11-10T17:29:24Z,"  Heretofore, automatic checkpointing at procedure-call boundaries, to reduce
the space complexity of reverse mode, has been provided by systems like
Tapenade. However, binomial checkpointing, or treeverse, has only been provided
in Automatic Differentiation (AD) systems in special cases, e.g., through
user-provided pragmas on DO loops in Tapenade, or as the nested taping
mechanism in adol-c for time integration processes, which requires that user
code be refactored. We present a framework for applying binomial checkpointing
to arbitrary code with no special annotation or refactoring required. This is
accomplished by applying binomial checkpointing directly to a program trace.
This trace is produced by a general-purpose checkpointing mechanism that is
orthogonal to AD.
","['\nJeffrey Mark Siskind\n', '\nBarak A. Pearlmutter\n']","Extended abstract presented at the AD 2016 Conference, Sep 2016,
  Oxford UK",,http://arxiv.org/abs/1611.03410v1,cs.PL,"['cs.PL', 'cs.LG', 'cs.MS']",,,[]
"A Case for Malleable Thread-Level Linear Algebra Libraries: The LU
  Factorization with Partial Pivoting",http://arxiv.org/abs/1611.06365v1,2016-11-19T13:55:29Z,2016-11-19T13:55:29Z,"  We propose two novel techniques for overcoming load-imbalance encountered
when implementing so-called look-ahead mechanisms in relevant dense matrix
factorizations for the solution of linear systems. Both techniques target the
scenario where two thread teams are created/activated during the factorization,
with each team in charge of performing an independent task/branch of execution.
The first technique promotes worker sharing (WS) between the two tasks,
allowing the threads of the task that completes first to be reallocated for use
by the costlier task. The second technique allows a fast task to alert the
slower task of completion, enforcing the early termination (ET) of the second
task, and a smooth transition of the factorization procedure into the next
iteration.
  The two mechanisms are instantiated via a new malleable thread-level
implementation of the Basic Linear Algebra Subprograms (BLAS), and their
benefits are illustrated via an implementation of the LU factorization with
partial pivoting enhanced with look-ahead. Concretely, our experimental results
on a six core Intel-Xeon processor show the benefits of combining WS+ET,
reporting competitive performance in comparison with a task-parallel
runtime-based solution.
","['\nSandra Catalán\n', '\nJosé R. Herrero\n', '\nEnrique S. Quintana-Ortí\n', '\nRafael Rodríguez-Sánchez\n', '\nRobert van de Geijn\n']",,,http://arxiv.org/abs/1611.06365v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
Bidiagonalization with Parallel Tiled Algorithms,http://arxiv.org/abs/1611.06892v1,2016-11-18T15:11:48Z,2016-11-18T15:11:48Z,"  We consider algorithms for going from a ""full"" matrix to a condensed ""band
bidiagonal"" form using orthogonal transformations. We use the framework of
""algorithms by tiles"". Within this framework, we study: (i) the tiled
bidiagonalization algorithm BiDiag, which is a tiled version of the standard
scalar bidiagonalization algorithm; and (ii) the R-bidiagonalization algorithm
R-BiDiag, which is a tiled version of the algorithm which consists in first
performing the QR factorization of the initial matrix, then performing the
band-bidiagonalization of the R-factor. For both bidiagonalization algorithms
BiDiag and R-BiDiag, we use four main types of reduction trees, namely FlatTS,
FlatTT, Greedy, and a newly introduced auto-adaptive tree, Auto. We provide a
study of critical path lengths for these tiled algorithms, which shows that (i)
R-BiDiag has a shorter critical path length than BiDiag for tall and skinny
matrices, and (ii) Greedy based schemes are much better than earlier proposed
variants with unbounded resources. We provide experiments on a single multicore
node, and on a few multicore nodes of a parallel distributed shared-memory
system, to show the superiority of the new algorithms on a variety of matrix
sizes, matrix shapes and core counts.
","['\nMathieu Faverge\n', '\nJulien Langou\n', '\nYves Robert\n', '\nJack Dongarra\n']",,,http://arxiv.org/abs/1611.06892v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'math.RA']",,,[]
dMath: Distributed Linear Algebra for DL,http://arxiv.org/abs/1611.07819v1,2016-11-19T00:24:12Z,2016-11-19T00:24:12Z,"  The paper presents a parallel math library, dMath, that demonstrates leading
scaling when using intranode, internode, and hybrid-parallelism for deep
learning (DL). dMath provides easy-to-use distributed primitives and a variety
of domain-specific algorithms including matrix multiplication, convolutions,
and others allowing for rapid development of scalable applications like deep
neural networks (DNNs). Persistent data stored in GPU memory and advanced
memory management techniques avoid costly transfers between host and device.
dMath delivers performance, portability, and productivity to its specific
domain of support.
","['\nSteven Eliuk\n', '\nCameron Upright\n', '\nHars Vardhan\n', '\nStephen Walsh\n', '\nTrevor Gale\n']",5 pages. arXiv admin note: text overlap with arXiv:1604.01416,,http://arxiv.org/abs/1611.07819v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NE']",,,[]
Generating Families of Practical Fast Matrix Multiplication Algorithms,http://arxiv.org/abs/1611.01120v1,2016-11-03T18:27:00Z,2016-11-03T18:27:00Z,"  Matrix multiplication (GEMM) is a core operation to numerous scientific
applications. Traditional implementations of Strassen-like fast matrix
multiplication (FMM) algorithms often do not perform well except for very large
matrix sizes, due to the increased cost of memory movement, which is
particularly noticeable for non-square matrices. Such implementations also
require considerable workspace and modifications to the standard BLAS
interface. We propose a code generator framework to automatically implement a
large family of FMM algorithms suitable for multiplications of arbitrary matrix
sizes and shapes. By representing FMM with a triple of matrices [U,V,W] that
capture the linear combinations of submatrices that are formed, we can use the
Kronecker product to define a multi-level representation of Strassen-like
algorithms. Incorporating the matrix additions that must be performed for
Strassen-like algorithms into the inherent packing and micro-kernel operations
inside GEMM avoids extra workspace and reduces the cost of memory movement.
Adopting the same loop structures as high-performance GEMM implementations
allows parallelization of all FMM algorithms with simple but efficient data
parallelism without the overhead of task parallelism. We present a simple
performance model for general FMM algorithms and compare actual performance of
20+ FMM algorithms to modeled predictions. Our implementations demonstrate a
performance benefit over conventional GEMM on single core and multi-core
systems. This study shows that Strassen-like fast matrix multiplication can be
incorporated into libraries for practical use.
","['\nJianyu Huang\n', '\nLeslie Rice\n', '\nDevin A. Matthews\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1611.01120v1,cs.MS,['cs.MS'],,,[]
"GFA: Exploratory Analysis of Multiple Data Sources with Group Factor
  Analysis",http://arxiv.org/abs/1611.01534v1,2016-11-03T10:09:13Z,2016-11-03T10:09:13Z,"  The R package GFA provides a full pipeline for factor analysis of multiple
data sources that are represented as matrices with co-occurring samples. It
allows learning dependencies between subsets of the data sources, decomposed
into latent factors. The package also implements sparse priors for the
factorization, providing interpretable biclusters of the multi-source data
","['\nEemeli Leppäaho\n', '\nMuhammad Ammad-ud-din\n', '\nSamuel Kaski\n']",,,http://arxiv.org/abs/1611.01534v1,cs.MS,['cs.MS'],,,[]
Anisotropic mesh adaptation in Firedrake with PETSc DMPlex,http://arxiv.org/abs/1610.09874v1,2016-10-31T11:34:29Z,2016-10-31T11:34:29Z,"  Despite decades of research in this area, mesh adaptation capabilities are
still rarely found in numerical simulation software. We postulate that the
primary reason for this is lack of usability. Integrating mesh adaptation into
existing software is difficult as non-trivial operators, such as error metrics
and interpolation operators, are required, and integrating available adaptive
remeshers is not straightforward. Our approach presented here is to first
integrate Pragmatic, an anisotropic mesh adaptation library, into DMPlex, a
PETSc object that manages unstructured meshes and their interactions with
PETSc's solvers and I/O routines. As PETSc is already widely used, this will
make anisotropic mesh adaptation available to a much larger community. As a
demonstration of this we describe the integration of anisotropic mesh
adaptation into Firedrake, an automated Finite Element based system for the
portable solution of partial differential equations which already uses PETSc
solvers and I/O via DMPlex. We present a proof of concept of this integration
with a three-dimensional advection test case.
","['\nNicolas Barral\n', '\nMatthew G. Knepley\n', '\nMichael Lange\n', '\nMatthew D. Piggott\n', '\nGerard J. Gorman\n']","5 page, 2 figures, Proceedings of the 25th International Meshing
  Roundtable, ed. Steve Owen and Hang Si, 2016",,http://arxiv.org/abs/1610.09874v1,math.NA,"['math.NA', 'cs.CG', 'cs.MS']",,,[]
emgr - The Empirical Gramian Framework,http://arxiv.org/abs/1611.00675v2,2016-11-02T16:39:06Z,2018-05-28T11:47:47Z,"  System Gramian matrices are a well-known encoding for properties of
input-output systems such as controllability, observability or minimality.
These so-called system Gramians were developed in linear system theory for
applications such as model order reduction of control systems. Empirical
Gramian are an extension to the system Gramians for parametric and nonlinear
systems as well as a data-driven method of computation. The empirical Gramian
framework - emgr - implements the empirical Gramians in a uniform and
configurable manner, with applications such as Gramian-based (nonlinear) model
reduction, decentralized control, sensitivity analysis, parameter
identification and combined state and parameter reduction.
",['\nChristian Himpe\n'],,"Algorithms 11(7): 91, 2018",http://dx.doi.org/10.3390/a11070091,cs.MS,"['cs.MS', 'cs.SY', 'math.OC', '93A15, 93B20, 93C10', 'G.4']",10.3390/a11070091,,[]
"GPU-Based Parallel Integration of Large Numbers of Independent ODE
  Systems",http://arxiv.org/abs/1611.02274v1,2016-11-06T18:11:16Z,2016-11-06T18:11:16Z,"  The task of integrating a large number of independent ODE systems arises in
various scientific and engineering areas. For nonstiff systems, common explicit
integration algorithms can be used on GPUs, where individual GPU threads
concurrently integrate independent ODEs with different initial conditions or
parameters. One example is the fifth-order adaptive Runge-Kutta-Cash-Karp
(RKCK) algorithm. In the case of stiff ODEs, standard explicit algorithms
require impractically small time-step sizes for stability reasons, and implicit
algorithms are therefore commonly used instead to allow larger time steps and
reduce the computational expense. However, typical high-order implicit
algorithms based on backwards differentiation formulae (e.g., VODE, LSODE)
involve complex logical flow that causes severe thread divergence when
implemented on GPUs, limiting the performance. Therefore, alternate algorithms
are needed. A GPU-based Runge-Kutta-Chebyshev (RKC) algorithm can handle
moderate levels of stiffness and performs significantly faster than not only an
equivalent CPU version but also a CPU-based implicit algorithm (VODE) based on
results shown in the literature. In this chapter, we present the mathematical
background, implementation details, and source code for the RKCK and RKC
algorithms for use integrating large numbers of independent systems of ODEs on
GPUs. In addition, brief performance comparisons are shown for each algorithm,
demonstrating the potential benefit of moving to GPU-based ODE integrators.
","['\nKyle E Niemeyer\n', '\nChih-Jen Sung\n']","21 pages, 2 figures","Numerical Computations with GPUs, Ch. 8 (2014) 159-182. V
  Kindratenko (Ed.)",http://dx.doi.org/10.1007/978-3-319-06548-9_8,cs.MS,"['cs.MS', 'cs.DC', 'physics.comp-ph', '80A32 (Primary) 80A30, 65L04, 65L06 (Secondary)']",10.1007/978-3-319-06548-9_8,,[]
"Accelerating BLAS on Custom Architecture through Algorithm-Architecture
  Co-design",http://arxiv.org/abs/1610.06385v5,2016-10-20T12:46:07Z,2016-11-27T14:11:36Z,"  Basic Linear Algebra Subprograms (BLAS) play key role in high performance and
scientific computing applications. Experimentally, yesteryear multicore and
General Purpose Graphics Processing Units (GPGPUs) are capable of achieving up
to 15 to 57% of the theoretical peak performance at 65W to 240W respectively
for compute bound operations like Double/Single Precision General Matrix
Multiplication (XGEMM). For bandwidth bound operations like Single/Double
precision Matrix-vector Multiplication (XGEMV) the performance is merely 5 to
7% of the theoretical peak performance in multicores and GPGPUs respectively.
Achieving performance in BLAS requires moving away from conventional wisdom and
evolving towards customized accelerator tailored for BLAS through
algorithm-architecture co-design. In this paper, we present acceleration of
Level-1 (vector operations), Level-2 (matrix-vector operations), and Level-3
(matrix-matrix operations) BLAS through algorithm architecture co-design on a
Coarse-grained Reconfigurable Architecture (CGRA). We choose REDEFINE CGRA as a
platform for our experiments since REDEFINE can be adapted to support domain of
interest through tailor-made Custom Function Units (CFUs). For efficient
sequential realization of BLAS, we present design of a Processing Element (PE)
and perform micro-architectural enhancements in the PE to achieve up-to 74% of
the theoretical peak performance of PE in DGEMM, 40% in DGEMV and 20% in double
precision inner product (DDOT). We attach this PE to REDEFINE CGRA as a CFU and
show the scalability of our solution. Finally, we show performance improvement
of 3-140x in PE over commercially available Intel micro-architectures,
ClearSpeed CSX700, FPGA, and Nvidia GPGPUs.
","['\nFarhad Merchant\n', '\nTarun Vatwani\n', '\nAnupam Chattopadhyay\n', '\nSoumyendu Raha\n', '\nS K Nandy\n', '\nRanjani Narayan\n']",,,http://arxiv.org/abs/1610.06385v5,cs.AR,"['cs.AR', 'cs.MS']",,,[]
IB2d: a Python and MATLAB implementation of the immersed boundary method,http://arxiv.org/abs/1610.07944v1,2016-10-24T16:15:40Z,2016-10-24T16:15:40Z,"  The development of fluid-structure interaction (FSI) software involves
trade-offs between ease of use, generality, performance, and cost. Typically
there are large learning curves when using low-level software to model the
interaction of an elastic structure immersed in a uniform density fluid. Many
existing codes are not publicly available, and the commercial software that
exists usually requires expensive licenses and may not be as robust or allow
the necessary flexibility that in house codes can provide. We present an open
source immersed boundary software package, IB2d, with full implementations in
both MATLAB and Python, that is capable of running a vast range of biomechanics
models and is accessible to scientists who have experience in high-level
programming environments. IB2d contains multiple options for constructing
material properties of the fiber structure, as well as the advection-diffusion
of a chemical gradient, muscle mechanics models, and artificial forcing to
drive boundaries with a preferred motion.
","['\nNicholas A. Battista\n', '\nW. Christopher Strickland\n', '\nLaura A. Miller\n']","34 pages, 24 figures",,http://dx.doi.org/10.1088/1748-3190/aa5e08,physics.flu-dyn,"['physics.flu-dyn', 'cs.MS', '76Z99, 74F10, 92C10, 92C99, 76D99']",10.1088/1748-3190/aa5e08,,[]
Large Scale Parallel Computations in R through Elemental,http://arxiv.org/abs/1610.07310v1,2016-10-24T07:30:27Z,2016-10-24T07:30:27Z,"  Even though in recent years the scale of statistical analysis problems has
increased tremendously, many statistical software tools are still limited to
single-node computations. However, statistical analyses are largely based on
dense linear algebra operations, which have been deeply studied, optimized and
parallelized in the high-performance-computing community. To make
high-performance distributed computations available for statistical analysis,
and thus enable large scale statistical computations, we introduce RElem, an
open source package that integrates the distributed dense linear algebra
library Elemental into R. While on the one hand, RElem provides direct wrappers
of Elemental's routines, on the other hand, it overloads various operators and
functions to provide an entirely native R experience for distributed
computations. We showcase how simple it is to port existing R programs to Relem
and demonstrate that Relem indeed allows to scale beyond the single-node
limitation of R with the full performance of Elemental without any overhead.
","['\nRodrigo Canales\n', '\nElmar Peise\n', '\nPaolo Bientinesi\n']","16 pages, 5 figures",,http://arxiv.org/abs/1610.07310v1,stat.CO,"['stat.CO', 'cs.DC', 'cs.MS', 'G.3; G.4; D.1.3']",,,[]
The Reverse Cuthill-McKee Algorithm in Distributed-Memory,http://arxiv.org/abs/1610.08128v1,2016-10-26T00:26:44Z,2016-10-26T00:26:44Z,"  Ordering vertices of a graph is key to minimize fill-in and data structure
size in sparse direct solvers, maximize locality in iterative solvers, and
improve performance in graph algorithms. Except for naturally parallelizable
ordering methods such as nested dissection, many important ordering methods
have not been efficiently mapped to distributed-memory architectures. In this
paper, we present the first-ever distributed-memory implementation of the
reverse Cuthill-McKee (RCM) algorithm for reducing the profile of a sparse
matrix. Our parallelization uses a two-dimensional sparse matrix decomposition.
We achieve high performance by decomposing the problem into a small number of
primitives and utilizing optimized implementations of these primitives. Our
implementation shows strong scaling up to 1024 cores for smaller matrices and
up to 4096 cores for larger matrices.
","['\nAriful Azad\n', '\nMathias Jacquelin\n', '\nAydin Buluc\n', '\nEsmond G. Ng\n']",,,http://arxiv.org/abs/1610.08128v1,cs.DC,"['cs.DC', 'cs.MS', 'math.NA']",,,[]
The Probabilistic Model Checker Storm (Extended Abstract),http://arxiv.org/abs/1610.08713v1,2016-10-27T11:14:53Z,2016-10-27T11:14:53Z,"  We present a new probabilistic model checker Storm. Using state-of-the-art
libraries, we aim for both high performance and versatility. This extended
abstract gives a brief overview of the features of Storm.
","['\nChristian Dehnert\n', '\nSebastian Junges\n', '\nJoost-Pieter Katoen\n', '\nMatthias Volk\n']",Extended abstract,,http://arxiv.org/abs/1610.08713v1,cs.SE,"['cs.SE', 'cs.LO', 'cs.MS']",,,[]
"Performance evaluation of explicit finite difference algorithms with
  varying amounts of computational and memory intensity",http://arxiv.org/abs/1610.09146v1,2016-10-28T09:45:31Z,2016-10-28T09:45:31Z,"  Future architectures designed to deliver exascale performance motivate the
need for novel algorithmic changes in order to fully exploit their
capabilities. In this paper, the performance of several numerical algorithms,
characterised by varying degrees of memory and computational intensity, are
evaluated in the context of finite difference methods for fluid dynamics
problems. It is shown that, by storing some of the evaluated derivatives as
single thread- or process-local variables in memory, or recomputing the
derivatives on-the-fly, a speed-up of ~2 can be obtained compared to
traditional algorithms that store all derivatives in global arrays.
","['\nSatya P. Jammy\n', '\nChristian T. Jacobs\n', '\nNeil D. Sandham\n']","Author accepted version. Accepted for publication in Journal of
  Computational Science on 27 October 2016",,http://arxiv.org/abs/1610.09146v1,cs.DS,"['cs.DS', 'cs.DC', 'cs.MS', 'physics.comp-ph', 'physics.flu-dyn']",,,[]
Numerical Implicitization,http://arxiv.org/abs/1610.03034v2,2016-10-10T19:14:59Z,2019-04-13T01:50:06Z,"  We present the $\textit{NumericalImplicitization}$ package for
$\textit{Macaulay2}$, which allows for user-friendly computation of the
invariants of the image of a polynomial map, such as dimension, degree, and
Hilbert function values. This package relies on methods of numerical algebraic
geometry, including homotopy continuation and monodromy.
","['\nJustin Chen\n', '\nJoe Kileel\n']","5 pages, various improvements, to appear in Journal of Software for
  Algebra and Geometry",J. Softw. Alg. Geom. 9 (2019) 55-63,http://dx.doi.org/10.2140/jsag.2019.9.55,math.AG,"['math.AG', 'cs.MS', 'math.AC', '14-04, 14Q99, 65H10, 65H20']",10.2140/jsag.2019.9.55,,[]
"Efficient Random Sampling -- Parallel, Vectorized, Cache-Efficient, and
  Online",http://arxiv.org/abs/1610.05141v2,2016-10-17T14:38:02Z,2019-11-15T15:27:42Z,"  We consider the problem of sampling $n$ numbers from the range
$\{1,\ldots,N\}$ without replacement on modern architectures. The main result
is a simple divide-and-conquer scheme that makes sequential algorithms more
cache efficient and leads to a parallel algorithm running in expected time
$\mathcal{O}(n/p+\log p)$ on $p$ processors, i.e., scales to massively parallel
machines even for moderate values of $n$. The amount of communication between
the processors is very small (at most $\mathcal{O}(\log p)$) and independent of
the sample size. We also discuss modifications needed for load balancing,
online sampling, sampling with replacement, Bernoulli sampling, and
vectorization on SIMD units or GPUs.
","['\nPeter Sanders\n', '\nSebastian Lamm\n', '\nLorenz Hübschle-Schneider\n', '\nEmanuel Schrade\n', '\nCarsten Dachsbacher\n']",,"ACM Transactions on Mathematical Software (TOMS), Volume 44, Issue
  3 (April 2018), pages 29:1-29:14",http://dx.doi.org/10.1145/3157734,cs.DS,"['cs.DS', 'cs.DC', 'cs.MS', 'G.4; G.3; G.2']",10.1145/3157734,,[]
"OpenMP, OpenMP/MPI, and CUDA/MPI C programs for solving the
  time-dependent dipolar Gross-Pitaevskii equation",http://arxiv.org/abs/1610.05329v2,2016-10-17T20:07:09Z,2022-08-01T21:00:03Z,"  We present new versions of the previously published C and CUDA programs for
solving the dipolar Gross-Pitaevskii equation in one, two, and three spatial
dimensions, which calculate stationary and non-stationary solutions by
propagation in imaginary or real time. Presented programs are improved and
parallelized versions of previous programs, divided into three packages
according to the type of parallelization. First package contains improved and
threaded version of sequential C programs using OpenMP. Second package
additionally parallelizes three-dimensional variants of the OpenMP programs
using MPI, allowing them to be run on distributed-memory systems. Finally,
previous three-dimensional CUDA-parallelized programs are further parallelized
using MPI, similarly as the OpenMP programs. We also present speedup test
results obtained using new versions of programs in comparison with the previous
sequential C and parallel CUDA programs. The improvements to the sequential
version yield a speedup of 1.1 to 1.9, depending on the program. OpenMP
parallelization yields further speedup of 2 to 12 on a 16-core workstation,
while OpenMP/MPI version demonstrates a speedup of 11.5 to 16.5 on a computer
cluster with 32 nodes used. CUDA/MPI version shows a speedup of 9 to 10 on a
computer cluster with 32 nodes.
","['\nVladimir Loncar\n', '\nLuis E. Young-S.\n', '\nSrdjan Skrbic\n', '\nPaulsamy Muruganandam\n', '\nSadhan K. Adhikari\n', '\nAntun Balaz\n']","8 pages, 6 figures; to download the programs, click ""Other formats""
  and download the source",Comput. Phys. Commun. 209 (2016) 190,http://dx.doi.org/10.1016/j.cpc.2016.07.029,cond-mat.quant-gas,"['cond-mat.quant-gas', 'cs.MS', 'nlin.PS', 'physics.comp-ph']",10.1016/j.cpc.2016.07.029,,[]
Solving polynomial systems via homotopy continuation and monodromy,http://arxiv.org/abs/1609.08722v4,2016-09-28T01:48:48Z,2018-04-16T20:01:02Z,"  We study methods for finding the solution set of a generic system in a family
of polynomial systems with parametric coefficients. We present a framework for
describing monodromy based solvers in terms of decorated graphs. Under the
theoretical assumption that monodromy actions are generated uniformly, we show
that the expected number of homotopy paths tracked by an algorithm following
this framework is linear in the number of solutions. We demonstrate that our
software implementation is competitive with the existing state-of-the-art
methods implemented in other software packages.
","['\nTimothy Duff\n', '\nCvetelina Hill\n', '\nAnders Jensen\n', '\nKisun Lee\n', '\nAnton Leykin\n', '\nJeff Sommars\n']",30 pages,,http://arxiv.org/abs/1609.08722v4,math.AG,"['math.AG', 'cs.MS', '14Q99, 65H99, 68W20']",,,[]
Benchmarking the Graphulo Processing Framework,http://arxiv.org/abs/1609.08642v1,2016-09-27T20:09:03Z,2016-09-27T20:09:03Z,"  Graph algorithms have wide applicablity to a variety of domains and are often
used on massive datasets. Recent standardization efforts such as the GraphBLAS
specify a set of key computational kernels that hardware and software
developers can adhere to. Graphulo is a processing framework that enables
GraphBLAS kernels in the Apache Accumulo database. In our previous work, we
have demonstrated a core Graphulo operation called \textit{TableMult} that
performs large-scale multiplication operations of database tables. In this
article, we present the results of scaling the Graphulo engine to larger
problems and scalablity when a greater number of resources is used.
Specifically, we present two experiments that demonstrate Graphulo scaling
performance is linear with the number of available resources. The first
experiment demonstrates cluster processing rates through Graphulo's TableMult
operator on two large graphs, scaled between $2^{17}$ and $2^{19}$ vertices.
The second experiment uses TableMult to extract a random set of rows from a
large graph ($2^{19}$ nodes) to simulate a cued graph analytic. These
benchmarking results are of relevance to Graphulo users who wish to apply
Graphulo to their graph problems.
","['\nTimothy Weale\n', '\nVijay Gadepally\n', '\nDylan Hutchison\n', '\nJeremy Kepner\n']","5 pages, 4 figures, IEEE High Performance Extreme Computing (HPEC)
  conference 2016",,http://dx.doi.org/10.1109/HPEC.2016.7761640,cs.DB,"['cs.DB', 'cs.MS', 'cs.PF']",10.1109/HPEC.2016.7761640,,[]
"GPU Acceleration of Hermite Methods for the Simulation of Wave
  Propagation",http://arxiv.org/abs/1609.09841v1,2016-09-30T18:02:54Z,2016-09-30T18:02:54Z,"  The Hermite methods of Goodrich, Hagstrom, and Lorenz (2006) use Hermite
interpolation to construct high order numerical methods for hyperbolic initial
value problems. The structure of the method has several favorable features for
parallel computing. In this work, we propose algorithms that take advantage of
the many-core architecture of Graphics Processing Units. The algorithm exploits
the compact stencil of Hermite methods and uses data structures that allow for
efficient data load and stores. Additionally the highly localized evolution
operator of Hermite methods allows us to combine multi-stage time-stepping
methods within the new algorithms incurring minimal accesses of global memory.
Using a scalar linear wave equation, we study the algorithm by considering
Hermite interpolation and evolution as individual kernels and alternatively
combined them into a monolithic kernel. For both approaches we demonstrate
strategies to increase performance. Our numerical experiments show that
although a two kernel approach allows for better performance on the hardware, a
monolithic kernel can offer a comparable time to solution with less global
memory usage.
","['\nArturo Vargas\n', '\nJesse Chan\n', '\nThomas Hagstrom\n', '\nTimothy Warburton\n']",12 pages. Submitted to ICOSAHOM 2016 proceedings,,http://arxiv.org/abs/1609.09841v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Density Estimation with Distribution Element Trees,http://arxiv.org/abs/1610.00345v2,2016-10-02T20:07:28Z,2017-05-03T07:08:16Z,"  The estimation of probability densities based on available data is a central
task in many statistical applications. Especially in the case of large
ensembles with many samples or high-dimensional sample spaces, computationally
efficient methods are needed. We propose a new method that is based on a
decomposition of the unknown distribution in terms of so-called distribution
elements (DEs). These elements enable an adaptive and hierarchical
discretization of the sample space with small or large elements in regions with
smoothly or highly variable densities, respectively. The novel refinement
strategy that we propose is based on statistical goodness-of-fit and pair-wise
(as an approximation to mutual) independence tests that evaluate the local
approximation of the distribution in terms of DEs. The capabilities of our new
method are inspected based on several examples of different dimensionality and
successfully compared with other state-of-the-art density estimators.
",['\nDaniel W. Meyer\n'],,,http://dx.doi.org/10.1007/s11222-017-9751-9,stat.ME,"['stat.ME', 'cs.MS', 'stat.CO', 'stat.ML', '62G07', 'G.3']",10.1007/s11222-017-9751-9,,[]
A Computer Algebra Package for Polynomial Sequence Recognition,http://arxiv.org/abs/1609.07301v1,2016-09-23T10:31:39Z,2016-09-23T10:31:39Z,"  The software package developed in the MS thesis research implements functions
for the intelligent guessing of polynomial sequence formulas based on
user-defined expected sequence factors of the input coefficients. We present a
specialized hybrid approach to finding exact representations for polynomial
sequences that is motivated by the need for an automated procedures to discover
the precise forms of these sums based on user guidance, or intuition, as to
special sequence factors present in the formulas. In particular, the package
combines the user input on the expected special sequence factors in the
polynomial coefficient formulas with calls to the existing functions as
subroutines that then process formulas for the remaining sequence terms already
recognized by these packages.
  The factorization-based approach to polynomial sequence recognition is unique
to this package and allows the search functions to find expressions for
polynomial sums involving Stirling numbers and other special triangular
sequences that are not readily handled by other software packages. In contrast
to many other sequence recognition and summation software, the package not
provide an explicit proof, or certificate, for the correctness of these
sequence formulas -- only computationally guided educated guesses at a complete
identity generating the sequence over all $n$. The thesis contains a number of
concrete, working examples of the package that are intended to both demonstrate
its usage and to document its current sequence recognition capabilities.
",['\nMaxie D. Schmidt\n'],,,http://arxiv.org/abs/1609.07301v1,math.CO,"['math.CO', 'cs.MS']",,,[]
"Scaling betweenness centrality using communication-efficient sparse
  matrix multiplication",http://arxiv.org/abs/1609.07008v2,2016-09-22T15:01:30Z,2017-08-09T15:30:00Z,"  Betweenness centrality (BC) is a crucial graph problem that measures the
significance of a vertex by the number of shortest paths leading through it. We
propose Maximal Frontier Betweenness Centrality (MFBC): a succinct BC algorithm
based on novel sparse matrix multiplication routines that performs a factor of
$p^{1/3}$ less communication on $p$ processors than the best known
alternatives, for graphs with $n$ vertices and average degree $k=n/p^{2/3}$. We
formulate, implement, and prove the correctness of MFBC for weighted graphs by
leveraging monoids instead of semirings, which enables a surprisingly succinct
formulation. MFBC scales well for both extremely sparse and relatively dense
graphs. It automatically searches a space of distributed data decompositions
and sparse matrix multiplication algorithms for the most advantageous
configuration. The MFBC implementation outperforms the well-known CombBLAS
library by up to 8x and shows more robust performance. Our design methodology
is readily extensible to other graph problems.
","['\nEdgar Solomonik\n', '\nMaciej Besta\n', '\nFlavio Vella\n', '\nTorsten Hoefler\n']",,,http://arxiv.org/abs/1609.07008v2,cs.DC,"['cs.DC', 'cs.DM', 'cs.MS', 'G.1.0; G.2.2']",,,[]
Devito: Towards a generic Finite Difference DSL using Symbolic Python,http://arxiv.org/abs/1609.03361v1,2016-09-12T12:15:36Z,2016-09-12T12:15:36Z,"  Domain specific languages (DSL) have been used in a variety of fields to
express complex scientific problems in a concise manner and provide automated
performance optimization for a range of computational architectures. As such
DSLs provide a powerful mechanism to speed up scientific Python computation
that goes beyond traditional vectorization and pre-compilation approaches,
while allowing domain scientists to build applications within the comforts of
the Python software ecosystem. In this paper we present Devito, a new finite
difference DSL that provides optimized stencil computation from high-level
problem specifications based on symbolic Python expressions. We demonstrate
Devito's symbolic API and performance advantages over traditional Python
acceleration methods before highlighting its use in the scientific context of
seismic inversion problems.
","['\nMichael Lange\n', '\nNavjot Kukreja\n', '\nMathias Louboutin\n', '\nFabio Luporini\n', '\nFelippe Vieira\n', '\nVincenzo Pandolfo\n', '\nPaulius Velesko\n', '\nPaulius Kazakas\n', '\nGerard Gorman\n']",pyHPC 2016 conference submission,,http://arxiv.org/abs/1609.03361v1,cs.MS,"['cs.MS', 'cs.PF']",,,[]
GTApprox: surrogate modeling for industrial design,http://arxiv.org/abs/1609.01088v1,2016-09-05T10:41:14Z,2016-09-05T10:41:14Z,"  We describe GTApprox - a new tool for medium-scale surrogate modeling in
industrial design. Compared to existing software, GTApprox brings several
innovations: a few novel approximation algorithms, several advanced methods of
automated model selection, novel options in the form of hints. We demonstrate
the efficiency of GTApprox on a large collection of test problems. In addition,
we describe several applications of GTApprox to real engineering problems.
","['\nMikhail Belyaev\n', '\nEvgeny Burnaev\n', '\nErmek Kapushev\n', '\nMaxim Panov\n', '\nPavel Prikhodko\n', '\nDmitry Vetrov\n', '\nDmitry Yarotsky\n']","31 pages, 11 figures",,http://arxiv.org/abs/1609.01088v1,cs.MS,"['cs.MS', 'cs.CE', 'stat.ML']",,,[]
"OpenSBLI: A framework for the automated derivation and parallel
  execution of finite difference solvers on a range of computer architectures",http://arxiv.org/abs/1609.01277v2,2016-09-05T10:11:31Z,2016-11-14T17:17:48Z,"  Exascale computing will feature novel and potentially disruptive hardware
architectures. Exploiting these to their full potential is non-trivial.
Numerical modelling frameworks involving finite difference methods are
currently limited by the 'static' nature of the hand-coded discretisation
schemes and repeatedly may have to be re-written to run efficiently on new
hardware. In contrast, OpenSBLI uses code generation to derive the model's code
from a high-level specification. Users focus on the equations to solve, whilst
not concerning themselves with the detailed implementation. Source-to-source
translation is used to tailor the code and enable its execution on a variety of
hardware.
","['\nChristian T. Jacobs\n', '\nSatya P. Jammy\n', '\nNeil D. Sandham\n']","Author accepted version, with a small amendment: the link in the
  ""Code Availability"" section has been updated, and now refers to the OpenSBLI
  source code repository on GitHub. Accepted for publication in the Journal of
  Computational Science on 8 November 2016",Journal of Computational Science 18 (2017) 12-23,http://dx.doi.org/10.1016/j.jocs.2016.11.001,cs.MS,"['cs.MS', 'cs.SC', 'cs.SE', 'physics.comp-ph']",10.1016/j.jocs.2016.11.001,,[]
Nanosurveyor: a framework for real-time data processing,http://arxiv.org/abs/1609.02831v1,2016-09-09T15:21:19Z,2016-09-09T15:21:19Z,"  Scientists are drawn to synchrotrons and accelerator based light sources
because of their brightness, coherence and flux. The rate of improvement in
brightness and detector technology has outpaced Moore's law growth seen for
computers, networks, and storage, and is enabling novel observations and
discoveries with faster frame rates, larger fields of view, higher resolution,
and higher dimensionality. Here we present an integrated software/algorithmic
framework designed to capitalize on high throughput experiments, and describe
the streamlined processing pipeline of ptychography data analysis. The pipeline
provides throughput, compression, and resolution as well as rapid feedback to
the microscope operators.
","['\nBenedikt J. Daurer\n', '\nHari Krishnan\n', '\nTalita Perciano\n', '\nFilipe R. N. C. Maia\n', '\nDavid A. Shapiro\n', '\nJames A. Sethian\n', '\nStefano Marchesini\n']","8 pages, 3 figures",Advanced Structural and Chemical Imaging 2017 3:7,http://dx.doi.org/10.1186/s40679-017-0039-0,physics.ins-det,"['physics.ins-det', 'cs.MS', 'physics.data-an']",10.1186/s40679-017-0039-0,,[]
Math-Aware Search Engines: Physics Applications and Overview,http://arxiv.org/abs/1609.03457v1,2016-09-08T06:07:23Z,2016-09-08T06:07:23Z,"  Search engines for equations now exist, which return results matching the
query's mathematical meaning or structural presentation. Operating over
scientific papers, online encyclopedias, and math discussion forums, their
content includes physics, math, and other sciences. They enable physicists to
avoid jargon and more easily target mathematical content within and across
disciplines. As a natural extension of keyword-based search, they open up a new
world for discovering both exact and approximate mathematical solutions;
physical systems' analogues and alternative models; and physics' patterns.
  This review presents the existing math-aware search engines, discusses
methods for maximizing their search success, and overviews their math-matching
capabilities. Proposed applications to physics are also given, to contribute
towards developers' and physicists' exploration of the newly available search
horizons.
",['\nDeanna C. Pineau\nUniversity of Waterloo\n'],"Full abstract in PDF; 66 pages, 4 tables, 8 figures",,http://arxiv.org/abs/1609.03457v1,cs.DL,"['cs.DL', 'cs.IR', 'cs.MS', 'math.HO', 'H.3.3; H.3.5; H.3.7']",,,['University of Waterloo']
BLISlab: A Sandbox for Optimizing GEMM,http://arxiv.org/abs/1609.00076v1,2016-09-01T01:11:48Z,2016-09-01T01:11:48Z,"  Matrix-matrix multiplication is a fundamental operation of great importance
to scientific computing and, increasingly, machine learning. It is a simple
enough concept to be introduced in a typical high school algebra course yet in
practice important enough that its implementation on computers continues to be
an active research topic. This note describes a set of exercises that use this
operation to illustrate how high performance can be attained on modern CPUs
with hierarchical memories (multiple caches). It does so by building on the
insights that underly the BLAS-like Library Instantiation Software (BLIS)
framework by exposing a simplified ""sandbox"" that mimics the implementation in
BLIS. As such, it also becomes a vehicle for the ""crowd sourcing"" of the
optimization of BLIS. We call this set of exercises BLISlab.
","['\nJianyu Huang\n', '\nRobert A. van de Geijn\n']",FLAME Working Note #80,,http://arxiv.org/abs/1609.00076v1,cs.MS,['cs.MS'],,,[]
Devito: automated fast finite difference computation,http://arxiv.org/abs/1608.08658v2,2016-08-30T21:05:21Z,2016-10-10T13:15:52Z,"  Domain specific languages have successfully been used in a variety of fields
to cleanly express scientific problems as well as to simplify implementation
and performance opti- mization on different computer architectures. Although a
large number of stencil languages are available, finite differ- ence domain
specific languages have proved challenging to design because most practical use
cases require additional features that fall outside the finite difference
abstraction. Inspired by the complexity of real-world seismic imaging problems,
we introduce Devito, a domain specific language in which high level equations
are expressed using symbolic expressions from the SymPy package. Complex
equations are automatically manipulated, optimized, and translated into highly
optimized C code that aims to perform compa- rably or better than hand-tuned
code. All this is transpar- ent to users, who only see concise symbolic
mathematical expressions.
","['\nNavjot Kukreja\n', '\nMathias Louboutin\n', '\nFelippe Vieira\n', '\nFabio Luporini\n', '\nMichael Lange\n', '\nGerard Gorman\n']",Accepted at WolfHPC 2016,,http://arxiv.org/abs/1608.08658v2,cs.MS,"['cs.MS', 'cs.PF']",,,[]
Efficient computation of Laguerre polynomials,http://arxiv.org/abs/1609.00829v1,2016-09-03T13:59:43Z,2016-09-03T13:59:43Z,"  An efficient algorithm and a Fortran 90 module (LaguerrePol) for computing
Laguerre polynomials $L^{(\alpha)}_n(z)$ are presented. The standard three-term
recurrence relation satisfied by the polynomials and different types of
asymptotic expansions valid for $n$ large and $\alpha$ small, are used
depending on the parameter region.
  Based on tests of contiguous relations in the parameter $\alpha$ and the
degree $n$ satisfied by the polynomials, we claim that a relative accuracy
close or better than $10^{-12}$ can be obtained using the module LaguerrePol
for computing the functions $L^{(\alpha)}_n(z)$ in the parameter range $z \ge
0$, $-1 < \alpha \le 5$, $n \ge 0$.
","['\nA. Gil\n', '\nJ. Segura\n', '\nN. M. Temme\n']",To appear in Computer Physics Communications,,http://dx.doi.org/10.1016/j.cpc.2016.09.002,cs.NA,"['cs.NA', 'cs.MS', 'math.CA']",10.1016/j.cpc.2016.09.002,,[]
"Containers for portable, productive and performant scientific computing",http://arxiv.org/abs/1608.07573v2,2016-08-26T11:58:00Z,2016-11-03T18:21:56Z,"  Containers are an emerging technology that hold promise for improving
productivity and code portability in scientific computing. We examine Linux
container technology for the distribution of a non-trivial scientific computing
software stack and its execution on a spectrum of platforms from laptop
computers through to high performance computing (HPC) systems. We show on a
workstation and a leadership-class HPC system that when deployed appropriately
there are no performance penalties running scientific programs inside
containers. For Python code run on large parallel computers, the run time is
reduced inside a container due to faster library imports. The software
distribution approach and data that we present will help developers and users
decide on whether container technology is appropriate for them. We also provide
guidance for the vendors of HPC systems that rely on proprietary libraries for
performance on what they can do to make containers work seamlessly and without
performance penalty.
","['\nJack S. Hale\n', '\nLizao Li\n', '\nChris N. Richardson\n', '\nGarth N. Wells\n']",,,http://dx.doi.org/10.1109/MCSE.2017.2421459,cs.DC,"['cs.DC', 'cs.MS', 'cs.SE', '68N99, 68U0', 'D.2.7; D.2.8; D.2.9']",10.1109/MCSE.2017.2421459,,[]
"Computation of the incomplete gamma function for negative values of the
  argument",http://arxiv.org/abs/1608.04152v1,2016-08-14T23:17:03Z,2016-08-14T23:17:03Z,"  An algorithm for computing the incomplete gamma function $\gamma^*(a,z)$ for
real values of the parameter $a$ and negative real values of the argument $z$
is presented. The algorithm combines the use of series expansions,
Poincar\'e-type expansions, uniform asymptotic expansions and recurrence
relations, depending on the parameter region. A relative accuracy $\sim
10^{-13}$ in the parameter region $(a,z) \in [-500,\,500] \times [-500,\,0)$
can be obtained when computing the function $\gamma^*(a,z)$ with the Fortran 90
module IncgamNEG implementing the algorithm.
","['\nA. Gil\n', '\nD. Ruiz-Antolín\n', '\nJ. Segura\n', '\nN. M. Temme\n']",To appear in ACM Trans. Math. Softw,,http://arxiv.org/abs/1608.04152v1,cs.MS,"['cs.MS', 'math.CA']",,,[]
"A Functional Package for Automatic Solution of Ordinary Differential
  Equations with Spectral Methods",http://arxiv.org/abs/1608.04815v3,2016-08-17T00:06:48Z,2016-11-04T08:20:36Z,"  We present a Python module named PyCheb, to solve the ordinary differential
equations by using spectral collocation method. PyCheb incorporates
discretization using Chebyshev points, barycentric interpolation and iterate
methods. With this Python module, users can initialize the ODEsolver class by
passing attributes, including the both sides of a given differential equation,
boundary conditions, and the number of Chebyshev points, which can also be
generated automatically by the ideal precision, to the constructor of ODEsolver
class. Then, the instance of the ODEsolver class can be used to automatically
determine the resolution of the differential equation as well as generate the
graph of the high-precision approximate solution. (If you have any questions,
please send me an email and I will reply ASAP.
e-mail:shaohui_liu@qq.com/2013141482143@stu.scu.edu.cn)
","['\nShaohui Liu\n', '\nTianshi Wang\n', '\nYouran Zhang\n']","This paper has been withdrawn by the author due to some serious
  mistakes made in the context since it is for the first time for all the
  authors to do independent research. Hope that we can fix all the problems
  soon and come back with some better results",,http://arxiv.org/abs/1608.04815v3,cs.MS,"['cs.MS', 'math.NA']",,,[]
Julia Implementation of the Dynamic Distributed Dimensional Data Model,http://arxiv.org/abs/1608.04041v1,2016-08-14T00:58:41Z,2016-08-14T00:58:41Z,"  Julia is a new language for writing data analysis programs that are easy to
implement and run at high performance. Similarly, the Dynamic Distributed
Dimensional Data Model (D4M) aims to clarify data analysis operations while
retaining strong performance. D4M accomplishes these goals through a
composable, unified data model on associative arrays. In this work, we present
an implementation of D4M in Julia and describe how it enables and facilitates
data analysis. Several experiments showcase scalable performance in our new
Julia version as compared to the original Matlab implementation.
","['\nAlexander Chen\n', '\nAlan Edelman\n', '\nJeremy Kepner\n', '\nVijay Gadepally\n', '\nDylan Hutchison\n']","7 pages, 16 figures, IEEE HPEC 2016",,http://dx.doi.org/10.1109/HPEC.2016.7761626,cs.MS,"['cs.MS', 'cs.PF', 'cs.PL']",10.1109/HPEC.2016.7761626,,[]
Randomized Matrix Decompositions using R,http://arxiv.org/abs/1608.02148v5,2016-08-06T19:47:48Z,2019-11-26T23:33:14Z,"  Matrix decompositions are fundamental tools in the area of applied
mathematics, statistical computing, and machine learning. In particular,
low-rank matrix decompositions are vital, and widely used for data analysis,
dimensionality reduction, and data compression. Massive datasets, however, pose
a computational challenge for traditional algorithms, placing significant
constraints on both memory and processing power. Recently, the powerful concept
of randomness has been introduced as a strategy to ease the computational load.
The essential idea of probabilistic algorithms is to employ some amount of
randomness in order to derive a smaller matrix from a high-dimensional data
matrix. The smaller matrix is then used to compute the desired low-rank
approximation. Such algorithms are shown to be computationally efficient for
approximating matrices with low-rank structure. We present the \proglang{R}
package rsvd, and provide a tutorial introduction to randomized matrix
decompositions. Specifically, randomized routines for the singular value
decomposition, (robust) principal component analysis, interpolative
decomposition, and CUR decomposition are discussed. Several examples
demonstrate the routines, and show the computational advantage over other
methods implemented in R.
","['\nN. Benjamin Erichson\n', '\nSergey Voronin\n', '\nSteven L. Brunton\n', '\nJ. Nathan Kutz\n']",,"Journal of Statistical Software. May 2019, Volume 89, Issue 11",http://dx.doi.org/10.18637/jss.v089.i11,stat.CO,"['stat.CO', 'cs.MS', 'stat.ME']",10.18637/jss.v089.i11,,[]
An Asynchronous Task-based Fan-Both Sparse Cholesky Solver,http://arxiv.org/abs/1608.00044v2,2016-07-29T22:37:07Z,2016-08-23T04:04:56Z,"  Systems of linear equations arise at the heart of many scientific and
engineering applications. Many of these linear systems are sparse; i.e., most
of the elements in the coefficient matrix are zero. Direct methods based on
matrix factorizations are sometimes needed to ensure accurate solutions. For
example, accurate solution of sparse linear systems is needed in shift-invert
Lanczos to compute interior eigenvalues. The performance and resource usage of
sparse matrix factorizations are critical to time-to-solution and maximum
problem size solvable on a given platform. In many applications, the
coefficient matrices are symmetric, and exploiting symmetry will reduce both
the amount of work and storage cost required for factorization. When the
factorization is performed on large-scale distributed memory platforms,
communication cost is critical to the performance of the algorithm. At the same
time, network topologies have become increasingly complex, so that modern
platforms exhibit a high level of performance variability. This makes
scheduling of computations an intricate and performance-critical task. In this
paper, we investigate the use of an asynchronous task paradigm, one-sided
communication and dynamic scheduling in implementing sparse Cholesky
factorization (symPACK) on large-scale distributed memory platforms. Our solver
symPACK relies on efficient and flexible communication primitives provided by
the UPC++ library. Performance evaluation shows good scalability and that
symPACK outperforms state-of-the-art parallel distributed memory factorization
packages, validating our approach on practical cases.
","['\nMathias Jacquelin\n', '\nYili Zheng\n', '\nEsmond Ng\n', '\nKatherine Yelick\n']",,,http://arxiv.org/abs/1608.00044v2,cs.MS,['cs.MS'],,,[]
Forward-Mode Automatic Differentiation in Julia,http://arxiv.org/abs/1607.07892v1,2016-07-26T20:32:29Z,2016-07-26T20:32:29Z,"  We present ForwardDiff, a Julia package for forward-mode automatic
differentiation (AD) featuring performance competitive with low-level languages
like C++. Unlike recently developed AD tools in other popular high-level
languages such as Python and MATLAB, ForwardDiff takes advantage of
just-in-time (JIT) compilation to transparently recompile AD-unaware user code,
enabling efficient support for higher-order differentiation and differentiation
using custom number types (including complex numbers). For gradient and
Jacobian calculations, ForwardDiff provides a variant of vector-forward mode
that avoids expensive heap allocation and makes better use of memory bandwidth
than traditional vector mode. In our numerical experiments, we demonstrate that
for nontrivially large dimensions, ForwardDiff's gradient computations can be
faster than a reverse-mode implementation from the Python-based autograd
package. We also illustrate how ForwardDiff is used effectively within JuMP, a
modeling language for optimization. According to our usage statistics, 41
unique repositories on GitHub depend on ForwardDiff, with users from diverse
fields such as astronomy, optimization, finite element analysis, and
statistics.
  This document is an extended abstract that has been accepted for presentation
at the AD2016 7th International Conference on Algorithmic Differentiation.
","['\nJarrett Revels\n', '\nMiles Lubin\n', '\nTheodore Papamarkou\n']",4 pages,,http://arxiv.org/abs/1607.07892v1,cs.MS,['cs.MS'],,,[]
TRIOT: Faster tensor manipulation in C++11,http://arxiv.org/abs/1608.00099v2,2016-07-30T10:40:29Z,2017-03-31T22:40:34Z,"  [abridged] Context: Multidimensional arrays are used by many different
algorithms. As such, indexing and broadcasting complex operations over
multidimensional arrays are ubiquitous tasks and can be performance limiting.
Inquiry: Simultaneously indexing two or more multidimensional arrays with
different shapes (e.g., copying data from one tensor to another larger, zero
padded tensor in anticipation of a convolution) is difficult to do efficiently:
Hard-coded nested for loops in C, Fortran, and Go cannot be applied when the
dimension of a tensor is unknown at compile time. Likewise, boost::multi_array
cannot be used unless the dimensions of the array are known at compile time,
and the style of implementation restricts the user from using the index tuple
inside a vectorized operation (as would be required to compute an expected
value of a multidimensional distribution). On the other hand, iteration methods
that do not require the dimensionality or shape to be known at compile time
(e.g., incrementing and applying carry operations to index tuples or remapping
integer indices in the flat array), can be substantially slower than hard-coded
nested for loops. ... Importance: Manipulation of multidimensional arrays is a
common task in software, especially in high performance numerical methods. This
paper proposes a novel way to leverage template recursion to iterate over and
apply operations to multidimensional arrays, and then demonstrates the superior
performance and flexibility of operations that can be achieved using this new
approach.
","['\nFlorian Heyl\n', '\nOliver Serang\n']",,"The Art, Science, and Engineering of Programming, 2017, Vol. 1,
  Issue 2, Article 6",http://dx.doi.org/10.22152/programming-journal.org/2017/1/6,cs.MS,"['cs.MS', 'cs.PL']",10.22152/programming-journal.org/2017/1/6,,[]
"An exact, cache-localized algorithm for the sub-quadratic convolution of
  hypercubes",http://arxiv.org/abs/1608.00206v1,2016-07-31T10:22:40Z,2016-07-31T10:22:40Z,"  Fast multidimensional convolution can be performed naively in quadratic time
and can often be performed more efficiently via the Fourier transform; however,
when the dimensionality is large, these algorithms become more challenging. A
method is proposed for performing exact hypercube convolution in sub-quadratic
time. The method outperforms FFTPACK, called via numpy, and FFTW, called via
pyfftw) for hypercube convolution. Embeddings in hypercubes can be paired with
sub-quadratic hypercube convolution method to construct sub-quadratic
algorithms for variants of vector convolution.
",['\nOliver Serang\n'],,,http://arxiv.org/abs/1608.00206v1,cs.CG,"['cs.CG', 'cs.MS']",,,[]
"R package imputeTestbench to compare imputations methods for univariate
  time series",http://arxiv.org/abs/1608.00476v2,2016-08-01T15:54:26Z,2016-11-04T05:55:32Z,"  This paper describes the R package imputeTestbench that provides a testbench
for comparing imputation methods for missing data in univariate time series.
The imputeTestbench package can be used to simulate the amount and type of
missing data in a complete dataset and compare filled data using different
imputation methods. The user has the option to simulate missing data by
removing observations completely at random or in blocks of different sizes.
Several default imputation methods are included with the package, including
historical means, linear interpolation, and last observation carried forward.
The testbench is not limited to the default functions and users can add or
remove additional methods using a simple two-step process. The testbench
compares the actual missing and imputed data for each method with different
error metrics, including RMSE, MAE, and MAPE. Alternative error metrics can
also be supplied by the user. The simplicity of use and significant reduction
in time to compare imputation methods for missing data in univariate time
series is a significant advantage of the package. This paper provides an
overview of the core functions, including a demonstration with examples.
","['\nNeeraj Bokde\n', '\nKishore Kulat\n', '\nMarcus W Beck\n', '\nGualberto Asencio-Cortés\n']",,,http://dx.doi.org/10.32614/RJ-2018-024,stat.ME,"['stat.ME', 'cs.MS']",10.32614/RJ-2018-024,,[]
Generalized Sampling in Julia,http://arxiv.org/abs/1607.04091v2,2016-07-14T11:26:28Z,2016-11-23T09:58:28Z,"  Generalized sampling is a numerically stable framework for obtaining
reconstructions of signals in different bases and frames from their samples. In
this paper, we will introduce a carefully documented toolbox for performing
generalized sampling in Julia. Julia is a new language for technical computing
with focus on performance, which is ideally suited to handle the large size
problems often encountered in generalized sampling. The toolbox provides
specialized solutions for the setup of Fourier bases and wavelets. The
performance of the toolbox is compared to existing implementations of
generalized sampling in MATLAB.
","['\nRobert Dahl Jacobsen\n', '\nMorten Nielsen\n', '\nMorten Grud Rasmussen\n']",,,http://arxiv.org/abs/1607.04091v2,cs.MS,['cs.MS'],,,[]
Finite Element Integration with Quadrature on the GPU,http://arxiv.org/abs/1607.04245v1,2016-07-14T18:53:48Z,2016-07-14T18:53:48Z,"  We present a novel, quadrature-based finite element integration method for
low-order elements on GPUs, using a pattern we call \textit{thread
transposition} to avoid reductions while vectorizing aggressively. On the
NVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s
and a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element
integration on first-order discretization of the Laplacian operator with
variable coefficients in two dimensions, and over 400 GF/s in three dimensions.
From our performance model we find that this corresponds to 90\% of our
measured achievable bandwidth peak of 310 GF/s. Further experimental results
also match the predicted performance when used with double precision (120 GF/s
in two dimensions, 150 GF/s in three dimensions). Results obtained for the
linear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s
and 60 GF/s in three dimensions) also demonstrate the applicability of our
method to vector-valued partial differential equations.
","['\nMatthew G. Knepley\n', '\nKarl Rupp\n', '\nAndy R. Terrel\n']","14 pages, 6 figures",,http://arxiv.org/abs/1607.04245v1,cs.MS,"['cs.MS', 'G.4; G.1.8']",,,[]
Composing Scalable Nonlinear Algebraic Solvers,http://arxiv.org/abs/1607.04254v1,2016-07-14T19:21:43Z,2016-07-14T19:21:43Z,"  Most efficient linear solvers use composable algorithmic components, with the
most common model being the combination of a Krylov accelerator and one or more
preconditioners. A similar set of concepts may be used for nonlinear algebraic
systems, where nonlinear composition of different nonlinear solvers may
significantly improve the time to solution. We describe the basic concepts of
nonlinear composition and preconditioning and present a number of solvers
applicable to nonlinear partial differential equations. We have developed a
software framework in order to easily explore the possible combinations of
solvers. We show that the performance gains from using composed solvers can be
substantial compared with gains from standard Newton-Krylov methods.
","['\nPeter R. Brune\n', '\nMatthew G. Knepley\n', '\nBarry F. Smith\n', '\nXuemin Tu\n']","29 pages, 14 figures, 13 tables","SIAM Review 57(4), 535-565, 2015",http://dx.doi.org/10.1137/130936725,math.NA,"['math.NA', 'cs.MS', '65F08, 65Y05, 65Y20, 68W10']",10.1137/130936725,,[]
"Optimized Automatic Code Generation for Geometric Algebra Based
  Algorithms with Ray Tracing Application",http://arxiv.org/abs/1607.04767v1,2016-07-16T16:54:39Z,2016-07-16T16:54:39Z,"  Automatic code generation for low-dimensional geometric algorithms is capable
of producing efficient low-level software code through a high-level geometric
domain specific language. Geometric Algebra (GA) is one of the most suitable
algebraic systems for being the base for such code generator. This work
presents an attempt at realizing such idea in practice. A novel GA-based
geometric code generator, called GMac, is proposed. Comparisons to similar
GA-based code generators are provided. The possibility of fully benefiting from
the symbolic power of GA while obtaining good performance and maintainability
of software implementations is illustrated through a ray tracing application.
",['\nAhmad Hosney Awad Eid\n'],"PhD Thesis, 2010, 249 pages",,http://arxiv.org/abs/1607.04767v1,cs.MS,"['cs.MS', 'cs.GR']",,,[]
"Scheduling massively parallel multigrid for multilevel Monte Carlo
  methods",http://arxiv.org/abs/1607.03252v1,2016-07-12T07:47:45Z,2016-07-12T07:47:45Z,"  The computational complexity of naive, sampling-based uncertainty
quantification for 3D partial differential equations is extremely high.
Multilevel approaches, such as multilevel Monte Carlo (MLMC), can reduce the
complexity significantly, but to exploit them fully in a parallel environment,
sophisticated scheduling strategies are needed. Often fast algorithms that are
executed in parallel are essential to compute fine level samples in 3D, whereas
to compute individual coarse level samples only moderate numbers of processors
can be employed efficiently. We make use of multiple instances of a parallel
multigrid solver combined with advanced load balancing techniques. In
particular, we optimize the concurrent execution across the three layers of the
MLMC method: parallelization across levels, across samples, and across the
spatial grid. The overall efficiency and performance of these methods will be
analyzed. Here the scalability window of the multigrid solver is revealed as
being essential, i.e., the property that the solution can be computed with a
range of process numbers while maintaining good parallel efficiency. We
evaluate the new scheduling strategies in a series of numerical tests, and
conclude the paper demonstrating large 3D scaling experiments.
","['\nBjörn Gmeiner\n', '\nDaniel Drzisga\n', '\nUlrich Ruede\n', '\nRobert Scheichl\n', '\nBarbara Wohlmuth\n']",,,http://arxiv.org/abs/1607.03252v1,cs.CE,"['cs.CE', 'cs.DC', 'cs.MS', 'cs.NA', 'math.NA', 'G.1.8']",,,[]
Using the pyMIC Offload Module in PyFR,http://arxiv.org/abs/1607.00844v1,2016-07-01T18:59:11Z,2016-07-01T18:59:11Z,"  PyFR is an open-source high-order accurate computational fluid dynamics
solver for unstructured grids. It is designed to efficiently solve the
compressible Navier-Stokes equations on a range of hardware platforms,
including GPUs and CPUs. In this paper we will describe how the Python Offload
Infrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used
to enable PyFR to run with near native performance on the Intel Xeon Phi
coprocessor. We will introduce the architecture of both pyMIC and PyFR and
present a variety of examples showcasing the capabilities of pyMIC. Further, we
will also compare the contrast pyMIC to other approaches including native
execution and OpenCL. The process of adding support for pyMIC into PyFR will be
described in detail. Benchmark results show that for a standard cylinder flow
problem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double
precision floating point performance; for a 1.85 times improvement over PyFR
with C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.
","['\nMichael Klemm\n', '\nFreddie Witherden\n', '\nPeter Vincent\n']",,,http://arxiv.org/abs/1607.00844v1,cs.MS,['cs.MS'],,,[]
"Massively parallel implementation in Python of a pseudo-spectral DNS
  code for turbulent flows",http://arxiv.org/abs/1607.00850v1,2016-07-01T19:05:11Z,2016-07-01T19:05:11Z,"  Direct Numerical Simulations (DNS) of the Navier Stokes equations is a
valuable research tool in fluid dynamics, but there are very few publicly
available codes and, due to heavy number crunching, codes are usually written
in low-level languages. In this work a \textasciitilde{}100 line standard
scientific Python DNS code is described that nearly matches the performance of
pure C for thousands of processors and billions of unknowns. With optimization
of a few routines in Cython, it is found to match the performance of a more or
less identical solver implemented from scratch in C++. Keys to the efficiency
of the solver are the mesh decomposition and three dimensional FFT routines,
implemented directly in Python using MPI, wrapped through MPI for Python, and a
serial FFT module (both numpy.fft or pyFFTW may be used). Two popular
decomposition strategies, slab and pencil, have been implemented and tested.
",['\nMikael Mortensen\n'],,,http://arxiv.org/abs/1607.00850v1,cs.MS,['cs.MS'],,,[]
Design of a high-performance GEMM-like Tensor-Tensor Multiplication,http://arxiv.org/abs/1607.00145v3,2016-07-01T08:13:50Z,2017-11-07T08:21:02Z,"  We present ""GEMM-like Tensor-Tensor multiplication"" (GETT), a novel approach
to tensor contractions that mirrors the design of a high-performance general
matrix-matrix multiplication (GEMM). The critical insight behind GETT is the
identification of three index sets, involved in the tensor contraction, which
enable us to systematically reduce an arbitrary tensor contraction to loops
around a highly tuned ""macro-kernel"". This macro-kernel operates on suitably
prepared (""packed"") sub-tensors that reside in a specified level of the cache
hierarchy. In contrast to previous approaches to tensor contractions, GETT
exhibits desirable features such as unit-stride memory accesses,
cache-awareness, as well as full vectorization, without requiring auxiliary
memory. To compare our technique with other modern tensor contractions, we
integrate GETT alongside the so called Transpose-Transpose-GEMM-Transpose and
Loops-over-GEMM approaches into an open source ""Tensor Contraction Code
Generator"" (TCCG). The performance results for a wide range of tensor
contractions suggest that GETT has the potential of becoming the method of
choice: While GETT exhibits excellent performance across the board, its
effectiveness for bandwidth-bound tensor contractions is especially impressive,
outperforming existing approaches by up to $12.4\times$. More precisely, GETT
achieves speedups of up to $1.41\times$ over an equivalent-sized GEMM for
bandwidth-bound tensor contractions while attaining up to $91.3\%$ of peak
floating-point performance for compute-bound tensor contractions.
","['\nPaul Springer\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1607.00145v3,cs.MS,"['cs.MS', 'cs.PF', 'G.4; D.3.4; I.1.2; I.1.3']",,,[]
"Quasi-matrix-free hybrid multigrid on dynamically adaptive Cartesian
  grids",http://arxiv.org/abs/1607.00648v5,2016-07-03T14:54:45Z,2017-07-17T20:45:30Z,"  We present a family of spacetree-based multigrid realizations using the
tree's multiscale nature to derive coarse grids. They align with matrix-free
geometric multigrid solvers as they never assemble the system matrices which is
cumbersome for dynamically adaptive grids and full multigrid. The most
sophisticated realizations use BoxMG to construct operator-dependent
prolongation and restriction in combination with Galerkin/Petrov-Galerkin
coarse-grid operators. This yields robust solvers for nontrivial elliptic
problems. We embed the algebraic, problem- and grid-dependent multigrid
operators as stencils into the grid and evaluate all matrix-vector products
in-situ throughout the grid traversals. While such an approach is not literally
matrix-free---the grid carries the matrix---we propose to switch to a
hierarchical representation of all operators. Only differences of algebraic
operators to their geometric counterparts are held. These hierarchical
differences can be stored and exchanged with small memory footprint. Our
realizations support arbitrary dynamically adaptive grids while they vertically
integrate the multilevel operations through spacetree linearization. This
yields good memory access characteristics, while standard colouring of mesh
entities with domain decomposition allows us to use parallel manycore clusters.
All realization ingredients are detailed such that they can be used by other
codes.
","['\nMarion Weinzierl\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1145/3165280,cs.NA,"['cs.NA', 'cs.MS', '97N80, 65M50, 65N50, 68W10, 65M55']",10.1145/3165280,,[]
"Best Practices for Replicability, Reproducibility and Reusability of
  Computer-Based Experiments Exemplified by Model Reduction Software",http://arxiv.org/abs/1607.01191v1,2016-07-05T11:02:45Z,2016-07-05T11:02:45Z,"  Over the recent years the importance of numerical experiments has gradually
been more recognized. Nonetheless, sufficient documentation of how
computational results have been obtained is often not available. Especially in
the scientific computing and applied mathematics domain this is crucial, since
numerical experiments are usually employed to verify the proposed hypothesis in
a publication. This work aims to propose standards and best practices for the
setup and publication of numerical experiments. Naturally, this amounts to a
guideline for development, maintenance, and publication of numerical research
software. Such a primer will enable the replicability and reproducibility of
computer-based experiments and published results and also promote the
reusability of the associated software.
","['\nJörg Fehr\n', '\nJan Heiland\n', '\nChristian Himpe\n', '\nJens Saak\n']",,"AIMS Mathematics 2016, Volume 1, Issue 3",http://dx.doi.org/10.3934/Math.2016.3.261,cs.MS,"['cs.MS', 'cs.SE', '68N30', 'G.4']",10.3934/Math.2016.3.261,,[]
TTC: A Tensor Transposition Compiler for Multiple Architectures,http://arxiv.org/abs/1607.01249v1,2016-07-05T13:53:57Z,2016-07-05T13:53:57Z,"  We consider the problem of transposing tensors of arbitrary dimension and
describe TTC, an open source domain-specific parallel compiler. TTC generates
optimized parallel C++/CUDA C code that achieves a significant fraction of the
system's peak memory bandwidth. TTC exhibits high performance across multiple
architectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD
Steamroller), Intel's Knights Corner as well as different CUDA-based GPUs such
as NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a
meaningful baseline implementation generated by external C++ compilers; the
results suggest that a domain-specific compiler can outperform its general
purpose counterpart significantly: For instance, comparing with Intel's latest
C++ compiler on the Haswell and Knights Corner architecture, TTC yields
speedups of up to $8\times$ and $32\times$, respectively. We also showcase
TTC's support for multiple leading dimensions, making it a suitable candidate
for the generation of performance-critical packing functions that are at the
core of the ubiquitous BLAS 3 routines.
","['\nPaul Springer\n', '\nAravind Sankaran\n', '\nPaolo Bientinesi\n']",,,http://dx.doi.org/10.1145/2935323.2935328,cs.MS,"['cs.MS', 'cs.PF', 'G.4; D.3.4; I.1.2; I.1.3']",10.1145/2935323.2935328,,[]
High-Performance Tensor Contraction without Transposition,http://arxiv.org/abs/1607.00291v4,2016-07-01T15:37:59Z,2017-07-11T15:03:52Z,"  Tensor computations--in particular tensor contraction (TC)--are important
kernels in many scientific computing applications. Due to the fundamental
similarity of TC to matrix multiplication (MM) and to the availability of
optimized implementations such as the BLAS, tensor operations have
traditionally been implemented in terms of BLAS operations, incurring both a
performance and a storage overhead. Instead, we implement TC using the flexible
BLIS framework, which allows for transposition (reshaping) of the tensor to be
fused with internal partitioning and packing operations, requiring no explicit
transposition operations or additional workspace. This implementation, TBLIS,
achieves performance approaching that of MM, and in some cases considerably
higher than that of traditional TC. Our implementation supports multithreading
using an approach identical to that used for MM in BLIS, with similar
performance characteristics. The complexity of managing tensor-to-matrix
transformations is also handled automatically in our approach, greatly
simplifying its use in scientific applications.
",['\nDevin A. Matthews\n'],"24 pages, 8 figures, uses pgfplots",,http://arxiv.org/abs/1607.00291v4,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF', '15A69', 'G.4']",,,[]
Distributed-memory Hierarchical Interpolative Factorization,http://arxiv.org/abs/1607.00346v4,2016-07-01T18:37:34Z,2017-02-23T07:42:28Z,"  The hierarchical interpolative factorization (HIF) offers an efficient way
for solving or preconditioning elliptic partial differential equations. By
exploiting locality and low-rank properties of the operators, the HIF achieves
quasi-linear complexity for factorizing the discrete positive definite elliptic
operator and linear complexity for solving the associated linear system. In
this paper, the distributed-memory HIF (DHIF) is introduced as a parallel and
distributed-memory implementation of the HIF. The DHIF organizes the processes
in a hierarchical structure and keep the communication as local as possible.
The computation complexity is $O\left(\frac{N\log N}{P}\right)$ and
$O\left(\frac{N}{P}\right)$ for constructing and applying the DHIF,
respectively, where $N$ is the size of the problem and $P$ is the number of
processes. The communication complexity is $O\left(\sqrt{P}\log^3
P\right)\alpha + O\left(\frac{N^{2/3}}{\sqrt{P}}\right)\beta$ where $\alpha$ is
the latency and $\beta$ is the inverse bandwidth. Extensive numerical examples
are performed on the NERSC Edison system with up to 8192 processes. The
numerical results agree with the complexity analysis and demonstrate the
efficiency and scalability of the DHIF.
","['\nYingzhou Li\n', '\nLexing Ying\n']",,,http://dx.doi.org/10.1186/s40687-017-0100-6,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.1186/s40687-017-0100-6,,[]
"PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate
  Large-Scale Computations",http://arxiv.org/abs/1607.01404v2,2016-07-05T20:15:56Z,2017-01-24T18:27:56Z,"  The increasing number of applications requiring the solution of large scale
singular value problems have rekindled interest in iterative methods for the
SVD. Some promising recent ad- vances in large scale iterative methods are
still plagued by slow convergence and accuracy limitations for computing
smallest singular triplets. Furthermore, their current implementations in
MATLAB cannot address the required large problems. Recently, we presented a
preconditioned, two-stage method to effectively and accurately compute a small
number of extreme singular triplets. In this research, we present a
high-performance software, PRIMME SVDS, that implements our hybrid method based
on the state-of-the-art eigensolver package PRIMME for both largest and
smallest singular values. PRIMME SVDS fills a gap in production level software
for computing the partial SVD, especially with preconditioning. The numerical
experiments demonstrate its superior performance compared to other
state-of-the-art software and its good parallel performance under strong and
weak scaling.
","['\nLingfei Wu\n', '\nEloy Romero\n', '\nAndreas Stathopoulos\n']","23 pages, 10 figures",,http://arxiv.org/abs/1607.01404v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA']",,,[]
"Accelerating eigenvector and pseudospectra computation using blocked
  multi-shift triangular solves",http://arxiv.org/abs/1607.01477v2,2016-07-06T04:19:04Z,2016-07-30T16:52:39Z,"  Multi-shift triangular solves are basic linear algebra calculations with
applications in eigenvector and pseudospectra computation. We propose blocked
algorithms that efficiently exploit Level 3 BLAS to perform multi-shift
triangular solves and safe multi-shift triangular solves. Numerical experiments
indicate that computing triangular eigenvectors with a safe multi-shift
triangular solve achieves speedups by a factor of 60 relative to LAPACK. This
algorithm accelerates the calculation of general eigenvectors threefold. When
using multi-shift triangular solves to compute pseudospectra, we report
ninefold speedups relative to EigTool.
","['\nTim Moon\n', '\nJack Poulson\n']","20 pages, 6 figures",,http://arxiv.org/abs/1607.01477v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
Benchmarking Python Tools for Automatic Differentiation,http://arxiv.org/abs/1606.06311v1,2016-06-20T20:14:12Z,2016-06-20T20:14:12Z,"  In this paper we compare several Python tools for automatic differentiation.
In order to assess the difference in performance and precision, the problem of
finding the optimal geometrical structure of the cluster with identical atoms
is used as follows. First, we compare performance of calculating gradients for
the objective function. We showed that the PyADOL-C and PyCppAD tools have much
better performance for big clusters than the other ones. Second, we assess
precision of these two tools by calculating the difference between the obtained
at the optimal configuration gradient norms. We conclude that PyCppAD has the
best performance among others, while having almost the same precision as the
second- best performing tool - PyADOL-C.
","['\nAndrei Turkin\n', '\nAung Thu\n']","4 pages, 1 figure",,http://arxiv.org/abs/1606.06311v1,cs.MS,['cs.MS'],,,[]
jInv -- a flexible Julia package for PDE parameter estimation,http://arxiv.org/abs/1606.07399v2,2016-06-23T18:37:41Z,2016-12-14T07:58:27Z,"  Estimating parameters of Partial Differential Equations (PDEs) from noisy and
indirect measurements often requires solving ill-posed inverse problems. These
so called parameter estimation or inverse medium problems arise in a variety of
applications such as geophysical, medical imaging, and nondestructive testing.
Their solution is computationally intense since the underlying PDEs need to be
solved numerous times until the reconstruction of the parameters is
sufficiently accurate. Typically, the computational demand grows significantly
when more measurements are available, which poses severe challenges to
inversion algorithms as measurement devices become more powerful.
  In this paper we present jInv, a flexible framework and open source software
that provides parallel algorithms for solving parameter estimation problems
with many measurements. Being written in the expressive programming language
Julia, jInv is portable, easy to understand and extend, cross-platform tested,
and well-documented. It provides novel parallelization schemes that exploit the
inherent structure of many parameter estimation problems and can be used to
solve multiphysics inversion problems as is demonstrated using numerical
experiments motivated by geophysical imaging.
","['\nLars Ruthotto\n', '\nEran Treister\n', '\nEldad Haber\n']",,,http://arxiv.org/abs/1606.07399v2,cs.MS,['cs.MS'],,,[]
"Stochastic Runge-Kutta Software Package for Stochastic Differential
  Equations",http://arxiv.org/abs/1606.06604v1,2016-06-21T14:51:11Z,2016-06-21T14:51:11Z,"  As a result of the application of a technique of multistep processes
stochastic models construction the range of models, implemented as a
self-consistent differential equations, was obtained. These are partial
differential equations (master equation, the Fokker--Planck equation) and
stochastic differential equations (Langevin equation). However, analytical
methods do not always allow to research these equations adequately. It is
proposed to use the combined analytical and numerical approach studying these
equations. For this purpose the numerical part is realized within the framework
of symbolic computation. It is recommended to apply stochastic Runge--Kutta
methods for numerical study of stochastic differential equations in the form of
the Langevin. Under this approach, a program complex on the basis of analytical
calculations metasystem Sage is developed. For model verification logarithmic
walks and Black--Scholes two-dimensional model are used. To illustrate the
stochastic ""predator--prey"" type model is used. The utility of the combined
numerical-analytical approach is demonstrated.
","['\nM. N. Gevorkyan\n', '\nT. R. Velieva\n', '\nA. V. Korolkova\n', '\nD. S. Kulyabov\n', '\nL. A. Sevastyanov\n']","in English, in Russian. M.N. Gevorkyan, T.R. Velieva, A.V. Korolkova,
  D.S. Kulyabov, L.A. Sevastyanov, Stochastic Runge-Kutta Software Package for
  Stochastic Differential Equations, in Dependability Engineering and Complex
  Systems, Vol. 470, 2016, pp. 169-179",,http://dx.doi.org/10.1007/978-3-319-39639-2_15,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'cs.NA']",10.1007/978-3-319-39639-2_15,,[]
Computing hypergeometric functions rigorously,http://arxiv.org/abs/1606.06977v2,2016-06-22T15:07:11Z,2016-07-05T11:58:14Z,"  We present an efficient implementation of hypergeometric functions in
arbitrary-precision interval arithmetic. The functions ${}_0F_1$, ${}_1F_1$,
${}_2F_1$ and ${}_2F_0$ (or the Kummer $U$-function) are supported for
unrestricted complex parameters and argument, and by extension, we cover
exponential and trigonometric integrals, error functions, Fresnel integrals,
incomplete gamma and beta functions, Bessel functions, Airy functions, Legendre
functions, Jacobi polynomials, complete elliptic integrals, and other special
functions. The output can be used directly for interval computations or to
generate provably correct floating-point approximations in any format.
Performance is competitive with earlier arbitrary-precision software, and
sometimes orders of magnitude faster. We also partially cover the generalized
hypergeometric function ${}_pF_q$ and computation of high-order parameter
derivatives.
",['\nFredrik Johansson\n'],"v2: corrected example in section 3.1; corrected timing data for case
  E-G in section 8.5 (table 6, figure 2); adjusted paper size",,http://arxiv.org/abs/1606.06977v2,cs.MS,"['cs.MS', 'cs.NA', 'cs.SC', '33F05, 33C20, 33C05, 33C10, 33C15, 65G30, 65Y20, 65D20, 97N80,\n  33B15, 33B20, 33C45']",,,[]
"From NoSQL Accumulo to NewSQL Graphulo: Design and Utility of Graph
  Algorithms inside a BigTable Database",http://arxiv.org/abs/1606.07085v2,2016-06-22T20:08:47Z,2016-08-11T04:09:48Z,"  Google BigTable's scale-out design for distributed key-value storage inspired
a generation of NoSQL databases. Recently the NewSQL paradigm emerged in
response to analytic workloads that demand distributed computation local to
data storage. Many such analytics take the form of graph algorithms, a trend
that motivated the GraphBLAS initiative to standardize a set of matrix math
kernels for building graph algorithms. In this article we show how it is
possible to implement the GraphBLAS kernels in a BigTable database by
presenting the design of Graphulo, a library for executing graph algorithms
inside the Apache Accumulo database. We detail the Graphulo implementation of
two graph algorithms and conduct experiments comparing their performance to two
main-memory matrix math systems. Our results shed insight into the conditions
that determine when executing a graph algorithm is faster inside a database
versus an external system---in short, that memory requirements and relative I/O
are critical factors.
","['\nDylan Hutchison\n', '\nJeremy Kepner\n', '\nVijay Gadepally\n', '\nBill Howe\n']","9 pages, to appear in 2016 IEEE High Performance Extreme Computing
  Conference (HPEC)",,http://dx.doi.org/10.1109/HPEC.2016.7761577,cs.DB,"['cs.DB', 'cs.DC', 'cs.MS']",10.1109/HPEC.2016.7761577,,[]
"Automatic finite element implementation of hyperelastic material with a
  double numerical differentiation algorithm",http://arxiv.org/abs/1606.04987v1,2016-06-13T17:54:41Z,2016-06-13T17:54:41Z,"  In order to accelerate implementation of hyperelastic materials for finite
element analysis, we developed an automatic numerical algorithm that only
requires the strain energy function. This saves the effort on analytical
derivation and coding of stress and tangent modulus, which is time-consuming
and prone to human errors. Using the one-sided Newton difference quotients, the
proposed algorithm first perturbs deformation gradients and calculate the
difference on strain energy to approximate stress. Then, we perturb again to
get difference in stress to approximate tangent modulus. Accuracy of the
approximations were evaluated across the perturbation parameter space, where we
find the optimal amount of perturbation being $10^{-6}$ to obtain stress and
$10^{-4}$ to obtain tangent modulus. Single element verification in ABAQUS with
Neo-Hookean material resulted in a small stress error of only $7\times10^{-5}$
on average across uniaxial compression and tension, biaxial tension and simple
shear situations. A full 3D model with Holzapfel anisotropic material for
artery inflation generated a small relative error of $4\times10^{-6}$ for
inflated radius at $25 kPa$ pressure. Results of the verification tests suggest
that the proposed numerical method has good accuracy and convergence
performance, therefore a good material implementation algorithm in small scale
models and a useful debugging tool for large scale models.
","['\nYuxiang Wang\n', '\nGregory J. Gerling\n']","19 pages, 3 figures, and 2 tables. Was presented as a podium
  presentation at the Computer Methods in Biomechanics and Biomedical
  Engineering 2015, September 3rd, Montreal, Quebec, Canada",,http://arxiv.org/abs/1606.04987v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
"D2O - a distributed data object for parallel high-performance computing
  in Python",http://arxiv.org/abs/1606.05385v2,2016-06-16T23:19:58Z,2016-08-13T08:28:59Z,"  We introduce D2O, a Python module for cluster-distributed multi-dimensional
numerical arrays. It acts as a layer of abstraction between the algorithm code
and the data-distribution logic. The main goal is to achieve usability without
losing numerical performance and scalability. D2O's global interface is similar
to the one of a numpy.ndarray, whereas the cluster node's local data is
directly accessible for use in customized high-performance modules. D2O is
written in pure Python which makes it portable and easy to use and modify.
Expensive operations are carried out by dedicated external libraries like numpy
and mpi4py. The performance of D2O is on a par with numpy for serial
applications and scales well when moving to an MPI cluster. D2O is open-source
software available under the GNU General Public License v3 (GPL-3) at
https://gitlab.mpcdf.mpg.de/ift/D2O
","['\nT. Steininger\n', '\nM. Greiner\n', '\nF. Beaujean\n', '\nT. Enßlin\n']",,,http://dx.doi.org/10.1186/s40537-016-0052-5,cs.MS,"['cs.MS', 'cs.DC']",10.1186/s40537-016-0052-5,,[]
"Computing all Space Curve Solutions of Polynomial Systems by Polyhedral
  Methods",http://arxiv.org/abs/1606.05563v1,2016-06-17T15:28:40Z,2016-06-17T15:28:40Z,"  A polyhedral method to solve a system of polynomial equations exploits its
sparse structure via the Newton polytopes of the polynomials. We propose a
hybrid symbolic-numeric method to compute a Puiseux series expansion for every
space curve that is a solution of a polynomial system. The focus of this paper
concerns the difficult case when the leading powers of the Puiseux series of
the space curve are contained in the relative interior of a higher dimensional
cone of the tropical prevariety. We show that this difficult case does not
occur for polynomials with generic coefficients. To resolve this case, we
propose to apply polyhedral end games to recover tropisms hidden in the
tropical prevariety.
","['\nNathan Bliss\n', '\nJan Verschelde\n']","14 pages, 1 figure, accepted for presentation at Computer Algebra in
  Scientific Computing, CASC 2016",,http://arxiv.org/abs/1606.05563v1,cs.SC,"['cs.SC', 'cs.MS', 'math.AG', 'math.NA']",,,[]
Mathematical Foundations of the GraphBLAS,http://arxiv.org/abs/1606.05790v2,2016-06-18T18:46:20Z,2016-07-14T02:52:48Z,"  The GraphBLAS standard (GraphBlas.org) is being developed to bring the
potential of matrix based graph algorithms to the broadest possible audience.
Mathematically the Graph- BLAS defines a core set of matrix-based graph
operations that can be used to implement a wide class of graph algorithms in a
wide range of programming environments. This paper provides an introduction to
the mathematics of the GraphBLAS. Graphs represent connections between vertices
with edges. Matrices can represent a wide range of graphs using adjacency
matrices or incidence matrices. Adjacency matrices are often easier to analyze
while incidence matrices are often better for representing data. Fortunately,
the two are easily connected by matrix mul- tiplication. A key feature of
matrix mathematics is that a very small number of matrix operations can be used
to manipulate a very wide range of graphs. This composability of small number
of operations is the foundation of the GraphBLAS. A standard such as the
GraphBLAS can only be effective if it has low performance overhead. Performance
measurements of prototype GraphBLAS implementations indicate that the overhead
is low.
","['\nJeremy Kepner\n', '\nPeter Aaltonen\n', '\nDavid Bader\n', '\nAydın Buluc\n', '\nFranz Franchetti\n', '\nJohn Gilbert\n', '\nDylan Hutchison\n', '\nManoj Kumar\n', '\nAndrew Lumsdaine\n', '\nHenning Meyerhenke\n', '\nScott McMillan\n', '\nJose Moreira\n', '\nJohn D. Owens\n', '\nCarl Yang\n', '\nMarcin Zalewski\n', '\nTimothy Mattson\n']","9 pages; 11 figures; accepted to IEEE High Performance Extreme
  Computing (HPEC) conference 2016. arXiv admin note: text overlap with
  arXiv:1504.01039",,http://dx.doi.org/10.1109/HPEC.2016.7761646,cs.MS,"['cs.MS', 'astro-ph.IM', 'cs.DC', 'cs.DS']",10.1109/HPEC.2016.7761646,,[]
Parallel Triangular Solvers on GPU,http://arxiv.org/abs/1606.00541v1,2016-06-02T05:54:09Z,2016-06-02T05:54:09Z,"  In this paper, we investigate GPU based parallel triangular solvers
systematically. The parallel triangular solvers are fundamental to incomplete
LU factorization family preconditioners and algebraic multigrid solvers. We
develop a new matrix format suitable for GPU devices. Parallel lower triangular
solvers and upper triangular solvers are developed for this new data structure.
With these solvers, ILU preconditioners and domain decomposition
preconditioners are developed. Numerical results show that we can speed
triangular solvers around seven times faster.
","['\nZhangxin Chen\n', '\nHui Liu\n', '\nBo Yang\n']",,,http://arxiv.org/abs/1606.00541v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"Development of Krylov and AMG linear solvers for large-scale sparse
  matrices on GPUs",http://arxiv.org/abs/1606.00545v1,2016-06-02T06:01:05Z,2016-06-02T06:01:05Z,"  This research introduce our work on developing Krylov subspace and AMG
solvers on NVIDIA GPUs. As SpMV is a crucial part for these iterative methods,
SpMV algorithms for single GPU and multiple GPUs are implemented. A HEC matrix
format and a communication mechanism are established. And also, a set of
specific algorithms for solving preconditioned systems in parallel environments
are designed, including ILU(k), RAS and parallel triangular solvers. Based on
these work, several Krylov solvers and AMG solvers are developed. According to
numerical experiments, favorable acceleration performance is acquired from our
Krylov solver and AMG solver under various parameter conditions.
","['\nBo Yang\n', '\nHui Liu\n', '\nZhangxin Chen\n']",,,http://arxiv.org/abs/1606.00545v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"Boda-RTC: Productive Generation of Portable, Efficient Code for
  Convolutional Neural Networks on Mobile Computing Platforms",http://arxiv.org/abs/1606.00094v2,2016-06-01T02:17:26Z,2016-09-13T16:20:09Z,"  The popularity of neural networks (NNs) spans academia, industry, and popular
culture. In particular, convolutional neural networks (CNNs) have been applied
to many image based machine learning tasks and have yielded strong results. The
availability of hardware/software systems for efficient training and deployment
of large and/or deep CNN models has been, and continues to be, an important
consideration for the field. Early systems for NN computation focused on
leveraging existing dense linear algebra techniques and libraries. Current
approaches use low-level machine specific programming and/or closed-source,
purpose-built vendor libraries. In this work, we present an open source system
that, compared to existing approaches, achieves competitive computational speed
while achieving higher portability. We achieve this by targeting the
vendor-neutral OpenCL platform using a code-generation approach. We argue that
our approach allows for both: (1) the rapid development of new computational
kernels for existing hardware targets, and (2) the rapid tuning of existing
computational kernels for new hardware targets. Results are presented for a
case study of targeting the Qualcomm Snapdragon 820 mobile computing platform
for CNN deployment.
","['\nMatthew Moskewicz\n', '\nForrest Iandola\n', '\nKurt Keutzer\n']",,,http://arxiv.org/abs/1606.00094v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.NE']",,,[]
"Conforming restricted Delaunay mesh generation for piecewise smooth
  complexes",http://arxiv.org/abs/1606.01289v2,2016-06-03T22:06:58Z,2016-07-26T18:06:16Z,"  A Frontal-Delaunay refinement algorithm for mesh generation in piecewise
smooth domains is described. Built using a restricted Delaunay framework, this
new algorithm combines a number of novel features, including: (i) an
unweighted, conforming restricted Delaunay representation for domains specified
as a (non-manifold) collection of piecewise smooth surface patches and curve
segments, (ii) a protection strategy for domains containing curve segments that
subtend sharply acute angles, and (iii) a new class of off-centre refinement
rules designed to achieve high-quality point-placement along embedded curve
features. Experimental comparisons show that the new Frontal-Delaunay algorithm
outperforms a classical (statically weighted) restricted Delaunay-refinement
technique for a number of three-dimensional benchmark problems.
",['\nDarren Engwirda\n'],To appear at the 25th International Meshing Roundtable,,http://arxiv.org/abs/1606.01289v2,cs.CG,"['cs.CG', 'cs.CE', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
"OPESCI-FD: Automatic Code Generation Package for Finite Difference
  Models",http://arxiv.org/abs/1605.06381v1,2016-05-20T14:44:55Z,2016-05-20T14:44:55Z,"  In this project, we introduce OPESCI-FD, a Python package built on symbolic
mathematics to automatically generate Finite Difference models from a
high-level description of the model equations. We investigate applying this
framework to generate the propagator program used in seismic imaging. We
implement the 3D velocity-stress FD scheme as an example and demonstrate the
advantages of usability, flexibility and accuracy of the framework. The design
of OPESCI-FD aims to allow rapid development, analysis and optimisation of
Finite Difference programs. OPESCI-FD is the foundation for continuing
development by the OPESCI project team, building on the research presented in
this report. This report concludes by reviewing the further developments that
are already under way, as well as the scope for extension to cater for other
equations and numerical schemes.
",['\nTianjiao Sun\n'],,,http://arxiv.org/abs/1605.06381v1,cs.MS,['cs.MS'],,,[]
HLinear: Exact Dense Linear Algebra in Haskell,http://arxiv.org/abs/1605.02532v3,2016-05-09T11:24:39Z,2017-08-10T20:20:02Z,"  We present an implementation in the functional programming language Haskell
of the PLE decomposition of matrices over division rings. Our benchmarks
indicate that it is competitive with the C-based implementation provided in
Flint. Describing the guiding principles of our work, we introduce the reader
to basic ideas from high-performance functional programming.
","['\nAlexandru Ghitza\n', '\nMartin Raum\n']","13 pages, 6 tables; code available at
  https://github.com/martinra/hlinear/tree/paper-toms",,http://arxiv.org/abs/1605.02532v3,cs.MS,"['cs.MS', 'cs.SC', '68N18', 'G.4; D.1.1']",,,[]
"Theano: A Python framework for fast computation of mathematical
  expressions",http://arxiv.org/abs/1605.02688v1,2016-05-09T18:32:34Z,2016-05-09T18:32:34Z,"  Theano is a Python library that allows to define, optimize, and evaluate
mathematical expressions involving multi-dimensional arrays efficiently. Since
its introduction, it has been one of the most used CPU and GPU mathematical
compilers - especially in the machine learning community - and has shown steady
performance improvements. Theano is being actively and continuously developed
since 2008, multiple frameworks have been built on top of it and it has been
used to produce many state-of-the-art machine learning models.
  The present article is structured as follows. Section I provides an overview
of the Theano software and its community. Section II presents the principal
features of Theano and how to use them, and compares them with other similar
projects. Section III focuses on recently-introduced functionalities and
improvements. Section IV compares the performance of Theano against Torch7 and
TensorFlow on several machine learning models. Section V discusses current
limitations of Theano and potential ways of improving it.
","['\n The Theano Development Team\n', '\nRami Al-Rfou\n', '\nGuillaume Alain\n', '\nAmjad Almahairi\n', '\nChristof Angermueller\n', '\nDzmitry Bahdanau\n', '\nNicolas Ballas\n', '\nFrédéric Bastien\n', '\nJustin Bayer\n', '\nAnatoly Belikov\n', '\nAlexander Belopolsky\n', '\nYoshua Bengio\n', '\nArnaud Bergeron\n', '\nJames Bergstra\n', '\nValentin Bisson\n', '\nJosh Bleecher Snyder\n', '\nNicolas Bouchard\n', '\nNicolas Boulanger-Lewandowski\n', '\nXavier Bouthillier\n', '\nAlexandre de Brébisson\n', '\nOlivier Breuleux\n', '\nPierre-Luc Carrier\n', '\nKyunghyun Cho\n', '\nJan Chorowski\n', '\nPaul Christiano\n', '\nTim Cooijmans\n', '\nMarc-Alexandre Côté\n', '\nMyriam Côté\n', '\nAaron Courville\n', '\nYann N. Dauphin\n', '\nOlivier Delalleau\n', '\nJulien Demouth\n', '\nGuillaume Desjardins\n', '\nSander Dieleman\n', '\nLaurent Dinh\n', '\nMélanie Ducoffe\n', '\nVincent Dumoulin\n', '\nSamira Ebrahimi Kahou\n', '\nDumitru Erhan\n', '\nZiye Fan\n', '\nOrhan Firat\n', '\nMathieu Germain\n', '\nXavier Glorot\n', '\nIan Goodfellow\n', '\nMatt Graham\n', '\nCaglar Gulcehre\n', '\nPhilippe Hamel\n', '\nIban Harlouchet\n', '\nJean-Philippe Heng\n', '\nBalázs Hidasi\n', '\nSina Honari\n', '\nArjun Jain\n', '\nSébastien Jean\n', '\nKai Jia\n', '\nMikhail Korobov\n', '\nVivek Kulkarni\n', '\nAlex Lamb\n', '\nPascal Lamblin\n', '\nEric Larsen\n', '\nCésar Laurent\n', '\nSean Lee\n', '\nSimon Lefrancois\n', '\nSimon Lemieux\n', '\nNicholas Léonard\n', '\nZhouhan Lin\n', '\nJesse A. Livezey\n', '\nCory Lorenz\n', '\nJeremiah Lowin\n', '\nQianli Ma\n', '\nPierre-Antoine Manzagol\n', '\nOlivier Mastropietro\n', '\nRobert T. McGibbon\n', '\nRoland Memisevic\n', '\nBart van Merriënboer\n', '\nVincent Michalski\n', '\nMehdi Mirza\n', '\nAlberto Orlandi\n', '\nChristopher Pal\n', '\nRazvan Pascanu\n', '\nMohammad Pezeshki\n', '\nColin Raffel\n', '\nDaniel Renshaw\n', '\nMatthew Rocklin\n', '\nAdriana Romero\n', '\nMarkus Roth\n', '\nPeter Sadowski\n', '\nJohn Salvatier\n', '\nFrançois Savard\n', '\nJan Schlüter\n', '\nJohn Schulman\n', '\nGabriel Schwartz\n', '\nIulian Vlad Serban\n', '\nDmitriy Serdyuk\n', '\nSamira Shabanian\n', '\nÉtienne Simon\n', '\nSigurd Spieckermann\n', '\nS. Ramana Subramanyam\n', '\nJakub Sygnowski\n', '\nJérémie Tanguay\n', '\nGijs van Tulder\n', '\nJoseph Turian\n', '\nSebastian Urban\n', '\nPascal Vincent\n', '\nFrancesco Visin\n', '\nHarm de Vries\n', '\nDavid Warde-Farley\n', '\nDustin J. Webb\n', '\nMatthew Willson\n', '\nKelvin Xu\n', '\nLijun Xue\n', '\nLi Yao\n', '\nSaizheng Zhang\n', '\nYing Zhang\n']","19 pages, 5 figures",,http://arxiv.org/abs/1605.02688v1,cs.SC,"['cs.SC', 'cs.LG', 'cs.MS']",,,[]
Implementing Strassen's Algorithm with BLIS,http://arxiv.org/abs/1605.01078v1,2016-05-03T20:28:00Z,2016-05-03T20:28:00Z,"  We dispel with ""street wisdom"" regarding the practical implementation of
Strassen's algorithm for matrix-matrix multiplication (DGEMM). Conventional
wisdom: it is only practical for very large matrices. Our implementation is
practical for small matrices. Conventional wisdom: the matrices being
multiplied should be relatively square. Our implementation is practical for
rank-k updates, where k is relatively small (a shape of importance for
libraries like LAPACK). Conventional wisdom: it inherently requires substantial
workspace. Our implementation requires no workspace beyond buffers already
incorporated into conventional high-performance DGEMM implementations.
Conventional wisdom: a Strassen DGEMM interface must pass in workspace. Our
implementation requires no such workspace and can be plug-compatible with the
standard DGEMM interface. Conventional wisdom: it is hard to demonstrate
speedup on multi-core architectures. Our implementation demonstrates speedup
over conventional DGEMM even on an Intel(R) Xeon Phi(TM) coprocessor utilizing
240 threads. We show how a distributed memory matrix-matrix multiplication also
benefits from these advances.
","['\nJianyu Huang\n', '\nTyler M. Smith\n', '\nGreg M. Henry\n', '\nRobert A. van de Geijn\n']",,,http://arxiv.org/abs/1605.01078v1,cs.MS,['cs.MS'],,,[]
"Blackbox: A procedure for parallel optimization of expensive black-box
  functions",http://arxiv.org/abs/1605.00998v1,2016-05-03T17:49:27Z,2016-05-03T17:49:27Z,"  This note provides a description of a procedure that is designed to
efficiently optimize expensive black-box functions. It uses the response
surface methodology by incorporating radial basis functions as the response
model. A simple method based on a Latin hypercube is used for initial sampling.
A modified version of CORS algorithm with space rescaling is used for the
subsequent sampling. The procedure is able to scale on multicore processors by
performing multiple function evaluations in parallel. The source code of the
procedure is written in Python.
","['\nPaul Knysh\n', '\nYannis Korkolis\n']","8 pages, 3 figures",,http://arxiv.org/abs/1605.00998v1,cs.MS,"['cs.MS', 'math.OC']",,,[]
Computing Real Roots of Real Polynomials ... and now For Real!,http://arxiv.org/abs/1605.00410v1,2016-05-02T09:47:10Z,2016-05-02T09:47:10Z,"  Very recent work introduces an asymptotically fast subdivision algorithm,
denoted ANewDsc, for isolating the real roots of a univariate real polynomial.
The method combines Descartes' Rule of Signs to test intervals for the
existence of roots, Newton iteration to speed up convergence against clusters
of roots, and approximate computation to decrease the required precision. It
achieves record bounds on the worst-case complexity for the considered problem,
matching the complexity of Pan's method for computing all complex roots and
improving upon the complexity of other subdivision methods by several
magnitudes.
  In the article at hand, we report on an implementation of ANewDsc on top of
the RS root isolator. RS is a highly efficient realization of the classical
Descartes method and currently serves as the default real root solver in Maple.
We describe crucial design changes within ANewDsc and RS that led to a
high-performance implementation without harming the theoretical complexity of
the underlying algorithm.
  With an excerpt of our extensive collection of benchmarks, available online
at http://anewdsc.mpi-inf.mpg.de/, we illustrate that the theoretical gain in
performance of ANewDsc over other subdivision methods also transfers into
practice. These experiments also show that our new implementation outperforms
both RS and mature competitors by magnitudes for notoriously hard instances
with clustered roots. For all other instances, we avoid almost any overhead by
integrating additional optimizations and heuristics.
","['\nAlexander Kobel\n', '\nFabrice Rouillier\n', '\nMichael Sagraloff\n']","Accepted for presentation at the 41st International Symposium on
  Symbolic and Algebraic Computation (ISSAC), July 19--22, 2016, Waterloo,
  Ontario, Canada",,http://dx.doi.org/10.1145/2930889.2930937,cs.MS,"['cs.MS', 'cs.NA', 'cs.SC', 'math.NA', '65H04, 68N30 (Primary) 68W30 (Secondary)', 'G.1.5; G.1.0; G.4']",10.1145/2930889.2930937,,[]
"High level implementation of geometric multigrid solvers for finite
  element problems: applications in atmospheric modelling",http://arxiv.org/abs/1605.00492v2,2016-05-02T14:06:24Z,2016-09-14T09:10:47Z,"  The implementation of efficient multigrid preconditioners for elliptic
partial differential equations (PDEs) is a challenge due to the complexity of
the resulting algorithms and corresponding computer code. For sophisticated
finite element discretisations on unstructured grids an efficient
implementation can be very time consuming and requires the programmer to have
in-depth knowledge of the mathematical theory, parallel computing and
optimisation techniques on manycore CPUs. In this paper we show how the
development of bespoke multigrid preconditioners can be simplified
significantly by using a framework which allows the expression of the each
component of the algorithm at the correct abstraction level. Our approach (1)
allows the expression of the finite element problem in a language which is
close to the mathematical formulation of the problem, (2) guarantees the
automatic generation and efficient execution of parallel optimised low-level
computer code and (3) is flexible enough to support different abstraction
levels and give the programmer control over details of the preconditioner. We
use the composable abstractions of the Firedrake/PyOP2 package to demonstrate
the efficiency of this approach for the solution of strongly anisotropic PDEs
in atmospheric modelling. The weak formulation of the PDE is expressed in
Unified Form Language (UFL) and the lower PyOP2 abstraction layer allows the
manual design of computational kernels for a bespoke geometric multigrid
preconditioner. We compare the performance of this preconditioner to a
single-level method and hypre's BoomerAMG algorithm. The Firedrake/PyOP2 code
is inherently parallel and we present a detailed performance analysis for a
single node (24 cores) on the ARCHER supercomputer. Our implementation utilises
a significant fraction of the available memory bandwidth and shows very good
weak scaling on up to 6,144 compute cores.
","['\nLawrence Mitchell\n', '\nEike Hermann Müller\n']","22 pages, 5 figures, 9 tables. Submitted to JCP",Journal of Computational Physics 327:1-18 (2016),http://dx.doi.org/10.1016/j.jcp.2016.09.037,cs.MS,"['cs.MS', 'math.NA', 'physics.flu-dyn', '65F08, 65N55, 76M10, 86A10', 'D.2.2; G.1.3; G.1.8; G.4; J.2']",10.1016/j.jcp.2016.09.037,,[]
UBL: an R package for Utility-based Learning,http://arxiv.org/abs/1604.08079v2,2016-04-27T14:13:11Z,2016-07-12T23:08:46Z,"  This document describes the R package UBL that allows the use of several
methods for handling utility-based learning problems. Classification and
regression problems that assume non-uniform costs and/or benefits pose serious
challenges to predictive analytic tasks. In the context of meteorology,
finance, medicine, ecology, among many other, specific domain information
concerning the preference bias of the users must be taken into account to
enhance the models predictive performance. To deal with this problem, a large
number of techniques was proposed by the research community for both
classification and regression tasks. The main goal of UBL package is to
facilitate the utility-based predictive analytic task by providing a set of
methods to deal with this type of problems in the R environment. It is a
versatile tool that provides mechanisms to handle both regression and
classification (binary and multiclass) tasks. Moreover, UBL package allows the
user to specify his domain preferences, but it also provides some automatic
methods that try to infer those preference bias from the domain, considering
some common known settings.
","['\nPaula Branco\n', '\nRita P. Ribeiro\n', '\nLuis Torgo\n']",,,http://arxiv.org/abs/1604.08079v2,cs.MS,"['cs.MS', 'cs.LG', 'stat.ML']",,,[]
An algorithm for the optimization of finite element integration loops,http://arxiv.org/abs/1604.05872v1,2016-04-20T09:39:29Z,2016-04-20T09:39:29Z,"  We present an algorithm for the optimization of a class of finite element
integration loop nests. This algorithm, which exploits fundamental mathematical
properties of finite element operators, is proven to achieve a locally optimal
operation count. In specified circumstances the optimum achieved is global.
Extensive numerical experiments demonstrate significant performance
improvements over the state of the art in finite element code generation in
almost all cases. This validates the effectiveness of the algorithm presented
here, and illustrates its limitations.
","['\nFabio Luporini\n', '\nDavid A. Ham\n', '\nPaul H. J. Kelly\n']",,,http://dx.doi.org/10.1145/3054944,cs.MS,"['cs.MS', 'G.1.8; G.4']",10.1145/3054944,,[]
"A structure-exploiting numbering algorithm for finite elements on
  extruded meshes, and its performance evaluation in Firedrake",http://arxiv.org/abs/1604.05937v3,2016-04-20T13:05:04Z,2016-10-28T11:28:32Z,"  We present a generic algorithm for numbering and then efficiently iterating
over the data values attached to an extruded mesh. An extruded mesh is formed
by replicating an existing mesh, assumed to be unstructured, to form layers of
prismatic cells. Applications of extruded meshes include, but are not limited
to, the representation of 3D high aspect ratio domains employed by geophysical
finite element simulations. These meshes are structured in the extruded
direction. The algorithm presented here exploits this structure to avoid the
performance penalty traditionally associated with unstructured meshes. We
evaluate the implementation of this algorithm in the Firedrake finite element
system on a range of low compute intensity operations which constitute worst
cases for data layout performance exploration. The experiments show that having
structure along the extruded direction enables the cost of the indirect data
accesses to be amortized after 10-20 layers as long as the underlying mesh is
well-ordered. We characterise the resulting spatial and temporal reuse in a
representative set of both continuous-Galerkin and discontinuous-Galerkin
discretisations. On meshes with realistic numbers of layers the performance
achieved is between 70% and 90% of a theoretical hardware-specific limit.
","['\nGheorghe-Teodor Bercea\n', '\nAndrew T. T. McRae\n', '\nDavid A. Ham\n', '\nLawrence Mitchell\n', '\nFlorian Rathgeber\n', '\nLuigi Nardi\n', '\nFabio Luporini\n', '\nPaul H. J. Kelly\n']","Bibliography fixes, 23 pages",Geoscientific Model Development 9:3803-3815 (2016),http://dx.doi.org/10.5194/gmd-9-3803-2016,cs.MS,['cs.MS'],10.5194/gmd-9-3803-2016,,[]
"Convex Hull Calculations: a Matlab Implementation and Correctness Proofs
  for the lrs-Algorithm",http://arxiv.org/abs/1604.06112v1,2016-04-20T20:07:48Z,2016-04-20T20:07:48Z,"  This paper provides full \Matlab-code and informal correctness proofs for the
lexicographic reverse search algorithm for convex hull calculations. The
implementation was tested on a 1993 486-PC for various small and some larger,
partially highly degenerate combinatorial polytopes, one of which (a certain
13-dimensional 24 vertex polyhedron) occurs naturally in the study of a well
known problem posed by Professor Graciano de Oliveira: see end of section 1.
","['\nAlexander Kovačec\n', '\nBernardete Ribeiro\n']","21 pages, 2 figures",,http://arxiv.org/abs/1604.06112v1,cs.MS,['cs.MS'],,,[]
"A Left-Looking Selected Inversion Algorithm and Task Parallelism on
  Shared Memory Systems",http://arxiv.org/abs/1604.02528v1,2016-04-09T06:15:15Z,2016-04-09T06:15:15Z,"  Given a sparse matrix $A$, the selected inversion algorithm is an efficient
method for computing certain selected elements of $A^{-1}$. These selected
elements correspond to all or some nonzero elements of the LU factors of $A$.
In many ways, the type of matrix updates performed in the selected inversion
algorithm is similar to that performed in the LU factorization, although the
sequence of operation is different. In the context of LU factorization, it is
known that the left-looking and right-looking algorithms exhibit different
memory access and data communication patterns, and hence different behavior on
shared memory and distributed memory parallel machines. Corresponding to
right-looking and left-looking LU factorization, selected inversion algorithm
can be organized as a left-looking and a right-looking algorithm. The parallel
right-looking version of the algorithm has been developed in [1]. The sequence
of operations performed in this version of the selected inversion algorithm is
similar to those performed in a left-looking LU factorization algorithm. In
this paper, we describe the left-looking variant of the selected inversion
algorithm, and based on task parallel method, present an efficient
implementation of the algorithm for shared memory machines. We demonstrate that
with the task scheduling features provided by OpenMP 4.0, the left-looking
selected inversion algorithm can scale well both on the Intel Haswell multicore
architecture and on the Intel Knights Corner (KNC) manycore architecture.
Compared to the right-looking selected inversion algorithm, the left-looking
formulation facilitates pipelining of work along different branches of the
elimination tree, and can be a promising candidate for future development of
massively parallel selected inversion algorithms on heterogeneous architecture.
","['\nMathias Jacquelin\n', '\nLin Lin\n', '\nWeile Jia\n', '\nYonghua Zhao\n', '\nChao Yang\n']","9 pages, 7 figures, submitted to SuperComputing 2016",,http://arxiv.org/abs/1604.02528v1,cs.MS,['cs.MS'],,,[]
BoxLib with Tiling: An AMR Software Framework,http://arxiv.org/abs/1604.03570v1,2016-04-12T20:13:04Z,2016-04-12T20:13:04Z,"  In this paper we introduce a block-structured adaptive mesh refinement (AMR)
software framework that incorporates tiling, a well-known loop transformation.
Because the multiscale, multiphysics codes built in BoxLib are designed to
solve complex systems at high resolution, performance on current and next
generation architectures is essential. With the expectation of many more cores
per node on next generation architectures, the ability to effectively utilize
threads within a node is essential, and the current model for parallelization
will not be sufficient. We describe a new version of BoxLib in which the tiling
constructs are embedded so that BoxLib-based applications can easily realize
expected performance gains without extra effort on the part of the application
developer. We also discuss a path forward to enable future versions of BoxLib
to take advantage of NUMA-aware optimizations using the TiDA portable library.
","['\nWeiqun Zhang\n', '\nAnn Almgren\n', '\nMarcus Day\n', '\nTan Nguyen\n', '\nJohn Shalf\n', '\nDidem Unat\n']",Accepted for publication in SIAM J. on Scientific Computing,,http://arxiv.org/abs/1604.03570v1,cs.MS,"['cs.MS', 'physics.comp-ph', '97N80']",,,[]
"dMath: A Scalable Linear Algebra and Math Library for Heterogeneous
  GP-GPU Architectures",http://arxiv.org/abs/1604.01416v1,2016-04-05T20:28:26Z,2016-04-05T20:28:26Z,"  A new scalable parallel math library, dMath, is presented in this paper that
demonstrates leading scaling when using intranode, or internode,
hybrid-parallelism for deep-learning. dMath provides easy-to-use distributed
base primitives and a variety of domain-specific algorithms. These include
matrix multiplication, convolutions, and others allowing for rapid development
of highly scalable applications, including Deep Neural Networks (DNN), whereas
previously one was restricted to libraries that provided effective primitives
for only a single GPU, like Nvidia cublas and cudnn or DNN primitives from
Nervana neon framework. Development of HPC software is difficult,
labor-intensive work, requiring a unique skill set. dMath allows a wide range
of developers to utilize parallel and distributed hardware easily. One
contribution of this approach is that data is stored persistently on the GPU
hardware, avoiding costly transfers between host and device. Advanced memory
management techniques are utilized, including caching of transferred data and
memory reuse through pooling. A key contribution of dMath is that it delivers
performance, portability, and productivity to its specific domain of support.
It enables algorithm and application programmers to quickly solve problems
without managing the significant complexity associated with multi-level
parallelism.
","['\nSteven Eliuk\n', '\nCameron Upright\n', '\nAnthony Skjellum\n']",,,http://arxiv.org/abs/1604.01416v1,cs.NE,"['cs.NE', 'cs.DC', 'cs.MS']",,,[]
A Subdivision Solver for Systems of Large Dense Polynomials,http://arxiv.org/abs/1603.07916v2,2016-03-25T14:07:49Z,2016-10-06T14:38:23Z,"  We describe here the package {\tt subdivision\\_solver} for the mathematical
software {\tt SageMath}. It provides a solver on real numbers for square
systems of large dense polynomials. By large polynomials we mean multivariate
polynomials with large degrees, which coefficients have large bit-size. While
staying robust, symbolic approaches to solve systems of polynomials see their
performances dramatically affected by high degree and bit-size of input
polynomials.Available numeric approaches suffer from the cost of the evaluation
of large polynomials and their derivatives.Our solver is based on interval
analysis and bisections of an initial compact domain of $\R^n$ where solutions
are sought. Evaluations on intervals with Horner scheme is performed by the
package {\tt fast\\_polynomial} for {\tt SageMath}.The non-existence of a
solution within a box is certified by an evaluation scheme that uses a Taylor
expansion at order 2, and existence and uniqueness of a solution within a box
is certified with krawczyk operator.The precision of the working arithmetic is
adapted on the fly during the subdivision process and we present a new
heuristic criterion to decide if the arithmetic precision has to be increased.
",['\nRémi Imbach\nVEGAS\n'],,,http://arxiv.org/abs/1603.07916v2,cs.MS,['cs.MS'],,,['VEGAS']
"COCO: A Platform for Comparing Continuous Optimizers in a Black-Box
  Setting",http://arxiv.org/abs/1603.08785v4,2016-03-29T14:18:52Z,2020-09-09T14:41:57Z,"  We introduce COCO, an open source platform for Comparing Continuous
Optimizers in a black-box setting. COCO aims at automatizing the tedious and
repetitive task of benchmarking numerical optimization algorithms to the
greatest possible extent. The platform and the underlying methodology allow to
benchmark in the same framework deterministic and stochastic solvers for both
single and multiobjective optimization. We present the rationales behind the
(decade-long) development of the platform as a general proposition for
guidelines towards better benchmarking. We detail underlying fundamental
concepts of COCO such as the definition of a problem as a function instance,
the underlying idea of instances, the use of target values, and runtime defined
by the number of function calls as the central performance measure. Finally, we
give a quick overview of the basic code structure and the currently available
test suites.
","['\nNikolaus Hansen\nRANDOPT\n', '\nAnne Auger\nRANDOPT\n', '\nRaymond Ros\nTAO\n', '\nOlaf Mersmann\nTU\n', '\nTea Tušar\nIJS\n', '\nDimo Brockhoff\nRANDOPT\n']","Optimization Methods and Software, Taylor & Francis, In press,
  pp.1-31",,http://dx.doi.org/10.1080/10556788.2020.1808977,cs.AI,"['cs.AI', 'cs.MS', 'cs.NA', 'math.NA', 'stat.ML']",10.1080/10556788.2020.1808977,,"['RANDOPT', 'RANDOPT', 'TAO', 'TU', 'IJS', 'RANDOPT']"
"Fast calculation of inverse square root with the use of magic constant
  $-$ analytical approach",http://arxiv.org/abs/1603.04483v1,2016-03-14T21:28:46Z,2016-03-14T21:28:46Z,"  We present a mathematical analysis of transformations used in fast
calculation of inverse square root for single-precision floating-point numbers.
Optimal values of the so called magic constants are derived in a systematic
way, minimizing either absolute or relative errors at subsequent stages of the
discussed algorithm.
","['\nLeonid V. Moroz\n', '\nCezary J. Walczyk\n', '\nAndriy Hrynchyshyn\n', '\nVijay Holimath\n', '\nJan L. Cieśliński\n']","17 pages, 8 figures",,http://arxiv.org/abs/1603.04483v1,cs.MS,"['cs.MS', 'G.1.2; G.4']",,,[]
"Interoperability in the OpenDreamKit Project: The Math-in-the-Middle
  Approach",http://arxiv.org/abs/1603.06424v1,2016-03-21T13:18:44Z,2016-03-21T13:18:44Z,"  OpenDreamKit --- ""Open Digital Research Environment Toolkit for the
Advancement of Mathematics"" --- is an H2020 EU Research Infrastructure project
that aims at supporting, over the period 2015--2019, the ecosystem of
open-source mathematical software systems. From that, OpenDreamKit will deliver
a flexible toolkit enabling research groups to set up Virtual Research
Environments, customised to meet the varied needs of research projects in pure
mathematics and applications.
  An important step in the OpenDreamKit endeavor is to foster the
interoperability between a variety of systems, ranging from computer algebra
systems over mathematical databases to front-ends. This is the mission of the
integration work package (WP6). We report on experiments and future plans with
the \emph{Math-in-the-Middle} approach. This information architecture consists
in a central mathematical ontology that documents the domain and fixes a joint
vocabulary, combined with specifications of the functionalities of the various
systems. Interaction between systems can then be enriched by pivoting off this
information architecture.
","['\nPaul-Olivier Dehaye\n', '\nMichael Kohlhase\n', '\nAlexander Konovalov\n', '\nSamuel Lelièvre\n', '\nMarkus Pfeiffer\n', '\nNicolas M. Thiéry\n']","15 pages, 7 figures",,http://dx.doi.org/10.1007/978-3-319-42547-4_9,cs.MS,['cs.MS'],10.1007/978-3-319-42547-4_9,,[]
SimOutUtils - Utilities for analyzing time series simulation output,http://arxiv.org/abs/1603.06914v4,2016-03-22T19:11:07Z,2017-01-06T12:10:24Z,"  SimOutUtils is a suite of MATLAB/Octave functions for studying and analyzing
time series-like output from stochastic simulation models. More specifically,
SimOutUtils allows modelers to study and visualize simulation output dynamics,
perform distributional analysis of output statistical summaries, as well as
compare these summaries in order to assert the statistical equivalence of two
or more model implementations. Additionally, the provided functions are able to
produce publication quality figures and tables showcasing results from the
specified simulation output studies.
","['\nNuno Fachada\n', '\nVitor V. Lopes\n', '\nRui C. Martins\n', '\nAgostinho C. Rosa\n']","The peer-reviewed version of this paper is published in the Journal
  of Open Research Software at http://doi.org/10.5334/jors.110 . This version
  is typeset by the authors and differs only in pagination and typographical
  detail","Journal of Open Research Software. 4(1), p.e38, 2016",http://dx.doi.org/10.5334/jors.110,cs.MS,"['cs.MS', '62-07', 'D.2.4; G.3; I.6.4; I.6.6']",10.5334/jors.110,,[]
"micompr: An R Package for Multivariate Independent Comparison of
  Observations",http://arxiv.org/abs/1603.06907v5,2016-03-22T18:57:41Z,2017-02-21T19:06:05Z,"  The R package micompr implements a procedure for assessing if two or more
multivariate samples are drawn from the same distribution. The procedure uses
principal component analysis to convert multivariate observations into a set of
linearly uncorrelated statistical measures, which are then compared using a
number of statistical methods. This technique is independent of the
distributional properties of samples and automatically selects features that
best explain their differences. The procedure is appropriate for comparing
samples of time series, images, spectrometric measures or similar
high-dimension multivariate observations.
","['\nNuno Fachada\n', '\nJoão Rodrigues\n', '\nVitor V. Lopes\n', '\nRui C. Martins\n', '\nAgostinho C. Rosa\n']","The peer-reviewed version of this paper is published in The R Journal
  at
  https://journal.r-project.org/archive/2016-2/fachada-rodrigues-lopes-etal.pdf
  . This version is typeset by the authors and differs only in pagination and
  typographical detail","The R Journal, 8(2): 405-420 (2016)",http://dx.doi.org/10.32614/RJ-2016-055,cs.MS,"['cs.MS', 'stat.CO', '62-07, 62H15, 62H25', 'G.3']",10.32614/RJ-2016-055,,[]
States and channels in quantum mechanics without complex numbers,http://arxiv.org/abs/1603.04787v1,2016-03-15T18:00:52Z,2016-03-15T18:00:52Z,"  In the presented note we aim at exploring the possibility of abandoning
complex numbers in the representation of quantum states and operations. We
demonstrate a simplified version of quantum mechanics in which the states are
represented using real numbers only. The main advantage of this approach is
that the simulation of the $n$-dimensional quantum system requires $n^2$ real
numbers, in contrast to the standard case where $n^4$ real numbers are
required. The main disadvantage is the lack of hermicity in the representation
of quantum states. Using Mathematica computer algebra system we develop a set
of functions for manipulating real-only quantum states. With the help of this
tool we study the properties of the introduced representation and the induced
representation of quantum channels.
",['\nJ. A. Miszczak\n'],"10 pages, 2 figures, presented at ACA2015, July 20-23, 2015,
  Kalamata, Greece","Springer Proceedings in Mathematics & Statistics, vol 198 (2017)",http://dx.doi.org/10.1007/978-3-319-56932-1_21,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'quant-ph']",10.1007/978-3-319-56932-1_21,,[]
A Flexible Primal-Dual Toolbox,http://arxiv.org/abs/1603.05835v2,2016-03-18T11:01:23Z,2016-07-20T13:11:14Z,"  \textbf{FlexBox} is a flexible MATLAB toolbox for finite dimensional convex
variational problems in image processing and beyond. Such problems often
consist of non-differentiable parts and involve linear operators. The toolbox
uses a primal-dual scheme to avoid (computationally) inefficient operator
inversion and to get reliable error estimates. From the user-side,
\textbf{FlexBox} expects the primal formulation of the problem, automatically
decouples operators and dualizes the problem. For large-scale problems,
\textbf{FlexBox} also comes with a \cpp-module, which can be used stand-alone
or together with MATLAB via MEX-interfaces. Besides various pre-implemented
data-fidelities and regularization-terms, \textbf{FlexBox} is able to handle
arbitrary operators while being easily extendable, due to its object-oriented
design. The toolbox is available at
\href{http://www.flexbox.im}{http://www.flexbox.im}
",['\nHendrik Dirks\n'],"10 pages, 1 table",,http://arxiv.org/abs/1603.05835v2,math.OC,"['math.OC', 'cs.CV', 'cs.MS', 'I.4; G.1.6; G.4']",,,[]
Automatic Theorem Proving in Walnut,http://arxiv.org/abs/1603.06017v2,2016-03-18T23:53:10Z,2021-05-25T23:20:24Z,"  Walnut is a software package that implements a mechanical decision procedure
for deciding certain combinatorial properties of some special words referred to
as automatic words or automatic sequences. Walnut is written in Java and is
open source. It is licensed under GNU General Public License.
",['\nHamoon Mousavi\n'],Added a few more sections,,http://arxiv.org/abs/1603.06017v2,cs.FL,"['cs.FL', 'cs.LO', 'cs.MS', 'math.CO']",,,[]
"A mixed precision semi-Lagrangian algorithm and its performance on
  accelerators",http://arxiv.org/abs/1603.07008v1,2016-03-22T22:07:18Z,2016-03-22T22:07:18Z,"  In this paper we propose a mixed precision algorithm in the context of the
semi-Lagrangian discontinuous Galerkin method. The performance of this approach
is evaluated on a traditional dual socket workstation as well as on a Xeon Phi
and an NVIDIA K80. We find that the mixed precision algorithm can be
implemented efficiently on these architectures. This implies that, in addition
to the considerable reduction in memory, a substantial increase in performance
can be observed as well. Moreover, we discuss the relative performance of our
implementations.
",['\nLukas Einkemmer\n'],,,http://dx.doi.org/10.1109/HPCSim.2016.7568318,cs.MS,"['cs.MS', 'math.NA', 'physics.comp-ph']",10.1109/HPCSim.2016.7568318,,[]
A New Numerical Method for Solving the Acoustic Radiation Problem,http://arxiv.org/abs/1603.01793v2,2016-03-06T06:21:30Z,2018-05-17T08:51:02Z,"  A numerical method of solving the problem of acoustic wave radiation in the
presence of a rigid scatterer is described. It combines the finite element
method and the boundary algebraic equations. In the proposed method, the
exterior domain around the scatterer is discretized, so that there appear an
infinite domain with regular discretization and a relatively small layer with
irregular mesh. For the infinite regular mesh, the boundary algebraic equation
method is used with spurious resonance suppression according to Burton and
Miller. In the thin layer with irregular mesh, the finite element method is
used. The proposed method is characterized by simple implementation, fair
accuracy, and absence of spurious resonances.
","['\nJ. Poblet-Puig\n', '\nA. V. Shanin\n']",,"Poblet-Puig J., Shanin A.V., A new numerical method for solving
  the acoustic radiation problem. Acoustical Physics. Vol. 64, no. 2. PP.
  252-259 (2018)",http://dx.doi.org/10.1134/S1063771018020148,cs.NA,"['cs.NA', 'cs.MS']",10.1134/S1063771018020148,,[]
TTC: A high-performance Compiler for Tensor Transpositions,http://arxiv.org/abs/1603.02297v1,2016-03-07T21:13:00Z,2016-03-07T21:13:00Z,"  We present TTC, an open-source parallel compiler for multidimensional tensor
transpositions. In order to generate high-performance C++ code, TTC explores a
number of optimizations, including software prefetching, blocking,
loop-reordering, and explicit vectorization. To evaluate the performance of
multidimensional transpositions across a range of possible use-cases, we also
release a benchmark covering arbitrary transpositions of up to six dimensions.
Performance results show that the routines generated by TTC achieve close to
peak memory bandwidth on both the Intel Haswell and the AMD Steamroller
architectures, and yield significant performance gains over modern compilers.
By implementing a set of pruning heuristics, TTC allows users to limit the
number of potential solutions; this option is especially useful when dealing
with high-dimensional tensors, as the search space might become prohibitively
large. Experiments indicate that when only 100 potential solutions are
considered, the resulting performance is about 99% of that achieved with
exhaustive search.
","['\nPaul Springer\n', '\nJeff R. Hammond\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1603.02297v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF']",,,[]
Testing fine-grained parallelism for the ADMM on a factor-graph,http://arxiv.org/abs/1603.02526v1,2016-03-08T14:13:38Z,2016-03-08T14:13:38Z,"  There is an ongoing effort to develop tools that apply distributed
computational resources to tackle large problems or reduce the time to solve
them. In this context, the Alternating Direction Method of Multipliers (ADMM)
arises as a method that can exploit distributed resources like the dual ascent
method and has the robustness and improved convergence of the augmented
Lagrangian method. Traditional approaches to accelerate the ADMM using multiple
cores are problem-specific and often require multi-core programming. By
contrast, we propose a problem-independent scheme of accelerating the ADMM that
does not require the user to write any parallel code. We show that this scheme,
an interpretation of the ADMM as a message-passing algorithm on a factor-graph,
can automatically exploit fine-grained parallelism both in GPUs and
shared-memory multi-core computers and achieves significant speedup in such
diverse application domains as combinatorial optimization, machine learning,
and optimal control. Specifically, we obtain 10-18x speedup using a GPU, and
5-9x using multiple CPU cores, over a serial, optimized C-version of the ADMM,
which is similar to the typical speedup reported for existing GPU-accelerated
libraries, including cuFFT (19x), cuBLAS (17x), and cuRAND (8x).
","['\nNing Hao\n', '\nAmirReza Oghbaee\n', '\nMohammad Rostami\n', '\nNate Derbinsky\n', '\nJosé Bento\n']",,,http://arxiv.org/abs/1603.02526v1,cs.DC,"['cs.DC', 'cs.MS', 'math.OC']",,,[]
"Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic
  Differentiation",http://arxiv.org/abs/1603.03236v4,2016-03-10T12:23:12Z,2016-09-08T09:23:08Z,"  Optimization on manifolds is a class of methods for optimization of an
objective function, subject to constraints which are smooth, in the sense that
the set of points which satisfy the constraints admits the structure of a
differentiable manifold. While many optimization problems are of the described
form, technicalities of differential geometry and the laborious calculation of
derivatives pose a significant barrier for experimenting with these methods.
  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox
for optimization on manifolds, implemented in Python, that---similarly to the
Manopt Matlab toolbox---implements several manifold geometries and optimization
algorithms. Moreover, we lower the barriers to users further by using automated
differentiation for calculating derivative information, saving users time and
saving them from potential calculation and implementation errors.
","['\nJames Townsend\n', '\nNiklas Koep\n', '\nSebastian Weichwald\n']",,"Journal of Machine Learning Research, 17(137):1-5, 2016 (
  https://jmlr.org/papers/v17/16-177.html )",http://arxiv.org/abs/1603.03236v4,cs.MS,"['cs.MS', 'cs.LG', 'math.OC', 'stat.ML']",,,[]
"Algorithm 979: Recursive Algorithms for Dense Linear Algebra -- The
  ReLAPACK Collection",http://arxiv.org/abs/1602.06763v2,2016-02-22T13:21:05Z,2022-04-06T06:32:17Z,"  To exploit both memory locality and the full performance potential of highly
tuned kernels, dense linear algebra libraries such as LAPACK commonly implement
operations as blocked algorithms. However, to achieve next-to-optimal
performance with such algorithms, significant tuning is required. On the other
hand, recursive algorithms are virtually tuning free, and yet attain similar
performance. In this paper, we first analyze and compare blocked and recursive
algorithms in terms of performance, and then introduce ReLAPACK, an open-source
library of recursive algorithms to seamlessly replace most of LAPACK's blocked
algorithms. In many scenarios, ReLAPACK clearly outperforms reference LAPACK,
and even improves upon the performance of optimizes libraries.
","['\nElmar Peise\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",,,http://arxiv.org/abs/1602.06763v2,cs.MS,"['cs.MS', 'cs.PF']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
Differentiation of the Cholesky decomposition,http://arxiv.org/abs/1602.07527v1,2016-02-24T14:35:31Z,2016-02-24T14:35:31Z,"  We review strategies for differentiating matrix-based computations, and
derive symbolic and algorithmic update rules for differentiating expressions
containing the Cholesky decomposition. We recommend new `blocked' algorithms,
based on differentiating the Cholesky algorithm DPOTRF in the LAPACK library,
which uses `Level 3' matrix-matrix operations from BLAS, and so is
cache-friendly and easy to parallelize. For large matrices, the resulting
algorithms are the fastest way to compute Cholesky derivatives, and are an
order of magnitude faster than the algorithms in common usage. In some
computing environments, symbolically-derived updates are faster for small
matrices than those based on differentiating Cholesky algorithms. The symbolic
and algorithmic approaches can be combined to get the best of both worlds.
",['\nIain Murray\n'],"18 pages, including 7 pages of code listings",,http://arxiv.org/abs/1602.07527v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
Alpaka - An Abstraction Library for Parallel Kernel Acceleration,http://arxiv.org/abs/1602.08477v1,2016-02-26T20:49:37Z,2016-02-26T20:49:37Z,"  Porting applications to new hardware or programming models is a tedious and
error prone process. Every help that eases these burdens is saving developer
time that can then be invested into the advancement of the application itself
instead of preserving the status-quo on a new platform.
  The Alpaka library defines and implements an abstract hierarchical redundant
parallelism model. The model exploits parallelism and memory hierarchies on a
node at all levels available in current hardware. By doing so, it allows to
achieve platform and performance portability across various types of
accelerators by ignoring specific unsupported levels and utilizing only the
ones supported on a specific accelerator. All hardware types (multi- and
many-core CPUs, GPUs and other accelerators) are supported for and can be
programmed in the same way. The Alpaka C++ template interface allows for
straightforward extension of the library to support other accelerators and
specialization of its internals for optimization.
  Running Alpaka applications on a new (and supported) platform requires the
change of only one source code line instead of a lot of \#ifdefs.
","['\nErik Zenker\n', '\nBenjamin Worpitz\n', '\nRené Widera\n', '\nAxel Huebl\n', '\nGuido Juckeland\n', '\nAndreas Knüpfer\n', '\nWolfgang E. Nagel\n', '\nMichael Bussmann\n']","10 pages, 10 figures",,http://dx.doi.org/10.1109/IPDPSW.2016.50,cs.DC,"['cs.DC', 'cs.MS']",10.1109/IPDPSW.2016.50,,[]
Extending DUNE: The dune-xt modules,http://arxiv.org/abs/1602.08991v1,2016-02-25T22:42:50Z,2016-02-25T22:42:50Z,"  We present our effort to extend and complement the core modules of the
Distributed and Unified Numerics Environment DUNE (http://dune-project.org) by
a well tested and structured collection of utilities and concepts. We describe
key elements of our four modules dune-xt-common, dune-xt-grid, dune-xt-la and
dune-xt-functions, which aim at further enabling the programming of generic
algorithms within DUNE as well as adding an extra layer of usability and
convenience.
","['\nTobias Leibner\n', '\nRené Milk\n', '\nFelix Schindler\n']",,"Archive of Numerical Software, 5 (2017), pp. 193-216",http://dx.doi.org/10.11588/ans.2017.1.27720,cs.MS,"['cs.MS', 'math.NA']",10.11588/ans.2017.1.27720,,[]
Oasis: a high-level/high-performance open source Navier-Stokes solver,http://arxiv.org/abs/1602.03643v1,2016-02-11T08:56:43Z,2016-02-11T08:56:43Z,"  Oasis is a high-level/high-performance finite element Navier-Stokes solver
written from scratch in Python using building blocks from the FEniCS project
(fenicsproject.org). The solver is unstructured and targets large-scale
applications in complex geometries on massively parallel clusters. Oasis
utilizes MPI and interfaces, through FEniCS, to the linear algebra backend
PETSc. Oasis advocates a high-level, programmable user interface through the
creation of highly flexible Python modules for new problems. Through the
high-level Python interface the user is placed in complete control of every
aspect of the solver. A version of the solver, that is using piecewise linear
elements for both velocity and pressure, is shown reproduce very well the
classical, spectral, turbulent channel simulations of Moser, Kim and Mansour at
$Re_{\tau}=180$ [Phys. Fluids, vol 11(4), p. 964]. The computational speed is
strongly dominated by the iterative solvers provided by the linear algebra
backend, which is arguably the best performance any similar implicit solver
using PETSc may hope for. Higher order accuracy is also demonstrated and new
solvers may be easily added within the same framework.
","['\nMikael Mortensen\n', '\nKristian Valen-Sendstad\n']",,"Computer Physics Communications, Volume 188, p 177-188, 2015",http://dx.doi.org/10.1016/j.cpc.2014.10.026,cs.MS,['cs.MS'],10.1016/j.cpc.2014.10.026,,[]
"High performance Python for direct numerical simulations of turbulent
  flows",http://arxiv.org/abs/1602.03638v1,2016-02-11T08:12:37Z,2016-02-11T08:12:37Z,"  Direct Numerical Simulations (DNS) of the Navier Stokes equations is an
invaluable research tool in fluid dynamics. Still, there are few publicly
available research codes and, due to the heavy number crunching implied,
available codes are usually written in low-level languages such as C/C++ or
Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS
code that nearly matches the performance of C++ for thousands of processors and
billions of unknowns. We also describe a version optimized through Cython, that
is found to match the speed of C++. The solvers are written from scratch in
Python, both the mesh, the MPI domain decomposition, and the temporal
integrators. The solvers have been verified and benchmarked on the Shaheen
supercomputer at the KAUST supercomputing laboratory, and we are able to show
very good scaling up to several thousand cores.
  A very important part of the implementation is the mesh decomposition (we
implement both slab and pencil decompositions) and 3D parallel Fast Fourier
Transforms (FFT). The mesh decomposition and FFT routines have been implemented
in Python using serial FFT routines (either NumPy, pyFFTW or any other serial
FFT module), NumPy array manipulations and with MPI communications handled by
MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT
in Python for a slab mesh decomposition using 4 lines of compact Python code,
for which the parallel performance on Shaheen is found to be slightly better
than similar routines provided through the FFTW library. For a pencil mesh
decomposition 7 lines of code is required to execute a transform.
","['\nMikael Mortensen\n', '\nHans Petter Langtangen\n']",,,http://dx.doi.org/10.1016/j.cpc.2016.02.005,cs.MS,"['cs.MS', 'cs.DC']",10.1016/j.cpc.2016.02.005,,[]
An SSD-based eigensolver for spectral analysis on billion-node graphs,http://arxiv.org/abs/1602.01421v3,2016-02-03T19:23:44Z,2016-02-26T06:43:03Z,"  Many eigensolvers such as ARPACK and Anasazi have been developed to compute
eigenvalues of a large sparse matrix. These eigensolvers are limited by the
capacity of RAM. They run in memory of a single machine for smaller eigenvalue
problems and require the distributed memory for larger problems.
  In contrast, we develop an SSD-based eigensolver framework called FlashEigen,
which extends Anasazi eigensolvers to SSDs, to compute eigenvalues of a graph
with hundreds of millions or even billions of vertices in a single machine.
FlashEigen performs sparse matrix multiplication in a semi-external memory
fashion, i.e., we keep the sparse matrix on SSDs and the dense matrix in
memory. We store the entire vector subspace on SSDs and reduce I/O to improve
performance through caching the most recent dense matrix. Our result shows that
FlashEigen is able to achieve 40%-60% performance of its in-memory
implementation and has performance comparable to the Anasazi eigensolvers on a
machine with 48 CPU cores. Furthermore, it is capable of scaling to a graph
with 3.4 billion vertices and 129 billion edges. It takes about four hours to
compute eight eigenvalues of the billion-node graph using 120 GB memory.
","['\nDa Zheng\n', '\nRandal Burns\n', '\nJoshua Vogelstein\n', '\nCarey E. Priebe\n', '\nAlexander S. Szalay\n']",,,http://arxiv.org/abs/1602.01421v3,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Inv-ASKIT: A Parallel Fast Diret Solver for Kernel Matrices,http://arxiv.org/abs/1602.01376v1,2016-02-03T17:23:24Z,2016-02-03T17:23:24Z,"  We present a parallel algorithm for computing the approximate factorization
of an $N$-by-$N$ kernel matrix. Once this factorization has been constructed
(with $N \log^2 N $ work), we can solve linear systems with this matrix with $N
\log N $ work. Kernel matrices represent pairwise interactions of points in
metric spaces. They appear in machine learning, approximation theory, and
computational physics. Kernel matrices are typically dense (matrix
multiplication scales quadratically with $N$) and ill-conditioned (solves can
require 100s of Krylov iterations). Thus, fast algorithms for matrix
multiplication and factorization are critical for scalability.
  Recently we introduced ASKIT, a new method for approximating a kernel matrix
that resembles N-body methods. Here we introduce INV-ASKIT, a factorization
scheme based on ASKIT. We describe the new method, derive complexity estimates,
and conduct an empirical study of its accuracy and scalability. We report
results on real-world datasets including ""COVTYPE"" ($0.5$M points in 54
dimensions), ""SUSY"" ($4.5$M points in 8 dimensions) and ""MNIST"" (2M points in
784 dimensions) using shared and distributed memory parallelism. In our largest
run we approximately factorize a dense matrix of size 32M $\times$ 32M
(generated from points in 64 dimensions) on 4,096 Sandy-Bridge cores. To our
knowledge these results improve the state of the art by several orders of
magnitude.
","['\nChenhan D. Yu\n', '\nWilliam B. March\n', '\nBo Xiao\n', '\nGeorge Biros\n']","11 pages, 2 figures, to appear in IPDPS 2016",,http://arxiv.org/abs/1602.01376v1,cs.NA,"['cs.NA', 'cs.DS', 'cs.MS']",,,[]
"Task Parallel Incomplete Cholesky Factorization using 2D
  Partitioned-Block Layout",http://arxiv.org/abs/1601.05871v1,2016-01-22T03:19:45Z,2016-01-22T03:19:45Z,"  We introduce a task-parallel algorithm for sparse incomplete Cholesky
factorization that utilizes a 2D sparse partitioned-block layout of a matrix.
Our factorization algorithm follows the idea of algorithms-by-blocks by using
the block layout. The algorithm-by-blocks approach induces a task graph for the
factorization. These tasks are inter-related to each other through their data
dependences in the factorization algorithm. To process the tasks on various
manycore architectures in a portable manner, we also present a portable tasking
API that incorporates different tasking backends and device-specific features
using an open-source framework for manycore platforms i.e., Kokkos. A
performance evaluation is presented on both Intel Sandybridge and Xeon Phi
platforms for matrices from the University of Florida sparse matrix collection
to illustrate merits of the proposed task-based factorization. Experimental
results demonstrate that our task-parallel implementation delivers about 26.6x
speedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and
19.2x speedup over serial Cholesky performance which does not carry tasking
overhead using 56 threads on the Intel Xeon Phi processor for sparse matrices
arising from various application problems.
","['\nKyungjoo Kim\n', '\nSivasankaran Rajamanickam\n', '\nGeorge Stelle\n', '\nH. Carter Edwards\n', '\nStephen L. Olivier\n']",25 pages,,http://arxiv.org/abs/1601.05871v1,cs.MS,"['cs.MS', '68W10']",,,[]
Vectorization of Multibyte Floating Point Data Formats,http://arxiv.org/abs/1601.07789v3,2016-01-26T13:24:40Z,2016-07-22T14:38:42Z,"  We propose a scheme for reduced-precision representation of floating point
data on a continuum between IEEE-754 floating point types. Our scheme enables
the use of lower precision formats for a reduction in storage space
requirements and data transfer volume. We describe how our scheme can be
accelerated using existing hardware vector units on a general-purpose processor
(GPP). Exploiting native vector hardware allows us to support reduced precision
floating point with low overhead. We demonstrate that supporting reduced
precision in the compiler as opposed to using a library approach can yield a
low overhead solution for GPPs.
","['\nAndrew Anderson\n', '\nDavid Gregg\n']",,,http://dx.doi.org/10.1145/2967938.2967966,cs.MS,"['cs.MS', 'D.3.4; G.1.0; B.2.4; I.4.2']",10.1145/2967938.2967966,,[]
"Reducing local minima in fitness landscapes of parameter estimation by
  using piecewise evaluation and state estimation",http://arxiv.org/abs/1601.04458v1,2016-01-18T10:38:52Z,2016-01-18T10:38:52Z,"  Ordinary differential equations (ODE) are widely used for modeling in Systems
Biology. As most commonly only some of the kinetic parameters are measurable or
precisely known, parameter estimation techniques are applied to parametrize the
model to experimental data. A main challenge for the parameter estimation is
the complexity of the parameter space, especially its high dimensionality and
local minima.
  Parameter estimation techniques consist of an objective function, measuring
how well a certain parameter set describes the experimental data, and an
optimization algorithm that optimizes this objective function. A lot of effort
has been spent on developing highly sophisticated optimization algorithms to
cope with the complexity in the parameter space, but surprisingly few articles
address the influence of the objective function on the computational complexity
in finding global optima. We extend a recently developed multiple shooting for
stochastic systems (MSS) objective function for parameter estimation of
stochastic models and apply it to parameter estimation of ODE models. This MSS
objective function treats the intervals between measurement points separately.
This separate treatment allows the ODE trajectory to stay closer to the data
and we show that it reduces the complexity of the parameter space.
  We use examples from Systems Biology, namely a Lotka-Volterra model, a
FitzHugh-Nagumo oscillator and a Calcium oscillation model, to demonstrate the
power of the MSS approach for reducing the complexity and the number of local
minima in the parameter space. The approach is fully implemented in the COPASI
software package and, therefore, easily accessible for a wide community of
researchers.
","['\nChristoph Zimmer\n', '\nFrank T. Bergmann\n', '\nSven Sahle\n']",,,http://arxiv.org/abs/1601.04458v1,q-bio.QM,"['q-bio.QM', 'cs.DS', 'cs.MS']",,,[]
Software for enumerative and analytic combinatorics,http://arxiv.org/abs/1601.02683v1,2016-01-11T23:03:10Z,2016-01-11T23:03:10Z,"  We survey some general-purpose symbolic software packages that implement
algorithms from enumerative and analytic combinatorics. Software for the
following areas is covered: basic combinatorial objects, symbolic
combinatorics, P\'olya theory, combinatorial species, and asymptotics. We
describe the capabilities that the packages offer as well as some of the
algorithms used, and provide links to original documentation. Most of the
packages are freely downloadable from the web.
",['\nAndrew MacFie\n'],,,http://arxiv.org/abs/1601.02683v1,cs.MS,"['cs.MS', 'math.CO', '68R99', 'G.4']",,,[]
"Evaluation of the Partitioned Global Address Space (PGAS) model for an
  inviscid Euler solver",http://arxiv.org/abs/1601.03623v2,2016-01-14T15:30:47Z,2016-11-12T20:50:57Z,"  In this paper we evaluate the performance of Unified Parallel C (which
implements the partitioned global address space programming model) using a
numerical method that is widely used in fluid dynamics. In order to evaluate
the incremental approach to parallelization (which is possible with UPC) and
its performance characteristics, we implement different levels of optimization
of the UPC code and compare it with an MPI parallelization on four different
clusters of the Austrian HPC infrastructure (LEO3, LEO3E, VSC2, VSC3) and on an
Intel Xeon Phi. We find that UPC is significantly easier to develop in compared
to MPI and that the performance achieved is comparable to MPI in most
situations. The obtained results show worse performance (on VSC2), competitive
performance (on LEO3, LEO3E and VSC3), and superior performance (on the Intel
Xeon Phi).
","['\nMartina Prugger\n', '\nLukas Einkemmer\n', '\nAlexander Ostermann\n']",Parallel Computing 2016,"Parallel Computing, Volume 60, December 2016, Pages 22-40",http://dx.doi.org/10.1016/j.parco.2016.11.001,cs.DC,"['cs.DC', 'cs.MS']",10.1016/j.parco.2016.11.001,,[]
The interface for functions in the dune-functions module,http://arxiv.org/abs/1512.06136v1,2015-12-18T21:09:10Z,2015-12-18T21:09:10Z,"  The dune-functions dune module introduces a new programmer interface for
discrete and non-discrete functions. Unlike the previous interfaces considered
in the existing dune modules, it is based on overloading operator(), and
returning values by-value. This makes user code much more readable, and allows
the incorporation of newer C++ features such as lambda expressions. Run-time
polymorphism is implemented not by inheritance, but by type erasure,
generalizing the ideas of the std::function class from the C++11 standard
library. We describe the new interface, show its possibilities, and measure the
performance impact of type erasure and return-by-value.
","['\nChristian Engwer\n', '\nCarsten Gräser\n', '\nSteffen Müthing\n', '\nOliver Sander\n']",The C++ source code of tests is attached to pdf file of the paper,Archive of Numerical Software 5 (2017) 95-109,http://dx.doi.org/10.11588/ans.2017.1.27683,cs.MS,"['cs.MS', '68N99']",10.11588/ans.2017.1.27683,,[]
"An Extension of Moebius--Lie Geometry with Conformal Ensembles of Cycles
  and Its Implementation in a GiNaC Library",http://arxiv.org/abs/1512.02960v3,2015-12-09T17:32:30Z,2018-08-19T20:16:48Z,"  We propose to consider ensembles of cycles (quadrics), which are
interconnected through conformal-invariant geometric relations (e.g. ""to be
orthogonal"", ""to be tangent"", etc.), as new objects in an extended Moebius--Lie
geometry. It was recently demonstrated in several related papers, that such
ensembles of cycles naturally parameterise many other conformally-invariant
objects, e.g. loxodromes or continued fractions. The paper describes a method,
which reduces a collection of conformally invariant geometric relations to a
system of linear equations, which may be accompanied by one fixed quadratic
relation.
  To show its usefulness, the method is implemented as a C++ library. It
operates with numeric and symbolic data of cycles in spaces of arbitrary
dimensionality and metrics with any signatures. Numeric calculations can be
done in exact or approximate arithmetic. In the two- and three-dimensional
cases illustrations and animations can be produced. An interactive Python
wrapper of the library is provided as well.
",['\nVladimir V. Kisil\n'],"LaTeX 16pp+111pp of appendices, including 10 PDF graphic files and
  program code; v2: major revision of the paper, code in v3.1; v3: formal
  definition of the extended geometry, connection with integrable systems, code
  in v3.2rc1","Proc. Int. Geom. Cent. v.11 (2018), n.3, pp.45-67",http://dx.doi.org/10.15673/tmgc.v11i3.1203,cs.CG,"['cs.CG', 'cs.MS', 'cs.SC', 'math.DG', '51B25, 51N25, 68U05, 11E88, 68W30']",10.15673/tmgc.v11i3.1203,,[]
Grid: A next generation data parallel C++ QCD library,http://arxiv.org/abs/1512.03487v1,2015-12-10T23:51:19Z,2015-12-10T23:51:19Z,"  In this proceedings we discuss the motivation, implementation details, and
performance of a new physics code base called Grid. It is intended to be more
performant, more general, but similar in spirit to QDP++\cite{QDP}. Our
approach is to engineer the basic type system to be consistently fast, rather
than bolt on a few optimised routines, and we are attempt to write all our
optimised routines directly in the Grid framework. It is hoped this will
deliver best known practice performance across the next generation of
supercomputers, which will provide programming challenges to traditional scalar
codes.
  We illustrate the programming patterns used to implement our goals, and
advances in productivity that have been enabled by using new features in C++11.
","['\nPeter Boyle\n', '\nAzusa Yamaguchi\n', '\nGuido Cossu\n', '\nAntonin Portelli\n']","14 pages, Lattice 2015",,http://arxiv.org/abs/1512.03487v1,hep-lat,"['hep-lat', 'cs.DC', 'cs.MS']",,,[]
DiffSharp: Automatic Differentiation Library,http://arxiv.org/abs/1511.07727v2,2015-11-24T14:28:13Z,2015-11-26T16:32:40Z,"  In this paper we introduce DiffSharp, an automatic differentiation (AD)
library designed with machine learning in mind. AD is a family of techniques
that evaluate derivatives at machine precision with only a small constant
factor of overhead, by systematically applying the chain rule of calculus at
the elementary operator level. DiffSharp aims to make an extensive array of AD
techniques available, in convenient form, to the machine learning community.
These including arbitrary nesting of forward/reverse AD operations, AD with
linear algebra primitives, and a functional API that emphasizes the use of
higher-order functions and composition. The library exposes this functionality
through an API that provides gradients, Hessians, Jacobians, directional
derivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the
performance requirements of the latest machine learning techniques in mind, the
underlying computations are run through a high-performance BLAS/LAPACK backend,
using OpenBLAS by default. GPU support is currently being implemented.
","['\nAtilim Gunes Baydin\n', '\nBarak A. Pearlmutter\n', '\nJeffrey Mark Siskind\n']","5 pages, 1 figure, minor fixes, added coauthor",,http://arxiv.org/abs/1511.07727v2,cs.MS,"['cs.MS', '68T05, 68W30', 'I.2.6; G.1.4']",,,[]
Sparse Tensor Algebra as a Parallel Programming Model,http://arxiv.org/abs/1512.00066v1,2015-11-30T22:08:23Z,2015-11-30T22:08:23Z,"  Dense and sparse tensors allow the representation of most bulk data
structures in computational science applications. We show that sparse tensor
algebra can also be used to express many of the transformations on these
datasets, especially those which are parallelizable. Tensor computations are a
natural generalization of matrix and graph computations. We extend the usual
basic operations of tensor summation and contraction to arbitrary functions,
and further operations such as reductions and mapping. The expression of these
transformations in a high-level sparse linear algebra domain specific language
allows our framework to understand their properties at runtime to select the
preferred communication-avoiding algorithm. To demonstrate the efficacy of our
approach, we show how key graph algorithms as well as common numerical kernels
can be succinctly expressed using our interface and provide performance results
of a general library implementation.
","['\nEdgar Solomonik\n', '\nTorsten Hoefler\n']",,,http://arxiv.org/abs/1512.00066v1,cs.MS,['cs.MS'],,,[]
"MXNet: A Flexible and Efficient Machine Learning Library for
  Heterogeneous Distributed Systems",http://arxiv.org/abs/1512.01274v1,2015-12-03T22:49:21Z,2015-12-03T22:49:21Z,"  MXNet is a multi-language machine learning (ML) library to ease the
development of ML algorithms, especially for deep neural networks. Embedded in
the host language, it blends declarative symbolic expression with imperative
tensor computation. It offers auto differentiation to derive gradients. MXNet
is computation and memory efficient and runs on various heterogeneous systems,
ranging from mobile devices to distributed GPU clusters.
  This paper describes both the API design and the system implementation of
MXNet, and explains how embedding of both symbolic expression and tensor
operation is handled in a unified fashion. Our preliminary experiments reveal
promising results on large scale deep neural network applications using
multiple GPU machines.
","['\nTianqi Chen\n', '\nMu Li\n', '\nYutian Li\n', '\nMin Lin\n', '\nNaiyan Wang\n', '\nMinjie Wang\n', '\nTianjun Xiao\n', '\nBing Xu\n', '\nChiyuan Zhang\n', '\nZheng Zhang\n']","In Neural Information Processing Systems, Workshop on Machine
  Learning Systems, 2016",,http://arxiv.org/abs/1512.01274v1,cs.DC,"['cs.DC', 'cs.LG', 'cs.MS', 'cs.NE']",,,[]
Computing with Harmonic Functions,http://arxiv.org/abs/1511.05986v2,2015-11-15T19:33:39Z,2016-11-07T05:06:40Z,"  This document is the manual for a free Mathematica package for computing with
harmonic functions. This package allows the user to make calculations that
would take a prohibitive amount of time if done without a computer. For
example, the Poisson integral of any polynomial can be computed exactly. This
software can find exact solutions to Dirichlet, Neumann, and biDirichlet
problems in R^n with polynomial data on balls, ellipsoids, and annular regions.
It can also find bases for spaces of spherical harmonics, compute projections
onto the harmonic Bergman space, and perform other manipulations with harmonic
functions.
",['\nSheldon Axler\n'],77 pages. Software available at http://axler.net/HFT_Math.html,,http://arxiv.org/abs/1511.05986v2,cs.MS,"['cs.MS', '31B05, 31B20']",,,[]
mplrs: A scalable parallel vertex/facet enumeration code,http://arxiv.org/abs/1511.06487v4,2015-11-20T04:54:22Z,2017-10-12T01:44:42Z,"  We describe a new parallel implementation, mplrs, of the vertex enumeration
code lrs that uses the MPI parallel environment and can be run on a network of
computers. The implementation makes use of a C wrapper that essentially uses
the existing lrs code with only minor modifications. mplrs was derived from the
earlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses
the Boost library and runs on a shared memory machine. In developing mplrs we
discovered a method of balancing the parallel tree search, called budgeting,
that greatly improves parallelization beyond the bottleneck encountered
previously at around 32 cores.
  This method can be readily adapted for use in other reverse search
enumeration codes. We also report some preliminary computational results
comparing parallel and sequential codes for vertex/facet enumeration problems
for convex polyhedra. The problems chosen span the range from simple to highly
degenerate polytopes. For most problems tested, the results clearly show the
advantage of using the parallel implementation mplrs of the reverse search
based code lrs, even when as few as 8 cores are available. For some problems
almost linear speedup was observed up to 1200 cores, the largest number of
cores tested.
","['\nDavid Avis\n', '\nCharles Jordan\n']",Revision incorporating additional suggested changes,,http://arxiv.org/abs/1511.06487v4,cs.MS,"['cs.MS', 'cs.CG', 'cs.DC', '90C05']",,,[]
"BOAT: a cross-platform software for data analysis and numerical
  computing with arbitrary-precision",http://arxiv.org/abs/1511.03167v1,2015-11-10T16:22:27Z,2015-11-10T16:22:27Z,"  BOAT is a free cross-platform software for statistical data analysis and
numerical computing. Thanks to its multiple-precision floating point engine, it
allows arbitrary-precision calculations, whose digits of precision are only
limited by the amount of memory of the host machine. At the core of the
software is a simple and efficient expression language, whose use is
facilitated by the assisted typing, the auto-complete engine and the built-in
help for the syntax. In this paper a quick overview of the software is given.
Detailed information, together with its applications to some case studies, is
available at the BOAT web page.
",['\nDavide Pagano\n'],,,http://arxiv.org/abs/1511.03167v1,cs.MS,['cs.MS'],,,[]
Exact diagonalization of quantum lattice models on coprocessors,http://arxiv.org/abs/1511.00863v2,2015-11-03T11:26:28Z,2016-05-24T11:20:06Z,"  We implement the Lanczos algorithm on an Intel Xeon Phi coprocessor and
compare its performance to a multi-core Intel Xeon CPU and an NVIDIA graphics
processor. The Xeon and the Xeon Phi are parallelized with OpenMP and the
graphics processor is programmed with CUDA. The performance is evaluated by
measuring the execution time of a single step in the Lanczos algorithm. We
study two quantum lattice models with different particle numbers, and conclude
that for small systems, the multi-core CPU is the fastest platform, while for
large systems, the graphics processor is the clear winner, reaching speedups of
up to 7.6 compared to the CPU. The Xeon Phi outperforms the CPU with
sufficiently large particle number, reaching a speedup of 2.5.
","['\nTopi Siro\n', '\nAri Harju\n']",,,http://dx.doi.org/10.1016/j.cpc.2016.07.018,cond-mat.str-el,"['cond-mat.str-el', 'cs.MS']",10.1016/j.cpc.2016.07.018,,[]
"Multi-Threaded Dense Linear Algebra Libraries for Low-Power Asymmetric
  Multicore Processors",http://arxiv.org/abs/1511.02171v1,2015-11-06T17:36:20Z,2015-11-06T17:36:20Z,"  Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant
collection of numerical tools for many scientific and engineering applications.
While there exist high performance implementations of the BLAS (and LAPACK)
functionality for many current multi-threaded architectures,the adaption of
these libraries for asymmetric multicore processors (AMPs)is still pending. In
this paper we address this challenge by developing an asymmetry-aware
implementation of the BLAS, based on the BLIS framework, and tailored for AMPs
equipped with two types of cores: fast/power hungry versus slow/energy
efficient. For this purpose, we integrate coarse-grain and fine-grain
parallelization strategies into the library routines which, respectively,
dynamically distribute the workload between the two core types and statically
repartition this work among the cores of the same type.
  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,
using the asymmetry-aware version of the BLAS and a plain migration of the
legacy version of LAPACK, experimentally assess the benefits, limitations, and
potential of this approach.
","['\nSandra Catalán\n', '\nJosé R. Herrero\n', '\nFrancisco D. Igual\n', '\nRafael Rodríguez-Sánchez\n', '\nEnrique S. Quintana-Ortí\n']",,,http://arxiv.org/abs/1511.02171v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
The Dune FoamGrid implementation for surface and network grids,http://arxiv.org/abs/1511.03415v1,2015-11-11T08:23:46Z,2015-11-11T08:23:46Z,"  We present FoamGrid, a new implementation of the DUNE grid interface.
FoamGrid implements one- and two-dimensional grids in a physical space of
arbitrary dimension, which allows for grids for curved domains. Even more, the
grids are not expected to have a manifold structure, i.e., more than two
elements can share a common facet. This makes FoamGrid the grid data structure
of choice for simulating structures such as foams, discrete fracture networks,
or network flow problems. FoamGrid implements adaptive non-conforming
refinement with element parametrizations. As an additional feature it allows
removal and addition of elements in an existing grid, which makes FoamGrid
suitable for network growth problems. We show how to use FoamGrid, with
particular attention to the extensions of the grid interface needed to handle
non-manifold topology and grid growth. Three numerical examples demonstrate the
possibilities offered by FoamGrid.
","['\nOliver Sander\n', '\nTimo Koch\n', '\nNatalie Schröder\n', '\nBernd Flemisch\n']",,Archive of Numerical Software Vol 5 No 1 2017,http://dx.doi.org/10.11588/ans.2017.1.28490,cs.MS,"['cs.MS', 'cs.CE']",10.11588/ans.2017.1.28490,,[]
"Embedded Ensemble Propagation for Improving Performance, Portability and
  Scalability of Uncertainty Quantification on Emerging Computational
  Architectures",http://arxiv.org/abs/1511.03703v1,2015-11-11T21:55:35Z,2015-11-11T21:55:35Z,"  Quantifying simulation uncertainties is a critical component of rigorous
predictive simulation. A key component of this is forward propagation of
uncertainties in simulation input data to output quantities of interest.
Typical approaches involve repeated sampling of the simulation over the
uncertain input data, and can require numerous samples when accurately
propagating uncertainties from large numbers of sources. Often simulation
processes from sample to sample are similar and much of the data generated from
each sample evaluation could be reused. We explore a new method for
implementing sampling methods that simultaneously propagates groups of samples
together in an embedded fashion, which we call embedded ensemble propagation.
We show how this approach takes advantage of properties of modern computer
architectures to improve performance by enabling reuse between samples,
reducing memory bandwidth requirements, improving memory access patterns,
improving opportunities for fine-grained parallelization, and reducing
communication costs. We describe a software technique for implementing embedded
ensemble propagation based on the use of C++ templates and describe its
integration with various scientific computing libraries within Trilinos. We
demonstrate improved performance, portability and scalability for the approach
applied to the simulation of partial differential equations on a variety of
CPU, GPU, and accelerator architectures, including up to 131,072 cores on a
Cray XK7 (Titan).
","['\nE. Phipps\n', ""\nM. D'Elia\n"", '\nH. C. Edwards\n', '\nM. Hoemmen\n', '\nJ. Hu\n', '\nS. Rajamanickam\n']",,,http://arxiv.org/abs/1511.03703v1,cs.MS,"['cs.MS', 'cs.CE']",,,[]
"A quantitative performance analysis for Stokes solvers at the extreme
  scale",http://arxiv.org/abs/1511.02134v1,2015-11-06T16:07:04Z,2015-11-06T16:07:04Z,"  This article presents a systematic quantitative performance analysis for
large finite element computations on extreme scale computing systems. Three
parallel iterative solvers for the Stokes system, discretized by low order
tetrahedral elements, are compared with respect to their numerical efficiency
and their scalability running on up to $786\,432$ parallel threads. A genuine
multigrid method for the saddle point system using an Uzawa-type smoother
provides the best overall performance with respect to memory consumption and
time-to-solution. The largest system solved on a Blue Gene/Q system has more
than ten trillion ($1.1 \cdot 10 ^{13}$) unknowns and requires about 13 minutes
compute time. Despite the matrix free and highly optimized implementation, the
memory requirement for the solution vector and the auxiliary vectors is about
200 TByte. Brandt's notion of ""textbook multigrid efficiency"" is employed to
study the algorithmic performance of iterative solvers. A recent extension of
this paradigm to ""parallel textbook multigrid efficiency"" makes it possible to
assess also the efficiency of parallel iterative solvers for a given hardware
architecture in absolute terms. The efficiency of the method is demonstrated
for simulating incompressible fluid flow in a pipe filled with spherical
obstacles.
","['\nBjörn Gmeiner\n', '\nMarkus Huber\n', '\nLorenz John\n', '\nUlrich Rüde\n', '\nBarbara Wohlmuth\n']",,,http://arxiv.org/abs/1511.02134v1,cs.CE,"['cs.CE', 'cs.MS', 'cs.NA', 'math.NA', '65N55, 65Y05, 68Q25']",,,[]
"Evaluation of the Intel Xeon Phi 7120 and NVIDIA K80 as accelerators for
  two-dimensional panel codes",http://arxiv.org/abs/1511.02166v2,2015-11-06T17:17:36Z,2018-03-28T15:07:53Z,"  To optimize the geometry of airfoils for a specific application is an
important engineering problem. In this context genetic algorithms have enjoyed
some success as they are able to explore the search space without getting stuck
in local optima. However, these algorithms require the computation of
aerodynamic properties for a significant number of airfoil geometries.
Consequently, for low-speed aerodynamics, panel methods are most often used as
the inner solver.
  In this paper we evaluate the performance of such an optimization algorithm
on modern accelerators (more specifically, the Intel Xeon Phi 7120 and the
NVIDIA K80). For that purpose, we have implemented an optimized version of the
algorithm on the CPU and Xeon Phi (based on OpenMP, vectorization, and the
Intel MKL library) and on the GPU (based on CUDA and the MAGMA library). We
present timing results for all codes and discuss the similarities and
differences between the three implementations. Overall, we observe a speedup of
approximately $2.5$ for adding an Intel Xeon Phi 7120 to a dual socket
workstation and a speedup between $3.4$ and $3.8$ for adding a NVIDIA K80 to a
dual socket workstation.
",['\nLukas Einkemmer\n'],,"PLoS ONE 12(6): e0178156, 2017",http://dx.doi.org/10.1371/journal.pone.0178156,cs.DC,"['cs.DC', 'cs.MS', 'physics.comp-ph']",10.1371/journal.pone.0178156,,[]
"Approximation of boundary element matrices using GPGPUs and nested cross
  approximation",http://arxiv.org/abs/1510.07244v2,2015-10-25T13:27:11Z,2017-10-18T15:52:08Z,"  The efficiency of boundary element methods depends crucially on the time
required for setting up the stiffness matrix. The far-field part of the matrix
can be approximated by compression schemes like the fast multipole method or
$\mathcal{H}$-matrix techniques. The near-field part is typically approximated
by special quadrature rules like the Sauter-Schwab technique that can handle
the singular integrals appearing in the diagonal and near-diagonal matrix
elements.
  Since computing one element of the matrix requires only a small amount of
data but a fairly large number of operations, we propose to use general-purpose
graphics processing units (GPGPUs) to handle vectorizable portions of the
computation: near-field computations are ideally suited for vectorization and
can therefore be handled very well by GPGPUs. Modern far-field compression
schemes can be split into a small adaptive portion that exhibits divergent
control flows, and should therefore be handled by the CPU, and a vectorizable
portion that can again be sent to GPGPUs.
  We propose a hybrid algorithm that splits the computation into tasks for CPUs
and GPGPUs. Our method presented in this article is able to reduce the setup
time of boundary integral operators by a significant factor of 19-30 for both
the Laplace and the Helmholtz equation in 3D when using two consumer GPGPUs
compared to a quad-core CPU.
","['\nSteffen Börm\n', '\nSven Christophersen\n']",,,http://arxiv.org/abs/1510.07244v2,cs.MS,"['cs.MS', '65N38, 65Y05, 65Y10']",,,[]
FIESTA 4: optimized Feynman integral calculations with GPU support,http://arxiv.org/abs/1511.03614v1,2015-10-23T16:07:56Z,2015-10-23T16:07:56Z,"  This paper presents a new major release of the program FIESTA (Feynman
Integral Evaluation by a Sector decomposiTion Approach). The new release is
mainly aimed at optimal performance at large scales when one is increasing the
number of sampling points in order to reduce the uncertainty estimates. The
release now supports graphical processor units (GPU) for the numerical
integration, methods to optimize cluster-usage, as well as other speed, memory,
and stability improvements.
",['\nAlexander V. Smirnov\n'],arXiv admin note: substantial text overlap with arXiv:1312.3186,"Comp. Phys. Comm, 204, 2016, p, 189-199",http://dx.doi.org/10.1016/j.cpc.2016.03.013,hep-ph,"['hep-ph', 'cs.MS']",10.1016/j.cpc.2016.03.013,,[]
"Performance evaluation of multiple precision matrix multiplications
  using parallelized Strassen and Winograd algorithms",http://arxiv.org/abs/1510.08642v1,2015-10-29T10:58:55Z,2015-10-29T10:58:55Z,"  It is well known that Strassen and Winograd algorithms can reduce the
computational costs associated with dense matrix multiplication. We have
already shown that they are also very effective for software-based multiple
precision floating-point arithmetic environments such as the MPFR/GMP library.
In this paper, we show that we can obtain the same effectiveness for
double-double (DD) and quadruple-double (QD) environments supported by the QD
library, and that parallelization can increase the speed of these multiple
precision matrix multiplications. Finally, we demonstrate that our implemented
parallelized Strassen and Winograd algorithms can increase the speed of
parallelized LU decomposition.
",['\nTomonori Kouya\n'],,JSIAM Letters Vol. 8 (2016) p. 21-24,http://dx.doi.org/10.14495/jsiaml.8.21,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",10.14495/jsiaml.8.21,,[]
Sapporo2: A versatile direct $N$-body library,http://arxiv.org/abs/1510.04068v1,2015-10-14T12:56:13Z,2015-10-14T12:56:13Z,"  Astrophysical direct $N$-body methods have been one of the first production
algorithms to be implemented using NVIDIA's CUDA architecture. Now, almost
seven years later, the GPU is the most used accelerator device in astronomy for
simulating stellar systems. In this paper we present the implementation of the
Sapporo2 $N$-body library, which allows researchers to use the GPU for $N$-body
simulations with little to no effort. The first version, released five years
ago, is actively used, but lacks advanced features and versatility in numerical
precision and support for higher order integrators. In this updated version we
have rebuilt the code from scratch and added support for OpenCL,
multi-precision and higher order integrators. We show how to tune these codes
for different GPU architectures and present how to continue utilizing the GPU
optimal even when only a small number of particles ($N < 100$) is integrated.
This careful tuning allows Sapporo2 to be faster than Sapporo1 even with the
added options and double precision data loads. The code runs on a range of
NVIDIA and AMD GPUs in single and double precision accuracy. With the addition
of OpenCL support the library is also able to run on CPUs and other
accelerators that support OpenCL.
","['\nJeroen Bédorf\n', '\nEvghenii Gaburov\n', '\nSimon Portegies Zwart\n']","15 pages, 7 figures. Accepted for publication in Computational
  Astrophysics and Cosmology",,http://arxiv.org/abs/1510.04068v1,astro-ph.IM,"['astro-ph.IM', 'cs.MS']",,,[]
"Hybridization of Interval CP and Evolutionary Algorithms for Optimizing
  Difficult Problems",http://arxiv.org/abs/1510.04914v1,2015-10-16T15:18:42Z,2015-10-16T15:18:42Z,"  The only rigorous approaches for achieving a numerical proof of optimality in
global optimization are interval-based methods that interleave branching of the
search-space and pruning of the subdomains that cannot contain an optimal
solution. State-of-the-art solvers generally integrate local optimization
algorithms to compute a good upper bound of the global minimum over each
subspace. In this document, we propose a cooperative framework in which
interval methods cooperate with evolutionary algorithms. The latter are
stochastic algorithms in which a population of candidate solutions iteratively
evolves in the search-space to reach satisfactory solutions.
  Within our cooperative solver Charibde, the evolutionary algorithm and the
interval-based algorithm run in parallel and exchange bounds, solutions and
search-space in an advanced manner via message passing. A comparison of
Charibde with state-of-the-art interval-based solvers (GlobSol, IBBA, Ibex) and
NLP solvers (Couenne, BARON) on a benchmark of difficult COCONUT problems shows
that Charibde is highly competitive against non-rigorous solvers and converges
faster than rigorous solvers by an order of magnitude.
","['\nCharlie Vanaret\n', '\nJean-Baptiste Gotteland\n', '\nNicolas Durand\n', '\nJean-Marc Alliot\n']","21st International Conference on Principles and Practice of
  Constraint Programming (CP 2015), 2015",,http://dx.doi.org/10.1007/978-3-319-23219-5_32,cs.AI,"['cs.AI', 'cs.DC', 'cs.MS', 'math.NA', 'math.OC']",10.1007/978-3-319-23219-5_32,,[]
"A novel code generation methodology for block diagram modeler and
  simulators Scicos and VSS",http://arxiv.org/abs/1510.02789v1,2015-10-08T09:47:51Z,2015-10-08T09:47:51Z,"  Block operations during simulation in Scicos and VSS environments can
naturally be described as Nsp functions. But the direct use of Nsp functions
for simulation leads to poor performance since the Nsp language is interpreted,
not compiled. The methodology presented in this paper is used to develop a tool
for generating efficient compilable code, such as C and ADA, for Scicos and VSS
models from these block Nsp functions. Operator overloading and partial
evaluation are the key elements of this novel approach. This methodology may be
used in other simulation environments such as Matlab/Simulink.
","['\nJean-Philippe Chancelier\nCERMICS\n', '\nRamine Nikoukhah\nMETALAU\n']",,,http://arxiv.org/abs/1510.02789v1,cs.MS,['cs.MS'],,,"['CERMICS', 'METALAU']"
"On The Evolution Of User Support Topics in Computational Science and
  Engineering Software",http://arxiv.org/abs/1510.01122v1,2015-10-05T12:19:46Z,2015-10-05T12:19:46Z,"  We investigate ten years of user support emails in the large-scale solver
library PETSc in order to identify changes in user requests. For this purpose
we assign each email thread to one or several categories describing the type of
support request. We find that despite several changes in hardware architecture
as well programming models, the relative share of emails for the individual
categories does not show a notable change over time. This is particularly
remarkable as the total communication volume has increased four-fold in the
considered time frame, indicating a considerable growth of the user base. Our
data also demonstrates that user support cannot be substituted with what is
often referred to as 'better documentation' and that the involvement of core
developers in user support is essential.
","['\nK. Rupp\n', '\nS. Balay\n', '\nJ. Brown\n', '\nM. Knepley\n', '\nL. C. McInnes\n', '\nB. Smith\n']","2 pages, 1 figure, whitepaper for the workshop ""Computational Science
  & Engineering Software Sustainability and Productivity Challenges""",,http://arxiv.org/abs/1510.01122v1,cs.OH,"['cs.OH', 'cs.MS', '68N01', 'D.2.7']",,,[]
"Comparative computational results for some vertex and facet enumeration
  codes",http://arxiv.org/abs/1510.02545v3,2015-10-09T02:07:10Z,2016-06-14T01:45:20Z,"  We report some computational results comparing parallel and sequential codes
for vertex/facet enumeration problems for convex polyhedra. The problems chosen
span the range from simple to highly degenerate polytopes. We tested one code
(lrs) based on pivoting and four codes (cddr+, ppl, normaliz, PORTA) based on
the double description method. normaliz employs parallelization as do the codes
plrs and mplrs which are based on lrs. We tested these codes using various
hardware configurations with up to 1200 cores. Major speedups were obtained by
parallelization, particularly by the code mplrs which uses MPI and can operate
on clusters of machines.
","['\nDavid Avis\n', '\nCharles Jordan\n']","7 pages, 6 tables. Revised version now includes PORTA, normaliz and
  v6.2 of lrslib. The cluster and test set used were also expanded. Broken
  table footnote fixed",,http://arxiv.org/abs/1510.02545v3,cs.MS,"['cs.MS', 'cs.CG', '90-04']",,,[]
The Stan Math Library: Reverse-Mode Automatic Differentiation in C++,http://arxiv.org/abs/1509.07164v1,2015-09-23T21:34:46Z,2015-09-23T21:34:46Z,"  As computational challenges in optimization and statistical inference grow
ever harder, algorithms that utilize derivatives are becoming increasingly more
important. The implementation of the derivatives that make these algorithms so
powerful, however, is a substantial user burden and the practicality of these
algorithms depends critically on tools like automatic differentiation that
remove the implementation burden entirely. The Stan Math Library is a C++,
reverse-mode automatic differentiation library designed to be usable, extensive
and extensible, efficient, scalable, stable, portable, and redistributable in
order to facilitate the construction and utilization of such algorithms.
  Usability is achieved through a simple direct interface and a cleanly
abstracted functional interface. The extensive built-in library includes
functions for matrix operations, linear algebra, differential equation solving,
and most common probability functions. Extensibility derives from a
straightforward object-oriented framework for expressions, allowing users to
easily create custom functions. Efficiency is achieved through a combination of
custom memory management, subexpression caching, traits-based metaprogramming,
and expression templates. Partial derivatives for compound functions are
evaluated lazily for improved scalability. Stability is achieved by taking care
with arithmetic precision in algebraic expressions and providing stable,
compound functions where possible. For portability, the library is
standards-compliant C++ (03) and has been tested for all major compilers for
Windows, Mac OS X, and Linux.
","['\nBob Carpenter\n', '\nMatthew D. Hoffman\n', '\nMarcus Brubaker\n', '\nDaniel Lee\n', '\nPeter Li\n', '\nMichael Betancourt\n']","96 pages, 9 figures",,http://arxiv.org/abs/1509.07164v1,cs.MS,"['cs.MS', 'G.1.0; G.1.3; G.1.4; F.2.1']",,,[]
"A dedicated greedy pursuit algorithm for sparse spectral representation
  of music sound",http://arxiv.org/abs/1509.07659v2,2015-09-25T10:03:17Z,2016-11-07T13:48:34Z,"  A dedicated algorithm for sparse spectral representation of music sound is
presented. The goal is to enable the representation of a piece of music signal,
as a linear superposition of as few spectral components as possible. A
representation of this nature is said to be sparse. In the present context
sparsity is accomplished by greedy selection of the spectral components, from
an overcomplete set called a dictionary. The proposed algorithm is tailored to
be applied with trigonometric dictionaries. Its distinctive feature being that
it avoids the need for the actual construction of the whole dictionary, by
implementing the required operations via the Fast Fourier Transform. The
achieved sparsity is theoretically equivalent to that rendered by the
Orthogonal Matching Pursuit method. The contribution of the proposed dedicated
implementation is to extend the applicability of the standard Orthogonal
Matching Pursuit algorithm, by reducing its storage and computational demands.
The suitability of the approach for producing sparse spectral models is
illustrated by comparison with the traditional method, in the line of the Short
Time Fourier Transform, involving only the corresponding orthonormal
trigonometric basis.
","['\nLaura Rebollo-Neira\n', '\nGagan Aggarwal\n']","Routines for implementing the approach are available on
  http://www.nonlinear-approx.info/examples/node02.html","Journal of the Acoustical Society of America, Vol.140, No.4,
  2933-2943 (2016)",http://dx.doi.org/10.1121/1.4964342,cs.SD,"['cs.SD', 'cs.MS']",10.1121/1.4964342,,[]
SnapVX: A Network-Based Convex Optimization Solver,http://arxiv.org/abs/1509.06397v2,2015-09-21T20:44:12Z,2017-02-21T05:50:05Z,"  SnapVX is a high-performance Python solver for convex optimization problems
defined on networks. For these problems, it provides a fast and scalable
solution with guaranteed global convergence. SnapVX combines the capabilities
of two open source software packages: Snap.py and CVXPY. Snap.py is a large
scale graph processing library, and CVXPY provides a general modeling framework
for small-scale subproblems. SnapVX offers a customizable yet easy-to-use
interface with out-of-the-box functionality. Based on the Alternating Direction
Method of Multipliers (ADMM), it is able to efficiently store, analyze, and
solve large optimization problems from a variety of different applications.
Documentation, examples, and more can be found on the SnapVX website at
http://snap.stanford.edu/snapvx.
","['\nDavid Hallac\n', '\nChristopher Wong\n', '\nSteven Diamond\n', '\nAbhijit Sharang\n', '\nRok Sosic\n', '\nStephen Boyd\n', '\nJure Leskovec\n']",,,http://arxiv.org/abs/1509.06397v2,cs.SI,"['cs.SI', 'cs.MS', 'math.OC']",,,[]
Shared Memory Pipelined Parareal,http://arxiv.org/abs/1509.06935v3,2015-09-23T12:04:23Z,2019-11-11T15:20:23Z,"  For the parallel-in-time integration method Parareal, pipelining can be used
to hide some of the cost of the serial correction step and improve its
efficiency. The paper introduces a basic OpenMP implementation of pipelined
Parareal and compares it to a standard MPI-based variant. Both versions yield
almost identical runtimes, but, depending on the compiler, the OpenMP variant
consumes about 7% less energy and has a significantly smaller memory footprint.
However, its higher implementation complexity might make it difficult to use in
legacy codes and in combination with spatial parallelisation.
",['\nDaniel Ruprecht\n'],,"In: Rivera F., Pena T., Cabaleiro J. (eds) Euro-Par 2017: Parallel
  Processing. Lecture Notes in Computer Science, vol 10417. Springer",http://dx.doi.org/10.1007/978-3-319-64203-1_48,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.NA', '68W10, 65Y05, 68N19']",10.1007/978-3-319-64203-1_48,,[]
"Analysis of A Splitting Approach for the Parallel Solution of Linear
  Systems on GPU Cards",http://arxiv.org/abs/1509.07919v1,2015-09-25T23:04:17Z,2015-09-25T23:04:17Z,"  We discuss an approach for solving sparse or dense banded linear systems
${\bf A} {\bf x} = {\bf b}$ on a Graphics Processing Unit (GPU) card. The
matrix ${\bf A} \in {\mathbb{R}}^{N \times N}$ is possibly nonsymmetric and
moderately large; i.e., $10000 \leq N \leq 500000$. The ${\it split\ and\
parallelize}$ (${\tt SaP}$) approach seeks to partition the matrix ${\bf A}$
into diagonal sub-blocks ${\bf A}_i$, $i=1,\ldots,P$, which are independently
factored in parallel. The solution may choose to consider or to ignore the
matrices that couple the diagonal sub-blocks ${\bf A}_i$. This approach, along
with the Krylov subspace-based iterative method that it preconditions, are
implemented in a solver called ${\tt SaP::GPU}$, which is compared in terms of
efficiency with three commonly used sparse direct solvers: ${\tt PARDISO}$,
${\tt SuperLU}$, and ${\tt MUMPS}$. ${\tt SaP::GPU}$, which runs entirely on
the GPU except several stages involved in preliminary row-column permutations,
is robust and compares well in terms of efficiency with the aforementioned
direct solvers. In a comparison against Intel's ${\tt MKL}$, ${\tt SaP::GPU}$
also fares well when used to solve dense banded systems that are close to being
diagonally dominant. ${\tt SaP::GPU}$ is publicly available and distributed as
open source under a permissive BSD3 license.
","['\nAng Li\n', '\nRadu Serban\n', '\nDan Negrut\n']",38 pages,,http://arxiv.org/abs/1509.07919v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA']",,,[]
Rust-Bio - a fast and safe bioinformatics library,http://arxiv.org/abs/1509.02796v1,2015-09-09T14:53:02Z,2015-09-09T14:53:02Z,"  We present Rust-Bio, the first general purpose bioinformatics library for the
innovative Rust programming language. Rust-Bio leverages the unique combination
of speed, memory safety and high-level syntax offered by Rust to provide a fast
and safe set of bioinformatics algorithms and data structures with a focus on
sequence analysis.
",['\nJohannes Köster\n'],,,http://dx.doi.org/10.1093/bioinformatics/btv573,cs.MS,['cs.MS'],10.1093/bioinformatics/btv573,,[]
A tetrahedral space-filling curve for non-conforming adaptive meshes,http://arxiv.org/abs/1509.04627v2,2015-09-15T16:16:54Z,2017-04-21T09:44:26Z,"  We introduce a space-filling curve for triangular and tetrahedral
red-refinement that can be computed using bitwise interleaving operations
similar to the well-known Z-order or Morton curve for cubical meshes. To store
sufficient information for random access, we define a low-memory encoding using
10 bytes per triangle and 14 bytes per tetrahedron. We present algorithms that
compute the parent, children, and face-neighbors of a mesh element in constant
time, as well as the next and previous element in the space-filling curve and
whether a given element is on the boundary of the root simplex or not. Our
presentation concludes with a scalability demonstration that creates and adapts
selected meshes on a large distributed-memory system.
","['\nCarsten Burstedde\n', '\nJohannes Holke\n']","33 pages, 12 figures, 8 tables",,http://dx.doi.org/10.1137/15M1040049,cs.DC,"['cs.DC', 'cs.MS', '65M50, 68W10, 65Y05, 65D18']",10.1137/15M1040049,,[]
"Fundamental concepts in the Cyclus nuclear fuel cycle simulation
  framework",http://arxiv.org/abs/1509.03604v2,2015-09-11T18:39:59Z,2016-03-11T16:05:10Z,"  As nuclear power expands, technical, economic, political, and environmental
analyses of nuclear fuel cycles by simulators increase in importance. To date,
however, current tools are often fleet-based rather than discrete and
restrictively licensed rather than open source. Each of these choices presents
a challenge to modeling fidelity, generality, efficiency, robustness, and
scientific transparency. The Cyclus nuclear fuel cycle simulator framework and
its modeling ecosystem incorporate modern insights from simulation science and
software architecture to solve these problems so that challenges in nuclear
fuel cycle analysis can be better addressed. A summary of the Cyclus fuel cycle
simulator framework and its modeling ecosystem are presented. Additionally, the
implementation of each is discussed in the context of motivating challenges in
nuclear fuel cycle simulation. Finally, the current capabilities of Cyclus are
demonstrated for both open and closed fuel cycles.
","['\nKathryn D. Huff\n', '\nMatthew J. Gidden\n', '\nRobert W. Carlsen\n', '\nRobert R. Flanagan\n', '\nMeghan B. McGarry\n', '\nArrielle C. Opotowsky\n', '\nErich A. Schneider\n', '\nAnthony M. Scopatz\n', '\nPaul P. H. Wilson\n']",,"Advances in Engineering Software, Volume 94, April 2016, Pages
  46-59",http://dx.doi.org/10.1016/j.advengsoft.2016.01.014,cs.SE,"['cs.SE', 'cs.CE', 'cs.MA', 'cs.MS', 'D.2.13; I.6.7; I.6.8; D.2.4']",10.1016/j.advengsoft.2016.01.014,,[]
"A deterministic global optimization using smooth diagonal auxiliary
  functions",http://arxiv.org/abs/1509.04518v1,2015-09-15T12:24:58Z,2015-09-15T12:24:58Z,"  In many practical decision-making problems it happens that functions involved
in optimization process are black-box with unknown analytical representations
and hard to evaluate. In this paper, a global optimization problem is
considered where both the goal function~$f(x)$ and its gradient $f'(x)$ are
black-box functions. It is supposed that $f'(x)$ satisfies the Lipschitz
condition over the search hyperinterval with an unknown Lipschitz constant~$K$.
A new deterministic `Divide-the-Best' algorithm based on efficient diagonal
partitions and smooth auxiliary functions is proposed in its basic version, its
convergence conditions are studied and numerical experiments executed on eight
hundred test functions are presented.
","['\nYaroslav D. Sergeyev\n', '\nDmitri E. Kvasov\n']","25 pages, 7 figures, 3 tables","Communications in Nonlinear Science and Numerical Simulation,
  2015, 21, 99-111",http://dx.doi.org/10.1016/j.cnsns.2014.08.026,math.OC,"['math.OC', 'cs.MS', 'math.NA', '65K05, 90C26, 90C56', 'G.1.6; G.1.0']",10.1016/j.cnsns.2014.08.026,,[]
Scalable Metropolis Monte Carlo for simulation of hard shapes,http://arxiv.org/abs/1509.04692v1,2015-09-15T19:25:33Z,2015-09-15T19:25:33Z,"  We design and implement HPMC, a scalable hard particle Monte Carlo simulation
toolkit, and release it open source as part of HOOMD-blue. HPMC runs in
parallel on many CPUs and many GPUs using domain decomposition. We employ BVH
trees instead of cell lists on the CPU for fast performance, especially with
large particle size disparity, and optimize inner loops with SIMD vector
intrinsics on the CPU. Our GPU kernel proposes many trial moves in parallel on
a checkerboard and uses a block-level queue to redistribute work among threads
and avoid divergence. HPMC supports a wide variety of shape classes, including
spheres / disks, unions of spheres, convex polygons, convex spheropolygons,
concave polygons, ellipsoids / ellipses, convex polyhedra, convex
spheropolyhedra, spheres cut by planes, and concave polyhedra. NVT and NPT
ensembles can be run in 2D or 3D triclinic boxes. Additional integration
schemes permit Frenkel-Ladd free energy computations and implicit depletant
simulations. In a benchmark system of a fluid of 4096 pentagons, HPMC performs
10 million sweeps in 10 minutes on 96 CPU cores on XSEDE Comet. The same
simulation would take 7.6 hours in serial. HPMC also scales to large system
sizes, and the same benchmark with 16.8 million particles runs in 1.4 hours on
2048 GPUs on OLCF Titan.
","['\nJoshua A. Anderson\n', '\nM. Eric Irrgang\n', '\nSharon C. Glotzer\n']",5 figures,,http://dx.doi.org/10.1016/j.cpc.2016.02.024,cond-mat.soft,"['cond-mat.soft', 'cs.MS', 'physics.comp-ph']",10.1016/j.cpc.2016.02.024,,[]
"Direct high-order edge-preserving regularization for tomographic image
  reconstruction",http://arxiv.org/abs/1509.04706v1,2015-09-15T18:23:56Z,2015-09-15T18:23:56Z,"  In this paper we present a new two-level iterative algorithm for tomographic
image reconstruction. The algorithm uses a regularization technique, which we
call edge-preserving Laplacian, that preserves sharp edges between objects
while damping spurious oscillations in the areas where the reconstructed image
is smooth. Our numerical simulations demonstrate that the proposed method
outperforms total variation (TV) regularization and it is competitive with the
combined TV-L2 penalty. Obtained reconstructed images show increased
signal-to-noise ratio and visually appealing structural features. Computer
implementation and parameter control of the proposed technique is
straightforward, which increases the feasibility of it across many tomographic
applications. In this paper, we applied our method to the under-sampled
computed tomography (CT) projection data and also considered a case of
reconstruction in emission tomography The MATLAB code is provided to support
obtained results.
","['\nDaniil Kazantsev\n', '\nEvgueni Ovtchinnikov\n', '\nWilliam R. B. Lionheart\n', '\nPhilip J. Withers\n', '\nPeter D. Lee\n']","16 pages, 11 figures",,http://arxiv.org/abs/1509.04706v1,cs.CV,"['cs.CV', 'cs.MS', 'cs.NA', 'math.NA']",,,[]
Clone and graft: Testing scientific applications as they are built,http://arxiv.org/abs/1508.07231v1,2015-08-28T14:42:09Z,2015-08-28T14:42:09Z,"  This article describes our experience developing and maintaining automated
tests for scientific applications. The main idea evolves around building on
already existing tests by cloning and grafting. The idea is demonstrated on a
minimal model problem written in Python.
","['\nBruno Turcksin\n', '\nTimo Heister\n', '\nWolfgang Bangerth\n']",,,http://arxiv.org/abs/1508.07231v1,cs.MS,['cs.MS'],,,[]
"Verificarlo: checking floating point accuracy through Monte Carlo
  Arithmetic",http://arxiv.org/abs/1509.01347v4,2015-09-04T06:20:18Z,2018-11-09T07:55:49Z,"  Numerical accuracy of floating point computation is a well studied topic
which has not made its way to the end-user in scientific computing. Yet, it has
become a critical issue with the recent requirements for code modernization to
harness new highly parallel hardware and perform higher resolution computation.
To democratize numerical accuracy analysis, it is important to propose tools
and methodologies to study large use cases in a reliable and automatic way. In
this paper, we propose verificarlo, an extension to the LLVM compiler to
automatically use Monte Carlo Arithmetic in a transparent way for the end-user.
It supports all the major languages including C, C++, and Fortran. Unlike
source-to-source approaches, our implementation captures the influence of
compiler optimizations on the numerical accuracy. We illustrate how Monte Carlo
Arithmetic using the verificarlo tool outperforms the existing approaches on
various use cases and is a step toward automatic numerical analysis.
","['\nChristophe Denis\nCMLA\n', '\nPablo De Oliveira Castro\nLI-PaRAD, UVSQ\n', '\nEric Petit\nUVSQ\n']",,,http://arxiv.org/abs/1509.01347v4,cs.MS,"['cs.MS', 'cs.NA']",,,"['CMLA', 'LI-PaRAD, UVSQ', 'UVSQ']"
Approximating the Sum of Correlated Lognormals: An Implementation,http://arxiv.org/abs/1508.07582v1,2015-08-30T14:47:50Z,2015-08-30T14:47:50Z,"  Lognormal random variables appear naturally in many engineering disciplines,
including wireless communications, reliability theory, and finance. So, too,
does the sum of (correlated) lognormal random variables. Unfortunately, no
closed form probability distribution exists for such a sum, and it requires
approximation. Some approximation methods date back over 80 years and most take
one of two approaches, either: 1) an approximate probability distribution is
derived mathematically, or 2) the sum is approximated by a single lognormal
random variable. In this research, we take the latter approach and review a
fairly recent approximation procedure proposed by Mehta, Wu, Molisch, and Zhang
(2007), then implement it using C++. The result is applied to a discrete time
model commonly encountered within the field of financial economics.
","['\nChristopher J. Rook\n', '\nMitchell Kerman\n']",Fully documented source code is included,,http://arxiv.org/abs/1508.07582v1,q-fin.GN,"['q-fin.GN', 'cs.MS', 'stat.AP', 'D.2.4; G.3; J.2']",,,[]
Strong Pseudoprimes to Twelve Prime Bases,http://arxiv.org/abs/1509.00864v1,2015-09-02T20:23:07Z,2015-09-02T20:23:07Z,"  Let $\psi_m$ be the smallest strong pseudoprime to the first $m$ prime bases.
This value is known for $1 \leq m \leq 11$. We extend this by finding
$\psi_{12}$ and $\psi_{13}$. We also present an algorithm to find all integers
$n\le B$ that are strong pseudoprimes to the first $m$ prime bases; with a
reasonable heuristic assumption we can show that it takes at most
$B^{2/3+o(1)}$ time.
","['\nJonathan P. Sorenson\n', '\nJonathan Webster\n']",,,http://dx.doi.org/10.1090/mcom/3134,math.NT,"['math.NT', 'cs.DS', 'cs.MS', 'Primary 11Y16, 11Y16, Secondary 11A41, 68W40, 68W10']",10.1090/mcom/3134,,[]
"Complex additive geometric multilevel solvers for Helmholtz equations on
  spacetrees",http://arxiv.org/abs/1508.03954v3,2015-08-17T08:51:04Z,2016-08-30T09:02:27Z,"  We introduce a family of implementations of low order, additive, geometric
multilevel solvers for systems of Helmholtz equations. Both grid spacing and
arithmetics may comprise complex numbers and we thus can apply complex scaling
techniques to the indefinite Helmholtz operator. Our implementations are based
upon the notion of a spacetree and work exclusively with a finite number of
precomputed local element matrices. They are globally matrix-free.
  Combining various relaxation factors with two grid transfer operators allows
us to switch from pure additive multigrid over a hierarchical basis method into
BPX with several multiscale smoothing variants within one code base. Pipelining
allows us to realise a full approximation storage (FAS) scheme within the
additive environment where, amortised, each grid vertex carrying degrees of
freedom is read/written only once per iteration. The codes thus realise a
single-touch policy. Among the features facilitated by matrix-free FAS is
arbitrary dynamic mesh refinement (AMR) for all solver variants. AMR as enabler
for full multigrid (FMG) cycling---the grid unfolds throughout the
computation---allows us to reduce the cost per unknown per order of accuracy.
  The present paper primary contributes towards software realisation and design
questions. Our experiments show that the consolidation of single-touch FAS,
dynamic AMR and vectorisation-friendly, complex scaled, matrix-free FMG cycles
delivers a mature implementation blueprint for solvers for a non-trivial class
of problems such as Helmholtz equations. Besides this validation, we put
particular emphasis on a strict implementation formalism as well as some
implementation correctness proofs.
","['\nBram Reps\n', '\nTobias Weinzierl\n']",,,http://dx.doi.org/10.1145/3054946,cs.MS,['cs.MS'],10.1145/3054946,,[]
"Marathon: An open source software library for the analysis of
  Markov-Chain Monte Carlo algorithms",http://arxiv.org/abs/1508.04740v2,2015-08-19T18:55:18Z,2016-09-14T13:16:04Z,"  In this paper, we consider the Markov-Chain Monte Carlo (MCMC) approach for
random sampling of combinatorial objects. The running time of such an algorithm
depends on the total mixing time of the underlying Markov chain and is unknown
in general. For some Markov chains, upper bounds on this total mixing time
exist but are too large to be applicable in practice. We try to answer the
question, whether the total mixing time is close to its upper bounds, or if
there is a significant gap between them. In doing so, we present the software
library marathon which is designed to support the analysis of MCMC based
sampling algorithms. The main application of this library is to compute
properties of so-called state graphs which represent the structure of Markov
chains. We use marathon to investigate the quality of several bounding methods
on four well-known Markov chains for sampling perfect matchings and bipartite
graph realizations. In a set of experiments, we compute the total mixing time
and several of its bounds for a large number of input instances. We find that
the upper bound gained by the famous canonical path method is several
magnitudes larger than the total mixing time and deteriorates with growing
input size. In contrast, the spectral bound is found to be a precise
approximation of the total mixing time.
","['\nSteffen Rechner\n', '\nAnnabell Berger\n']",,,http://dx.doi.org/10.1371/journal.pone.0147935,cs.DM,"['cs.DM', 'cs.MS']",10.1371/journal.pone.0147935,,[]
Non-Metric Space Library Manual,http://arxiv.org/abs/1508.05470v4,2015-08-22T04:43:36Z,2019-06-07T00:49:39Z,"  This document covers a library for fast similarity (k-NN)search. It describes
only search methods and distances (spaces). Details about building, installing,
Python bindings can be found
online:https://github.com/searchivarius/nmslib/tree/v1.8/. Even though the
library contains a variety of exact metric-space access methods, our main focus
is on more generic and approximate search methods, in particular, on methods
for non-metric spaces. NMSLIB is possibly the first library with a principled
support for non-metric space searching.
","['\nBilegsaikhan Naidan\n', '\nLeonid Boytsov\n', '\nYury Malkov\n', '\nDavid Novak\n']",Methodology paper,,http://arxiv.org/abs/1508.05470v4,cs.MS,"['cs.MS', 'cs.IR']",,,[]
Support for Non-conformal Meshes in PETSc's DMPlex Interface,http://arxiv.org/abs/1508.02470v1,2015-08-11T02:06:01Z,2015-08-11T02:06:01Z,"  PETSc's DMPlex interface for unstructured meshes has been extended to support
non-conformal meshes. The topological construct that DMPlex implements---the
CW-complex---is by definition conformal, so representing non- conformal meshes
in a way that hides complexity requires careful attention to the interface
between DMPlex and numerical methods such as the finite element method. Our
approach---which combines a tree structure for subset- superset relationships
and a ""reference tree"" describing the types of non-conformal
interfaces---allows finite element code written for conformal meshes to extend
automatically: in particular, all ""hanging-node"" constraint calculations are
handled behind the scenes. We give example code demonstrating the use of this
extension, and use it to convert forests of quadtrees and forests of octrees
from the p4est library to DMPlex meshes.
","['\nTobin Isaac\n', '\nMatthew G. Knepley\n']","16 pages, 13 figures, 5 code examples",,http://arxiv.org/abs/1508.02470v1,cs.MS,['cs.MS'],,,[]
JuMP: A Modeling Language for Mathematical Optimization,http://arxiv.org/abs/1508.01982v3,2015-08-09T03:55:19Z,2016-08-15T04:27:52Z,"  JuMP is an open-source modeling language that allows users to express a wide
range of optimization problems (linear, mixed-integer, quadratic,
conic-quadratic, semidefinite, and nonlinear) in a high-level, algebraic
syntax. JuMP takes advantage of advanced features of the Julia programming
language to offer unique functionality while achieving performance on par with
commercial modeling tools for standard tasks. In this work we will provide
benchmarks, present the novel aspects of the implementation, and discuss how
JuMP can be extended to new problem classes and composed with state-of-the-art
tools for visualization and interactivity.
","['\nIain Dunning\n', '\nJoey Huchette\n', '\nMiles Lubin\n']",,,http://dx.doi.org/10.1137/15M1020575,math.OC,"['math.OC', 'cs.MS']",10.1137/15M1020575,,[]
Using the VBARMS method in parallel computing,http://arxiv.org/abs/1508.02219v1,2015-08-10T12:26:49Z,2015-08-10T12:26:49Z,"  The paper describes an improved parallel MPI-based implementation of VBARMS,
a variable block variant of the pARMS preconditioner proposed by Li,~Saad and
Sosonkina [NLAA, 2003] for solving general nonsymmetric linear systems. The
parallel VBARMS solver can detect automatically exact or approximate dense
structures in the linear system, and exploits this information to achieve
improved reliability and increased throughput during the factorization. A novel
graph compression algorithm is discussed that finds these approximate dense
blocks structures and requires only one simple to use parameter. A complete
study of the numerical and parallel performance of parallel VBARMS is presented
for the analysis of large turbulent Navier-Stokes equations on a suite of
three-dimensional test cases.
","['\nBruno Carpentieri\n', '\nJia Liao\n', '\nMasha Sosonkina\n', '\nAldo Bonfiglioli\n']",,,http://arxiv.org/abs/1508.02219v1,math.NA,"['math.NA', 'cs.MA', 'cs.MS']",,,[]
"Computing accurate Horner form approximations to special functions in
  finite precision arithmetic",http://arxiv.org/abs/1508.03211v1,2015-08-13T13:42:35Z,2015-08-13T13:42:35Z,"  In various applications, computers are required to compute approximations to
univariate elementary and special functions such as $\exp$ and $\arctan$ to
modest accuracy. This paper proposes a new heuristic for automating the design
of such implementations. This heuristic takes a certain restricted
specification of program structure and the desired error properties as input
and takes explicit account of roundoff error during evaluation.
",['\nTor G. J. Myklebust\n'],"10 pages, 6 figures",,http://arxiv.org/abs/1508.03211v1,cs.NA,"['cs.NA', 'cs.MS', 'math.NA', '33F05', 'G.1.2']",,,[]
Accelerating R with high performance linear algebra libraries,http://arxiv.org/abs/1508.00688v1,2015-08-04T07:25:56Z,2015-08-04T07:25:56Z,"  Linear algebra routines are basic building blocks for the statistical
software. In this paper we analyzed how can we can improve R performance for
matrix computations. We benchmarked few matrix operations using the standard
linear algebra libraries included in the R distribution and high performance
libraries like OpenBLAS, GotoBLAS and MKL. Our tests showed the the best
results are obtained with the MKL library, the other two libraries having
similar performances, but lower than MKL
","['\nBogdan Oancea\n', '\nTudorel Andrei\n', '\nRaluca Mariana Dragoescu\n']",,"Romanian Statistical Review, No. 3, 2015, pp. 109-117",http://arxiv.org/abs/1508.00688v1,cs.MS,"['cs.MS', '68N99', 'H.3.4']",,,[]
"GHOST: Building blocks for high performance sparse linear algebra on
  heterogeneous systems",http://arxiv.org/abs/1507.08101v3,2015-07-29T11:08:57Z,2016-02-15T12:28:41Z,"  While many of the architectural details of future exascale-class high
performance computer systems are still a matter of intense research, there
appears to be a general consensus that they will be strongly heterogeneous,
featuring ""standard"" as well as ""accelerated"" resources. Today, such resources
are available as multicore processors, graphics processing units (GPUs), and
other accelerators such as the Intel Xeon Phi. Any software infrastructure that
claims usefulness for such environments must be able to meet their inherent
challenges: massive multi-level parallelism, topology, asynchronicity, and
abstraction. The ""General, Hybrid, and Optimized Sparse Toolkit"" (GHOST) is a
collection of building blocks that targets algorithms dealing with sparse
matrix representations on current and future large-scale systems. It implements
the ""MPI+X"" paradigm, has a pure C interface, and provides hybrid-parallel
numerical kernels, intelligent resource management, and truly heterogeneous
parallelism for multicore CPUs, Nvidia GPUs, and the Intel Xeon Phi. We
describe the details of its design with respect to the challenges posed by
modern heterogeneous supercomputers and recent algorithmic developments.
Implementation details which are indispensable for achieving high efficiency
are pointed out and their necessity is justified by performance measurements or
predictions based on performance models. The library code and several
applications are available as open source. We also provide instructions on how
to make use of GHOST in existing software packages, together with a case study
which demonstrates the applicability and performance of GHOST as a component
within a larger software stack.
","['\nMoritz Kreutzer\n', '\nJonas Thies\n', '\nMelven Röhrig-Zöllner\n', '\nAndreas Pieper\n', '\nFaisal Shahzad\n', '\nMartin Galgon\n', '\nAchim Basermann\n', '\nHolger Fehske\n', '\nGeorg Hager\n', '\nGerhard Wellein\n']","32 pages, 11 figures",,http://dx.doi.org/10.1007/s10766-016-0464-z,cs.DC,"['cs.DC', 'cs.MS']",10.1007/s10766-016-0464-z,,[]
"Graphulo Implementation of Server-Side Sparse Matrix Multiply in the
  Accumulo Database",http://arxiv.org/abs/1507.01066v2,2015-07-04T05:20:22Z,2015-08-30T05:47:18Z,"  The Apache Accumulo database excels at distributed storage and indexing and
is ideally suited for storing graph data. Many big data analytics compute on
graph data and persist their results back to the database. These graph
calculations are often best performed inside the database server. The GraphBLAS
standard provides a compact and efficient basis for a wide range of graph
applications through a small number of sparse matrix operations. In this
article, we implement GraphBLAS sparse matrix multiplication server-side by
leveraging Accumulo's native, high-performance iterators. We compare the
mathematics and performance of inner and outer product implementations, and
show how an outer product implementation achieves optimal performance near
Accumulo's peak write rate. We offer our work as a core component to the
Graphulo library that will deliver matrix math primitives for graph analytics
within Accumulo.
","['\nDylan Hutchison\n', '\nJeremy Kepner\n', '\nVijay Gadepally\n', '\nAdam Fuchs\n']",To be presented at IEEE HPEC 2015: http://www.ieee-hpec.org/,,http://dx.doi.org/10.1109/HPEC.2015.7322448,cs.DB,"['cs.DB', 'cs.DC', 'cs.MS']",10.1109/HPEC.2015.7322448,,[]
"MADNESS: A Multiresolution, Adaptive Numerical Environment for
  Scientific Simulation",http://arxiv.org/abs/1507.01888v1,2015-07-05T15:32:13Z,2015-07-05T15:32:13Z,"  MADNESS (multiresolution adaptive numerical environment for scientific
simulation) is a high-level software environment for solving integral and
differential equations in many dimensions that uses adaptive and fast harmonic
analysis methods with guaranteed precision based on multiresolution analysis
and separated representations. Underpinning the numerical capabilities is a
powerful petascale parallel programming environment that aims to increase both
programmer productivity and code scalability. This paper describes the features
and capabilities of MADNESS and briefly discusses some current applications in
chemistry and several areas of physics.
","['\nRobert J. Harrison\n', '\nGregory Beylkin\n', '\nFlorian A. Bischoff\n', '\nJustus A. Calvin\n', '\nGeorge I. Fann\n', '\nJacob Fosso-Tande\n', '\nDiego Galindo\n', '\nJeff R. Hammond\n', '\nRebecca Hartman-Baker\n', '\nJudith C. Hill\n', '\nJun Jia\n', '\nJakob S. Kottmann\n', '\nM-J. Yvonne Ou\n', '\nLaura E. Ratcliff\n', '\nMatthew G. Reuter\n', '\nAdam C. Richie-Halford\n', '\nNichols A. Romero\n', '\nHideo Sekino\n', '\nWilliam A. Shelton\n', '\nBryan E. Sundahl\n', '\nW. Scott Thornton\n', '\nEdward F. Valeev\n', '\nÁlvaro Vázquez-Mayagoitia\n', '\nNicholas Vence\n', '\nYukina Yokoi\n']",,"SIAM SISC 38, S123-S142 (2016)",http://dx.doi.org/10.1137/15M1026171,cs.MS,"['cs.MS', 'cs.CE', 'math.NA']",10.1137/15M1026171,,[]
"GenASiS Basics: Object-oriented utilitarian functionality for
  large-scale physics simulations (Version 4)",http://arxiv.org/abs/1507.02506v4,2015-07-09T13:38:55Z,2023-06-12T15:15:32Z,"  GenASiS Basics provides modern Fortran classes furnishing extensible
object-oriented utilitarian functionality for large-scale physics simulations
on distributed memory supercomputers. This functionality includes physical
units and constants; display to the screen or standard output device; message
passing; I/O to disk; and runtime parameter management and usage statistics.
This revision -- Version 4 of GenASiS Basics -- includes a name change and
additions to functionality, including the facilitation of direct communication
between GPUs.
","['\nReuben D. Budiardja\n', '\nChristian Y. Cardall\n']","The first Journal Reference and DOI are for the original publication
  (v1 on this archive). The second and subsequent Journal References and DOIs
  are for a New Version Announcements (successive versions on this archive)","Computer Physics Communications 196, 506 (2015); 214, 247 (2017);
  244, 483 (2019); 281, 108505 (2022)",http://dx.doi.org/10.1016/j.cpc.2015.06.001,astro-ph.IM,"['astro-ph.IM', 'cs.MS', 'physics.comp-ph']","10.1016/j.cpc.2015.06.001 10.1016/j.cpc.2016.12.019
  10.1016/j.cpc.2019.05.014 10.1016/j.cpc.2022.108505",,[]
Efficient mesh management in Firedrake using PETSc-DMPlex,http://arxiv.org/abs/1506.07749v1,2015-06-25T13:42:29Z,2015-06-25T13:42:29Z,"  The use of composable abstractions allows the application of new and
established algorithms to a wide range of problems while automatically
inheriting the benefits of well-known performance optimisations. This work
highlights the composition of the PETSc DMPlex domain topology abstraction with
the Firedrake automated finite element system to create a PDE solving
environment that combines expressiveness, flexibility and high performance. We
describe how Firedrake utilises DMPlex to provide the indirection maps required
for finite element assembly, while supporting various mesh input formats and
runtime domain decomposition. In particular, we describe how DMPlex and its
accompanying data structures allow the generic creation of user-defined
discretisations, while utilising data layout optimisations that improve cache
coherency and ensure overlapped communication during assembly computation.
","['\nMichael Lange\n', '\nLawrence Mitchell\n', '\nMatthew G. Knepley\n', '\nGerard J. Gorman\n']","12 pages, 6 figures, submitted to SISC CSE Special Issue",SIAM Journal on Scientific Computing 38(5):S143-S155 (2016),http://dx.doi.org/10.1137/15M1026092,cs.MS,['cs.MS'],10.1137/15M1026092,,[]
pyMOR - Generic Algorithms and Interfaces for Model Order Reduction,http://arxiv.org/abs/1506.07094v3,2015-06-23T17:08:59Z,2016-03-31T10:10:11Z,"  Reduced basis methods are projection-based model order reduction techniques
for reducing the computational complexity of solving parametrized partial
differential equation problems. In this work we discuss the design of pyMOR, a
freely available software library of model order reduction algorithms, in
particular reduced basis methods, implemented with the Python programming
language. As its main design feature, all reduction algorithms in pyMOR are
implemented generically via operations on well-defined vector array, operator
and discretization interface classes. This allows for an easy integration with
existing open-source high-performance partial differential equation solvers
without adding any model reduction specific code to these solvers. Besides an
in-depth discussion of pyMOR's design philosophy and architecture, we present
several benchmark results and numerical examples showing the feasibility of our
approach.
","['\nRené Milk\n', '\nStephan Rave\n', '\nFelix Schindler\n']",,"SIAM J. Sci. Comput., 38 (2016), pp. S194-S216",http://dx.doi.org/10.1137/15M1026614,cs.MS,"['cs.MS', 'math.NA', '35-04, 35J20, 35L03, 65-04, 65N30, 65Y05, 68N01']",10.1137/15M1026614,,[]
"A Java Implementation of the SGA, UMDA, ECGA, and HBOA",http://arxiv.org/abs/1506.07980v1,2015-06-26T07:44:38Z,2015-06-26T07:44:38Z,"  The Simple Genetic Algorithm, the Univariate Marginal Distribution Algorithm,
the Extended Compact Genetic Algorithm, and the Hierarchical Bayesian
Optimization Algorithm are all well known Evolutionary Algorithms.
  In this report we present a Java implementation of these four algorithms with
detailed instructions on how to use each of them to solve a given set of
optimization problems. Additionally, it is explained how to implement and
integrate new problems within the provided set. The source and binary files of
the Java implementations are available for free download at
https://github.com/JoseCPereira/2015EvolutionaryAlgorithmsJava.
","['\nJosé C. Pereira\n', '\nFernando G. Lobo\n']",6 pages,,http://arxiv.org/abs/1506.07980v1,cs.NE,"['cs.NE', 'cs.MS', 'I.2.8']",,,[]
A Java Implementation of Parameter-less Evolutionary Algorithms,http://arxiv.org/abs/1506.08694v1,2015-06-26T07:53:57Z,2015-06-26T07:53:57Z,"  The Parameter-less Genetic Algorithm was first presented by Harik and Lobo in
1999 as an alternative to the usual trial-and-error method of finding, for each
given problem, an acceptable set-up of the parameter values of the genetic
algorithm. Since then, the same strategy has been successfully applied to
create parameter-less versions of other population-based search algorithms such
as the Extended Compact Genetic Algorithm and the Hierarchical Bayesian
Optimization Algorithm. This report describes a Java implementation,
Parameter-less Evolutionary Algorithm (P-EAJava), that integrates several
parameter-less evolutionary algorithms into a single platform. Along with a
brief description of P-EAJava, we also provide detailed instructions on how to
use it, how to implement new problems, and how to generate new parameter-less
versions of evolutionary algorithms.
  At present time, P-EAJava already includes parameter-less versions of the
Simple Genetic Algorithm, the Extended Compact Genetic Algorithm, the
Univariate Marginal Distribution Algorithm, and the Hierarchical Bayesian
Optimization Algorithm. The source and binary files of the Java implementation
of P-EAJava are available for free download at
https://github.com/JoseCPereira/2015ParameterlessEvolutionaryAlgorithmsJava.
","['\nJosé C. Pereira\n', '\nFernando G. Lobo\n']",12 pages. arXiv admin note: text overlap with arXiv:1506.07980,,http://arxiv.org/abs/1506.08694v1,cs.MS,"['cs.MS', 'cs.NE', 'I.2.8']",,,[]
Java Implementation of a Parameter-less Evolutionary Portfolio,http://arxiv.org/abs/1506.08867v1,2015-06-26T07:58:32Z,2015-06-26T07:58:32Z,"  The Java implementation of a portfolio of parameter-less evolutionary
algorithms is presented. The Parameter-less Evolutionary Portfolio implements a
heuristic that performs adaptive selection of parameter-less evolutionary
algorithms in accordance with performance criteria that are measured during
running time. At present time, the portfolio includes three parameter-less
evolutionary algorithms: Parameter-less Univariate Marginal Distribution
Algorithm, Parameter-less Extended Compact Genetic Algorithm, and
Parameter-less Hierarchical Bayesian Optimization Algorithm. Initial
experiments showed that the parameter-less portfolio can solve various classes
of problems without the need for any prior parameter setting technique and with
an increase in computational effort that can be considered acceptable.
","['\nJosé C. Pereira\n', '\nFernando G. Lobo\n']","7 pages. arXiv admin note: substantial text overlap with
  arXiv:1506.08694, arXiv:1506.07980",,http://arxiv.org/abs/1506.08867v1,cs.MS,"['cs.MS', 'cs.NE', 'I.2.8']",,,[]
"Trigger detection for adaptive scientific workflows using percentile
  sampling",http://arxiv.org/abs/1506.08258v1,2015-06-27T04:34:26Z,2015-06-27T04:34:26Z,"  Increasing complexity of scientific simulations and HPC architectures are
driving the need for adaptive workflows, where the composition and execution of
computational and data manipulation steps dynamically depend on the
evolutionary state of the simulation itself. Consider for example, the
frequency of data storage. Critical phases of the simulation should be captured
with high frequency and with high fidelity for post-analysis, however we cannot
afford to retain the same frequency for the full simulation due to the high
cost of data movement. We can instead look for triggers, indicators that the
simulation will be entering a critical phase and adapt the workflow
accordingly.
  We present a method for detecting triggers and demonstrate its use in direct
numerical simulations of turbulent combustion using S3D. We show that chemical
explosive mode analysis (CEMA) can be used to devise a noise-tolerant indicator
for rapid increase in heat release. However, exhaustive computation of CEMA
values dominates the total simulation, thus is prohibitively expensive. To
overcome this bottleneck, we propose a quantile-sampling approach. Our
algorithm comes with provable error/confidence bounds, as a function of the
number of samples. Most importantly, the number of samples is independent of
the problem size, thus our proposed algorithm offers perfect scalability. Our
experiments on homogeneous charge compression ignition (HCCI) and reactivity
controlled compression ignition (RCCI) simulations show that the proposed
method can detect rapid increases in heat release, and its computational
overhead is negligible. Our results will be used for dynamic workflow decisions
about data storage and mesh resolution in future combustion simulations.
Proposed framework is generalizable and we detail how it could be applied to a
broad class of scientific simulation workflows.
","['\nJanine C. Bennett\n', '\nAnkit Bhagatwala\n', '\nJacqueline H. Chen\n', '\nC. Seshadhri\n', '\nAli Pinar\n', '\nMaher Salloum\n']",,,http://arxiv.org/abs/1506.08258v1,cs.CE,"['cs.CE', 'cs.DC', 'cs.MS']",,,[]
"Architecture-Aware Configuration and Scheduling of Matrix Multiplication
  on Asymmetric Multicore Processors",http://arxiv.org/abs/1506.08988v1,2015-06-30T08:35:15Z,2015-06-30T08:35:15Z,"  Asymmetric multicore processors (AMPs) have recently emerged as an appealing
technology for severely energy-constrained environments, especially in mobile
appliances where heterogeneity in applications is mainstream. In addition,
given the growing interest for low-power high performance computing, this type
of architectures is also being investigated as a means to improve the
throughput-per-Watt of complex scientific applications.
  In this paper, we design and embed several architecture-aware optimizations
into a multi-threaded general matrix multiplication (gemm), a key operation of
the BLAS, in order to obtain a high performance implementation for ARM
big.LITTLE AMPs. Our solution is based on the reference implementation of gemm
in the BLIS library, and integrates a cache-aware configuration as well as
asymmetric--static and dynamic scheduling strategies that carefully tune and
distribute the operation's micro-kernels among the big and LITTLE cores of the
target processor. The experimental results on a Samsung Exynos 5422, a
system-on-chip with ARM Cortex-A15 and Cortex-A7 clusters that implements the
big.LITTLE model, expose that our cache-aware versions of gemm with asymmetric
scheduling attain important gains in performance with respect to its
architecture-oblivious counterparts while exploiting all the resources of the
AMP to deliver considerable energy efficiency.
","['\nSandra Catalán\n', '\nFrancisco D. Igual\n', '\nRafael Mayo\n', '\nRafael Rodríguez-Sánchez\n', '\nEnrique S. Quintana-Ortí\n']",,,http://arxiv.org/abs/1506.08988v1,cs.PF,"['cs.PF', 'cs.DC', 'cs.MS', 'cs.NA']",,,[]
"The Peano software - parallel, automaton-based, dynamically adaptive
  grid traversals",http://arxiv.org/abs/1506.04496v6,2015-06-15T07:33:41Z,2018-12-02T15:58:43Z,"  We discuss the design decisions, design alternatives and rationale behind the
third generation of Peano, a framework for dynamically adaptive Cartesian
meshes derived from spacetrees. Peano ties the mesh traversal to the mesh
storage and supports only one element-wise traversal order resulting from
space-filling curves. The user is not free to choose a traversal order herself.
The traversal can exploit regular grid subregions and shared memory as well as
distributed memory systems with almost no modifications to a serial application
code. We formalize the software design by means of two interacting
automata---one automaton for the multiscale grid traversal and one for the
application-specific algorithmic steps. This yields a callback-based
programming paradigm. We further sketch the supported application types and the
two data storage schemes realized, before we detail high-performance computing
aspects and lessons learned. Special emphasis is put on observations regarding
the used programming idioms and algorithmic concepts. This transforms our
report from a ""one way to implement things"" code description into a generic
discussion and summary of some alternatives, rationale and design decisions to
be made for any tree-based adaptive mesh refinement software.
",['\nTobias Weinzierl\n'],,"ACM Transactions on Mathematical Software, 2019",http://dx.doi.org/10.1145/3319797,cs.MS,['cs.MS'],10.1145/3319797,,[]
"Encog: Library of Interchangeable Machine Learning Models for Java and
  C#",http://arxiv.org/abs/1506.04776v1,2015-06-15T21:20:06Z,2015-06-15T21:20:06Z,"  This paper introduces the Encog library for Java and C#, a scalable,
adaptable, multiplatform machine learning framework that was 1st released in
2008. Encog allows a variety of machine learning models to be applied to
datasets using regression, classification, and clustering. Various supported
machine learning models can be used interchangeably with minimal recoding.
Encog uses efficient multithreaded code to reduce training time by exploiting
modern multicore processors. The current version of Encog can be downloaded
from http://www.encog.org.
",['\nJeff Heaton\n'],,,http://arxiv.org/abs/1506.04776v1,cs.MS,"['cs.MS', 'cs.LG', '68T01', 'I.2']",,,[]
A fast exact simulation method for a class of Markov jump processes,http://arxiv.org/abs/1506.04802v2,2015-06-16T00:10:16Z,2015-10-22T22:09:30Z,"  A new method of the stochastic simulation algorithm (SSA), named the
Hashing-Leaping method (HLM), for exact simulations of a class of Markov jump
processes, is presented in this paper. The HLM has a conditional constant
computational cost per event, which is independent of the number of exponential
clocks in the Markov process. The main idea of the HLM is to repeatedly
implement a hash-table-like bucket sort algorithm for all times of occurrence
covered by a time step with length $\tau$. This paper serves as an introduction
to this new SSA method. We introduce the method, demonstrate its
implementation, analyze its properties, and compare its performance with three
other commonly used SSA methods in four examples. Our performance tests and CPU
operation statistics show certain advantage of the HLM for large scale
problems.
","['\nYao Li\n', '\nLili Hu\n']",The reviewers' comments are addressed in the new version,,http://arxiv.org/abs/1506.04802v2,math.NA,"['math.NA', 'cs.MS', '60J22, 65C05, 65C40']",,,[]
"Asynchronous processing of Coq documents: from the kernel up to the user
  interface",http://arxiv.org/abs/1506.05605v1,2015-06-18T09:47:41Z,2015-06-18T09:47:41Z,"  The work described in this paper improves the reactivity of the Coq system by
completely redesigning the way it processes a formal document. By subdividing
such work into independent tasks the system can give precedence to the ones of
immediate interest for the user and postpones the others. On the user side, a
modern interface based on the PIDE middleware aggregates and present in a
consistent way the output of the prover. Finally postponed tasks are processed
exploiting modern, parallel, hardware to offer better scalability.
","['\nBruno Barras\nSPECFUN\n', '\nCarst Tankink\nSPECFUN\n', '\nEnrico Tassi\nMARELLE\n']","in Proceedings of ITP, Aug 2015, Nanjing, China",,http://arxiv.org/abs/1506.05605v1,cs.LO,"['cs.LO', 'cs.MS']",,,"['SPECFUN', 'SPECFUN', 'MARELLE']"
"GRINS: A Multiphysics Framework Based on the libMesh Finite Element
  Library",http://arxiv.org/abs/1506.06102v1,2015-06-19T18:04:01Z,2015-06-19T18:04:01Z,"  The progression of scientific computing resources has enabled the numerical
approximation of mathematical models describing complex physical phenomena. A
significant portion of researcher time is typically dedicated to the
development of software to compute the numerical solutions. This work describes
a flexible C++ software framework, built on the libMesh finite element library,
designed to alleviate developer burden and provide easy access to modern
computational algorithms, including quantity-of-interest-driven parallel
adaptive mesh refinement on unstructured grids and adjoint-based sensitivities.
Other software environments are highlighted and the current work motivated; in
particular, the present work is an attempt to balance software infrastructure
and user flexibility. The applicable class of problems and design of the
software components is discussed in detail. Several examples demonstrate the
effectiveness of the design, including applications that incorporate
uncertainty. Current and planned developments are discussed.
","['\nPaul T. Bauman\n', '\nRoy H. Stogner\n']",Submitted to SISC CSE Special Issue,,http://arxiv.org/abs/1506.06102v1,cs.MS,"['cs.MS', 'cs.CE']",,,[]
Resilience for Multigrid Software at the Extreme Scale,http://arxiv.org/abs/1506.06185v1,2015-06-20T00:03:16Z,2015-06-20T00:03:16Z,"  Fault tolerant algorithms for the numerical approximation of elliptic partial
differential equations on modern supercomputers play a more and more important
role in the future design of exa-scale enabled iterative solvers. Here, we
combine domain partitioning with highly scalable geometric multigrid schemes to
obtain fast and fault-robust solvers in three dimensions. The recovery strategy
is based on a hierarchical hybrid concept where the values on lower dimensional
primitives such as faces are stored redundantly and thus can be recovered
easily in case of a failure. The lost volume unknowns in the faulty region are
re-computed approximately with multigrid cycles by solving a local Dirichlet
problem on the faulty subdomain. Different strategies are compared and
evaluated with respect to performance, computational cost, and speed up.
Especially effective are strategies in which the local recovery in the faulty
region is executed in parallel with global solves and when the local recovery
is additionally accelerated. This results in an asynchronous multigrid
iteration that can fully compensate faults. Excellent parallel performance on a
current peta-scale system is demonstrated.
","['\nMarkus Huber\n', '\nBjörn Gmeiner\n', '\nUlrich Rüde\n', '\nBarbara Wohlmuth\n']",,,http://arxiv.org/abs/1506.06185v1,cs.MS,"['cs.MS', 'cs.NA', '65N55, 65Y05, 68Q85']",,,[]
"Accurate computation of Galerkin double surface integrals in the 3-D
  boundary element method",http://arxiv.org/abs/1506.04462v1,2015-06-15T02:49:10Z,2015-06-15T02:49:10Z,"  Many boundary element integral equation kernels are based on the Green's
functions of the Laplace and Helmholtz equations in three dimensions. These
include, for example, the Laplace, Helmholtz, elasticity, Stokes, and Maxwell's
equations. Integral equation formulations lead to more compact, but dense
linear systems. These dense systems are often solved iteratively via Krylov
subspace methods, which may be accelerated via the fast multipole method. There
are advantages to Galerkin formulations for such integral equations, as they
treat problems associated with kernel singularity, and lead to symmetric and
better conditioned matrices. However, the Galerkin method requires each entry
in the system matrix to be created via the computation of a double surface
integral over one or more pairs of triangles. There are a number of
semi-analytical methods to treat these integrals, which all have some issues,
and are discussed in this paper. We present novel methods to compute all the
integrals that arise in Galerkin formulations involving kernels based on the
Laplace and Helmholtz Green's functions to any specified accuracy. Integrals
involving completely geometrically separated triangles are non-singular and are
computed using a technique based on spherical harmonics and multipole
expansions and translations, which results in the integration of polynomial
functions over the triangles. Integrals involving cases where the triangles
have common vertices, edges, or are coincident are treated via scaling and
symmetry arguments, combined with automatic recursive geometric decomposition
of the integrals. Example results are presented, and the developed software is
available as open source.
","['\nRoss Adelman\n', '\nNail A. Gumerov\n', '\nRamani Duraiswami\n']",,,http://dx.doi.org/10.1109/TAP.2016.2546951,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'cs.NA']",10.1109/TAP.2016.2546951,,[]
FEAST Eigensolver for non-Hermitian Problems,http://arxiv.org/abs/1506.04463v1,2015-06-15T02:55:29Z,2015-06-15T02:55:29Z,"  A detailed new upgrade of the FEAST eigensolver targeting non-Hermitian
eigenvalue problems is presented and thoroughly discussed. It aims at
broadening the class of eigenproblems that can be addressed within the
framework of the FEAST algorithm. The algorithm is ideally suited for computing
selected interior eigenvalues and their associated right/left bi-orthogonal
eigenvectors,located within a subset of the complex plane. It combines subspace
iteration with efficient contour integration techniques that approximate the
left and right spectral projectors. We discuss the various algorithmic choices
that have been made to improve the stability and usability of the new
non-Hermitian eigensolver. The latter retains the convergence property and
multi-level parallelism of Hermitian FEAST, making it a valuable new software
tool for the scientific community.
","['\nJames Kestyn\n', '\nEric Polizzi\n', '\nPing Tak Peter Tang\n']","22 pages, 8 figures, 4 tables",,http://arxiv.org/abs/1506.04463v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'physics.comp-ph']",,,[]
Unstructured Overlapping Mesh Distribution in Parallel,http://arxiv.org/abs/1506.06194v1,2015-06-20T02:25:14Z,2015-06-20T02:25:14Z,"  We present a simple mathematical framework and API for parallel mesh and data
distribution, load balancing, and overlap generation. It relies on viewing the
mesh as a Hasse diagram, abstracting away information such as cell shape,
dimension, and coordinates. The high level of abstraction makes our interface
both concise and powerful, as the same algorithm applies to any representable
mesh, such as hybrid meshes, meshes embedded in higher dimension, and
overlapped meshes in parallel. We present evidence, both theoretical and
experimental, that the algorithms are scalable and efficient. A working
implementation can be found in the latest release of the PETSc libraries.
","['\nMatthew G. Knepley\n', '\nMichael Lange\n', '\nGerard J. Gorman\n']","14 pages, 6 figures, submitted to TOMS",,http://arxiv.org/abs/1506.06194v1,cs.MS,"['cs.MS', 'cs.DC', 'math.NA']",,,[]
"decimalInfinite: All Decimals In Bits, No Loss, Same Order, Simple",http://arxiv.org/abs/1506.01598v2,2015-06-04T14:09:47Z,2015-06-17T12:01:04Z,"  This paper introduces a binary encoding that supports arbitrarily large,
small and precise decimals. It completely preserves information and order. It
does not rely on any arbitrary use-case-based choice of calibration and is
readily implementable and usable, as is. Finally, it is also simple to explain
and understand.
",['\nGhislain Fourny\n'],"Technical report, 9 pages",,http://arxiv.org/abs/1506.01598v2,cs.MS,"['cs.MS', '97R50', 'E.2']",,,[]
"Solving Polynomial Systems in the Cloud with Polynomial Homotopy
  Continuation",http://arxiv.org/abs/1506.02618v1,2015-06-08T19:05:49Z,2015-06-08T19:05:49Z,"  Polynomial systems occur in many fields of science and engineering.
Polynomial homotopy continuation methods apply symbolic-numeric algorithms to
solve polynomial systems. We describe the design and implementation of our web
interface and reflect on the application of polynomial homotopy continuation
methods to solve polynomial systems in the cloud. Via the graph isomorphism
problem we organize and classify the polynomial systems we solved. The
classification with the canonical form of a graph identifies newly submitted
systems with systems that have already been solved.
","['\nNathan Bliss\n', '\nJeff Sommars\n', '\nJan Verschelde\n', '\nXiangcheng Yu\n']",Accepted for publication in the Proceedings of CASC 2015,,http://arxiv.org/abs/1506.02618v1,cs.MS,"['cs.MS', 'cs.NA', 'cs.SC', 'math.AG', 'math.NA']",,,[]
"Remark on ""Algorithm 916: Computing the Faddeyeva and Voigt functions"":
  Efficiency Improvements and Fortran Translation",http://arxiv.org/abs/1505.06848v1,2015-05-26T08:25:45Z,2015-05-26T08:25:45Z,"  This remark describes efficiency improvements to Algorithm 916 [Zaghloul and
Ali 2011]. It is shown that the execution time required by the algorithm, when
run at its highest accuracy, may be improved by more than a factor of two. A
better accuracy vs efficiency trade off scheme is also implemented; this
requires the user to supply the number of significant figures desired in the
computed values as an extra input argument to the function. Using this
trade-off, it is shown that the efficiency of the algorithm may be further
improved significantly while maintaining reasonably accurate and safe results
that are free of the pitfalls and complete loss of accuracy seen in other
competitive techniques. The current version of the code is provided in Matlab
and Scilab in addition to a Fortran translation prepared to meet the needs of
real-world problems where very large numbers of function evaluations would
require the use of a compiled language. To fulfill this last requirement, a
recently proposed reformed version of Humlicek's w4 routine, shown to maintain
the claimed accuracy of the algorithm over a wide and fine grid is implemented
in the present Fortran translation for the case of 4 significant figures. This
latter modification assures the reliability of the code to be employed in the
solution of practical problems requiring numerous evaluation of the function
for applications tolerating low accuracy computations (<10-4).
",['\nMofreh R. Zaghloul\n'],"11 pages, 5 tables, Under review",,http://arxiv.org/abs/1505.06848v1,astro-ph.IM,"['astro-ph.IM', 'cs.MS']",,,[]
"A Practical Guide to Randomized Matrix Computations with MATLAB
  Implementations",http://arxiv.org/abs/1505.07570v6,2015-05-28T07:33:21Z,2015-11-03T03:26:49Z,"  Matrix operations such as matrix inversion, eigenvalue decomposition,
singular value decomposition are ubiquitous in real-world applications.
Unfortunately, many of these matrix operations so time and memory expensive
that they are prohibitive when the scale of data is large. In real-world
applications, since the data themselves are noisy, machine-precision matrix
operations are not necessary at all, and one can sacrifice a reasonable amount
of accuracy for computational efficiency.
  In recent years, a bunch of randomized algorithms have been devised to make
matrix computations more scalable. Mahoney (2011) and Woodruff (2014) have
written excellent but very technical reviews of the randomized algorithms.
Differently, the focus of this manuscript is on intuition, algorithm
derivation, and implementation. This manuscript should be accessible to people
with knowledge in elementary matrix algebra but unfamiliar with randomized
matrix computations. The algorithms introduced in this manuscript are all
summarized in a user-friendly way, and they can be implemented in lines of
MATLAB code. The readers can easily follow the implementations even if they do
not understand the maths and algorithms.
",['\nShusen Wang\n'],,,http://arxiv.org/abs/1505.07570v6,cs.MS,"['cs.MS', 'cs.LG']",,,[]
Research on the fast Fourier transform of image based on GPU,http://arxiv.org/abs/1505.08019v1,2015-05-29T12:33:52Z,2015-05-29T12:33:52Z,"  Study of general purpose computation by GPU (Graphics Processing Unit) can
improve the image processing capability of micro-computer system. This paper
studies the parallelism of the different stages of decimation in time radix 2
FFT algorithm, designs the butterfly and scramble kernels and implements 2D FFT
on GPU. The experiment result demonstrates the validity and advantage over
general CPU, especially in the condition of large input size. The approach can
also be generalized to other transforms alike.
","['\nFeifei Shen\n', '\nZhenjian Song\n', '\nCongrui Wu\n', '\nJiaqi Geng\n', '\nQingyun Wang\n']",,,http://arxiv.org/abs/1505.08019v1,cs.MS,"['cs.MS', 'cs.CV']",,,[]
"The Research and Optimization of Parallel Finite Element Algorithm based
  on MiniFE",http://arxiv.org/abs/1505.08023v1,2015-05-29T12:44:04Z,2015-05-29T12:44:04Z,"  Finite element method (FEM) is one of the most important numerical methods in
modern engineering design and analysis. Since traditional serial FEM is
difficult to solve large FE problems efficiently and accurately,
high-performance parallel FEM has become one of the essential way to solve
practical engineering problems. Based on MiniFE program, which is released by
National Energy Research Scientific Computing Center(NERSC), this work analyzes
concrete steps, key computing pattern and parallel mechanism of parallel FEM.
According to experimental results, this work analyzes the proportion of
calculation amount of each module and concludes the main performance bottleneck
of the program. Based on that, we optimize the MiniFE program on a server
platform. The optimization focuses on the bottleneck of the program - SpMV
kernel, and uses an efficient storage format named BCRS. Moreover, an improving
plan of hybrid MPI+OpenMP programming is provided. Experimental results show
that the optimized program performs better in both SpMV kernel and
synchronization. It can increase the performance of the program, on average, by
8.31%. Keywords : finite element, parallel, MiniFE, SpMV, performance
optimization
","['\nMeng Wu\n', '\nCan Yang\n', '\nTaoran Xiang\n', '\nDaning Cheng\n']",,,http://arxiv.org/abs/1505.08023v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
MLlib: Machine Learning in Apache Spark,http://arxiv.org/abs/1505.06807v1,2015-05-26T05:12:23Z,2015-05-26T05:12:23Z,"  Apache Spark is a popular open-source platform for large-scale data
processing that is well-suited for iterative machine learning tasks. In this
paper we present MLlib, Spark's open-source distributed machine learning
library. MLlib provides efficient functionality for a wide range of learning
settings and includes several underlying statistical, optimization, and linear
algebra primitives. Shipped with Spark, MLlib supports several languages and
provides a high-level API that leverages Spark's rich ecosystem to simplify the
development of end-to-end machine learning pipelines. MLlib has experienced a
rapid growth due to its vibrant open-source community of over 140 contributors,
and includes extensive documentation to support further growth and to let users
quickly get up to speed.
","['\nXiangrui Meng\n', '\nJoseph Bradley\n', '\nBurak Yavuz\n', '\nEvan Sparks\n', '\nShivaram Venkataraman\n', '\nDavies Liu\n', '\nJeremy Freeman\n', '\nDB Tsai\n', '\nManish Amde\n', '\nSean Owen\n', '\nDoris Xin\n', '\nReynold Xin\n', '\nMichael J. Franklin\n', '\nReza Zadeh\n', '\nMatei Zaharia\n', '\nAmeet Talwalkar\n']",,,http://arxiv.org/abs/1505.06807v1,cs.LG,"['cs.LG', 'cs.DC', 'cs.MS', 'stat.ML']",,,[]
"SYM-ILDL: Incomplete $LDL^{T}$ Factorization of Symmetric Indefinite and
  Skew-Symmetric Matrices",http://arxiv.org/abs/1505.07589v3,2015-05-28T08:25:45Z,2016-11-01T23:54:16Z,"  SYM-ILDL is a numerical software package that computes incomplete $LDL^{T}$
(or `ILDL') factorizations of symmetric indefinite and real skew-symmetric
matrices. The core of the algorithm is a Crout variant of incomplete LU (ILU),
originally introduced and implemented for symmetric matrices by [Li and Saad,
Crout versions of ILU factorization with pivoting for sparse symmetric
matrices, Transactions on Numerical Analysis 20, pp. 75--85, 2005]. Our code is
economical in terms of storage and it deals with real skew-symmetric matrices
as well, in addition to symmetric ones. The package is written in C++ and it is
templated, open source, and includes a MATLAB interface. The code includes
built-in RCM and AMD reordering, two equilibration strategies, threshold
Bunch-Kaufman pivoting and rook pivoting, as well as a wrapper to MC64, a
popular matching based equilibration and reordering algorithm. We also include
two built-in iterative solvers: SQMR preconditioned with ILDL, or MINRES
preconditioned with a symmetric positive definite preconditioner based on the
ILDL factorization.
","['\nChen Greif\n', '\nShiwen He\n', '\nPaul Liu\n']","19 pages, 3 figures",,http://arxiv.org/abs/1505.07589v3,cs.MS,"['cs.MS', 'cs.NA', 'math.NA', 'F.2.1; G.1.0; G.1.3']",,,[]
"Efficient FFT mapping on GPU for radar processing application: modeling
  and implementation",http://arxiv.org/abs/1505.08067v1,2015-05-29T14:45:03Z,2015-05-29T14:45:03Z,"  General-purpose multiprocessors (as, in our case, Intel IvyBridge and Intel
Haswell) increasingly add GPU computing power to the former multicore
architectures. When used for embedded applications (for us, Synthetic aperture
radar) with intensive signal processing requirements, they must constantly
compute convolution algorithms, such as the famous Fast Fourier Transform. Due
to its ""fractal"" nature (the typical butterfly shape, with larger FFTs defined
as combination of smaller ones with auxiliary data array transpose functions),
one can hope to compute analytically the size of the largest FFT that can be
performed locally on an elementary GPU compute block. Then, the full
application must be organized around this given building block size. Now, due
to phenomena involved in the data transfers between various memory levels
across CPUs and GPUs, the optimality of such a scheme is only loosely
predictable (as communications tend to overcome in time the complexity of
computations). Therefore a mix of (theoretical) analytic approach and
(practical) runtime validation is here needed. As we shall illustrate, this
occurs at both stage, first at the level of deciding on a given elementary FFT
block size, then at the full application level.
","['\nMohamed Amine Bergach\n', '\nEmilien Kofman\n', '\nRobert de Simone\n', '\nSerge Tissot\n', '\nMichel Syska\n']",,,http://arxiv.org/abs/1505.08067v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF']",,,[]
"Flexible, Scalable Mesh and Data Management using PETSc DMPlex",http://arxiv.org/abs/1505.04633v1,2015-05-18T13:35:50Z,2015-05-18T13:35:50Z,"  Designing a scientific software stack to meet the needs of the
next-generation of mesh-based simulation demands, not only scalable and
efficient mesh and data management on a wide range of platforms, but also an
abstraction layer that makes it useful for a wide range of application codes.
Common utility tasks, such as file I/O, mesh distribution, and work
partitioning, should be delegated to external libraries in order to promote
code re-use, extensibility and software interoperability. In this paper we
demonstrate the use of PETSc's DMPlex data management API to perform mesh input
and domain partitioning in Fluidity, a large scale CFD application. We
demonstrate that raising the level of abstraction adds new functionality to the
application code, such as support for additional mesh file formats and mesh re-
ordering, while improving simulation startup cost through more efficient mesh
distribution. Moreover, the separation of concerns accomplished through this
interface shifts critical performance and interoperability issues, such as
scalable I/O and file format support, to a widely used and supported open
source community library, improving the sustainability, performance, and
functionality of Fluidity.
","['\nMichael Lange\n', '\nMatthew G. Knepley\n', '\nGerard J. Gorman\n']","6 pages, 6 figures, to appear in EASC 2015",,http://arxiv.org/abs/1505.04633v1,cs.MS,['cs.MS'],,,[]
"POLYANA - A tool for the calculation of molecular radial distribution
  functions based on Molecular Dynamics trajectories",http://arxiv.org/abs/1508.05374v1,2015-05-11T19:11:56Z,2015-05-11T19:11:56Z,"  We present an application for the calculation of radial distribution
functions for molecular centres of mass, based on trajectories generated by
molecular simulation methods (Molecular Dynamics, Monte Carlo). When designing
this application, the emphasis was placed on ease of use as well as ease of
further development. In its current version, the program can read trajectories
generated by the well-known DL_POLY package, but it can be easily extended to
treat other formats. It is also very easy to 'hack' the program so it can
compute intermolecular radial distribution functions for groups of interaction
sites rather than whole molecules.
","['\nChristos Dimitroulis\n', '\nTheophanes Raptis\n', '\nVasilios Raptis\n']","16 pages, 3 figures",,http://dx.doi.org/10.1016/j.cpc.2015.08.011,cs.MS,['cs.MS'],10.1016/j.cpc.2015.08.011,,[]
A parallel edge orientation algorithm for quadrilateral meshes,http://arxiv.org/abs/1505.03357v3,2015-05-13T12:34:54Z,2015-12-11T17:24:01Z,"  One approach to achieving correct finite element assembly is to ensure that
the local orientation of facets relative to each cell in the mesh is consistent
with the global orientation of that facet. Rognes et al. have shown how to
achieve this for any mesh composed of simplex elements, and deal.II contains a
serial algorithm to construct a consistent orientation of any quadrilateral
mesh of an orientable manifold.
  The core contribution of this paper is the extension of this algorithm for
distributed memory parallel computers, which facilitates its seamless
application as part of a parallel simulation system.
  Furthermore, our analysis establishes a link between the well-known
Union-Find algorithm and the construction of a consistent orientation of a
quadrilateral mesh. As a result, existing work on the parallelisation of the
Union-Find algorithm can be easily adapted to construct further parallel
algorithms for mesh orientations.
","['\nMiklós Homolya\n', '\nDavid A. Ham\n']",Second revision: minor changes,"SIAM Journal on Scientific Computing, 38 (2016), pp. S48-S61",http://dx.doi.org/10.1137/15M1021325,cs.MS,"['cs.MS', 'cs.CG']",10.1137/15M1021325,,[]
"Automatic and Transparent Transfer of Theorems along Isomorphisms in the
  Coq Proof Assistant",http://arxiv.org/abs/1505.05028v4,2015-05-19T14:50:14Z,2015-07-09T11:45:47Z,"  In mathematics, it is common practice to have several constructions for the
same objects. Mathematicians will identify them modulo isomorphism and will not
worry later on which construction they use, as theorems proved for one
construction will be valid for all.
  When working with proof assistants, it is also common to see several
data-types representing the same objects. This work aims at making the use of
several isomorphic constructions as simple and as transparent as it can be done
informally in mathematics. This requires inferring automatically the missing
proof-steps.
  We are designing an algorithm which finds and fills these missing proof-steps
and we are implementing it as a plugin for Coq.
","['\nThéo Zimmermann\nENS Paris, PPS\n', '\nHugo Herbelin\nPPS, PI.R2\n']",,,http://arxiv.org/abs/1505.05028v4,cs.LO,"['cs.LO', 'cs.MS']",,,"['ENS Paris, PPS', 'PPS, PI.R2']"
"Sparse Automatic Differentiation for Complex Networks of
  Differential-Algebraic Equations Using Abstract Elementary Algebra",http://arxiv.org/abs/1505.00838v2,2015-05-04T23:05:54Z,2021-05-12T22:22:54Z,"  Most numerical solvers and libraries nowadays are implemented to use
mathematical models created with language-specific built-in data types (e.g.
real in Fortran or double in C) and their respective elementary algebra
implementations. However, the built-in elementary algebra typically has limited
functionality and often restricts the flexibility of mathematical models and
the analysis types that can be applied to those models. To overcome this
limitation, a number of domain-specific languages such as gPROMS or Modelica
with more feature-rich built-in data types have been proposed. In this paper,
we argue that if numerical libraries and solvers are designed to use abstract
elementary algebra rather than the language-specific built-in algebra, modern
mainstream languages can be as effective as any domain-specific language. We
illustrate our ideas using the example of sparse Jacobian matrix computation.
We implement an automatic differentiation method that takes advantage of sparse
system structures and is straightforward to parallelize in a distributed memory
setting. Furthermore, we show that the computational cost scales linearly with
the size of the system.
","['\nSlaven Peles\n', '\nStefan Klus\n']",,"International Journal of Numerical Analysis and Modeling. 14 (6).
  pp. 916-934 (2017)",http://arxiv.org/abs/1505.00838v2,cs.MS,['cs.MS'],,,[]
"Documentation Generator Focusing on Symbols for the HTML-ized Mizar
  Library",http://arxiv.org/abs/1505.01577v1,2015-05-07T04:09:24Z,2015-05-07T04:09:24Z,"  The purpose of this project is to collect symbol information in the Mizar
Mathematical Library and manipulate it into practical and organized
documentation. Inspired by the MathWiki project and API reference systems for
computer programs, we developed a documentation generator focusing on symbols
for the HTML-ized Mizar library. The system has several helpful features,
including a symbol list, incremental search, and a referrer list. It targets
those who use proof assistance systems, the volume of whose libraries has been
rapidly increasing year by year.
","['\nKazuhisa Nakasho\n', '\nYasunari Shidama\n']","5 pages, 1 figures, Conference on Intelligent Computer Mathematics
  2015 (CICM2015)",,http://arxiv.org/abs/1505.01577v1,cs.MS,"['cs.MS', 'G.4']",,,[]
Large-scale linear regression: Development of high-performance routines,http://arxiv.org/abs/1504.07890v1,2015-04-29T15:24:33Z,2015-04-29T15:24:33Z,"  In statistics, series of ordinary least squares problems (OLS) are used to
study the linear correlation among sets of variables of interest; in many
studies, the number of such variables is at least in the millions, and the
corresponding datasets occupy terabytes of disk space. As the availability of
large-scale datasets increases regularly, so does the challenge in dealing with
them. Indeed, traditional solvers---which rely on the use of black-box""
routines optimized for one single OLS---are highly inefficient and fail to
provide a viable solution for big-data analyses. As a case study, in this paper
we consider a linear regression consisting of two-dimensional grids of related
OLS problems that arise in the context of genome-wide association analyses, and
give a careful walkthrough for the development of {\sc ols-grid}, a
high-performance routine for shared-memory architectures; analogous steps are
relevant for tailoring OLS solvers to other applications. In particular, we
first illustrate the design of efficient algorithms that exploit the structure
of the OLS problems and eliminate redundant computations; then, we show how to
effectively deal with datasets that do not fit in main memory; finally, we
discuss how to cast the computation in terms of efficient kernels and how to
achieve scalability. Importantly, each design decision along the way is
justified by simple performance models. {\sc ols-grid} enables the solution of
$10^{11}$ correlated OLS problems operating on terabytes of data in a matter of
hours.
","['\nAlvaro Frank\n', '\nDiego Fabregat-Traver\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1504.07890v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
Applying Sorting Networks to Synthesize Optimized Sorting Libraries,http://arxiv.org/abs/1505.01962v2,2015-05-08T09:13:25Z,2015-10-16T14:33:46Z,"  This paper shows an application of the theory of sorting networks to
facilitate the synthesis of optimized general purpose sorting libraries.
Standard sorting libraries are often based on combinations of the classic
Quicksort algorithm with insertion sort applied as the base case for small
fixed numbers of inputs. Unrolling the code for the base case by ignoring loop
conditions eliminates branching and results in code which is equivalent to a
sorting network. This enables the application of further program
transformations based on sorting network optimizations, and eventually the
synthesis of code from sorting networks. We show that if considering the number
of comparisons and swaps then theory predicts no real advantage of this
approach. However, significant speed-ups are obtained when taking advantage of
instruction level parallelism and non-branching conditional assignment
instructions, both of which are common in modern CPU architectures. We provide
empirical evidence that using code synthesized from efficient sorting networks
as the base case for Quicksort libraries results in significant real-world
speed-ups.
","['\nMichael Codish\n', '\nLuís Cruz-Filipe\n', '\nMarkus Nebel\n', '\nPeter Schneider-Kamp\n']",IMADA-preprint-cs,,http://dx.doi.org/10.1007/978-3-319-27436-2_8,cs.DS,"['cs.DS', 'cs.MS']",10.1007/978-3-319-27436-2_8,,[]
The ELAPS Framework: Experimental Linear Algebra Performance Studies,http://arxiv.org/abs/1504.08035v1,2015-04-29T21:58:50Z,2015-04-29T21:58:50Z,"  Optimal use of computing resources requires extensive coding, tuning and
benchmarking. To boost developer productivity in these time consuming tasks, we
introduce the Experimental Linear Algebra Performance Studies framework
(ELAPS), a multi-platform open source environment for fast yet powerful
performance experimentation with dense linear algebra kernels, algorithms, and
libraries. ELAPS allows users to construct experiments to investigate how
performance and efficiency vary depending on factors such as caching,
algorithmic parameters, problem size, and parallelism. Experiments are designed
either through Python scripts or a specialized GUI, and run on the whole
spectrum of architectures, ranging from laptops to clusters, accelerators, and
supercomputers. The resulting experiment reports provide various metrics and
statistics that can be analyzed both numerically and visually. We demonstrate
the use of ELAPS in four concrete application scenarios and in as many
computing environments, illustrating its practical value in supporting critical
performance decisions.
","['\nElmar Peise\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",Submitted to SC15,,http://arxiv.org/abs/1504.08035v1,cs.PF,"['cs.PF', 'cs.MS', 'cs.NA']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
"Fireflies: New software for interactively exploring dynamical systems
  using GPU computing",http://arxiv.org/abs/1505.00344v1,2015-05-02T13:57:16Z,2015-05-02T13:57:16Z,"  In non-linear systems, where explicit analytic solutions usually can't be
found, visualisation is a powerful approach which can give insights into the
dynamical behaviour of models; it is also crucial for teaching this area of
mathematics. In this paper we present new software, Fireflies, which exploits
the power of graphical processing unit (GPU) computing to produce spectacular
interactive visualisations of arbitrary systems of ordinary differential
equations. In contrast to typical phase portraits, Fireflies draws the current
position of trajectories (projected onto 2D or 3D space) as single points of
light, which move as the system is simulated. Due to the massively parallel
nature of GPU hardware, Fireflies is able to simulate millions of trajectories
in parallel (even on standard desktop computer hardware), producing ""swarms"" of
particles that move around the screen in real-time according to the equations
of the system. Particles that move forwards in time reveal stable attractors
(e.g. fixed points and limit cycles), while the option of integrating another
group of trajectories backwards in time can reveal unstable objects
(repellers). Fireflies allows the user to change the parameters of the system
as it is running, in order to see the effect that they have on the dynamics and
to observe bifurcations. We demonstrate the capabilities of the software with
three examples: a two-dimensional ""mean field"" model of neuronal activity, the
classical Lorenz system, and a 15-dimensional model of three interacting
biologically realistic neurons.
",['\nRobert Merrison-Hort\n'],"31 pages, 8 figures, 4 supplementary videos",,http://dx.doi.org/10.1142/S0218127415501813,cs.MS,"['cs.MS', 'cs.DC', 'math.DS']",10.1142/S0218127415501813,,[]
"Tracking Many Solution Paths of a Polynomial Homotopy on a Graphics
  Processing Unit",http://arxiv.org/abs/1505.00383v1,2015-05-03T00:50:23Z,2015-05-03T00:50:23Z,"  Polynomial systems occur in many areas of science and engineering. Unlike
general nonlinear systems, the algebraic structure enables to compute all
solutions of a polynomial system. We describe our massive parallel
predictor-corrector algorithms to track many solution paths of a polynomial
homotopy. The data parallelism that provides the speedups stems from the
evaluation and differentiation of the monomials in the same polynomial system
at different data points, which are the points on the solution paths.
Polynomial homotopies that have tens of thousands of solution paths can keep a
sufficiently large amount of threads occupied. Our accelerated code combines
the reverse mode of algorithmic differentiation with double double and quad
double precision to compute more accurate results faster.
","['\nJan Verschelde\n', '\nXiangcheng Yu\n']",,,http://arxiv.org/abs/1505.00383v1,cs.MS,"['cs.MS', 'cs.NA', 'math.AG', 'math.NA']",,,[]
"LeoPARD --- A Generic Platform for the Implementation of Higher-Order
  Reasoners",http://arxiv.org/abs/1505.01629v1,2015-05-07T08:54:19Z,2015-05-07T08:54:19Z,"  LeoPARD supports the implementation of knowledge representation and reasoning
tools for higher-order logic(s). It combines a sophisticated data structure
layer (polymorphically typed {\lambda}-calculus with nameless spine notation,
explicit substitutions, and perfect term sharing) with an ambitious multi-agent
blackboard architecture (supporting prover parallelism at the term, clause, and
search level). Further features of LeoPARD include a parser for all TPTP
dialects, a command line interpreter, and generic means for the integration of
external reasoners.
","['\nMax Wisniewski\n', '\nAlexander Steen\n', '\nChristoph Benzmüller\n']","6 pages, to appear in the proceedings of CICM'2015 conference",,http://arxiv.org/abs/1505.01629v1,cs.LO,"['cs.LO', 'cs.AI', 'cs.MA', 'cs.MS', '03B35, 68T15', 'I.2.3; F.4.1']",,,[]
Symmetric matrix inversion using modified Gaussian elimination,http://arxiv.org/abs/1504.06734v1,2015-04-25T14:45:33Z,2015-04-25T14:45:33Z,"  In this paper we present two different variants of method for symmetric
matrix inversion, based on modified Gaussian elimination. Both methods avoid
computation of square roots and have a reduced machine time's spending.
Further, both of them can be used efficiently not only for positive (semi-)
definite, but for any non-singular symmetric matrix inversion. We use
simulation to verify results, which represented in this paper.
","['\nAnton Kochnev\n', '\nNicolai Savelov\n']","5 pages, 6 tables",,http://arxiv.org/abs/1504.06734v1,cs.MS,['cs.MS'],,,[]
Software realization of the complex spectra analysis algorithm in R,http://arxiv.org/abs/1506.06704v1,2015-04-25T07:16:35Z,2015-04-25T07:16:35Z,"  Software realization of the complex spectra decomposition on unknown number
of similarcomponents is proposed.The algorithm is based on non-linear
minimizing the sum of squared residuals of the spectrum model. For the adequacy
checking the complex of criteria is used.It tests the model residuals
correspondence with the normal distribution, equality to zero of their mean
value and autocorrelation. Also the closeness of residuals and experimental
data variances is checked.
",['\nVladimir Bakhrushin\n'],,"Bakhrushin, V. (2015) ""Software realization of the complex spectra
  analysis algorithm in R"" [""Programmnaya realizatsiya algoritma analiza
  slozhnyih spektrov na yazyike R""], Sistemni tehnologiyi, No 2 (97), pp. 3 - 7",http://arxiv.org/abs/1506.06704v1,cs.MS,"['cs.MS', 'physics.data-an']",,,[]
"Enhancing the scalability and load balancing of the parallel selected
  inversion algorithm via tree-based asynchronous communication",http://arxiv.org/abs/1504.04714v1,2015-04-18T12:46:33Z,2015-04-18T12:46:33Z,"  We develop a method for improving the parallel scalability of the recently
developed parallel selected inversion algorithm [Jacquelin, Lin and Yang 2014],
named PSelInv, on massively parallel distributed memory machines. In the
PSelInv method, we compute selected elements of the inverse of a sparse matrix
A that can be decomposed as A = LU, where L is lower triangular and U is upper
triangular. Updating these selected elements of A-1 requires restricted
collective communications among a subset of processors within each column or
row communication group created by a block cyclic distribution of L and U. We
describe how this type of restricted collective communication can be
implemented by using asynchronous point-to-point MPI communication functions
combined with a binary tree based data propagation scheme. Because multiple
restricted collective communications may take place at the same time in the
parallel selected inversion algorithm, we need to use a heuristic to prevent
processors participating in multiple collective communications from receiving
too many messages. This heuristic allows us to reduce communication load
imbalance and improve the overall scalability of the selected inversion
algorithm. For instance, when 6,400 processors are used, we observe over 5x
speedup for test matrices. It also mitigates the performance variability
introduced by an inhomogeneous network topology.
","['\nMathias Jacquelin\n', '\nLin Lin\n', '\nNathan Wichmann\n', '\nChao Yang\n']",,,http://arxiv.org/abs/1504.04714v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
"A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and
  Heterogeneous Processors",http://arxiv.org/abs/1504.05022v2,2015-04-20T11:58:05Z,2015-09-13T07:38:29Z,"  General sparse matrix-matrix multiplication (SpGEMM) is a fundamental
building block for numerous applications such as algebraic multigrid method
(AMG), breadth first search and shortest path problem. Compared to other sparse
BLAS routines, an efficient parallel SpGEMM implementation has to handle extra
irregularity from three aspects: (1) the number of nonzero entries in the
resulting sparse matrix is unknown in advance, (2) very expensive parallel
insert operations at random positions in the resulting sparse matrix dominate
the execution time, and (3) load balancing must account for sparse data in both
input matrices.
  In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU
heterogeneous processors. This framework particularly focuses on the above
three problems. Memory pre-allocation for the resulting matrix is organized by
a hybrid method that saves a large amount of global memory space and
efficiently utilizes the very limited on-chip scratchpad memory. Parallel
insert operations of the nonzero entries are implemented through the GPU merge
path algorithm that is experimentally found to be the fastest GPU merge
approach. Load balancing builds on the number of necessary arithmetic
operations on the nonzero entries and is guaranteed in all stages.
  Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach
delivers excellent absolute performance and relative speedups on various
benchmarks multiplying matrices with diverse sparsity structures. Furthermore,
on heterogeneous processors, our SpGEMM approach achieves higher throughput by
using re-allocatable shared virtual memory.
  The source code of this work is available at
https://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR
","['\nWeifeng Liu\n', '\nBrian Vinter\n']","25 pages, 12 figures, published at Journal of Parallel and
  Distributed Computing (JPDC)",,http://dx.doi.org/10.1016/j.jpdc.2015.06.010,cs.MS,"['cs.MS', 'cs.DC', 'math.NA', '65F50', 'G.4; G.1.3']",10.1016/j.jpdc.2015.06.010,,[]
"Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on
  Heterogeneous Processors",http://arxiv.org/abs/1504.06474v2,2015-04-24T11:23:38Z,2015-09-14T09:59:24Z,"  Sparse matrix-vector multiplication (SpMV) is a central building block for
scientific software and graph applications. Recently, heterogeneous processors
composed of different types of cores attracted much attention because of their
flexible core configuration and high energy efficiency. In this paper, we
propose a compressed sparse row (CSR) format based SpMV algorithm utilizing
both types of cores in a CPU-GPU heterogeneous processor. We first
speculatively execute segmented sum operations on the GPU part of a
heterogeneous processor and generate a possibly incorrect results. Then the CPU
part of the same chip is triggered to re-arrange the predicted partial sums for
a correct resulting vector. On three heterogeneous processors from Intel, AMD
and nVidia, using 20 sparse matrices as a benchmark suite, the experimental
results show that our method obtains significant performance improvement over
the best existing CSR-based SpMV algorithms. The source code of this work is
downloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR
","['\nWeifeng Liu\n', '\nBrian Vinter\n']","22 pages, 8 figures, Published at Parallel Computing (PARCO)",,http://dx.doi.org/10.1016/j.parco.2015.04.004,cs.MS,"['cs.MS', 'cs.DC', 'math.NA', '65F50', 'G.4; G.1.3']",10.1016/j.parco.2015.04.004,,[]
Representing numeric data in 32 bits while preserving 64-bit precision,http://arxiv.org/abs/1504.02914v1,2015-04-11T20:33:06Z,2015-04-11T20:33:06Z,"  Data files often consist of numbers having only a few significant decimal
digits, whose information content would allow storage in only 32 bits. However,
we may require that arithmetic operations involving these numbers be done with
64-bit floating-point precision, which precludes simply representing the data
as 32-bit floating-point values. Decimal floating point gives a compact and
exact representation, but requires conversion with a slow division operation
before it can be used. Here, I show that interesting subsets of 64-bit
floating-point values can be compactly and exactly represented by the 32 bits
consisting of the sign, exponent, and high-order part of the mantissa, with the
lower-order 32 bits of the mantissa filled in by table lookup, indexed by bits
from the part of the mantissa retained, and possibly from the exponent. For
example, decimal data with 4 or fewer digits to the left of the decimal point
and 2 or fewer digits to the right of the decimal point can be represented in
this way using the lower-order 5 bits of the retained part of the mantissa as
the index. Data consisting of 6 decimal digits with the decimal point in any of
the 7 positions before or after one of the digits can also be represented this
way, and decoded using 19 bits from the mantissa and exponent as the index.
Encoding with such a scheme is a simple copy of half the 64-bit value, followed
if necessary by verification that the value can be represented, by checking
that it decodes correctly. Decoding requires only extraction of index bits and
a table lookup. Lookup in a small table will usually reference cache; even with
larger tables, decoding is still faster than conversion from decimal floating
point with a division operation. I discuss how such schemes perform on recent
computer systems, and how they might be used to automatically compress large
arrays in interpretive languages such as R.
",['\nRadford M. Neal\n'],,,http://arxiv.org/abs/1504.02914v1,stat.CO,"['stat.CO', 'cs.MS', 'cs.NA']",,,[]
"A Collection of Challenging Optimization Problems in Science,
  Engineering and Economics",http://arxiv.org/abs/1504.02366v1,2015-04-09T16:31:25Z,2015-04-09T16:31:25Z,"  Function optimization and finding simultaneous solutions of a system of
nonlinear equations (SNE) are two closely related and important optimization
problems. However, unlike in the case of function optimization in which one is
required to find the global minimum and sometimes local minima, a database of
challenging SNEs where one is required to find stationary points (extrama and
saddle points) is not readily available. In this article, we initiate building
such a database of important SNE (which also includes related function
optimization problems), arising from Science, Engineering and Economics. After
providing a short review of the most commonly used mathematical and
computational approaches to find solutions of such systems, we provide a
preliminary list of challenging problems by writing the Mathematical
formulation down, briefly explaning the origin and importance of the problem
and giving a short account on the currently known results, for each of the
problems. We anticipate that this database will not only help benchmarking
novel numerical methods for solving SNEs and function optimization problems but
also will help advancing the corresponding research areas.
","['\nDhagash Mehta\n', '\nCrina Grosan\n']","Accepted as an invited contribution to the special session on
  Evolutionary Computation for Nonlinear Equation Systems at the 2015 IEEE
  Congress on Evolutionary Computation (at Sendai International Center, Sendai,
  Japan, from 25th to 28th May, 2015.)",,http://dx.doi.org/10.1109/CEC.2015.7257223,cs.NA,"['cs.NA', 'cs.MS', 'cs.NE', 'math.AG', 'math.NA', 'math.OC', 'physics.comp-ph']",10.1109/CEC.2015.7257223,,[]
"Finite element numerical integration for first order approximations on
  multi-core architectures",http://arxiv.org/abs/1504.01023v1,2015-04-04T16:56:02Z,2015-04-04T16:56:02Z,"  The paper presents investigations on the implementation and performance of
the finite element numerical integration algorithm for first order
approximations and three processor architectures, popular in scientific
computing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying
programming model and portable OpenCL implementation is considered for all
architectures. Variations of the algorithm due to different problems solved and
different element types are investigated and several optimizations aimed at
proper optimization and mapping of the algorithm to computer architectures are
demonstrated. Performance models of execution are developed for different
processors and tested in practical experiments. The results show the varying
levels of performance for different architectures, but indicate that the
algorithm can be effectively ported to all of them. The general conclusion is
that the finite element numerical integration can achieve sufficient
performance on different multi- and many-core architectures and should not
become a performance bottleneck for finite element simulation codes. Specific
observations lead to practical advises on how to optimize the kernels and what
performance can be expected for the tested architectures.
","['\nKrzysztof Banaś\n', '\nFilip Krużel\n', '\nJan Bielański\n']",,,http://dx.doi.org/10.1016/j.cma.2016.03.038,cs.MS,['cs.MS'],10.1016/j.cma.2016.03.038,,[]
Assessing Excel VBA Suitability for Monte Carlo Simulation,http://arxiv.org/abs/1503.08376v1,2015-03-29T01:51:49Z,2015-03-29T01:51:49Z,"  Monte Carlo (MC) simulation includes a wide range of stochastic techniques
used to quantitatively evaluate the behavior of complex systems or processes.
Microsoft Excel spreadsheets with Visual Basic for Applications (VBA) software
is, arguably, the most commonly employed general purpose tool for MC
simulation. Despite the popularity of the Excel in many industries and
educational institutions, it has been repeatedly criticized for its flaws and
often described as questionable, if not completely unsuitable, for statistical
problems. The purpose of this study is to assess suitability of the Excel
(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC
simulation. The results of the study indicate that Microsoft Excel (versions
2010 and 2013) is a strong Monte Carlo simulation application offering a solid
framework of core simulation components including spreadsheets for data input
and output, VBA development environment and summary statistics functions. This
framework should be complemented with an external high-quality pseudo-random
number generator added as a VBA module. A large and diverse category of Excel
incidental simulation components that includes statistical distributions,
linear and non-linear regression and other statistical, engineering and
business functions require execution of due diligence to determine their
suitability for a specific MC project.
",['\nAlexei Botchkarev\n'],,"Spreadsheets in Education (eJSiE): 2015, Vol. 8: Iss. 2, Article 3",http://arxiv.org/abs/1503.08376v1,cs.MS,"['cs.MS', 'stat.CO']",,,[]
Python bindings for libcloudph++,http://arxiv.org/abs/1504.01161v1,2015-04-05T20:58:18Z,2015-04-05T20:58:18Z,"  This technical note introduces the Python bindings for libcloudph++. The
libcloudph++ is a C++ library of algorithms for representing atmospheric cloud
microphysics in numerical models. The bindings expose the complete
functionality of the library to the Python users. The bindings are implemented
using the Boost.Python C++ library and use NumPy arrays. This note includes
listings with Python scripts exemplifying the use of selected library
components. An example solution for using the Python bindings to access
libcloudph++ from Fortran is presented.
","['\nDorota Jarecka\n', '\nSylwester Arabas\n', '\nDavide Del Vento\n']",,,http://arxiv.org/abs/1504.01161v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'physics.ao-ph']",,,[]
"Fast Multiplication of Large Integers: Implementation and Analysis of
  the DKSS Algorithm",http://arxiv.org/abs/1503.04955v1,2015-03-17T09:03:34Z,2015-03-17T09:03:34Z,"  The Sch\""onhage-Strassen algorithm (SSA) is the de-facto standard for
multiplication of large integers. For $N$-bit numbers it has a time bound of
$O(N \cdot \log N \cdot \log \log N)$. De, Kurur, Saha and Saptharishi (DKSS)
presented an asymptotically faster algorithm with a better time bound of $N
\cdot \log N \cdot 2^{O(\log^* N)}$. In this diploma thesis, results of an
implementation of DKSS multiplication are presented: run-time is about 30 times
larger than SSA, while memory requirements are about 3.75 times higher than
SSA. A possible crossover point is estimated to be out of reach even if we
utilized the whole universe for computer memory.
",['\nChristoph Lüders\n'],"Diploma Thesis, Universit\""at Bonn",,http://arxiv.org/abs/1503.04955v1,cs.MS,"['cs.MS', 'G.1.0; G.4; I.1.2']",,,[]
"A distributed-memory package for dense Hierarchically Semi-Separable
  matrix computations using randomization",http://arxiv.org/abs/1503.05464v2,2015-03-18T16:01:25Z,2015-06-26T18:59:36Z,"  We present a distributed-memory library for computations with dense
structured matrices. A matrix is considered structured if its off-diagonal
blocks can be approximated by a rank-deficient matrix with low numerical rank.
Here, we use Hierarchically Semi-Separable representations (HSS). Such matrices
appear in many applications, e.g., finite element methods, boundary element
methods, etc. Exploiting this structure allows for fast solution of linear
systems and/or fast computation of matrix-vector products, which are the two
main building blocks of matrix computations. The compression algorithm that we
use, that computes the HSS form of an input dense matrix, relies on randomized
sampling with a novel adaptive sampling mechanism. We discuss the
parallelization of this algorithm and also present the parallelization of
structured matrix-vector product, structured factorization and solution
routines. The efficiency of the approach is demonstrated on large problems from
different academic and industrial applications, on up to 8,000 cores.
  This work is part of a more global effort, the STRUMPACK (STRUctured Matrices
PACKage) software package for computations with sparse and dense structured
matrices. Hence, although useful on their own right, the routines also
represent a step in the direction of a distributed-memory sparse solver.
","['\nFrançois-Henry Rouet\n', '\nXiaoye S. Li\n', '\nPieter Ghysels\n', '\nArtem Napov\n']",,,http://arxiv.org/abs/1503.05464v2,cs.MS,['cs.MS'],,,[]
"GAIL---Guaranteed Automatic Integration Library in MATLAB: Documentation
  for Version 2.1",http://arxiv.org/abs/1503.06544v2,2015-03-23T07:45:09Z,2015-03-24T00:53:39Z,"  Automatic and adaptive approximation, optimization, or integration of
functions in a cone with guarantee of accuracy is a relatively new paradigm.
Our purpose is to create an open-source MATLAB package, Guaranteed Automatic
Integration Library (GAIL), following the philosophy of reproducible research
and sustainable practices of robust scientific software development. For our
conviction that true scholarship in computational sciences are characterized by
reliable reproducibility, we employ the best practices in mathematical research
and software engineering known to us and available in MATLAB. This document
describes the key features of functions in GAIL, which includes one-dimensional
function approximation and minimization using linear splines, one-dimensional
numerical integration using trapezoidal rule, and last but not least, mean
estimation and multidimensional integration by Monte Carlo methods or Quasi
Monte Carlo methods.
","['\nSou-Cheng T. Choi\n', '\nYuhan Ding\n', '\nFred J. Hickernell\n', '\nLan Jiang\n', '\nLluís Antoni Jiménez Rugama\n', '\nXin Tong\n', '\nYizhi Zhang\n', '\nXuan Zhou\n']",,,http://arxiv.org/abs/1503.06544v2,cs.MS,['cs.MS'],,,[]
Computer Assisted Parallel Program Generation,http://arxiv.org/abs/1503.04501v1,2015-03-16T02:07:50Z,2015-03-16T02:07:50Z,"  Parallel computation is widely employed in scientific researches, engineering
activities and product development. Parallel program writing itself is not
always a simple task depending on problems solved. Large-scale scientific
computing, huge data analyses and precise visualizations, for example, would
require parallel computations, and the parallel computing needs the
parallelization techniques. In this Chapter a parallel program generation
support is discussed, and a computer-assisted parallel program generation
system P-NCAS is introduced. Computer assisted problem solving is one of key
methods to promote innovations in science and engineering, and contributes to
enrich our society and our life toward a programming-free environment in
computing science. Problem solving environments (PSE) research activities had
started to enhance the programming power in 1970's. The P-NCAS is one of the
PSEs; The PSE concept provides an integrated human-friendly computational
software and hardware system to solve a target class of problems
",['\nShigeo Kawata\n'],"10 pages and 8 figures. Prepared for a book entitled ""Encyclopedia of
  Information Science and Technology"", IGI global",,http://arxiv.org/abs/1503.04501v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'cs.SE']",,,[]
"CSR5: An Efficient Storage Format for Cross-Platform Sparse
  Matrix-Vector Multiplication",http://arxiv.org/abs/1503.05032v2,2015-03-17T13:18:49Z,2015-04-09T21:28:03Z,"  Sparse matrix-vector multiplication (SpMV) is a fundamental building block
for numerous applications. In this paper, we propose CSR5 (Compressed Sparse
Row 5), a new storage format, which offers high-throughput SpMV on various
platforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is
insensitive to the sparsity structure of the input matrix. Thus the single
format can support an SpMV algorithm that is efficient both for regular
matrices and for irregular matrices. Furthermore, we show that the overhead of
the format conversion from the CSR to the CSR5 can be as low as the cost of a
few SpMV operations. We compare the CSR5-based SpMV algorithm with 11
state-of-the-art formats and algorithms on four mainstream processors using 14
regular and 10 irregular matrices as a benchmark suite. For the 14 regular
matrices in the suite, we achieve comparable or better performance over the
previous work. For the 10 irregular matrices, the CSR5 obtains average
performance improvement of 17.6\%, 28.5\%, 173.0\% and 293.3\% (up to 213.3\%,
153.6\%, 405.1\% and 943.3\%) over the best existing work on dual-socket Intel
CPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For
real-world applications such as a solver with only tens of iterations, the CSR5
format can be more practical because of its low-overhead for format conversion.
The source code of this work is downloadable at
https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5
","['\nWeifeng Liu\n', '\nBrian Vinter\n']","12 pages, 10 figures, In Proceedings of the 29th ACM International
  Conference on Supercomputing (ICS '15)",,http://arxiv.org/abs/1503.05032v2,cs.MS,"['cs.MS', 'cs.DC', 'math.NA', '65F50', 'G.4; G.1.3']",,,[]
A Multi-Threaded Version of MCFM,http://arxiv.org/abs/1503.06182v1,2015-03-20T18:02:33Z,2015-03-20T18:02:33Z,"  We report on our findings modifying MCFM using OpenMP to implement
multi-threading. By using OpenMP, the modified MCFM will execute on any
processor, automatically adjusting to the number of available threads. We
modified the integration routine VEGAS to distribute the event evaluation over
the threads, while combining all events at the end of every iteration to
optimize the numerical integration. Special care has been taken that the
results of the Monte Carlo integration are independent of the number of threads
used, to facilitate the validation of the OpenMP version of MCFM.
","['\nJohn M. Campbell\n', '\nR. Keith Ellis\n', '\nWalter T. Giele\n']","7 pages, 3 figures, MCFM-7.0 which runs under the OpenMP protocol as
  described in this paper can be downloaded from http://mcfm.fnal.gov",,http://arxiv.org/abs/1503.06182v1,physics.comp-ph,"['physics.comp-ph', 'cs.DC', 'cs.MS', 'hep-ph']",,,[]
"Implementation of a Practical Distributed Calculation System with
  Browsers and JavaScript, and Application to Distributed Deep Learning",http://arxiv.org/abs/1503.05743v1,2015-03-19T12:41:29Z,2015-03-19T12:41:29Z,"  Deep learning can achieve outstanding results in various fields. However, it
requires so significant computational power that graphics processing units
(GPUs) and/or numerous computers are often required for the practical
application. We have developed a new distributed calculation framework called
""Sashimi"" that allows any computer to be used as a distribution node only by
accessing a website. We have also developed a new JavaScript neural network
framework called ""Sukiyaki"" that uses general purpose GPUs with web browsers.
Sukiyaki performs 30 times faster than a conventional JavaScript library for
deep convolutional neural networks (deep CNNs) learning. The combination of
Sashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the
distributed deep learning of deep CNNs only with web browsers on various
devices. The libraries that comprise the proposed methods are available under
MIT license at http://mil-tokyo.github.io/.
","['\nKen Miura\n', '\nTatsuya Harada\n']",,,http://arxiv.org/abs/1503.05743v1,cs.DC,"['cs.DC', 'cs.LG', 'cs.MS', 'cs.NE', 'stat.ML']",,,[]
Algorithms and complexity for Turaev-Viro invariants,http://arxiv.org/abs/1503.04099v1,2015-03-13T15:21:06Z,2015-03-13T15:21:06Z,"  The Turaev-Viro invariants are a powerful family of topological invariants
for distinguishing between different 3-manifolds. They are invaluable for
mathematical software, but current algorithms to compute them require
exponential time.
  The invariants are parameterised by an integer $r \geq 3$. We resolve the
question of complexity for $r=3$ and $r=4$, giving simple proofs that computing
Turaev-Viro invariants for $r=3$ is polynomial time, but for $r=4$ is \#P-hard.
Moreover, we give an explicit fixed-parameter tractable algorithm for arbitrary
$r$, and show through concrete implementation and experimentation that this
algorithm is practical---and indeed preferable---to the prior state of the art
for real computation.
","['\nBenjamin A. Burton\n', '\nClément Maria\n', '\nJonathan Spreer\n']","17 pages, 5 figures","Journal of Applied and Computational Topology, 2018",http://dx.doi.org/10.1007/s41468-018-0016-2,math.GT,"['math.GT', 'cs.CC', 'cs.DS', 'cs.MS', '57M27, 57Q15, 68Q17', 'F.2.2; G.2.1; G.4']",10.1007/s41468-018-0016-2,,[]
"An efficient multi-core implementation of a novel HSS-structured
  multifrontal solver using randomized sampling",http://arxiv.org/abs/1502.07405v1,2015-02-25T23:54:16Z,2015-02-25T23:54:16Z,"  We present a sparse linear system solver that is based on a multifrontal
variant of Gaussian elimination, and exploits low-rank approximation of the
resulting dense frontal matrices. We use hierarchically semiseparable (HSS)
matrices, which have low-rank off-diagonal blocks, to approximate the frontal
matrices. For HSS matrix construction, a randomized sampling algorithm is used
together with interpolative decompositions. The combination of the randomized
compression with a fast ULV HSS factorization leads to a solver with lower
computational complexity than the standard multifrontal method for many
applications, resulting in speedups up to 7 fold for problems in our test
suite. The implementation targets many-core systems by using task parallelism
with dynamic runtime scheduling. Numerical experiments show performance
improvements over state-of-the-art sparse direct solvers. The implementation
achieves high performance and good scalability on a range of modern shared
memory parallel systems, including the Intel Xeon Phi (MIC). The code is part
of a software package called STRUMPACK -- STRUctured Matrices PACKage, which
also has a distributed memory component for dense rank-structured matrices.
","['\nPieter Ghysels\n', '\nXiaoye S. Li\n', '\nFrancois-Henry Rouet\n', '\nSamuel Williams\n', '\nArtem Napov\n']",,,http://arxiv.org/abs/1502.07405v1,cs.MS,['cs.MS'],,,[]
"Construction and implementation of asymptotic expansions for
  Jacobi--type orthogonal polynomials",http://arxiv.org/abs/1502.07191v4,2015-02-25T15:07:30Z,2015-10-22T12:28:37Z,"  We are interested in the asymptotic behavior of orthogonal polynomials of the
generalized Jacobi type as their degree $n$ goes to $\infty$. These are defined
on the interval $[-1,1]$ with weight function
$w(x)=(1-x)^{\alpha}(1+x)^{\beta}h(x)$, $\alpha,\beta>-1$ and $h(x)$ a real,
analytic and strictly positive function on $[-1,1]$. This information is
available in the work of Kuijlaars, McLaughlin, Van Assche and Vanlessen, where
the authors use the Riemann--Hilbert formulation and the Deift--Zhou non-linear
steepest descent method. We show that computing higher-order terms can be
simplified, leading to their efficient construction. The resulting asymptotic
expansions in every region of the complex plane are implemented both
symbolically and numerically, and the code is made publicly available. The main
advantage of these expansions is that they lead to increasing accuracy for
increasing degree of the polynomials, at a computational cost that is actually
independent of the degree. In contrast, the typical use of the recurrence
relation for orthogonal polynomials in computations leads to a cost that is at
least linear in the degree. Furthermore, the expansions may be used to compute
Gaussian quadrature rules in $\mathcal{O}(n)$ operations, rather than
$\mathcal{O}(n^2)$ based on the recurrence relation.
","['\nAlfredo Deaño\n', '\nDaan Huybrechs\n', '\nPeter Opsomer\n']","39 pages, 5 figures, 35 references. The article mentioned is
  arXiv:math/0111252 and the implementation is available on
  http://nines.cs.kuleuven.be/software/JACOBI/. The final publication is
  available at Springer via http://dx.doi.org/10.1007/s10444-015-9442-z",,http://dx.doi.org/10.1007/s10444-015-9442-z,cs.MS,"['cs.MS', 'math.CA', '26C04 (Primary), 30E10, 33C45, 35Q15, 65D15 (Secondary)', 'D.3.m; G.1.2; G.4']",10.1007/s10444-015-9442-z,,[]
libRoadRunner: A High Performance SBML Simulation and Analysis Library,http://arxiv.org/abs/1503.01095v1,2015-03-03T20:40:39Z,2015-03-03T20:40:39Z,"  This paper presents libRoadRunner, an extensible, high-performance,
cross-platform, open-source software library for the simulation and analysis of
models \ expressed using Systems Biology Markup Language (SBML). SBML is the
most widely used standard for representing dynamic networks, especially
biochemical networks. libRoadRunner supports solution of both large models and
multiple replicas of a single model on desktop, mobile and cluster computers.
libRoadRunner is a self-contained library, able to run both as a component
inside other tools via its C++ and C bindings andnteractively through its
Python interface. The Python Application Programming Interface (API) is similar
to the APIs of Matlab and SciPy, making it fast and easy to learn, even for new
users. libRoadRunner uses a custom Just-In-Time (JIT) compiler built on the
widely-used LLVM JIT compiler framework to compile SBML-specified models
directly into very fast native machine code for a variety of processors, making
it appropriate for solving very large models or multiple replicas of smaller
models. libRoadRunner is flexible, supporting the bulk of the SBML
specification (except for delay and nonlinear algebraic equations) and several
of its extensions. It offers multiple deterministic and stochastic integrators,
as well as tools for steady-state, stability analyses and flux balance
analysis. We regularly update libRoadRunner binary distributions for Mac OS X,
Linux and Windows and license them under Apache License Version 2.0.
http://www.libroadrunner.org provides online documentation, full build
instructions, binaries and a git source repository.
","['\nEndre T. Somogyi\n', '\nJean-Marie Bouteiller\n', '\nJames A. Glazier\n', '\nMatthias König\n', '\nKyle Medley\n', '\nMaciej H. Swat\n', '\nHerbert M. Sauro\n']",,,http://arxiv.org/abs/1503.01095v1,q-bio.SC,"['q-bio.SC', 'cs.MS']",,,[]
How to speed up R code: an introduction,http://arxiv.org/abs/1503.00855v1,2015-03-03T08:21:32Z,2015-03-03T08:21:32Z,"  Most calculations performed by the average R user are unremarkable in the
sense that nowadays, any computer can crush the related code in a matter of
seconds. But more and more often, heavy calculations are also performed using
R, something especially true in some fields such as statistics. The user then
faces total execution times of his codes that are hard to work with: hours,
days, even weeks. In this paper, how to reduce the total execution time of
various codes will be shown and typical bottlenecks will be discussed. As a
last resort, how to run your code on a cluster of computers (most workplaces
have one) in order to make use of a larger processing power than the one
available on an average computer will also be discussed through two examples.
",['\nNathan Uyttendaele\n'],,,http://arxiv.org/abs/1503.00855v1,stat.CO,"['stat.CO', 'cs.DC', 'cs.MS']",,,[]
Quantomatic: A Proof Assistant for Diagrammatic Reasoning,http://arxiv.org/abs/1503.01034v2,2015-03-03T18:20:39Z,2015-10-13T15:30:29Z,"  Monoidal algebraic structures consist of operations that can have multiple
outputs as well as multiple inputs, which have applications in many areas
including categorical algebra, programming language semantics, representation
theory, algebraic quantum information, and quantum groups. String diagrams
provide a convenient graphical syntax for reasoning formally about such
structures, while avoiding many of the technical challenges of a term-based
approach. Quantomatic is a tool that supports the (semi-)automatic construction
of equational proofs using string diagrams. We briefly outline the theoretical
basis of Quantomatic's rewriting engine, then give an overview of the core
features and architecture and give a simple example project that computes
normal forms for commutative bialgebras.
","['\nAleks Kissinger\n', '\nVladimir Zamdzhiev\n']","International Conference on Automated Deduction, CADE 2015 (CADE-25).
  The final publication is available at Springer via
  http://dx.doi.org/10.1007/978-3-319-21401-6_22",,http://dx.doi.org/10.1007/978-3-319-21401-6_22,cs.LO,"['cs.LO', 'cs.MS', 'math.CT']",10.1007/978-3-319-21401-6_22,,[]
T3PS: Tool for Parallel Processing in Parameter Scans,http://arxiv.org/abs/1503.01073v1,2015-02-27T08:48:24Z,2015-02-27T08:48:24Z,"  T3PS is a program that can be used to quickly design and perform parameter
scans while easily taking advantage of the multi-core architecture of current
processors. It takes an easy to read and write parameter scan definition file
format as input. Based on the parameter ranges and other options contained
therein, it distributes the calculation of the parameter space over multiple
processes and possibly computers. The derived data is saved in a plain text
file format readable by most plotting software. The supported scanning
strategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical
optimization. Several example parameter scans are shown and compared with
results in the literature.
",['\nVinzenz Maurer\n'],"50 pages, 7 figures, available for download at
  http://t3ps.hepforge.org/",,http://arxiv.org/abs/1503.01073v1,cs.MS,"['cs.MS', 'cs.CE', 'hep-ph']",,,[]
Twofold exp and log,http://arxiv.org/abs/1502.05216v1,2015-02-17T02:55:35Z,2015-02-17T02:55:35Z,"  This article is about twofold arithmetic. Here I introduce algorithms and
experimental code for twofold variant of C/C++ standard functions exp() and
log(), and expm1() and log1p(). Twofold function $y_0+y_1 \approx f(x_0+x_1)$
is nearly 2x-precise so can assess accuracy of standard one. Performance allows
assessing on-fly: twofold texp() over double is ~10x times faster than expq()
by GNU quadmath.
",['\nEvgeny Latkin\n'],"Experimental code and tests at ""twofolds"" project Web site:
  https://sites.google.com/site/yevgenylatkin/",,http://arxiv.org/abs/1502.05216v1,cs.MS,['cs.MS'],,,[]
"RSVDPACK: An implementation of randomized algorithms for computing the
  singular value, interpolative, and CUR decompositions of matrices on
  multi-core and GPU architectures",http://arxiv.org/abs/1502.05366v3,2015-02-18T20:13:26Z,2016-08-29T19:19:35Z,"  RSVDPACK is a library of functions for computing low rank approximations of
matrices. The library includes functions for computing standard (partial)
factorizations such as the Singular Value Decomposition (SVD), and also so
called ""structure preserving"" factorizations such as the Interpolative
Decomposition (ID) and the CUR decomposition. The ID and CUR factorizations
pick subsets of the rows/columns of a matrix to use as bases for its row/column
space. Such factorizations preserve properties of the matrix such as sparsity
or non-negativity, are helpful in data interpretation, and require in certain
contexts less memory than a partial SVD. The package implements highly
efficient computational algorithms based on randomized sampling, as described
and analyzed in [N. Halko, P.G. Martinsson, J. Tropp, ""Finding structure with
randomness: Probabilistic algorithms for constructing approximate matrix
decompositions,"" SIAM Review, 53(2), 2011], and subsequent papers. This
manuscript presents some modifications to the basic algorithms that improve
performance and ease of use. The library is written in C and supports both
multi-core CPU and GPU architectures.
","['\nSergey Voronin\n', '\nPer-Gunnar Martinsson\n']",,,http://arxiv.org/abs/1502.05366v3,math.NA,"['math.NA', 'cs.MS']",,,[]
Visualizing Marden's theorem with Scilab,http://arxiv.org/abs/1502.01367v2,2015-02-04T21:48:25Z,2015-02-11T23:47:10Z,"  A theorem which is named after the American Mathematician Moris Marden states
a very surprising and interesting fact concerning the relationship between the
points of a triangle in the complex plane and the zeros of two complex
polynomials related to this triangle: ""Suppose the zeroes z1, z2, and z3 of a
third-degree polynomial p(z) are non-collinear. There is a unique ellipse
inscribed in the triangle with vertices z1, z2, z3 and tangent to the sides at
their midpoints: the Steiner in-ellipse. The foci of that ellipse are the
zeroes of the derivative p'(z)."" (Wikipedia contributors, ""Marden's theorem"",
http://en.wikipedia.org/wiki/Marden%27s_theorem). This document describes how
Scilab, a popular and powerful open source alternative to MATLAB, can be used
to visualize the above stated theorem for arbitrary complex numbers z1, z2, and
z3 which are not collinear. It is further demonstrated how the equations of the
Steiner ellipses of a triangle in the complex plane can be calculated and
plotted by applying this theorem.
",['\nKlaus Rohe\n'],"Scilab, Marden's theorem, 2D implicit plots, geometry of complex
  numbers, Steiner ellipses",,http://arxiv.org/abs/1502.01367v2,cs.MS,['cs.MS'],,,[]
"Associative Arrays: Unified Mathematics for Spreadsheets, Databases,
  Matrices, and Graphs",http://arxiv.org/abs/1501.05709v1,2015-01-23T04:16:04Z,2015-01-23T04:16:04Z,"  Data processing systems impose multiple views on data as it is processed by
the system. These views include spreadsheets, databases, matrices, and graphs.
The common theme amongst these views is the need to store and operate on data
as whole sets instead of as individual data elements. This work describes a
common mathematical representation of these data sets (associative arrays) that
applies across a wide range of applications and technologies. Associative
arrays unify and simplify these different approaches for representing and
manipulating data into common two-dimensional view of data. Specifically,
associative arrays (1) reduce the effort required to pass data between steps in
a data processing system, (2) allow steps to be interchanged with full
confidence that the results will be unchanged, and (3) make it possible to
recognize when steps can be simplified or eliminated. Most database system
naturally support associative arrays via their tabular interfaces. The D4M
implementation of associative arrays uses this feature to provide a common
interface across SQL, NoSQL, and NewSQL databases.
","['\nJeremy Kepner\n', '\nJulian Chaidez\n', '\nVijay Gadepally\n', '\nHayden Jansen\n']","4 pages, 6 figures; New England Database Summit 2015",,http://arxiv.org/abs/1501.05709v1,cs.DB,"['cs.DB', 'cs.MS']",,,[]
Performance Tuning of a Parallel 3-D FFT Package OpenFFT,http://arxiv.org/abs/1501.07350v2,2015-01-29T06:12:52Z,2015-08-26T06:29:34Z,"  The fast Fourier transform (FFT) is a primitive kernel in numerous fields of
science and engineering. OpenFFT is an open-source parallel package for 3-D
FFTs, built on a communication-optimal domain decomposition method for
achieving minimal volume of communication. In this paper, we analyze and tune
the performance of OpenFFT, paying a particular attention to tuning of
communication that dominates the run time of large-scale calculations. We first
analyze its performance on different machines for an understanding of the
behaviors of the package and machines. Based on the performance analysis, we
develop six communication methods for performing communication with the aim of
covering varied calculation scales on a variety of computational platforms.
OpenFFT is then augmented with an auto-tuning of communication to select the
best method in run time depending on their performance. Numerical results
demonstrate that the optimized OpenFFT is able to deliver relatively good
performance in comparison with other state-of-the-art packages at different
computational scales on a number of parallel machines.
","['\nTruong Vinh Truong Duy\n', '\nTaisuke Ozaki\n']",,,http://arxiv.org/abs/1501.07350v2,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"Accelerating Polynomial Homotopy Continuation on a Graphics Processing
  Unit with Double Double and Quad Double Arithmetic",http://arxiv.org/abs/1501.06625v3,2015-01-26T23:54:20Z,2015-06-12T15:08:55Z,"  Numerical continuation methods track a solution path defined by a homotopy.
The systems we consider are defined by polynomials in several variables with
complex coefficients. For larger dimensions and degrees, the numerical
conditioning worsens and hardware double precision becomes often insufficient
to reach the end of the solution path. With double double and quad double
arithmetic, we can solve larger problems that we could not solve with hardware
double arithmetic, but at a higher computational cost. This cost overhead can
be compensated by acceleration on a Graphics Processing Unit (GPU). We describe
our implementation and report on computational results on benchmark polynomial
systems.
","['\nJan Verschelde\n', '\nXiangcheng Yu\n']","Accepted for publication in the Proceedings of the 7th International
  Workshop on Parallel Symbolic Computation (PASCO 2015)",,http://arxiv.org/abs/1501.06625v3,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA', 'math.AG', 'math.NA']",,,[]
"Solving Polynomial Systems by Penetrating Gradient Algorithm Applying
  Deepest Descent Strategy",http://arxiv.org/abs/1501.03341v1,2015-01-14T13:34:50Z,2015-01-14T13:34:50Z,"  An algorithm and associated strategy for solving polynomial systems within
the optimization framework is presented. The algorithm and strategy are named,
respectively, the penetrating gradient algorithm and the deepest descent
strategy. The most prominent feature of penetrating gradient algorithm, after
which it was named, is its ability to see and penetrate through the obstacles
in error space along the line of search direction and to jump to the global
minimizer in a single step. The ability to find the deepest point in an
arbitrary direction, no matter how distant the point is and regardless of the
relief of error space between the current and the best point, motivates
movements in directions in which cost function can be maximally reduced, rather
than in directions that seem to be the best locally (like, for instance, the
steepest descent, i.e., negative gradient direction). Therefore, the strategy
is named the deepest descent, in contrast but alluding to the steepest descent.
Penetrating gradient algorithm is derived and its properties are proven
mathematically, while features of the deepest descent strategy are shown by
comparative simulations. Extensive benchmark tests confirm that the proposed
algorithm and strategy jointly form an effective solver of polynomial systems.
In addition, further theoretical considerations in Section 5 about solving
linear systems by the proposed method reveal a surprising and interesting
relation of proposed and Gauss-Seidel method.
","['\nNikica Hlupic\n', '\nIvo Beros\n']",,,http://arxiv.org/abs/1501.03341v1,math.OC,"['math.OC', 'cs.MS', 'math.NA']",,,[]
FASTA: A Generalized Implementation of Forward-Backward Splitting,http://arxiv.org/abs/1501.04979v3,2015-01-16T01:22:55Z,2016-01-20T23:51:33Z,"  This is a user manual for the software package FASTA.
","['\nTom Goldstein\n', '\nChristoph Studer\n', '\nRichard Baraniuk\n']",,,http://arxiv.org/abs/1501.04979v3,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"A New Sparse Matrix Vector Multiplication GPU Algorithm Designed for
  Finite Element Problems",http://arxiv.org/abs/1501.00324v1,2015-01-01T21:57:19Z,2015-01-01T21:57:19Z,"  Recently, graphics processors (GPUs) have been increasingly leveraged in a
variety of scientific computing applications. However, architectural
differences between CPUs and GPUs necessitate the development of algorithms
that take advantage of GPU hardware. As sparse matrix vector multiplication
(SPMV) operations are commonly used in finite element analysis, a new SPMV
algorithm and several variations are developed for unstructured finite element
meshes on GPUs. The effective bandwidth of current GPU algorithms and the newly
proposed algorithms are measured and analyzed for 15 sparse matrices of varying
sizes and varying sparsity structures. The effects of optimization and
differences between the new GPU algorithm and its variants are then
subsequently studied. Lastly, both new and current SPMV GPU algorithms are
utilized in the GPU CG Solver in GPU finite element simulations of the heart.
These results are then compared against parallel PETSc finite element
implementation results. The effective bandwidth tests indicate that the new
algorithms compare very favorably with current algorithms for a wide variety of
sparse matrices and can yield very notable benefits. GPU finite element
simulation results demonstrate the benefit of using GPUs for finite element
analysis, and also show that the proposed algorithms can yield speedup factors
up to 12-fold for real finite element applications.
","['\nJonathan Wong\n', '\nEllen Kuhl\n', '\nEric Darve\n']","35 pages, 22 figures",,http://arxiv.org/abs/1501.00324v1,cs.MS,"['cs.MS', 'cs.CE', '65Y10']",,,[]
A persistence landscapes toolbox for topological statistics,http://arxiv.org/abs/1501.00179v3,2014-12-31T17:34:59Z,2015-08-28T17:16:40Z,"  Topological data analysis provides a multiscale description of the geometry
and topology of quantitative data. The persistence landscape is a topological
summary that can be easily combined with tools from statistics and machine
learning. We give efficient algorithms for calculating persistence landscapes,
their averages, and distances between such averages. We discuss an
implementation of these algorithms and some related procedures. These are
intended to facilitate the combination of statistics and machine learning with
topological data analysis. We present an experiment showing that the
low-dimensional persistence landscapes of points sampled from spheres (and
boxes) of varying dimensions differ.
","['\nPeter Bubenik\n', '\nPawel Dlotko\n']",24 pages,"Journal of Symbolic Computation, Volume 78, January-February 2017,
  Pages 91-114",http://dx.doi.org/10.1016/j.jsc.2016.03.009,cs.CG,"['cs.CG', 'cs.MS', 'math.AT', 'stat.CO']",10.1016/j.jsc.2016.03.009,,[]
"GammaCHI: a package for the inversion and computation of the gamma and
  chi-square cumulative distribution functions (central and noncentral)",http://arxiv.org/abs/1501.01578v1,2015-01-07T18:06:17Z,2015-01-07T18:06:17Z,"  A Fortran 90 module (GammaCHI) for computing and inverting the gamma and
chi-square cumulative distribution functions (central and noncentral) is
presented. The main novelty of this package are the reliable and accurate
inversion routines for the noncentral cumulative distribution functions.
Additionally, the package also provides routines for computing the gamma
function, the error function and other functions related to the gamma function.
The module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,
errorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation
of the central gamma distribution function (and its complementary function),
the inversion of the central gamma distribution function, the computation of
the noncentral gamma distribution function (and its complementary function),
the inversion of the noncentral gamma distribution function, the computation of
the error function and its complementary function, the inversion of the
complementary error function, the computation of: the gamma function, the
logarithm of the gamma function, the regulated gamma function and the ratio of
two gamma functions, respectively.
","['\nA. Gil\n', '\nJ. Segura\n', '\nN. M. Temme\n']",To appear in Computer Physics Communications,,http://dx.doi.org/10.1016/j.cpc.2015.01.004,cs.MS,"['cs.MS', 'math.CA', 'math.NA']",10.1016/j.cpc.2015.01.004,,[]
FlexDM: Enabling robust and reliable parallel data mining using WEKA,http://arxiv.org/abs/1412.5720v1,2014-12-18T05:07:44Z,2014-12-18T05:07:44Z,"  Performing massive data mining experiments with multiple datasets and methods
is a common task faced by most bioinformatics and computational biology
laboratories. WEKA is a machine learning package designed to facilitate this
task by providing tools that allow researchers to select from several
classification methods and specific test strategies. Despite its popularity,
the current WEKA environment for batch experiments, namely Experimenter, has
four limitations that impact its usability: the selection of value ranges for
methods options lacks flexibility and is not intuitive; there is no support for
parallelisation when running large-scale data mining tasks; the XML schema is
difficult to read, necessitating the use of the Experimenter's graphical user
interface for generation and modification; and robustness is limited by the
fact that results are not saved until the last test has concluded.
  FlexDM implements an interface to WEKA to run batch processing tasks in a
simple and intuitive way. In a short and easy-to-understand XML file, one can
define hundreds of tests to be performed on several datasets. FlexDM also
allows those tests to be executed asynchronously in parallel to take advantage
of multi-core processors, significantly increasing usability and productivity.
Results are saved incrementally for better robustness and reliability.
  FlexDM is implemented in Java and runs on Windows, Linux and OSX. As we
encourage other researchers to explore and adopt our software, FlexDM is made
available as a pre-configured bootable reference environment. All code,
supporting documentation and usage examples are also available for download at
http://sourceforge.net/projects/flexdm.
","['\nMadison Flannery\n', '\nDavid M Budden\n', '\nAlexandre Mendes\n']","4 pages, 2 figures",,http://arxiv.org/abs/1412.5720v1,cs.MS,"['cs.MS', 'cs.SE']",,,[]
"SClib, a hack for straightforward embedded C functions in Python",http://arxiv.org/abs/1412.6395v1,2014-12-19T15:51:21Z,2014-12-19T15:51:21Z,"  We present SClib, a simple hack that allows easy and straightforward
evaluation of C functions within Python code, boosting flexibility for better
trade-off between computation power and feature availability, such as
visualization and existing computation routines in SciPy. We also present two
cases were SClib has been used. In the first set of applications we use SClib
to write a port to Python of a Schr\""odinger equation solver that has been
extensively used the literature, the resulting script presents a speed-up of
about 150x with respect to the original one. A review of the situations where
the speeded-up script has been used is presented. We also describe the solution
to the related problem of solving a set of coupled Schr\""odinger-like equations
where SClib is used to implement the speed-critical parts of the code. We argue
that when using SClib within IPython we can use NumPy and Matplotlib for the
manipulation and visualization of the solutions in an interactive environment
with no performance compromise. The second case is an engineering application.
We use SClib to evaluate the control and system derivatives in a feedback
control loop for electrical motors. With this and the integration routines
available in SciPy, we can run simulations of the control loop a la Simulink.
The use of C code not only boosts the speed of the simulations, but also
enables to test the exact same code that we use in the test rig to get
experimental results. Again, integration with IPython gives us the flexibility
to analyze and visualize the data.
","['\nEsteban Fuentes\n', '\nHector E. Martinez\n']","Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)",,http://arxiv.org/abs/1412.6395v1,cs.MS,"['cs.MS', 'physics.comp-ph']",,,[]
"Proceedings of the 7th European Conference on Python in Science
  (EuroSciPy 2014)",http://arxiv.org/abs/1412.7030v1,2014-12-22T15:47:51Z,2014-12-22T15:47:51Z,"  These are the proceedings of the 7th European Conference on Python in
Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).
","['\nPierre de Buyl\n', '\nNelle Varoquaux\n']",,,http://arxiv.org/abs/1412.7030v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
"PyFAI: a Python library for high performance azimuthal integration on
  GPU",http://arxiv.org/abs/1412.6367v1,2014-12-19T15:06:50Z,2014-12-19T15:06:50Z,"  The pyFAI package has been designed to reduce X-ray diffraction images into
powder diffraction curves to be further processed by scientists. This
contribution describes how to convert an image into a radial profile using the
Numpy package, how the process was accelerated using Cython. The algorithm was
parallelised, needing a complete re-design to benefit from massively parallel
devices like graphical processing units or accelerators like the Intel Xeon Phi
using the PyOpenCL library.
","['\nJérôme Kieffer\n', '\nGiannis Ashiotis\n']","Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)",,http://arxiv.org/abs/1412.6367v1,astro-ph.IM,"['astro-ph.IM', 'cs.DC', 'cs.MS']",,,[]
Enhancing SfePy with Isogeometric Analysis,http://arxiv.org/abs/1412.6407v1,2014-12-19T16:03:26Z,2014-12-19T16:03:26Z,"  In the paper a recent enhancement to the open source package SfePy (Simple
Finite Elements in Python, http://sfepy.org) is introduced, namely the addition
of another numerical discretization scheme, the isogeometric analysis, to the
original implementation based on the nowadays standard and well-established
numerical solution technique, the finite element method. The isogeometric
removes the need of the solution domain approximation by a piece-wise polygonal
domain covered by the finite element mesh, and allows approximation of unknown
fields with a higher smoothness then the finite element method, which can be
advantageous in many applications. Basic numerical examples illustrating the
implementation and use of the isogeometric analysis in SfePy are shown.
",['\nRobert Cimrman\n'],"Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)",,http://arxiv.org/abs/1412.6407v1,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
"Software for Distributed Computation on Medical Databases: A
  Demonstration Project",http://arxiv.org/abs/1412.6890v2,2014-12-22T07:17:01Z,2017-02-10T02:03:23Z,"  Bringing together the information latent in distributed medical databases
promises to personalize medical care by enabling reliable, stable modeling of
outcomes with rich feature sets (including patient characteristics and
treatments received). However, there are barriers to aggregation of medical
data, due to lack of standardization of ontologies, privacy concerns,
proprietary attitudes toward data, and a reluctance to give up control over end
use. Aggregation of data is not always necessary for model fitting. In models
based on maximizing a likelihood, the computations can be distributed, with
aggregation limited to the intermediate results of calculations on local data,
rather than raw data. Distributed fitting is also possible for singular value
decomposition. There has been work on the technical aspects of shared
computation for particular applications, but little has been published on the
software needed to support the ""social networking"" aspect of shared computing,
to reduce the barriers to collaboration. We describe a set of software tools
that allow the rapid assembly of a collaborative computational project, based
on the flexible and extensible R statistical software and other open source
packages, that can work across a heterogeneous collection of database
environments, with full transparency to allow local officials concerned with
privacy protections to validate the safety of the method. We describe the
principles, architecture, and successful test results for the site-stratified
Cox model and rank-k Singular Value Decomposition (SVD).
","['\nBalasubramanian Narasimhan\n', '\nDaniel L. Rubin\n', '\nSamuel M. Gross\n', '\nMarina Bendersky\n', '\nPhilip W. Lavori\n']",,,http://arxiv.org/abs/1412.6890v2,stat.CO,"['stat.CO', 'cs.MS', 'cs.SE']",,,[]
The NIFTY way of Bayesian signal inference,http://arxiv.org/abs/1412.7160v1,2014-12-22T21:00:07Z,2014-12-22T21:00:07Z,"  We introduce NIFTY, ""Numerical Information Field Theory"", a software package
for the development of Bayesian signal inference algorithms that operate
independently from any underlying spatial grid and its resolution. A large
number of Bayesian and Maximum Entropy methods for 1D signal reconstruction, 2D
imaging, as well as 3D tomography, appear formally similar, but one often finds
individualized implementations that are neither flexible nor easily
transferable. Signal inference in the framework of NIFTY can be done in an
abstract way, such that algorithms, prototyped in 1D, can be applied to real
world problems in higher-dimensional settings. NIFTY as a versatile library is
applicable and already has been applied in 1D, 2D, 3D and spherical settings. A
recent application is the D3PO algorithm targeting the non-trivial task of
denoising, deconvolving, and decomposing photon observations in high energy
astronomy.
",['\nMarco Selig\n'],"6 pages, 2 figures, refereed proceeding of the 33rd International
  Workshop on Bayesian Inference and Maximum Entropy Methods in Science and
  Engineering (MaxEnt 2013), software available at
  http://www.mpa-garching.mpg.de/ift/nifty/ and
  http://www.mpa-garching.mpg.de/ift/d3po/","AIP Conf. Proc. 1636, 68 (2014)",http://dx.doi.org/10.1063/1.4903712,astro-ph.IM,"['astro-ph.IM', 'cs.IT', 'cs.MS', 'math.IT', 'physics.data-an']",10.1063/1.4903712,,[]
"An implementation of a randomized algorithm for principal component
  analysis",http://arxiv.org/abs/1412.3510v1,2014-12-11T00:52:41Z,2014-12-11T00:52:41Z,"  Recent years have witnessed intense development of randomized methods for
low-rank approximation. These methods target principal component analysis (PCA)
and the calculation of truncated singular value decompositions (SVD). The
present paper presents an essentially black-box, fool-proof implementation for
Mathworks' MATLAB, a popular software platform for numerical computation. As
illustrated via several tests, the randomized algorithms for low-rank
approximation outperform or at least match the classical techniques (such as
Lanczos iterations) in basically all respects: accuracy, computational
efficiency (both speed and memory usage), ease-of-use, parallelizability, and
reliability. However, the classical procedures remain the methods of choice for
estimating spectral norms, and are far superior for calculating the least
singular values and corresponding singular vectors (or singular subspaces).
","['\nArthur Szlam\n', '\nYuval Kluger\n', '\nMark Tygert\n']","13 pages, 4 figures","ACM TOMS, 43(3): 28:1-28:14, 2016",http://arxiv.org/abs/1412.3510v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
GPTIPS 2: an open-source software platform for symbolic data mining,http://arxiv.org/abs/1412.4690v2,2014-12-15T17:36:45Z,2015-05-22T08:46:46Z,"  GPTIPS is a free, open source MATLAB based software platform for symbolic
data mining (SDM). It uses a multigene variant of the biologically inspired
machine learning method of genetic programming (MGGP) as the engine that drives
the automatic model discovery process. Symbolic data mining is the process of
extracting hidden, meaningful relationships from data in the form of symbolic
equations. In contrast to other data-mining methods, the structural
transparency of the generated predictive equations can give new insights into
the physical systems or processes that generated the data. Furthermore, this
transparency makes the models very easy to deploy outside of MATLAB. The
rationale behind GPTIPS is to reduce the technical barriers to using,
understanding, visualising and deploying GP based symbolic models of data,
whilst at the same time remaining highly customisable and delivering robust
numerical performance for power users. In this chapter, notable new features of
the latest version of the software are discussed with these aims in mind.
Additionally, a simplified variant of the MGGP high level gene crossover
mechanism is proposed. It is demonstrated that the new functionality of GPTIPS
2 (a) facilitates the discovery of compact symbolic relationships from data
using multiple approaches, e.g. using novel gene-centric visualisation analysis
to mitigate horizontal bloat and reduce complexity in multigene symbolic
regression models (b) provides numerous methods for visualising the properties
of symbolic models (c) emphasises the generation of graphically navigable
libraries of models that are optimal in terms of the Pareto trade off surface
of model performance and complexity and (d) expedites real world applications
by the simple, rapid and robust deployment of symbolic models outside the
software environment they were developed in.
",['\nDominic P. Searson\n'],"26 pages, accepted for publication in the Springer Handbook of
  Genetic Programming Applications (2015, in press)",,http://arxiv.org/abs/1412.4690v2,cs.MS,"['cs.MS', 'cs.NE']",,,[]
Efficient SIMD RNG for Varying-Parameter Streams: C++ Class BatchRNG,http://arxiv.org/abs/1412.4825v1,2014-12-15T22:27:57Z,2014-12-15T22:27:57Z,"  Single-Instruction, Multiple-Data (SIMD) random number generators (RNGs) take
advantage of vector units to offer significant performance gain over
non-vectorized libraries, but they often rely on batch production of deviates
from distributions with fixed parameters. In many statistical applications such
as Gibbs sampling, parameters of sampled distributions change from one
iteration to the next, requiring that random deviates be generated
one-at-a-time. This situation can render vectorized RNGs inefficient, and even
inferior to their scalar counterparts. The C++ class BatchRNG uses buffers of
base distributions such uniform, Gaussian and exponential to take advantage of
vector units while allowing for sequences of deviates to be generated with
varying parameters. These small buffers are consumed and replenished as needed
during a program execution. Performance tests using Intel Vector Statistical
Library (VSL) on various probability distributions illustrates the
effectiveness of the proposed batching strategy.
","['\nAlireza S. Mahani\n', '\nMansour T. A. Sharabiani\n']",,,http://arxiv.org/abs/1412.4825v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
Minkowski sum of HV-polytopes in Rn,http://arxiv.org/abs/1412.2562v1,2014-12-08T13:56:17Z,2014-12-08T13:56:17Z,"  Minkowski sums cover a wide range of applications in many different fields
like algebra, morphing, robotics, mechanical CAD/CAM systems ... This paper
deals with sums of polytopes in a n dimensional space provided that both
H-representation and V-representation are available i.e. the polytopes are
described by both their half-spaces and vertices. The first method uses the
polytope normal fans and relies on the ability to intersect dual polyhedral
cones. Then we introduce another way of considering Minkowski sums of polytopes
based on the primal polyhedral cones attached to each vertex.
","['\nVincent Delos\nI2M\n', '\nDenis Teissandier\nI2M\n']","4th Annual International Conference on Computational Mathematics,
  Computational Geometry and Statistics, Jan 2015, Singapore, Singapore",,http://arxiv.org/abs/1412.2562v1,cs.CG,"['cs.CG', 'cs.MS', 'physics.class-ph']",,,"['I2M', 'I2M']"
Minkowski Sum of Polytopes Defined by Their Vertices,http://arxiv.org/abs/1412.2564v2,2014-12-08T13:57:21Z,2015-06-16T09:39:04Z,"  Minkowski sums are of theoretical interest and have applications in fields
related to industrial backgrounds. In this paper we focus on the specific case
of summing polytopes as we want to solve the tolerance analysis problem
described in [1]. Our approach is based on the use of linear programming and is
solvable in polynomial time. The algorithm we developed can be implemented and
parallelized in a very easy way.
","['\nVincent Delos\nI2M\n', '\nDenis Teissandier\nI2M\n']",,"Journal of Applied Mathematics and Physics (JAMP), Scientific
  Research Publishing, 2015, 3 (1), pp.62-67",http://dx.doi.org/10.4236/jamp.2015.31008,cs.CG,"['cs.CG', 'cs.MS', 'physics.class-ph']",10.4236/jamp.2015.31008,,"['I2M', 'I2M']"
MatConvNet - Convolutional Neural Networks for MATLAB,http://arxiv.org/abs/1412.4564v3,2014-12-15T12:23:35Z,2016-05-05T14:31:06Z,"  MatConvNet is an implementation of Convolutional Neural Networks (CNNs) for
MATLAB. The toolbox is designed with an emphasis on simplicity and flexibility.
It exposes the building blocks of CNNs as easy-to-use MATLAB functions,
providing routines for computing linear convolutions with filter banks, feature
pooling, and many more. In this manner, MatConvNet allows fast prototyping of
new CNN architectures; at the same time, it supports efficient computation on
CPU and GPU allowing to train complex models on large datasets such as ImageNet
ILSVRC. This document provides an overview of CNNs and how they are implemented
in MatConvNet and gives the technical details of each computational block in
the toolbox.
","['\nAndrea Vedaldi\n', '\nKarel Lenc\n']",Updated for release v1.0-beta20,,http://arxiv.org/abs/1412.4564v3,cs.CV,"['cs.CV', 'cs.LG', 'cs.MS', 'cs.NE']",,,[]
"An Infra-Structure for Performance Estimation and Experimental
  Comparison of Predictive Models in R",http://arxiv.org/abs/1412.0436v4,2014-12-01T11:35:47Z,2015-09-07T15:03:45Z,"  This document describes an infra-structure provided by the R package
performanceEstimation that allows to estimate the predictive performance of
different approaches (workflows) to predictive tasks. The infra-structure is
generic in the sense that it can be used to estimate the values of any
performance metrics, for any workflow on different predictive tasks, namely,
classification, regression and time series tasks. The package also includes
several standard workflows that allow users to easily set up their experiments
limiting the amount of work and information they need to provide. The overall
goal of the infra-structure provided by our package is to facilitate the task
of estimating the predictive performance of different modeling approaches to
predictive tasks in the R environment.
",['\nLuis Torgo\n'],"Updated to version 1.0.2 of the R package. Added a small section on
  package installation. Made explicit the reference to the R package version
  number within the document",,http://arxiv.org/abs/1412.0436v4,cs.MS,"['cs.MS', 'cs.LG', 'cs.SE', 'stat.CO']",,,[]
Conjugate gradient solvers on Intel Xeon Phi and NVIDIA GPUs,http://arxiv.org/abs/1411.4439v1,2014-11-17T11:27:55Z,2014-11-17T11:27:55Z,"  Lattice Quantum Chromodynamics simulations typically spend most of the
runtime in inversions of the Fermion Matrix. This part is therefore frequently
optimized for various HPC architectures. Here we compare the performance of the
Intel Xeon Phi to current Kepler-based NVIDIA Tesla GPUs running a conjugate
gradient solver. By exposing more parallelism to the accelerator through
inverting multiple vectors at the same time, we obtain a performance greater
than 300 GFlop/s on both architectures. This more than doubles the performance
of the inversions. We also give a short overview of the Knights Corner
architecture, discuss some details of the implementation and the effort
required to obtain the achieved performance.
","['\nO. Kaczmarek\n', '\nC. Schmidt\n', '\nP. Steinbrecher\n', '\nM. Wagner\n']","7 pages, proceedings, presented at 'GPU Computing in High Energy
  Physics', September 10-12, 2014, Pisa, Italy",,http://arxiv.org/abs/1411.4439v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'hep-lat']",,,[]
Julia: A Fresh Approach to Numerical Computing,http://arxiv.org/abs/1411.1607v4,2014-11-06T13:39:40Z,2015-07-19T19:58:28Z,"  Bridging cultures that have often been distant, Julia combines expertise from
the diverse fields of computer science and computational science to create a
new approach to numerical computing. Julia is designed to be easy and fast.
Julia questions notions generally held as ""laws of nature"" by practitioners of
numerical computing:
  1. High-level dynamic programs have to be slow.
  2. One must prototype in one language and then rewrite in another language
for speed or deployment, and
  3. There are parts of a system for the programmer, and other parts best left
untouched as they are built by the experts.
  We introduce the Julia programming language and its design --- a dance
between specialization and abstraction. Specialization allows for custom
treatment. Multiple dispatch, a technique from computer science, picks the
right algorithm for the right circumstance. Abstraction, what good computation
is really about, recognizes what remains the same after differences are
stripped away. Abstractions in mathematics are captured as code through another
technique from computer science, generic programming.
  Julia shows that one can have machine performance without sacrificing human
convenience.
","['\nJeff Bezanson\n', '\nAlan Edelman\n', '\nStefan Karpinski\n', '\nViral B. Shah\n']",37 pages,,http://arxiv.org/abs/1411.1607v4,cs.MS,['cs.MS'],,,[]
"Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and
  Convolution Kernels Via Linear Projections",http://arxiv.org/abs/1411.2860v1,2014-11-11T15:59:35Z,2014-11-11T15:59:35Z,"  Generic matrix multiplication (GEMM) and one-dimensional
convolution/cross-correlation (CONV) kernels often constitute the bulk of the
compute- and memory-intensive processing within image/audio recognition and
matching systems. We propose a novel method to scale the energy and processing
throughput of GEMM and CONV kernels for such error-tolerant multimedia
applications by adjusting the precision of computation. Our technique employs
linear projections to the input matrix or signal data during the top-level GEMM
and CONV blocking and reordering. The GEMM and CONV kernel processing then uses
the projected inputs and the results are accumulated to form the final outputs.
Throughput and energy scaling takes place by changing the number of projections
computed by each kernel, which in turn produces approximate results, i.e.
changes the precision of the performed computation. Results derived from a
voltage- and frequency-scaled ARM Cortex A15 processor running face recognition
and music matching algorithms demonstrate that the proposed approach allows for
280%~440% increase of processing throughput and 75%~80% decrease of energy
consumption against optimized GEMM and CONV kernels without any impact in the
obtained recognition or matching accuracy. Even higher gains can be obtained if
one is willing to tolerate some reduction in the accuracy of the recognition
and matching applications.
","['\nMohammad Ashraful Anam\n', '\nPaul N. Whatmough\n', '\nYiannis Andreopoulos\n']",,"IEEE Transactions on Circuits and Systems for Video Technology,
  vol. 24, no. 11, pp. 1860-1873, Nov. 2014",http://arxiv.org/abs/1411.2860v1,cs.MM,"['cs.MM', 'cs.MS']",,,[]
Introduction to the R package TDA,http://arxiv.org/abs/1411.1830v2,2014-11-07T05:10:34Z,2015-01-29T17:21:36Z,"  We present a short tutorial and introduction to using the R package TDA,
which provides some tools for Topological Data Analysis. In particular, it
includes implementations of functions that, given some data, provide
topological information about the underlying space, such as the distance
function, the distance to a measure, the kNN density estimator, the kernel
density estimator, and the kernel distance. The salient topological features of
the sublevel sets (or superlevel sets) of these functions can be quantified
with persistent homology. We provide an R interface for the efficient
algorithms of the C++ libraries GUDHI, Dionysus and PHAT, including a function
for the persistent homology of the Rips filtration, and one for the persistent
homology of sublevel sets (or superlevel sets) of arbitrary functions evaluated
over a grid of points. The significance of the features in the resulting
persistence diagrams can be analyzed with functions that implement recently
developed statistical methods. The R package TDA also includes the
implementation of an algorithm for density clustering, which allows us to
identify the spatial organization of the probability mass associated to a
density function and visualize it by means of a dendrogram, the cluster tree.
","['\nBrittany Terese Fasy\n', '\nJisu Kim\n', '\nFabrizio Lecci\n', '\nClément Maria\n']",,,http://arxiv.org/abs/1411.1830v2,cs.MS,"['cs.MS', 'cs.CG', 'stat.CO']",,,[]
"Automated generation and symbolic manipulation of tensor product finite
  elements",http://arxiv.org/abs/1411.2940v3,2014-11-11T19:47:45Z,2016-02-24T11:12:45Z,"  We describe and implement a symbolic algebra for scalar and vector-valued
finite elements, enabling the computer generation of elements with tensor
product structure on quadrilateral, hexahedral and triangular prismatic cells.
The algebra is implemented as an extension to the domain-specific language UFL,
the Unified Form Language. This allows users to construct many finite element
spaces beyond those supported by existing software packages. We have made
corresponding extensions to FIAT, the FInite element Automatic Tabulator, to
enable numerical tabulation of such spaces. This tabulation is consequently
used during the automatic generation of low-level code that carries out local
assembly operations, within the wider context of solving finite element
problems posed over such function spaces. We have done this work within the
code-generation pipeline of the software package Firedrake; we make use of the
full Firedrake package to present numerical examples.
","['\nAndrew T. T. McRae\n', '\nGheorghe-Teodor Bercea\n', '\nLawrence Mitchell\n', '\nDavid A. Ham\n', '\nColin J. Cotter\n']","Submitted to SISC special issue on CSE Software. Updated version,
  following reviewer comments",SIAM Journal on Scientific Computing 38(5):S25-S47 (2016),http://dx.doi.org/10.1137/15M1021167,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.1.8; G.4']",10.1137/15M1021167,,[]
"Efficient implementation of elementary functions in the medium-precision
  range",http://arxiv.org/abs/1410.7176v2,2014-10-27T10:35:42Z,2015-06-09T07:14:40Z,"  We describe a new implementation of the elementary transcendental functions
exp, sin, cos, log and atan for variable precision up to approximately 4096
bits. Compared to the MPFR library, we achieve a maximum speedup ranging from a
factor 3 for cos to 30 for atan. Our implementation uses table-based argument
reduction together with rectangular splitting to evaluate Taylor series. We
collect denominators to reduce the number of divisions in the Taylor series,
and avoid overhead by doing all multiprecision arithmetic using the mpn layer
of the GMP library. Our implementation provides rigorous error bounds.
",['\nFredrik Johansson\n'],Submitted to ARITH 22,,http://arxiv.org/abs/1410.7176v2,cs.MS,"['cs.MS', 'cs.NA']",,,[]
External Use of TOPCAT's Plotting Library,http://arxiv.org/abs/1410.8507v1,2014-10-30T19:29:08Z,2014-10-30T19:29:08Z,"  The table analysis application TOPCAT uses a custom Java plotting library for
highly configurable high-performance interactive or exported visualisations in
two and three dimensions. We present here a variety of ways for end users or
application developers to make use of this library outside of the TOPCAT
application: via the command-line suite STILTS or its Jython variant JyStilts,
via a traditional Java API, or by programmatically assigning values to a set of
parameters in java code or using some form of inter-process communication. The
library has been built with large datasets in mind; interactive plots scale
well up to several million points, and static output to standard graphics
formats is possible for unlimited sized input data.
",['\nM. B. Taylor\n'],"4 pages, 1 figure",,http://arxiv.org/abs/1410.8507v1,astro-ph.IM,"['astro-ph.IM', 'cs.MS']",,,[]
Programming the Adapteva Epiphany 64-core Network-on-chip Coprocessor,http://arxiv.org/abs/1410.8772v1,2014-10-30T08:29:11Z,2014-10-30T08:29:11Z,"  In the construction of exascale computing systems energy efficiency and power
consumption are two of the major challenges. Low-power high performance
embedded systems are of increasing interest as building blocks for large scale
high- performance systems. However, extracting maximum performance out of such
systems presents many challenges. Various aspects from the hardware
architecture to the programming models used need to be explored. The Epiphany
architecture integrates low-power RISC cores on a 2D mesh network and promises
up to 70 GFLOPS/Watt of processing efficiency. However, with just 32 KB of
memory per eCore for storing both data and code, and only low level inter-core
communication support, programming the Epiphany system presents several
challenges. In this paper we evaluate the performance of the Epiphany system
for a variety of basic compute and communication operations. Guided by this
data we explore strategies for implementing scientific applications on memory
constrained low-powered devices such as the Epiphany. With future systems
expected to house thousands of cores in a single chip, the merits of such
architectures as a path to exascale is compared to other competing systems.
","['\nAnish Varghese\n', '\nBob Edwards\n', '\nGaurav Mitra\n', '\nAlistair P. Rendell\n']","14 pages, submitted to IJHPCA Journal special edition",,http://arxiv.org/abs/1410.8772v1,cs.AR,"['cs.AR', 'cs.DC', 'cs.MS']",,,[]
SPIKY: A graphical user interface for monitoring spike train synchrony,http://arxiv.org/abs/1410.6910v3,2014-10-25T11:02:26Z,2015-04-15T16:40:11Z,"  Techniques for recording large-scale neuronal spiking activity are developing
very fast. This leads to an increasing demand for algorithms capable of
analyzing large amounts of experimental spike train data. One of the most
crucial and demanding tasks is the identification of similarity patterns with a
very high temporal resolution and across different spatial scales. To address
this task, in recent years three time-resolved measures of spike train
synchrony have been proposed, the ISI-distance, the SPIKE-distance, and event
synchronization. The Matlab source codes for calculating and visualizing these
measures have been made publicly available. However, due to the many different
possible representations of the results the use of these codes is rather
complicated and their application requires some basic knowledge of Matlab. Thus
it became desirable to provide a more user-friendly and interactive interface.
Here we address this need and present SPIKY, a graphical user interface which
facilitates the application of time-resolved measures of spike train synchrony
to both simulated and real data. SPIKY includes implementations of the
ISI-distance, the SPIKE-distance and SPIKE-synchronization (an improved and
simplified extension of event synchronization) which have been optimized with
respect to computation speed and memory demand. It also comprises a spike train
generator and an event detector which makes it capable of analyzing continuous
data. Finally, the SPIKY package includes additional complementary programs
aimed at the analysis of large numbers of datasets and the estimation of
significance levels.
","['\nThomas Kreuz\n', '\nMario Mulansky\n', '\nNebojsa Bozanic\n']","15 pages, 7 figures",,http://arxiv.org/abs/1410.6910v3,physics.data-an,"['physics.data-an', 'cs.MS', 'cs.SE', 'physics.bio-ph', 'physics.med-ph', 'q-bio.NC']",,,[]
Building pattern recognition applications with the SPARE library,http://arxiv.org/abs/1410.5263v2,2014-10-20T13:18:33Z,2015-02-20T15:56:36Z,"  This paper presents the SPARE C++ library, an open source software tool
conceived to build pattern recognition and soft computing systems. The library
follows the requirement of the generality: most of the implemented algorithms
are able to process user-defined input data types transparently, such as
labeled graphs and sequences of objects, as well as standard numeric vectors.
Here we present a high-level picture of the SPARE library characteristics,
focusing instead on the specific practical possibility of constructing pattern
recognition systems for different input data types. In particular, as a proof
of concept, we discuss two application instances involving clustering of
real-valued multidimensional sequences and classification of labeled graphs.
","['\nLorenzo Livi\n', '\nGuido Del Vescovo\n', '\nAntonello Rizzi\n', '\nFabio Massimo Frattale Mascioli\n']",Home page: https://sourceforge.net/p/libspare/home/Spare/,,http://arxiv.org/abs/1410.5263v2,cs.CV,"['cs.CV', 'cs.MS', 'D.2.2']",,,[]
"Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing
  Units",http://arxiv.org/abs/1410.4054v3,2014-10-15T13:23:31Z,2016-11-04T11:18:16Z,"  We revisit the implementation of iterative solvers on discrete graphics
processing units and demonstrate the benefit of implementations using extensive
kernel fusion for pipelined formulations over conventional implementations of
classical formulations. The proposed implementations with both CUDA and OpenCL
are freely available in ViennaCL and are shown to be competitive with or even
superior to other solver packages for graphics processing units. Highest
performance gains are obtained for small to medium-sized systems, while our
implementations are on par with vendor-tuned implementations for very large
systems. Our results are especially beneficial for transient problems, where
many small to medium-sized systems instead of a single big system need to be
solved.
","['\nKarl Rupp\n', '\nJosef Weinbub\n', '\nAnsgar Jüngel\n', '\nTibor Grasser\n']","27 pages, 9 figures, 3 tables","ACM Transactions on Mathematical Software (TOMS), Volume 43, Issue
  2, Article No. 11 (2016)",http://dx.doi.org/10.1145/2907944,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF', '65F10 (Secondary), 65F50, 65Y05 (Primary), 65Y10', 'G.1.3']",10.1145/2907944,,[]
HOPE: A Python Just-In-Time compiler for astrophysical computations,http://arxiv.org/abs/1410.4345v2,2014-10-16T09:28:18Z,2014-12-03T15:08:33Z,"  The Python programming language is becoming increasingly popular for
scientific applications due to its simplicity, versatility, and the broad range
of its libraries. A drawback of this dynamic language, however, is its low
runtime performance which limits its applicability for large simulations and
for the analysis of large data sets, as is common in astrophysics and
cosmology. While various frameworks have been developed to address this
limitation, most focus on covering the complete language set, and either force
the user to alter the code or are not able to reach the full speed of an
optimised native compiled language. In order to combine the ease of Python and
the speed of C++, we developed HOPE, a specialised Python just-in-time (JIT)
compiler designed for numerical astrophysical applications. HOPE focuses on a
subset of the language and is able to translate Python code into C++ while
performing numerical optimisation on mathematical expressions at runtime. To
enable the JIT compilation, the user only needs to add a decorator to the
function definition. We assess the performance of HOPE by performing a series
of benchmarks and compare its execution speed with that of plain Python, C++
and the other existing frameworks. We find that HOPE improves the performance
compared to plain Python by a factor of 2 to 120, achieves speeds comparable to
that of C++, and often exceeds the speed of the existing solutions. We discuss
the differences between HOPE and the other frameworks, as well as future
extensions of its capabilities. The fully documented HOPE package is available
at http://hope.phys.ethz.ch and is published under the GPLv3 license on PyPI
and GitHub.
","['\nJoel Akeret\nETH Zurich\n', '\nLukas Gamper\nETH Zurich\n', '\nAdam Amara\nETH Zurich\n', '\nAlexandre Refregier\nETH Zurich\n']","Accepted for publication in Astronomy and Computing. 14 pages, 1
  figure. The code is available at http://hope.phys.ethz.ch",,http://arxiv.org/abs/1410.4345v2,astro-ph.IM,"['astro-ph.IM', 'cs.MS', 'cs.PL', 'physics.comp-ph']",,,"['ETH Zurich', 'ETH Zurich', 'ETH Zurich', 'ETH Zurich']"
Convex Optimization in Julia,http://arxiv.org/abs/1410.4821v1,2014-10-17T18:53:04Z,2014-10-17T18:53:04Z,"  This paper describes Convex, a convex optimization modeling framework in
Julia. Convex translates problems from a user-friendly functional language into
an abstract syntax tree describing the problem. This concise representation of
the global structure of the problem allows Convex to infer whether the problem
complies with the rules of disciplined convex programming (DCP), and to pass
the problem to a suitable solver. These operations are carried out in Julia
using multiple dispatch, which dramatically reduces the time required to verify
DCP compliance and to parse a problem into conic form. Convex then
automatically chooses an appropriate backend solver to solve the conic form
problem.
","['\nMadeleine Udell\n', '\nKaranveer Mohan\n', '\nDavid Zeng\n', '\nJenny Hong\n', '\nSteven Diamond\n', '\nStephen Boyd\n']","To appear in Proceedings of the Workshop on High Performance
  Technical Computing in Dynamic Languages (HPTCDL) 2014",,http://arxiv.org/abs/1410.4821v1,math.OC,"['math.OC', 'cs.MS', 'stat.ML']",,,[]
"KBLAS: An Optimized Library for Dense Matrix-Vector Multiplication on
  GPU Accelerators",http://arxiv.org/abs/1410.1726v1,2014-10-07T13:43:53Z,2014-10-07T13:43:53Z,"  KBLAS is a new open source high performance library that provides optimized
kernels for a subset of Level 2 BLAS functionalities on CUDA-enabled GPUs.
Since performance of dense matrix-vector multiplication is hindered by the
overhead of memory accesses, a double-buffering optimization technique is
employed to overlap data motion with computation. After identifying a proper
set of tuning parameters, KBLAS is able to efficiently run on various GPU
architectures across different generations, avoiding the time-consuming step of
code rewriting, while still being compliant with the standard BLAS API. Another
advanced optimization technique allows to ensure coalesced memory access when
dealing with submatrices, especially in the context of high level dense linear
algebra algorithms. All four precisions KBLAS kernels have been leveraged to
multi-GPUs environment, which requires the introduction of new APIs to ease
users' experiences on these challenging systems. The KBLAS performance
outperforms existing state-of-the-art implementations on all matrix sizes,
achieves asymptotically up to 50% and 60% speedup on single GPU and multi-GPUs
systems, respectively, and validates our performance model. A subset of KBLAS
high performance kernels has been integrated into NVIDIA's standard BLAS
implementation (cuBLAS) for larger dissemination, starting version 6.0.
","['\nAhmad Abdelfattah\n', '\nDavid Keyes\n', '\nHatem Ltaief\n']",Submitted to the ACM Transactions on Mathematical Software,,http://arxiv.org/abs/1410.1726v1,cs.MS,['cs.MS'],,,[]
Automatic Generation of Loop-Invariants for Matrix Operations,http://arxiv.org/abs/1410.0564v1,2014-10-02T14:27:17Z,2014-10-02T14:27:17Z,"  In recent years it has been shown that for many linear algebra operations it
is possible to create families of algorithms following a very systematic
procedure. We do not refer to the fine tuning of a known algorithm, but to a
methodology for the actual generation of both algorithms and routines to solve
a given target matrix equation. Although systematic, the methodology relies on
complex algebraic manipulations and non-obvious pattern matching, making the
procedure challenging to be performed by hand, our goal is the development of a
fully automated system that from the sole description of a target equation
creates multiple algorithms and routines. We present CL1ck, a symbolic system
written in Mathematica, that starts with an equation, decomposes it into
multiple equations, and returns a set of loop-invariants for the algorithms --
yet to be generated -- that will solve the equation. In a successive step each
loop-invariant is then mapped to its corresponding algorithm and routine. For a
large class of equations, the methodology generates known algorithms as well as
many previously unknown ones. Most interestingly, the methodology unifies
algorithms traditionally developed in isolation. As an example, the five well
known algorithms for the LU factorization are for the first time unified under
a common root.
","['\nDiego Fabregat-Traver\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1410.0564v1,cs.MS,"['cs.MS', 'cs.SC']",,,[]
Knowledge-Based Automatic Generation of Partitioned Matrix Expressions,http://arxiv.org/abs/1410.0567v1,2014-10-02T14:33:43Z,2014-10-02T14:33:43Z,"  In a series of papers it has been shown that for many linear algebra
operations it is possible to generate families of algorithms by following a
systematic procedure. Although powerful, such a methodology involves complex
algebraic manipulation, symbolic computations and pattern matching, making the
generation a process challenging to be performed by hand. We aim for a fully
automated system that from the sole description of a target operation creates
multiple algorithms without any human intervention. Our approach consists of
three main stages. The first stage yields the core object for the entire
process, the Partitioned Matrix Expression (PME), which establishes how the
target problem may be decomposed in terms of simpler sub-problems. In the
second stage the PME is inspected to identify predicates, the Loop-Invariants,
to be used to set up the skeleton of a family of proofs of correctness. In the
third and last stage the actual algorithms are constructed so that each of them
satisfies its corresponding proof of correctness. In this paper we focus on the
first stage of the process, the automatic generation of Partitioned Matrix
Expressions. In particular, we discuss the steps leading to a PME and the
knowledge necessary for a symbolic system to perform such steps. We also
introduce Cl1ck, a prototype system written in Mathematica that generates PMEs
automatically.
","['\nDiego Fabregat-Traver\n', '\nPaolo Bientinesi\n']",,,http://arxiv.org/abs/1410.0567v1,cs.MS,"['cs.MS', 'cs.SC']",,,[]
Chemora: A PDE Solving Framework for Modern HPC Architectures,http://arxiv.org/abs/1410.1764v1,2014-10-03T20:53:26Z,2014-10-03T20:53:26Z,"  Modern HPC architectures consist of heterogeneous multi-core, many-node
systems with deep memory hierarchies. Modern applications employ ever more
advanced discretisation methods to study multi-physics problems. Developing
such applications that explore cutting-edge physics on cutting-edge HPC systems
has become a complex task that requires significant HPC knowledge and
experience. Unfortunately, this combined knowledge is currently out of reach
for all but a few groups of application developers.
  Chemora is a framework for solving systems of Partial Differential Equations
(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which
sees prominent usage in the computational relativistic astrophysics community.
In Chemora, PDEs are expressed either in a high-level \LaTeX-like language or
in Mathematica. Discretisation stencils are defined separately from equations,
and can include Finite Differences, Discontinuous Galerkin Finite Elements
(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.
  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on
CPUs and on accelerators, and study astrophysical systems such as black hole
binaries, neutron stars, and core-collapse supernovae.
","['\nErik Schnetter\n', '\nMarek Blazewicz\n', '\nSteven R. Brandt\n', '\nDavid M. Koppelman\n', '\nFrank Löffler\n']",,,http://arxiv.org/abs/1410.1764v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
cuDNN: Efficient Primitives for Deep Learning,http://arxiv.org/abs/1410.0759v3,2014-10-03T06:16:43Z,2014-12-18T01:13:16Z,"  We present a library of efficient implementations of deep learning
primitives. Deep learning workloads are computationally intensive, and
optimizing their kernels is difficult and time-consuming. As parallel
architectures evolve, kernels must be reoptimized, which makes maintaining
codebases difficult over time. Similar issues have long been addressed in the
HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS).
However, there is no analogous library for deep learning. Without such a
library, researchers implementing deep learning workloads on parallel
processors must create and optimize their own implementations of the main
computational kernels, and this work must be repeated as new parallel
processors emerge. To address this problem, we have created a library similar
in intent to BLAS, with optimized routines for deep learning workloads. Our
implementation contains routines for GPUs, although similarly to the BLAS
library, these routines could be implemented for other platforms. The library
is easy to integrate into existing frameworks, and provides optimized
performance and memory usage. For example, integrating cuDNN into Caffe, a
popular framework for convolutional networks, improves performance by 36% on a
standard model while also reducing memory consumption.
","['\nSharan Chetlur\n', '\nCliff Woolley\n', '\nPhilippe Vandermersch\n', '\nJonathan Cohen\n', '\nJohn Tran\n', '\nBryan Catanzaro\n', '\nEvan Shelhamer\n']",,,http://arxiv.org/abs/1410.0759v3,cs.NE,"['cs.NE', 'cs.LG', 'cs.MS']",,,[]
High-Order Finite-differences on multi-threaded architectures using OCCA,http://arxiv.org/abs/1410.1387v1,2014-10-02T18:15:22Z,2014-10-02T18:15:22Z,"  High-order finite-difference methods are commonly used in wave propagators
for industrial subsurface imaging algorithms. Computational aspects of the
reduced linear elastic vertical transversely isotropic propagator are
considered. Thread parallel algorithms suitable for implementing this
propagator on multi-core and many-core processing devices are introduced.
Portability is addressed through the use of the \OCCA runtime programming
interface. Finally, performance results are shown for various architectures on
a representative synthetic test case.
","['\nDavid S. Medina\n', '\nAmik St-Cyr\n', '\nTimothy Warburton\n']","ICOSAHOM 2014 conference paper, 9 pages, 2 figures, 3 tables",,http://arxiv.org/abs/1410.1387v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"$μ$-diff: an open-source Matlab toolbox for computing multiple
  scattering problems by disks",http://arxiv.org/abs/1409.8186v1,2014-09-29T16:48:16Z,2014-09-29T16:48:16Z,"  The aim of this paper is to describe a Matlab toolbox, called $\mu$-diff, for
modeling and numerically solving two-dimensional complex multiple scattering by
a large collection of circular cylinders. The approximation methods in
$\mu$-diff are based on the Fourier series expansions of the four basic
integral operators arising in scattering theory. Based on these expressions, an
efficient spectrally accurate finite-dimensional solution of multiple
scattering problems can be simply obtained for complex media even when many
scatterers are considered as well as large frequencies. The solution of the
global linear system to solve can use either direct solvers or preconditioned
iterative Krylov subspace solvers for block Toeplitz matrices. Based on this
approach, this paper explains how the code is built and organized. Some
complete numerical examples of applications (direct and inverse scattering) are
provided to show that $\mu$-diff is a flexible, efficient and robust toolbox
for solving some complex multiple scattering problems.
","['\nBertrand Thierry\n', '\nXavier Antoine\n', '\nChokri Chniti\n', '\nHasan Alzubaidi\n']","27 pages, 15 figures, associated code available online at
  http://mu-diff.math.cnrs.fr",,http://dx.doi.org/10.1016/j.cpc.2015.03.013,cs.MS,"['cs.MS', '35J05, 78A45, 78A48, 76Q05, 65M70, 31A10']",10.1016/j.cpc.2015.03.013,,[]
An Analysis of Publication Venues for Automatic Differentiation Research,http://arxiv.org/abs/1409.7316v1,2014-09-25T16:20:16Z,2014-09-25T16:20:16Z,"  We present the results of our analysis of publication venues for papers on
automatic differentiation (AD), covering academic journals and conference
proceedings. Our data are collected from the AD publications database
maintained by the autodiff.org community website. The database is purpose-built
for the AD field and is expanding via submissions by AD researchers. Therefore,
it provides a relatively noise-free list of publications relating to the field.
However, it does include noise in the form of variant spellings of journal and
conference names. We handle this by manually correcting and merging these
variants under the official names of corresponding venues. We also share the
raw data we get after these corrections.
","['\nAtilim Gunes Baydin\n', '\nBarak A. Pearlmutter\n']","6 pages, 3 figures",,http://arxiv.org/abs/1409.7316v1,cs.DL,"['cs.DL', 'cs.MS', '00A15']",,,[]
On the Performance Prediction of BLAS-based Tensor Contractions,http://arxiv.org/abs/1409.8608v1,2014-09-30T15:54:13Z,2014-09-30T15:54:13Z,"  Tensor operations are surging as the computational building blocks for a
variety of scientific simulations and the development of high-performance
kernels for such operations is known to be a challenging task. While for
operations on one- and two-dimensional tensors there exist standardized
interfaces and highly-optimized libraries (BLAS), for higher dimensional
tensors neither standards nor highly-tuned implementations exist yet. In this
paper, we consider contractions between two tensors of arbitrary dimensionality
and take on the challenge of generating high-performance implementations by
resorting to sequences of BLAS kernels. The approach consists in breaking the
contraction down into operations that only involve matrices or vectors. Since
in general there are many alternative ways of decomposing a contraction, we are
able to methodically derive a large family of algorithms. The main contribution
of this paper is a systematic methodology to accurately identify the fastest
algorithms in the bunch, without executing them. The goal is instead
accomplished with the help of a set of cache-aware micro-benchmarks for the
underlying BLAS kernels. The predictions we construct from such benchmarks
allow us to reliably single out the best-performing algorithms in a tiny
fraction of the time taken by the direct execution of the algorithms.
","['\nElmar Peise\nAICES, RWTH Aachen\n', '\nDiego Fabregat-Traver\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",Submitted to PMBS14,,http://arxiv.org/abs/1409.8608v1,cs.MS,"['cs.MS', 'cs.PF']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
Fast MATLAB assembly of FEM matrices in 2D and 3D: Edge elements,http://arxiv.org/abs/1409.4618v2,2014-09-16T13:08:47Z,2015-05-11T13:19:00Z,"  We propose an effective and flexible way to assemble finite element stiffness
and mass matrices in MATLAB. We apply this for problems discretized by edge
finite elements. Typical edge finite elements are Raviart-Thomas elements used
in discretizations of H(div) spaces and Nedelec elements in discretizations of
H(curl) spaces. We explain vectorization ideas and comment on a freely
available MATLAB code which is fast and scalable with respect to time.
","['\nImmanuel Anjam\n', '\nJan Valdman\n']","12 pages, 5 figures, ESCO 2014 conference",,http://dx.doi.org/10.1016/j.amc.2015.03.105,cs.MS,"['cs.MS', 'math.NA', '97N80, 65M60']",10.1016/j.amc.2015.03.105,,[]
"Intel Cilk Plus for Complex Parallel Algorithms: ""Enormous Fast Fourier
  Transform"" (EFFT) Library",http://arxiv.org/abs/1409.5757v1,2014-09-19T18:48:58Z,2014-09-19T18:48:58Z,"  In this paper we demonstrate the methodology for parallelizing the
computation of large one-dimensional discrete fast Fourier transforms (DFFTs)
on multi-core Intel Xeon processors. DFFTs based on the recursive Cooley-Tukey
method have to control cache utilization, memory bandwidth and vector hardware
usage, and at the same time scale across multiple threads or compute nodes. Our
method builds on single-threaded Intel Math Kernel Library (MKL) implementation
of DFFT, and uses the Intel Cilk Plus framework for thread parallelism. We
demonstrate the ability of Intel Cilk Plus to handle parallel recursion with
nested loop-centric parallelism without tuning the code to the number of cores
or cache metrics. The result of our work is a library called EFFT that performs
1D DFTs of size 2^N for N>=21 faster than the corresponding Intel MKL parallel
DFT implementation by up to 1.5x, and faster than FFTW by up to 2.5x. The code
of EFFT is available for free download under the GPLv3 license. This work
provides a new efficient DFFT implementation, and at the same time demonstrates
an educational example of how computer science problems with complex parallel
patterns can be optimized for high performance using the Intel Cilk Plus
framework.
","['\nRyo Asai\n', '\nAndrey Vladimirov\n']",17 pages. Submitted to Parallel Computing,,http://dx.doi.org/10.1016/j.parco.2015.05.004,cs.MS,"['cs.MS', 'cs.DC', 'cs.DS', 'cs.PF']",10.1016/j.parco.2015.05.004,,[]
"Computing the coefficients for the power series solution of the
  Lane-Emden equation with the Python library SymPy",http://arxiv.org/abs/1409.2008v2,2014-09-06T12:19:37Z,2015-01-25T18:34:58Z,"  It is shown how the Python library Sympy can be used to compute symbolically
the coefficients of the power series solution of the Lane-Emden equation (LEE).
Sympy is an open source Python library for symbolic mathematics. The power
series solutions are compared to the numerically computed solutions using
matplotlib. The results of a run time measurement of the implemented algorithm
are discussed at the end.
",['\nKlaus Rohe\n'],"14 pages, 4 figures, 2 source code listings",,http://arxiv.org/abs/1409.2008v2,cs.MS,['cs.MS'],,,[]
Performance Portability Study of Linear Algebra Kernels in OpenCL,http://arxiv.org/abs/1409.0669v1,2014-09-02T11:21:13Z,2014-09-02T11:21:13Z,"  The performance portability of OpenCL kernel implementations for common
memory bandwidth limited linear algebra operations across different hardware
generations of the same vendor as well as across vendors is studied. Certain
combinations of kernel implementations and work sizes are found to exhibit good
performance across compute kernels, hardware generations, and, to a lesser
degree, vendors. As a consequence, it is demonstrated that the optimization of
a single kernel is often sufficient to obtain good performance for a large
class of more complicated operations.
","['\nKarl Rupp\n', '\nPhilippe Tillet\n', '\nFlorian Rudolf\n', '\nJosef Weinbub\n', '\nTibor Grasser\n', '\nAnsgar Jüngel\n']","11 pages, 8 figures, 2 tables, International Workshop on OpenCL 2014","Proceedings of the International Workshop on OpenCL 2013 & 2014
  (IWOCL)",http://dx.doi.org/10.1145/2664666.2664674,cs.MS,"['cs.MS', 'cs.DC', 'cs.PF']",10.1145/2664666.2664674,,[]
CosmoMC Installation and Running Guidelines,http://arxiv.org/abs/1409.1354v3,2014-09-04T08:21:16Z,2014-09-11T02:24:35Z,"  CosmoMC is a Fortran 95 Markov-Chain Monte-Carlo (MCMC) engine to explore the
cosmological parameter space, plus a Python suite for plotting and presenting
results (see http://cosmologist.info/cosmomc/). This document describes the
installation of the CosmoMC on a Linux system (Ubuntu 14.04.1 LTS 64-bit
version). It is written for those who want to use it in their scientific
research but without much training on Linux and the program. Besides a
step-by-step installation guide, we also give a brief introduction of how to
run the program on both a desktop and a cluster. We share our way to generate
the plots that are commonly used in the references of cosmology. For more
information, one can refer to the CosmoCoffee forum
(http://cosmocoffee.info/viewforum.php?f=11) or contact the authors of this
document. Questions and comments would be much appreciated.
","['\nMing-Hua Li\n', '\nPing Wang\n', '\nZhe Chang\n', '\nDong Zhao\n']","10 pages, 0 figures. Publicly distributed and available",,http://arxiv.org/abs/1409.1354v3,astro-ph.IM,"['astro-ph.IM', 'astro-ph.CO', 'cs.MS', 'hep-th']",,,[]
"A Preconditioned Hybrid SVD Method for Computing Accurately Singular
  Triplets of Large Matrices",http://arxiv.org/abs/1408.5535v3,2014-08-23T23:19:39Z,2015-05-13T20:25:34Z,"  The computation of a few singular triplets of large, sparse matrices is a
challenging task, especially when the smallest magnitude singular values are
needed in high accuracy. Most recent efforts try to address this problem
through variations of the Lanczos bidiagonalization method, but they are still
challenged even for medium matrix sizes due to the difficulty of the problem.
We propose a novel SVD approach that can take advantage of preconditioning and
of any well designed eigensolver to compute both largest and smallest singular
triplets. Accuracy and efficiency is achieved through a hybrid, two-stage
meta-method, PHSVDS. In the first stage, PHSVDS solves the normal equations up
to the best achievable accuracy. If further accuracy is required, the method
switches automatically to an eigenvalue problem with the augmented matrix. Thus
it combines the advantages of the two stages, faster convergence and accuracy,
respectively. For the augmented matrix, solving the interior eigenvalue is
facilitated by a proper use of the good initial guesses from the first stage
and an efficient implementation of the refined projection method. We also
discuss how to precondition PHSVDS and to cope with some issues that arise.
Numerical experiments illustrate the efficiency and robustness of the method.
","['\nLingfei Wu\n', '\nAndreas Stathopoulos\n']","24 pages, 20 figures, and 8 tables. Accepted to SIAM Journal on
  Scientific Computing",,http://dx.doi.org/10.1137/140979381,cs.NA,"['cs.NA', 'cs.MS']",10.1137/140979381,,[]
"Orbital-Free Density Functional Theory Implementation with the Projector
  Augmented-Wave Method",http://arxiv.org/abs/1408.4701v2,2014-08-20T15:46:07Z,2014-11-28T11:09:12Z,"  We present a computational scheme for orbital-free density functional theory
(OFDFT) that simultaneously provides access to all-electron values and
preserves the OFDFT linear scaling as a function of the system size. Using the
projector augmented-wave method (PAW) in combination with real-space methods we
overcome some obstacles faced by other available implementation schemes.
Specifically, the advantages of using the PAW method are two fold. First, PAW
reproduces all-electron values offering freedom in adjusting the convergence
parameters and the atomic setups allow tuning the numerical accuracy per
element. Second, PAW can provide a solution to some of the convergence problems
exhibited in other OFDFT implementations based on Kohn-Sham codes. Using PAW
and real-space methods, our orbital-free results agree with the reference
all-electron values with a mean absolute error of 10~meV and the number of
iterations required by the self-consistent cycle is comparable to the KS
method. The comparison of all-electron and pseudopotential bulk modulus and
lattice constant reveal an enormous difference, demonstrating that in order to
assess the performance of OFDFT functionals it is necessary to use
implementations that obtain all-electron values. The proposed combination of
methods is the most promising route currently available. We finally show that a
parametrized kinetic energy functional can give lattice constants and bulk
moduli comparable in accuracy to those obtained by the KS PBE method,
exemplified with the case of diamond.
","['\nJ. Lehtomäki\n', '\nI. Makkonen\n', '\nM. A. Caro\n', '\nA. Harju\n', '\nO. Lopez-Acevedo\n']",accepted in Journal of Chemical Physics,"J. Chem. Phys. 141, 234102 (2014)",http://dx.doi.org/10.1063/1.4903450,physics.comp-ph,"['physics.comp-ph', 'cs.CE', 'cs.MS', 'physics.chem-ph']",10.1063/1.4903450,,[]
A Framework for Lattice QCD Calculations on GPUs,http://arxiv.org/abs/1408.5925v1,2014-08-25T20:50:08Z,2014-08-25T20:50:08Z,"  Computing platforms equipped with accelerators like GPUs have proven to
provide great computational power. However, exploiting such platforms for
existing scientific applications is not a trivial task. Current GPU programming
frameworks such as CUDA C/C++ require low-level programming from the developer
in order to achieve high performance code. As a result porting of applications
to GPUs is typically limited to time-dominant algorithms and routines, leaving
the remainder not accelerated which can open a serious Amdahl's law issue. The
lattice QCD application Chroma allows to explore a different porting strategy.
The layered structure of the software architecture logically separates the
data-parallel from the application layer. The QCD Data-Parallel software layer
provides data types and expressions with stencil-like operations suitable for
lattice field theory and Chroma implements algorithms in terms of this
high-level interface. Thus by porting the low-level layer one can effectively
move the whole application in one swing to a different platform. The
QDP-JIT/PTX library, the reimplementation of the low-level layer, provides a
framework for lattice QCD calculations for the CUDA architecture. The complete
software interface is supported and thus applications can be run unaltered on
GPU-based parallel computers. This reimplementation was possible due to the
availability of a JIT compiler (part of the NVIDIA Linux kernel driver) which
translates an assembly-like language (PTX) to GPU code. The expression template
technique is used to build PTX code generators and a software cache manages the
GPU memory. This reimplementation allows us to deploy an efficient
implementation of the full gauge-generation program with dynamical fermions on
large-scale GPU-based machines such as Titan and Blue Waters which accelerates
the algorithm by more than an order of magnitude.
","['\nF. T. Winter\n', '\nM. A. Clark\n', '\nR. G. Edwards\n', '\nB. Joó\n']","10 pages, 6 figures, as published in the proceedings of IPDPS '14",,http://dx.doi.org/10.1109/IPDPS.2014.112,hep-lat,"['hep-lat', 'cs.MS', 'physics.comp-ph']",10.1109/IPDPS.2014.112,,[]
Concurrent Cuba,http://arxiv.org/abs/1408.6373v1,2014-08-27T10:13:45Z,2014-08-27T10:13:45Z,"  The parallel version of the multidimensional numerical integration package
Cuba is presented and achievable speed-ups discussed.
",['\nT. Hahn\n'],"LaTeX, 14 pages",,http://arxiv.org/abs/1408.6373v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'hep-ph']",,,[]
"EURETILE D7.3 - Dynamic DAL benchmark coding, measurements on MPI
  version of DPSNN-STDP (distributed plastic spiking neural net) and
  improvements to other DAL codes",http://arxiv.org/abs/1408.4587v1,2014-08-20T10:00:15Z,2014-08-20T10:00:15Z,"  The EURETILE project required the selection and coding of a set of dedicated
benchmarks. The project is about the software and hardware architecture of
future many-tile distributed fault-tolerant systems. We focus on dynamic
workloads characterised by heavy numerical processing requirements. The
ambition is to identify common techniques that could be applied to both the
Embedded Systems and HPC domains. This document is the first public deliverable
of Work Package 7: Challenging Tiled Applications.
","['\nPier Stanislao Paolucci\n', '\nIuliana Bacivarov\n', '\nDevendra Rai\n', '\nLars Schor\n', '\nLothar Thiele\n', '\nHoeseok Yang\n', '\nElena Pastorelli\n', '\nRoberto Ammendola\n', '\nAndrea Biagioni\n', '\nOttorino Frezza\n', '\nFrancesca Lo Cicero\n', '\nAlessandro Lonardo\n', '\nFrancesco Simula\n', '\nLaura Tosoratto\n', '\nPiero Vicini\n']","34 pages. arXiv admin note: substantial text overlap with
  arXiv:1310.8478",,http://arxiv.org/abs/1408.4587v1,cs.DC,"['cs.DC', 'cs.CE', 'cs.MS', 'cs.NE', 'q-bio.NC']",,,[]
Algorithm xxx: RIDC Methods -- A Family of Parallel Time-Integrators,http://arxiv.org/abs/1408.3082v2,2014-08-13T18:42:01Z,2015-04-24T19:36:57Z,"  Revisionist integral deferred correction (RIDC) methods are a family of
parallel--in--time methods to solve systems of initial values problems. The
approach is able to bootstrap lower order time integrators to provide high
order approximations in approximately the same wall clock time, hence providing
a multiplicative increase in the number of compute cores utilized. Here we
provide a C++ framework which automatically produces a parallel--in--time
solution of a system of initial value problems given user supplied code for the
right hand side of the system and a sequential code for a first-order time
step. The user supplied time step routine may be explicit or implicit and may
make use of any auxiliary libraries which take care of the solution of any
nonlinear algebraic systems which may arise or the numerical linear algebra
required. The code contains six examples of increasing complexity which also
serve as templates to solve user defined problems.
","['\nBenjamin Ong\n', '\nRonald Haynes\n', '\nKyle Ladd\n']",,,http://dx.doi.org/10.1145/2964377,cs.MS,['cs.MS'],10.1145/2964377,,[]
"Experimental Evaluation of Multi-Round Matrix Multiplication on
  MapReduce",http://arxiv.org/abs/1408.2858v2,2014-08-12T21:23:11Z,2015-01-20T22:25:08Z,"  A common approach in the design of MapReduce algorithms is to minimize the
number of rounds. Indeed, there are many examples in the literature of
monolithic MapReduce algorithms, which are algorithms requiring just one or two
rounds. However, we claim that the design of monolithic algorithms may not be
the best approach in cloud systems. Indeed, multi-round algorithms may exploit
some features of cloud platforms by suitably setting the round number according
to the execution context. In this paper we carry out an experimental study of
multi-round MapReduce algorithms aiming at investigating the performance of the
multi-round approach. We use matrix multiplication as a case study. We first
propose a scalable Hadoop library, named M$_3$, for matrix multiplication in
the dense and sparse cases which allows to tradeoff round number with the
amount of data shuffled in each round and the amount of memory required by
reduce functions. Then, we present an extensive study of this library on an
in-house cluster and on Amazon Web Services aiming at showing its performance
and at comparing monolithic and multi-round approaches. The experiments show
that, even without a low level optimization, it is possible to design
multi-round algorithms with a small running time overhead.
","['\nMatteo Ceccarello\n', '\nFrancesco Silvestri\n']","Proc. of 17th Meeting on Algorithm Engineering and Experiments
  (ALENEX), 2015. The code is publicly available at http://www.dei.unipd.it/m3",,http://dx.doi.org/10.1137/1.9781611973754.11,cs.DC,"['cs.DC', 'cs.DS', 'cs.MS']",10.1137/1.9781611973754.11,,[]
"A brief survey on deep belief networks and introducing a new object
  oriented toolbox (DeeBNet)",http://arxiv.org/abs/1408.3264v7,2014-08-14T12:37:57Z,2016-01-06T13:20:11Z,"  Nowadays, this is very popular to use the deep architectures in machine
learning. Deep Belief Networks (DBNs) are deep architectures that use stack of
Restricted Boltzmann Machines (RBM) to create a powerful generative model using
training data. DBNs have many ability like feature extraction and
classification that are used in many applications like image processing, speech
processing and etc. This paper introduces a new object oriented MATLAB toolbox
with most of abilities needed for the implementation of DBNs. In the new
version, the toolbox can be used in Octave. According to the results of the
experiments conducted on MNIST (image), ISOLET (speech), and 20 Newsgroups
(text) datasets, it was shown that the toolbox can learn automatically a good
representation of the input from unlabeled data with better discrimination
between different classes. Also on all datasets, the obtained classification
errors are comparable to those of state of the art classifiers. In addition,
the toolbox supports different sampling methods (e.g. Gibbs, CD, PCD and our
new FEPCD method), different sparsity methods (quadratic, rate distortion and
our new normal method), different RBM types (generative and discriminative),
using GPU, etc. The toolbox is a user-friendly open source software and is
freely available on the website
http://ceit.aut.ac.ir/~keyvanrad/DeeBNet%20Toolbox.html .
","['\nMohammad Ali Keyvanrad\n', '\nMohammad Mehdi Homayounpour\n']","Technical Report 27 pages, Ver3.0",,http://arxiv.org/abs/1408.3264v7,cs.CV,"['cs.CV', 'cs.LG', 'cs.MS', 'cs.NE', '68T01']",,,[]
"JIDT: An information-theoretic toolkit for studying the dynamics of
  complex systems",http://arxiv.org/abs/1408.3270v2,2014-08-14T13:11:15Z,2014-12-03T13:02:48Z,"  Complex systems are increasingly being viewed as distributed information
processing systems, particularly in the domains of computational neuroscience,
bioinformatics and Artificial Life. This trend has resulted in a strong uptake
in the use of (Shannon) information-theoretic measures to analyse the dynamics
of complex systems in these fields. We introduce the Java Information Dynamics
Toolkit (JIDT): a Google code project which provides a standalone, (GNU GPL v3
licensed) open-source code implementation for empirical estimation of
information-theoretic measures from time-series data. While the toolkit
provides classic information-theoretic measures (e.g. entropy, mutual
information, conditional mutual information), it ultimately focusses on
implementing higher-level measures for information dynamics. That is, JIDT
focusses on quantifying information storage, transfer and modification, and the
dynamics of these operations in space and time. For this purpose, it includes
implementations of the transfer entropy and active information storage, their
multivariate extensions and local or pointwise variants. JIDT provides
implementations for both discrete and continuous-valued data for each measure,
including various types of estimator for continuous data (e.g. Gaussian,
box-kernel and Kraskov-Stoegbauer-Grassberger) which can be swapped at run-time
due to Java's object-oriented polymorphism. Furthermore, while written in Java,
the toolkit can be used directly in MATLAB, GNU Octave, Python and other
environments. We present the principles behind the code design, and provide
several examples to guide users.
",['\nJoseph T. Lizier\n'],"37 pages, 4 figures","Frontiers in Robotics and AI, 1:11, 2014",http://dx.doi.org/10.3389/frobt.2014.00011,cs.IT,"['cs.IT', 'cs.MS', 'cs.SI', 'math.IT', 'nlin.AO', 'physics.data-an', '94A15']",10.3389/frobt.2014.00011,,[]
Lighthouse: A User-Centered Web Service for Linear Algebra Software,http://arxiv.org/abs/1408.1363v1,2014-08-06T17:37:03Z,2014-08-06T17:37:03Z,"  Various fields of science and engineering rely on linear algebra for large
scale data analysis, modeling and simulation, machine learning, and other
applied problems. Linear algebra computations often dominate the execution time
of such applications. Meanwhile, experts in these domains typically lack the
training or time required to develop efficient, high-performance
implementations of linear algebra algorithms. In the Lighthouse project, we
enable developers with varied backgrounds to readily discover and effectively
apply the best available numerical software for their problems. We have
developed a search-based expert system that combines expert knowledge, machine
learningbased classification of existing numerical software collections, and
automated code generation and optimization. Lighthouse provides a novel
software engineering environment aimed at maximizing both developer
productivity and application performance for dense and sparse linear algebra
computations.
","['\nBoyana Norris\n', '\nSa-Lin Bernstein\n', '\nRamya Nair\n', '\nElizabeth Jessup\n']","10 pages, 10 figures, 3 tables",,http://arxiv.org/abs/1408.1363v1,cs.MS,"['cs.MS', 'G.4; H.4; D.2.8']",,,[]
"Software for Computing the Spheroidal Wave Functions Using Arbitrary
  Precision Arithmetic",http://arxiv.org/abs/1408.0074v1,2014-08-01T04:29:30Z,2014-08-01T04:29:30Z,"  The spheroidal wave functions, which are the solutions to the Helmholtz
equation in spheroidal coordinates, are notoriously difficult to compute.
Because of this, practically no programming language comes equipped with the
means to compute them. This makes problems that require their use hard to
tackle. We have developed computational software for calculating these special
functions. Our software is called spheroidal and includes several novel
features, such as: using arbitrary precision arithmetic; adaptively choosing
the number of expansion coefficients to compute and use; and using the
Wronskian to choose from several different methods for computing the spheroidal
radial functions to improve their accuracy. There are two types of spheroidal
wave functions: the prolate kind when prolate spheroidal coordinates are used;
and the oblate kind when oblate spheroidal coordinate are used. In this paper,
we describe both, methods for computing them, and our software. We have made
our software freely available on our webpage.
","['\nRoss Adelman\n', '\nNail A. Gumerov\n', '\nRamani Duraiswami\n']",,,http://arxiv.org/abs/1408.0074v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
Zolotarev Quadrature Rules and Load Balancing for the FEAST Eigensolver,http://arxiv.org/abs/1407.8078v1,2014-07-30T15:13:03Z,2014-07-30T15:13:03Z,"  The FEAST method for solving large sparse eigenproblems is equivalent to
subspace iteration with an approximate spectral projector and implicit
orthogonalization. This relation allows to characterize the convergence of this
method in terms of the error of a certain rational approximant to an indicator
function. We propose improved rational approximants leading to FEAST variants
with faster convergence, in particular, when using rational approximants based
on the work of Zolotarev. Numerical experiments demonstrate the possible
computational savings especially for pencils whose eigenvalues are not well
separated and when the dimension of the search space is only slightly larger
than the number of wanted eigenvalues. The new approach improves both
convergence robustness and load balancing when FEAST runs on multiple search
intervals in parallel.
","['\nStefan Guettel\n', '\nEric Polizzi\n', '\nPing Tak Peter Tang\n', '\nGautier Viaud\n']","22 pages, 8 figures",,http://arxiv.org/abs/1407.8078v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Standards for Graph Algorithm Primitives,http://arxiv.org/abs/1408.0393v1,2014-08-02T16:17:40Z,2014-08-02T16:17:40Z,"  It is our view that the state of the art in constructing a large collection
of graph algorithms in terms of linear algebraic operations is mature enough to
support the emergence of a standard set of primitive building blocks. This
paper is a position paper defining the problem and announcing our intention to
launch an open effort to define this standard.
","['\nTim Mattson\nIntel Corporation\n', '\nDavid Bader\nGeorgia Institute of Technology\n', '\nJon Berry\nSandia National Laboratory\n', '\nAydin Buluc\nLawrence Berkeley National Laboratory\n', '\nJack Dongarra\nUniversity of Tennessee\n', '\nChristos Faloutsos\nCarnegie Melon University\n', '\nJohn Feo\nPacific Northwest National Laboratory\n', '\nJohn Gilbert\nUniversity of California at Santa Barbara\n', '\nJoseph Gonzalez\nUniversity of California at Berkeley\n', '\nBruce Hendrickson\nSandia National Laboratory\n', '\nJeremy Kepner\nMassachusetts Institute of Technology\n', '\nCharles Leiserson\nMassachusetts Institute of Technology\n', '\nAndrew Lumsdaine\nIndiana University\n', '\nDavid Padua\nUniversity of Illinois at Urbana-Champaign\n', '\nStephen Poole\nOak Ridge National Laboratory\n', '\nSteve Reinhardt\nCray Corporation\n', '\nMike Stonebraker\nMassachusetts Institute of Technology\n', '\nSteve Wallach\nConvey Corporation\n', '\nAndrew Yoo\nLawrence Livermore National Laboratory\n']","2 pages, IEEE HPEC 2013",,http://dx.doi.org/10.1109/HPEC.2013.6670338,cs.MS,"['cs.MS', 'cs.DM', 'cs.DS']",10.1109/HPEC.2013.6670338,,"['Intel Corporation', 'Georgia Institute of Technology', 'Sandia National Laboratory', 'Lawrence Berkeley National Laboratory', 'University of Tennessee', 'Carnegie Melon University', 'Pacific Northwest National Laboratory', 'University of California at Santa Barbara', 'University of California at Berkeley', 'Sandia National Laboratory', 'Massachusetts Institute of Technology', 'Massachusetts Institute of Technology', 'Indiana University', 'University of Illinois at Urbana-Champaign', 'Oak Ridge National Laboratory', 'Cray Corporation', 'Massachusetts Institute of Technology', 'Convey Corporation', 'Lawrence Livermore National Laboratory']"
"Semi-Analytical Computation of Acoustic Scattering by Spheroids and
  Disks",http://arxiv.org/abs/1408.0854v1,2014-08-05T03:18:28Z,2014-08-05T03:18:28Z,"  Analytical solutions to acoustic scattering problems involving nonspherical
shapes, such as spheroids and disks, have long been known and have many
applications. However, these solutions require special functions that are not
easily computable. For this reason, their asymptotic forms are typically used
since they are more readily available. We explore these solutions and provide
computational software for calculating their nonasymptotic forms, which are
accurate over a wide range of frequencies and distances. This software, which
runs in MATLAB, computes the solutions to acoustic scattering problems
involving spheroids and disks by semi-analytical means, and is freely available
from our webpage.
","['\nRoss Adelman\n', '\nNail A. Gumerov\n', '\nRamani Duraiswami\n']",,,http://dx.doi.org/10.1121/1.4901318,cs.MS,"['cs.MS', 'cs.SD', 'physics.comp-ph']",10.1121/1.4901318,,[]
"Numerical Methods for the Computation of the Confluent and Gauss
  Hypergeometric Functions",http://arxiv.org/abs/1407.7786v2,2014-07-29T17:30:23Z,2015-08-28T17:54:25Z,"  The two most commonly used hypergeometric functions are the confluent
hypergeometric function and the Gauss hypergeometric function. We review the
available techniques for accurate, fast, and reliable computation of these two
hypergeometric functions in different parameter and variable regimes. The
methods that we investigate include Taylor and asymptotic series computations,
Gauss-Jacobi quadrature, numerical solution of differential equations,
recurrence relations, and others. We discuss the results of numerical
experiments used to determine the best methods, in practice, for each parameter
and variable regime considered. We provide 'roadmaps' with our recommendation
for which methods should be used in each situation.
","['\nJohn W. Pearson\n', '\nSheehan Olver\n', '\nMason A. Porter\n']",42 pages,,http://arxiv.org/abs/1407.7786v2,math.NA,"['math.NA', 'cs.MS', 'math-ph', 'math.MP', 'physics.comp-ph', 'Primary: 33C05, 33C15, Secondary: 41A58, 41A60']",,,[]
scikit-image: Image processing in Python,http://arxiv.org/abs/1407.6245v1,2014-07-23T14:55:21Z,2014-07-23T14:55:21Z,"  scikit-image is an image processing library that implements algorithms and
utilities for use in research, education and industry applications. It is
released under the liberal ""Modified BSD"" open source license, provides a
well-documented API in the Python programming language, and is developed by an
active, international team of collaborators. In this paper we highlight the
advantages of open source to achieve the goals of the scikit-image library, and
we showcase several real-world image processing applications that use
scikit-image.
","['\nStefan van der Walt\n', '\nJohannes L. Schönberger\n', '\nJuan Nunez-Iglesias\n', '\nFrançois Boulogne\n', '\nJoshua D. Warner\n', '\nNeil Yager\n', '\nEmmanuelle Gouillart\n', '\nTony Yu\n', '\nthe scikit-image contributors\n']",Distributed under Creative Commons CC-BY 4.0. Published in PeerJ,,http://dx.doi.org/10.7717/peerj.453,cs.MS,"['cs.MS', 'cs.CV']",10.7717/peerj.453,,[]
The DUNE-ALUGrid Module,http://arxiv.org/abs/1407.6954v3,2014-07-25T16:12:26Z,2015-08-15T11:23:22Z,"  In this paper we present the new DUNE-ALUGrid module. This module contains a
major overhaul of the sources from the ALUgrid library and the binding to the
DUNE software framework. The main changes include user defined load balancing,
parallel grid construction, and an redesign of the 2d grid which can now also
be used for parallel computations. In addition many improvements have been
introduced into the code to increase the parallel efficiency and to decrease
the memory footprint.
  The original ALUGrid library is widely used within the DUNE community due to
its good parallel performance for problems requiring local adaptivity and
dynamic load balancing. Therefore, this new model will benefit a number of DUNE
users. In addition we have added features to increase the range of problems for
which the grid manager can be used, for example, introducing a 3d tetrahedral
grid using a parallel newest vertex bisection algorithm for conforming grid
refinement. In this paper we will discuss the new features, extensions to the
DUNE interface, and explain for various examples how the code is used in
parallel environments.
","['\nMartin Alkämper\n', '\nAndreas Dedner\n', '\nRobert Klöfkorn\n', '\nMartin Nolte\n']","25 pages, 11 figures",,http://arxiv.org/abs/1407.6954v3,cs.MS,"['cs.MS', 'cs.DC']",,,[]
Implementing cryptographic pairings at standard security levels,http://arxiv.org/abs/1407.5953v1,2014-07-22T17:42:29Z,2014-07-22T17:42:29Z,"  This study reports on an implementation of cryptographic pairings in a
general purpose computer algebra system. For security levels equivalent to the
different AES flavours, we exhibit suitable curves in parametric families and
show that optimal ate and twisted ate pairings exist and can be efficiently
evaluated. We provide a correct description of Miller's algorithm for signed
binary expansions such as the NAF and extend a recent variant due to Boxall et
al. to addition-subtraction chains. We analyse and compare several algorithms
proposed in the literature for the final exponentiation. Finally, we ive
recommendations on which curve and pairing to choose at each security level.
","['\nAndreas Enge\nINRIA Bordeaux - Sud-Ouest, IMB\n', '\nJérôme Milan\nINRIA Futurs\n']",,,http://arxiv.org/abs/1407.5953v1,math.NT,"['math.NT', 'cs.CR', 'cs.MS']",,,"['INRIA Bordeaux - Sud-Ouest, IMB', 'INRIA Futurs']"
"A data porting tool for coupling models with different discretization
  needs",http://arxiv.org/abs/1407.2925v1,2014-07-09T10:45:40Z,2014-07-09T10:45:40Z,"  The presented work is part of a larger research program dealing with
developing tools for coupling biogeochemical models in contaminated landscapes.
The specific objective of this article is to provide the researchers a tool to
build hexagonal raster using information from a rectangular raster data (e.g.
GIS format), data porting. This tool involves a computational algorithm and an
open source software (written in C). The method of extending the reticulated
functions defined on 2D networks is an essential key of this algorithm and can
also be used for other purposes than data porting. The algorithm allows one to
build the hexagonal raster with a cell size independent from the geometry of
the rectangular raster. The extended function is a bi-cubic spline which can
exactly reconstruct polynomials up to degree three in each variable. We
validate the method by analyzing errors in some theoretical case studies
followed by other studies with real terrain elevation data. We also introduce
and briefly present an iterative water routing method and use it for validation
on a case with concrete terrain data.
","['\nStelian Ion\n', '\nDorin Marinescu\n', '\nStefan-Gicu Cruceanu\n', '\nVirgil Iordache\n']",,Environmental Modelling & Software 62 (2014) 240-252,http://dx.doi.org/10.1016/j.envsoft.2014.09.012,cs.MS,['cs.MS'],10.1016/j.envsoft.2014.09.012,,[]
Modular SIMD arithmetic in Mathemagix,http://arxiv.org/abs/1407.3383v1,2014-07-12T13:21:01Z,2014-07-12T13:21:01Z,"  Modular integer arithmetic occurs in many algorithms for computer algebra,
cryptography, and error correcting codes. Although recent microprocessors
typically offer a wide range of highly optimized arithmetic functions, modular
integer operations still require dedicated implementations. In this article, we
survey existing algorithms for modular integer arithmetic, and present detailed
vectorized counterparts. We also present several applications, such as fast
modular Fourier transforms and multiplication of integer polynomials and
matrices. The vectorized algorithms have been implemented in C++ inside the
free computer algebra and analysis system Mathemagix. The performance of our
implementation is illustrated by various benchmarks.
","['\nJoris van der Hoeven\n', '\nGrégoire Lecerf\n', '\nGuillaume Quintin\n']",,,http://arxiv.org/abs/1407.3383v1,cs.MS,"['cs.MS', 'G.4']",,,[]
"A modern resistive magnetohydrodynamics solver using C++ and the Boost
  library",http://arxiv.org/abs/1407.3189v1,2014-07-11T15:05:33Z,2014-07-11T15:05:33Z,"  In this paper we describe the implementation of our C++ resistive
magnetohydrodynamics solver. The framework developed facilitates the separation
of the code implementing the specific numerical method and the physical model,
on the one hand, from the handling of boundary conditions and the management of
the computational domain, on the other hand. In particular, this will allow us
to use finite difference stencils which are only defined in the interior of the
domain (the boundary conditions are handled automatically). We will discuss
this and other design considerations and their impact on performance in some
detail. In addition, we provide a documentation of the code developed and
demonstrate that a performance comparable to Fortran can be achieved, while
still maintaining a maximum of code readability and extensibility.
",['\nLukas Einkemmer\n'],,"Computer Physics Communications, Volume 206, September 2016, Pages
  69-77",http://dx.doi.org/10.1016/j.cpc.2016.04.015,cs.NA,"['cs.NA', 'cs.MS']",10.1016/j.cpc.2016.04.015,,[]
Run-time extensibility and librarization of simulation software,http://arxiv.org/abs/1407.2905v1,2014-07-10T19:08:32Z,2014-07-10T19:08:32Z,"  Build-time configuration and environment assumptions are hampering progress
and usability in scientific software. That which would be utterly unacceptable
in non-scientific software somehow passes for the norm in scientific packages.
The community needs reusable software packages that are easy use and flexible
enough to accommodate next-generation simulation and analysis demands.
","['\nJed Brown\n', '\nMatthew G. Knepley\n', '\nBarry F. Smith\n']",6 pages,,http://arxiv.org/abs/1407.2905v1,cs.SE,"['cs.SE', 'cs.CE', 'cs.MS']",,,[]
Integer formula encoding SageTeX package,http://arxiv.org/abs/1407.0039v1,2014-06-27T00:13:14Z,2014-06-27T00:13:14Z,"  The paper describes a SageTeX implementation of an integer encoding
procedures.
",['\nEdinah K. Gnang\n'],,,http://arxiv.org/abs/1407.0039v1,cs.MS,"['cs.MS', 'math.CO']",,,[]
"Bayesian Network Constraint-Based Structure Learning Algorithms:
  Parallel and Optimised Implementations in the bnlearn R Package",http://arxiv.org/abs/1406.7648v2,2014-06-30T09:56:20Z,2015-06-01T10:27:23Z,"  It is well known in the literature that the problem of learning the structure
of Bayesian networks is very hard to tackle: its computational complexity is
super-exponential in the number of nodes in the worst case and polynomial in
most real-world scenarios.
  Efficient implementations of score-based structure learning benefit from past
and current research in optimisation theory, which can be adapted to the task
by using the network score as the objective function to maximise. This is not
true for approaches based on conditional independence tests, called
constraint-based learning algorithms. The only optimisation in widespread use,
backtracking, leverages the symmetries implied by the definitions of
neighbourhood and Markov blanket.
  In this paper we illustrate how backtracking is implemented in recent
versions of the bnlearn R package, and how it degrades the stability of
Bayesian network structure learning for little gain in terms of speed. As an
alternative, we describe a software architecture and framework that can be used
to parallelise constraint-based structure learning algorithms (also implemented
in bnlearn) and we demonstrate its performance using four reference networks
and two real-world data sets from genetics and systems biology. We show that on
modern multi-core or multiprocessor hardware parallel implementations are
preferable over backtracking, which was developed when single-processor
machines were the norm.
",['\nMarco Scutari\n'],"20 pages, 4 figures","Journal of Statistical Software (2017), 77(2), 1-20",http://arxiv.org/abs/1406.7648v2,stat.CO,"['stat.CO', 'cs.AI', 'cs.MS', 'stat.ME']",,,[]
COFFEE: an Optimizing Compiler for Finite Element Local Assembly,http://arxiv.org/abs/1407.0904v2,2014-07-03T13:01:45Z,2014-07-04T09:12:46Z,"  The numerical solution of partial differential equations using the finite
element method is one of the key applications of high performance computing.
Local assembly is its characteristic operation. This entails the execution of a
problem-specific kernel to numerically evaluate an integral for each element in
the discretized problem domain. Since the domain size can be huge, executing
efficient kernels is fundamental. Their op- timization is, however, a
challenging issue. Even though affine loop nests are generally present, the
short trip counts and the complexity of mathematical expressions make it hard
to determine a single or unique sequence of successful transformations.
Therefore, we present the design and systematic evaluation of COF- FEE, a
domain-specific compiler for local assembly kernels. COFFEE manipulates
abstract syntax trees generated from a high-level domain-specific language for
PDEs by introducing domain-aware composable optimizations aimed at improving
instruction-level parallelism, especially SIMD vectorization, and register
locality. It then generates C code including vector intrinsics. Experiments
using a range of finite-element forms of increasing complexity show that
significant performance improvement is achieved.
","['\nFabio Luporini\n', '\nAna Lucia Varbanescu\n', '\nFlorian Rathgeber\n', '\nGheorghe-Teodor Bercea\n', '\nJ. Ramanujam\n', '\nDavid A. Ham\n', '\nPaul H. J. Kelly\n']",Remove volume metadata,,http://dx.doi.org/10.1145/2687415,cs.MS,"['cs.MS', 'cs.CE', 'cs.PF', 'G.1.8; G.4']",10.1145/2687415,,[]
Elements of Design for Containers and Solutions in the LinBox Library,http://arxiv.org/abs/1407.3262v1,2014-06-25T19:38:09Z,2014-06-25T19:38:09Z,"  We describe in this paper new design techniques used in the \cpp exact linear
algebra library \linbox, intended to make the library safer and easier to use,
while keeping it generic and efficient. First, we review the new simplified
structure for containers, based on our \emph{founding scope allocation} model.
We explain design choices and their impact on coding: unification of our matrix
classes, clearer model for matrices and submatrices, \etc Then we present a
variation of the \emph{strategy} design pattern that is comprised of a
controller--plugin system: the controller (solution) chooses among plug-ins
(algorithms) that always call back the controllers for subtasks. We give
examples using the solution \mul. Finally we present a benchmark architecture
that serves two purposes: Providing the user with easier ways to produce
graphs; Creating a framework for automatically tuning the library and
supporting regression testing.
","['\nBrice Boyer\nLJK\n', '\nJean-Guillaume Dumas\nLJK\n', '\nPascal Giorgi\nLIRMM\n', ""\nClément Pernet\nINRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble\n"", '\nB. David Saunders\nCIS\n']","8 pages, 4th International Congress on Mathematical Software, Seoul :
  Korea, Republic Of (2014)",,http://arxiv.org/abs/1407.3262v1,cs.MS,"['cs.MS', 'cs.SC', 'cs.SE']",,,"['LJK', 'LJK', 'LIRMM', ""INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble"", 'CIS']"
"Efficient Gluing of Numerical Continuation and a Multiple Solution
  Method for Elliptic PDEs",http://arxiv.org/abs/1406.6900v3,2014-06-26T14:37:40Z,2014-10-18T14:17:34Z,"  Numerical continuation calculations for ordinary differential equations
(ODEs) are, by now, an established tool for bifurcation analysis in dynamical
systems theory as well as across almost all natural and engineering sciences.
Although several excellent standard software packages are available for ODEs,
there are - for good reasons - no standard numerical continuation toolboxes
available for partial differential equations (PDEs), which cover a broad range
of different classes of PDEs automatically. A natural approach to this problem
is to look for efficient gluing computation approaches, with independent
components developed by researchers in numerical analysis, dynamical systems,
scientific computing and mathematical modelling. In this paper, we shall study
several elliptic PDEs (Lane-Emden-Fowler, Lane-Emden-Fowler with microscopic
force, Caginalp) via the numerical continuation software pde2path and develop a
gluing component to determine a set of starting solutions for the continuation
by exploting the variational structures of the PDEs. In particular, we solve
the initialization problem of numerical continuation for PDEs via a minimax
algorithm to find multiple unstable solution. Furthermore, for the Caginalp
system, we illustrate the efficient gluing link of pde2path to the underlying
mesh generation and the FEM MatLab pdetoolbox. Even though the approach works
efficiently due to the high-level programming language and without developing
any new algorithms, we still obtain interesting bifurcation diagrams and
directly applicable conclusions about the three elliptic PDEs we study, in
particular with respect to symmetry-breaking. In particular, we show for a
modified Lane-Emden-Fowler equation with an asymmetric microscopic force, how a
fully connected bifurcation diagram splits up into C-shaped isolas on which
localized pattern deformation appears towards two different regimes.
",['\nChristian Kuehn\n'],"Revised version based upon referee comments, 11 figures, shortened
  online abstract and slightly lower quality figures due to arXiv size
  limitations","Applied Mathematics and Computation, Vol. 266, pp. 656-674, 2015",http://dx.doi.org/10.1016/j.amc.2015.05.120,math.DS,"['math.DS', 'cs.MS', 'math.NA', 'nlin.PS', 'physics.comp-ph']",10.1016/j.amc.2015.05.120,,[]
Strongly stable ideals and Hilbert polynomials,http://arxiv.org/abs/1406.6924v2,2014-06-26T15:35:00Z,2018-11-05T07:59:45Z,"  The \texttt{StronglyStableIdeals} package for \textit{Macaulay2} provides a
method to compute all saturated strongly stable ideals in a given polynomial
ring with a fixed Hilbert polynomial. A description of the main method and
auxiliary tools is given.
","['\nDavide Alberelli\n', '\nPaolo Lella\n']",Source code available as an ancillary file. Final version,J. Softw. Alg. Geom. 9 (2019) 1-9,http://dx.doi.org/10.2140/jsag.2019.9.1,cs.SC,"['cs.SC', 'cs.MS', 'math.AC', 'math.AG', 'math.CO', '13P10, 13P99']",10.2140/jsag.2019.9.1,,[]
"A Scala Prototype to Generate Multigrid Solver Implementations for
  Different Problems and Target Multi-Core Platforms",http://arxiv.org/abs/1406.5369v1,2014-06-20T12:46:27Z,2014-06-20T12:46:27Z,"  Many problems in computational science and engineering involve partial
differential equations and thus require the numerical solution of large, sparse
(non)linear systems of equations. Multigrid is known to be one of the most
efficient methods for this purpose. However, the concrete multigrid algorithm
and its implementation highly depend on the underlying problem and hardware.
Therefore, changes in the code or many different variants are necessary to
cover all relevant cases. In this article we provide a prototype implementation
in Scala for a framework that allows abstract descriptions of PDEs, their
discretization, and their numerical solution via multigrid algorithms. From
these, one is able to generate data structures and implementations of multigrid
components required to solve elliptic PDEs on structured grids. Two different
test problems showcase our proposed automatic generation of multigrid solvers
for both CPU and GPU target platforms.
","['\nHarald Koestler\n', '\nChristian Schmitt\n', '\nSebastian Kuckuk\n', '\nFrank Hannig\n', '\nJuergen Teich\n', '\nUlrich Ruede\n']",,,http://arxiv.org/abs/1406.5369v1,cs.MS,['cs.MS'],,,[]
"ViDaExpert: user-friendly tool for nonlinear visualization and analysis
  of multidimensional vectorial data",http://arxiv.org/abs/1406.5550v2,2014-06-20T22:31:25Z,2014-06-27T14:40:04Z,"  ViDaExpert is a tool for visualization and analysis of multidimensional
vectorial data. ViDaExpert is able to work with data tables of ""object-feature""
type that might contain numerical feature values as well as textual labels for
rows (objects) and columns (features). ViDaExpert implements several
statistical methods such as standard and weighted Principal Component Analysis
(PCA) and the method of elastic maps (non-linear version of PCA), Linear
Discriminant Analysis (LDA), multilinear regression, K-Means clustering, a
variant of decision tree construction algorithm. Equipped with several
user-friendly dialogs for configuring data point representations (size, shape,
color) and fast 3D viewer, ViDaExpert is a handy tool allowing to construct an
interactive 3D-scene representing a table of data in multidimensional space and
perform its quick and insightfull statistical analysis, from basic to advanced
methods.
","['\nAlexander N. Gorban\n', '\nAlexander Pitenko\n', '\nAndrei Zinovyev\n']",,,http://arxiv.org/abs/1406.5550v2,cs.MS,"['cs.MS', 'stat.CO', '68N01, 68W25', 'G.3; G.4']",,,[]
An Open Source Pattern Recognition Toolbox for MATLAB,http://arxiv.org/abs/1406.5565v1,2014-06-21T01:50:54Z,2014-06-21T01:50:54Z,"  Pattern recognition and machine learning are becoming integral parts of
algorithms in a wide range of applications. Different algorithms and approaches
for machine learning include different tradeoffs between performance and
computation, so during algorithm development it is often necessary to explore a
variety of different approaches to a given task. A toolbox with a unified
framework across multiple pattern recognition techniques enables algorithm
developers the ability to rapidly evaluate different choices prior to
deployment. MATLAB is a widely used environment for algorithm development and
prototyping, and although several MATLAB toolboxes for pattern recognition are
currently available these are either incomplete, expensive, or restrictively
licensed. In this work we describe a MATLAB toolbox for pattern recognition and
machine learning known as the PRT (Pattern Recognition Toolbox), licensed under
the permissive MIT license. The PRT includes many popular techniques for data
preprocessing, supervised learning, clustering, regression and feature
selection, as well as a methodology for combining these components using a
simple, uniform syntax. The resulting algorithms can be evaluated using
cross-validation and a variety of scoring metrics to ensure robust performance
when the algorithm is deployed. This paper presents an overview of the PRT as
well as an example of usage on Fisher's Iris dataset.
","['\nKenneth D. Morton Jr.\n', '\nPeter Torrione\n', '\nLeslie Collins\n', '\nSam Keene\n']",,,http://arxiv.org/abs/1406.5565v1,stat.ML,"['stat.ML', 'cs.CV', 'cs.LG', 'cs.MS']",,,[]
"Achieving 100,000,000 database inserts per second using Accumulo and D4M",http://arxiv.org/abs/1406.4923v1,2014-06-19T00:44:12Z,2014-06-19T00:44:12Z,"  The Apache Accumulo database is an open source relaxed consistency database
that is widely used for government applications. Accumulo is designed to
deliver high performance on unstructured data such as graphs of network data.
This paper tests the performance of Accumulo using data from the Graph500
benchmark. The Dynamic Distributed Dimensional Data Model (D4M) software is
used to implement the benchmark on a 216-node cluster running the MIT
SuperCloud software stack. A peak performance of over 100,000,000 database
inserts per second was achieved which is 100x larger than the highest
previously published value for any other database. The performance scales
linearly with the number of ingest clients, number of database servers, and
data size. The performance was achieved by adapting several supercomputing
techniques to this application: distributed arrays, domain decomposition,
adaptive load balancing, and single-program-multiple-data programming.
","['\nJeremy Kepner\nMIT\n', '\nWilliam Arcand\nMIT\n', '\nDavid Bestor\nMIT\n', '\nBill Bergeron\nMIT\n', '\nChansup Byun\nMIT\n', '\nVijay Gadepally\nMIT\n', '\nMatthew Hubbell\nMIT\n', '\nPeter Michaleas\nMIT\n', '\nJulie Mullen\nMIT\n', '\nAndrew Prout\nMIT\n', '\nAlbert Reuther\nMIT\n', '\nAntonio Rosa\nMIT\n', '\nCharles Yee\nMIT\n']","6 pages; to appear in IEEE High Performance Extreme Computing (HPEC)
  2014",,http://dx.doi.org/10.1109/HPEC.2014.7040945,cs.DB,"['cs.DB', 'astro-ph.IM', 'cs.CE', 'cs.DC', 'cs.MS']",10.1109/HPEC.2014.7040945,,"['MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT']"
Transpose-free Fast Fourier Transform for Turbulence Simulation,http://arxiv.org/abs/1406.5597v1,2014-06-21T11:19:59Z,2014-06-21T11:19:59Z,"  Pseudo-spectral method is one of the most accurate techniques for simulating
turbulent flows. Fast Fourier transform (FFT) is an integral part of this
method. In this paper, we present a new procedure to compute FFT in which we
save operations during interprocess communications by avoiding transpose of the
array. As a result, our transpose-free FFT is 15\% to 20\% faster than FFTW.
","['\nA. G. Chatterjee\n', '\nM. K. Verma\n', '\nM. Chaudhuri\n']",,,http://arxiv.org/abs/1406.5597v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.DS', 'physics.comp-ph', 'physics.flu-dyn']",,,[]
"Proceedings Twelfth International Workshop on the ACL2 Theorem Prover
  and its Applications",http://arxiv.org/abs/1406.1238v1,2014-06-04T23:49:33Z,2014-06-04T23:49:33Z,"  This volume contains the proceedings of the Twelfth International Workshop on
the ACL2 Theorem Prover and Its Applications, ACL2'14, a two-day workshop held
in Vienna, Austria, on July 12-13, 2014. ACL2 workshops occur at approximately
18-month intervals and provide a major technical forum for researchers to
present and discuss improvements and extensions to the theorem prover,
comparisons of ACL2 with other systems, and applications of ACL2 in formal
verification. These proceedings include 13 peer reviewed technical papers.
  ACL2 is a state-of-the-art automated reasoning system that has been
successfully applied in academia, government, and industry for specification
and verification of computing systems and in teaching computer science courses.
In 2005, Boyer, Kaufmann, and Moore were awarded the 2005 ACM Software System
Award for their work in ACL2 and the other theorem provers in the Boyer-Moore
family.
","['\nFreek Verbeek\nOpen University of The Netherlands\n', '\nJulien Schmaltz\nEindhoven University of Technology\n']",,"EPTCS 152, 2014",http://dx.doi.org/10.4204/EPTCS.152,cs.LO,"['cs.LO', 'cs.MS']",10.4204/EPTCS.152,,"['Open University of The Netherlands', 'Eindhoven University of Technology']"
"Formal Verification of Medina's Sequence of Polynomials for
  Approximating Arctangent",http://arxiv.org/abs/1406.1561v1,2014-06-06T01:48:16Z,2014-06-06T01:48:16Z,"  The verification of many algorithms for calculating transcendental functions
is based on polynomial approximations to these functions, often Taylor series
approximations. However, computing and verifying approximations to the
arctangent function are very challenging problems, in large part because the
Taylor series converges very slowly to arctangent-a 57th-degree polynomial is
needed to get three decimal places for arctan(0.95). Medina proposed a series
of polynomials that approximate arctangent with far faster convergence-a
7th-degree polynomial is all that is needed to get three decimal places for
arctan(0.95). We present in this paper a proof in ACL2(r) of the correctness
and convergence rate of this sequence of polynomials. The proof is particularly
beautiful, in that it uses many results from real analysis. Some of these
necessary results were proven in prior work, but some were proven as part of
this effort.
","['\nRuben Gamboa\nUniversity of Wyoming\n', '\nJohn Cowles\nUniversity of Wyoming\n']","In Proceedings ACL2 2014, arXiv:1406.1238","EPTCS 152, 2014, pp. 101-110",http://dx.doi.org/10.4204/EPTCS.152.9,cs.LO,"['cs.LO', 'cs.MS']",10.4204/EPTCS.152.9,,"['University of Wyoming', 'University of Wyoming']"
"A Generic Numbering System based on Catalan Families of Combinatorial
  Objects",http://arxiv.org/abs/1406.1796v2,2014-06-06T19:22:44Z,2019-09-14T21:15:15Z,"  We describe arithmetic algorithms on a canonical number representation based
on the Catalan family of combinatorial objects specified as a Haskell type
class.
  Our algorithms work on a {\em generic} representation that we illustrate on
instances members of the Catalan family, like ordered binary and multiway
trees. We validate the correctness of our algorithms by defining an instance of
the same type class based the usual bitstring-based natural numbers.
  While their average and worst case complexity is within constant factors of
their traditional counterparts, our algorithms provide super-exponential gains
for numbers corresponding to Catalan objects of low representation size.
",['\nPaul Tarau\n'],preprint,,http://arxiv.org/abs/1406.1796v2,cs.MS,"['cs.MS', 'cs.DS']",,,[]
Program Verification of Numerical Computation - Part 2,http://arxiv.org/abs/1406.2079v4,2014-06-09T05:36:44Z,2014-11-20T08:28:13Z,"  These notes present some extensions of a formal method introduced in an
earlier paper. The formal method is designed as a tool for program verification
of numerical computation and forms the basis of the software package VPC.
Included in the extensions that are presented here are disjunctions and methods
for detecting non-computable programs. A more comprehensive list of the
construction rules as higher order constructs is also presented.
",['\nGarry Pantelis\n'],arXiv admin note: text overlap with arXiv:1401.1290,,http://arxiv.org/abs/1406.2079v4,cs.LO,"['cs.LO', 'cs.MS', '03Fxx', 'F.4.1; F.3.1']",,,[]
Industrial-Strength Documentation for ACL2,http://arxiv.org/abs/1406.2266v1,2014-06-06T01:47:12Z,2014-06-06T01:47:12Z,"  The ACL2 theorem prover is a complex system. Its libraries are vast.
Industrial verification efforts may extend this base with hundreds of thousands
of lines of additional modeling tools, specifications, and proof scripts. High
quality documentation is vital for teams that are working together on projects
of this scale. We have developed XDOC, a flexible, scalable documentation tool
for ACL2 that can incorporate the documentation for ACL2 itself, the Community
Books, and an organization's internal formal verification projects, and which
has many features that help to keep the resulting manuals up to date. Using
this tool, we have produced a comprehensive, publicly available ACL2+Books
Manual that brings better documentation to all ACL2 users. We have also
developed an extended manual for use within Centaur Technology that extends the
public manual to cover Centaur's internal books. We expect that other
organizations using ACL2 will wish to develop similarly extended manuals.
","['\nJared Davis\nCentaur Technology\n', '\nMatt Kaufmann\nUniversity of Texas at Austin\n']","In Proceedings ACL2 2014, arXiv:1406.1238","EPTCS 152, 2014, pp. 9-25",http://dx.doi.org/10.4204/EPTCS.152.2,cs.SE,"['cs.SE', 'cs.MS']",10.4204/EPTCS.152.2,,"['Centaur Technology', 'University of Texas at Austin']"
Fast Matlab compatible sparse assembly on multicore computers,http://arxiv.org/abs/1406.1066v3,2014-06-04T15:01:23Z,2015-10-23T10:58:34Z,"  We develop and implement in this paper a fast sparse assembly algorithm, the
fundamental operation which creates a compressed matrix from raw index data.
Since it is often a quite demanding and sometimes critical operation, it is of
interest to design a highly efficient implementation. We show how to do this,
and moreover, we show how our implementation can be parallelized to utilize the
power of modern multicore computers. Our freely available code, fully Matlab
compatible, achieves about a factor of 5 times in speedup on a typical 6-core
machine and 10 times on a dual-socket 16 core machine compared to the built-in
serial implementation.
","['\nStefan Engblom\n', '\nDimitar Lukarski\n']",,Parallel Comput. 56:1--17 (2016),http://dx.doi.org/10.1016/j.parco.2016.04.001,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', '68W10, 65Y10']",10.1016/j.parco.2016.04.001,,[]
"Enhancements to ACL2 in Versions 6.2, 6.3, and 6.4",http://arxiv.org/abs/1406.1556v1,2014-06-06T01:46:54Z,2014-06-06T01:46:54Z,"  We report on improvements to ACL2 made since the 2013 ACL2 Workshop.
","['\nMatt Kaufmann\nUT Austin\n', '\nJ Strother Moore\nUT Austin\n']","In Proceedings ACL2 2014, arXiv:1406.1238","EPTCS 152, 2014, pp. 1-7",http://dx.doi.org/10.4204/EPTCS.152.1,cs.AI,"['cs.AI', 'cs.LO', 'cs.MS']",10.4204/EPTCS.152.1,,"['UT Austin', 'UT Austin']"
"The OpenCPU System: Towards a Universal Interface for Scientific
  Computing through Separation of Concerns",http://arxiv.org/abs/1406.4806v1,2014-06-04T00:03:52Z,2014-06-04T00:03:52Z,"  Applications integrating analysis components require a programmable interface
which defines statistical operations independently of any programming language.
By separating concerns of scientific computing from application and
implementation details we can derive an interoperable API for data analysis.
But what exactly are the concerns of scientific computing? To answer this
question, the paper starts with an exploration of the purpose, problems,
characteristics, struggles, culture, and community of this unique branch of
computing. By mapping out the domain logic, we try to unveil the fundamental
principles and concepts behind statistical software. Along the way we highlight
important problems and bottlenecks that need to be addressed by the system in
order to facilitate reliable and scalable analysis units. Finally, the OpenCPU
software is introduced as an example implementation that builds on HTTP and R
to expose a simple, abstracted interface for scientific computing.
",['\nJeroen Ooms\n'],,,http://arxiv.org/abs/1406.4806v1,stat.CO,"['stat.CO', 'cs.MS', 'cs.SE']",,,[]
"Realms: A Structure for Consolidating Knowledge about Mathematical
  Theories",http://arxiv.org/abs/1405.5956v1,2014-05-23T03:05:42Z,2014-05-23T03:05:42Z,"  Since there are different ways of axiomatizing and developing a mathematical
theory, knowledge about a such a theory may reside in many places and in many
forms within a library of formalized mathematics. We introduce the notion of a
realm as a structure for consolidating knowledge about a mathematical theory. A
realm contains several axiomatizations of a theory that are separately
developed. Views interconnect these developments and establish that the
axiomatizations are equivalent in the sense of being mutually interpretable. A
realm also contains an external interface that is convenient for users of the
library who want to apply the concepts and facts of the theory without delving
into the details of how the concepts and facts were developed. We illustrate
the utility of realms through a series of examples. We also give an outline of
the mechanisms that are needed to create and maintain realms.
","['\nJacques Carette\n', '\nWilliam M. Farmer\n', '\nMichael Kohlhase\n']",As accepted for CICM 2014,,http://arxiv.org/abs/1405.5956v1,cs.MS,"['cs.MS', 'cs.LO']",,,[]
Recursive Algorithms for Distributed Forests of Octrees,http://arxiv.org/abs/1406.0089v3,2014-05-31T16:02:54Z,2015-08-20T03:26:29Z,"  The forest-of-octrees approach to parallel adaptive mesh refinement and
coarsening (AMR) has recently been demonstrated in the context of a number of
large-scale PDE-based applications. Although linear octrees, which store only
leaf octants, have an underlying tree structure by definition, it is not often
exploited in previously published mesh-related algorithms. This is because the
branches are not explicitly stored, and because the topological relationships
in meshes, such as the adjacency between cells, introduce dependencies that do
not respect the octree hierarchy. In this work we combine hierarchical and
topological relationships between octree branches to design efficient recursive
algorithms.
  We present three important algorithms with recursive implementations. The
first is a parallel search for leaves matching any of a set of multiple search
criteria. The second is a ghost layer construction algorithm that handles
arbitrarily refined octrees that are not covered by previous algorithms, which
require a 2:1 condition between neighboring leaves. The third is a universal
mesh topology iterator. This iterator visits every cell in a domain partition,
as well as every interface (face, edge and corner) between these cells. The
iterator calculates the local topological information for every interface that
it visits, taking into account the nonconforming interfaces that increase the
complexity of describing the local topology. To demonstrate the utility of the
topology iterator, we use it to compute the numbering and encoding of
higher-order $C^0$ nodal basis functions.
  We analyze the complexity of the new recursive algorithms theoretically, and
assess their performance, both in terms of single-processor efficiency and in
terms of parallel scalability, demonstrating good weak and strong scaling up to
458k cores of the JUQUEEN supercomputer.
","['\nTobin Isaac\n', '\nCarsten Burstedde\n', '\nLucas C. Wilcox\n', '\nOmar Ghattas\n']","35 pages, 15 figures, 3 tables",,http://dx.doi.org/10.1137/140970963,cs.DC,"['cs.DC', 'cs.CE', 'cs.MS']",10.1137/140970963,,[]
A formally verified proof of the Central Limit Theorem,http://arxiv.org/abs/1405.7012v4,2014-05-27T19:01:57Z,2017-02-01T15:53:42Z,"  We describe a proof of the Central Limit Theorem that has been formally
verified in the Isabelle proof assistant. Our formalization builds upon and
extends Isabelle's libraries for analysis and measure-theoretic probability.
The proof of the theorem uses characteristic functions, which are a kind of
Fourier transform, to demonstrate that, under suitable hypotheses, sums of
random variables converge weakly to the standard normal distribution. We also
discuss the libraries and infrastructure that supported the formalization, and
reflect on some of the lessons we have learned from the effort.
","['\nJeremy Avigad\n', '\nJohannes Hölzl\n', '\nLuke Serafin\n']",,,http://arxiv.org/abs/1405.7012v4,cs.MS,"['cs.MS', 'cs.LO', 'math.PR', '60F05, 03B35', 'F.4.1; G.3']",,,[]
"PyRDM: A Python-based library for automating the management and online
  publication of scientific software and data",http://arxiv.org/abs/1405.7290v2,2014-05-28T16:07:12Z,2014-08-21T10:48:05Z,"  The recomputability and reproducibility of results from scientific software
requires access to both the source code and all associated input and output
data. However, the full collection of these resources often does not accompany
the key findings published in journal articles, thereby making it difficult or
impossible for the wider scientific community to verify the correctness of a
result or to build further research on it. This paper presents a new
Python-based library, PyRDM, whose functionality aims to automate the process
of sharing the software and data via online, citable repositories such as
Figshare. The library is integrated into the workflow of an open-source
computational fluid dynamics package, Fluidity, to demonstrate an example of
its usage.
","['\nChristian T. Jacobs\n', '\nAlexandros Avdis\n', '\nGerard J. Gorman\n', '\nMatthew D. Piggott\n']","Revised version. The main changes are: Added pdfLaTeX to the
  dependencies list; Improved Figure 1 to show the 'publish' option selected in
  Diamond; Added two paragraphs to explain why users would want to use PyRDM;
  Added some content on the PyRDM roadmap, and also some content regarding
  engagement with libraries and research software engineers",Journal of Open Research Software 2:e28 (2014) 1-6,http://dx.doi.org/10.5334/jors.bj,cs.CE,"['cs.CE', 'cs.DL', 'cs.MS']",10.5334/jors.bj,,[]
Loo.py: transformation-based code generation for GPUs and CPUs,http://arxiv.org/abs/1405.7470v1,2014-05-29T05:53:56Z,2014-05-29T05:53:56Z,"  Today's highly heterogeneous computing landscape places a burden on
programmers wanting to achieve high performance on a reasonably broad
cross-section of machines. To do so, computations need to be expressed in many
different but mathematically equivalent ways, with, in the worst case, one
variant per target machine.
  Loo.py, a programming system embedded in Python, meets this challenge by
defining a data model for array-style computations and a library of
transformations that operate on this model. Offering transformations such as
loop tiling, vectorization, storage management, unrolling, instruction-level
parallelism, change of data layout, and many more, it provides a convenient way
to capture, parametrize, and re-unify the growth among code variants. Optional,
deep integration with numpy and PyOpenCL provides a convenient computing
environment where the transition from prototype to high-performance
implementation can occur in a gradual, machine-assisted form.
",['\nAndreas Klöckner\n'],,"Proceedings of ARRAY 2014: ACM SIGPLAN Workshop on Libraries,
  Languages, and Compilers for Array Programming",http://dx.doi.org/10.1145/2627373.2627387,cs.PL,"['cs.PL', 'cs.MS', 'math.NA', 'D.3.4; D.1.3; G.4']",10.1145/2627373.2627387,,[]
"Kahler: An Implementation of Discrete Exterior Calculus on Hermitian
  Manifolds",http://arxiv.org/abs/1405.7879v2,2014-05-30T14:36:33Z,2014-06-04T14:42:41Z,"  This paper details the techniques and algorithms implemented in Kahler, a
Python library that implements discrete exterior calculus on arbitrary
Hermitian manifolds. Borrowing techniques and ideas first implemented in PyDEC,
Kahler provides a uniquely general framework for computation using discrete
exterior calculus. Manifolds can have arbitrary dimension, topology, bilinear
Hermitian metrics, and embedding dimension. Kahler comes equipped with tools
for generating triangular meshes in arbitrary dimensions with arbitrary
topology. Kahler can also generate discrete sharp operators and implement de
Rham maps. Computationally intensive tasks are automatically parallelized over
the number of cores detected. The program itself is written in Cython--a
superset of the Python language that is translated to C and compiled for extra
speed. Kahler is applied to several example problems: normal modes of a
vibrating membrane, electromagnetic resonance in a cavity, the quantum harmonic
oscillator, and the Dirac-Kahler equation. Convergence is demonstrated on
random meshes.
",['\nAlex Eftimiades\n'],Added a link to the code,,http://arxiv.org/abs/1405.7879v2,cs.NA,"['cs.NA', 'cs.CG', 'cs.MS', 'math.DG', 'math.NA', '65N30', 'G.4; G.1.8; I.3.5']",,,[]
Hipster: Integrating Theory Exploration in a Proof Assistant,http://arxiv.org/abs/1405.3426v1,2014-05-14T09:43:09Z,2014-05-14T09:43:09Z,"  This paper describes Hipster, a system integrating theory exploration with
the proof assistant Isabelle/HOL. Theory exploration is a technique for
automatically discovering new interesting lemmas in a given theory development.
Hipster can be used in two main modes. The first is exploratory mode, used for
automatically generating basic lemmas about a given set of datatypes and
functions in a new theory development. The second is proof mode, used in a
particular proof attempt, trying to discover the missing lemmas which would
allow the current goal to be proved. Hipster's proof mode complements and
boosts existing proof automation techniques that rely on automatically
selecting existing lemmas, by inventing new lemmas that need induction to be
proved. We show example uses of both modes.
","['\nMoa Johansson\n', '\nDan Rosen\n', '\nNicholas Smallbone\n', '\nKoen Claessen\n']",,,http://arxiv.org/abs/1405.3426v1,cs.LO,"['cs.LO', 'cs.MS']",,,[]
Changing Computing Paradigms Towards Power Efficiency,http://arxiv.org/abs/1405.4644v1,2014-05-19T09:03:58Z,2014-05-19T09:03:58Z,"  Power awareness is fast becoming immensely important in computing, ranging
from the traditional High Performance Computing applications, to the new
generation of data centric workloads.
  In this work we describe our efforts towards a power efficient computing
paradigm that combines low precision and high precision arithmetic. We showcase
our ideas for the widely used kernel of solving systems of linear equations
that finds numerous applications in scientific and engineering disciplines as
well as in large scale data analytics, statistics and machine learning.
  Towards this goal we developed tools for the seamless power profiling of
applications at a fine grain level. In addition, we verify here previous work
on post FLOPS/Watt metrics and show that these can shed much more light in the
power/energy profile of important applications.
","['\nPavel Klavík\n', '\nA. Cristiano I. Malossi\n', '\nConstantin Bekas\n', '\nAlessandro Curioni\n']",,"Philosophical Transactions of the Royal Society A: Physical,
  Mathematical and Engineering Sciences. 372(2018)",http://dx.doi.org/10.1098/rsta.2013.0278,cs.MS,"['cs.MS', 'cs.NA']",10.1098/rsta.2013.0278,,[]
Zgoubi: A startup guide for the complete beginner,http://arxiv.org/abs/1405.4921v1,2014-05-19T23:53:58Z,2014-05-19T23:53:58Z,"  Zgoubi is a code which can be used to model accelerators and beam lines,
comprised of magnetic and electrostatic elements. It has been extensively
developed since the mid-1980s to include circular accelerators and related beam
physics. It has been made freely available by its author on a code development
site, including a Users' Guide, a data treatment/graphic interfacing tool, and
many examples. This startup guide give directions to install the required
elements onto a Windows or Unix system to enable running of the Zgoubi code
with examples of code written to model the EMMA accelerator based at the
Cockcroft Institute.
","['\nAnnette Pressman\n', '\nKai Hock\n']",,,http://arxiv.org/abs/1405.4921v1,physics.acc-ph,"['physics.acc-ph', 'cs.MS']",,,[]
Search Interfaces for Mathematicians,http://arxiv.org/abs/1405.3758v1,2014-05-15T06:55:21Z,2014-05-15T06:55:21Z,"  Access to mathematical knowledge has changed dramatically in recent years,
therefore changing mathematical search practices. Our aim with this study is to
scrutinize professional mathematicians' search behavior. With this
understanding we want to be able to reason why mathematicians use which tool
for what search problem in what phase of the search process. To gain these
insights we conducted 24 repertory grid interviews with mathematically inclined
people (ranging from senior professional mathematicians to non-mathematicians).
From the interview data we elicited patterns for the user group
""mathematicians"" that can be applied when understanding design issues or
creating new designs for mathematical search interfaces.
",['\nAndrea Kohlhase\n'],"conference article ""CICM'14: International Conference on Computer
  Mathematics 2014"", DML-Track: Digital Math Libraries 17 pages",,http://arxiv.org/abs/1405.3758v1,cs.HC,"['cs.HC', 'cs.DL', 'cs.MS']",,,[]
PLQCD library for Lattice QCD on multi-core machines,http://arxiv.org/abs/1405.0700v1,2014-05-04T14:12:53Z,2014-05-04T14:12:53Z,"  PLQCD is a stand-alone software library developed under PRACE for lattice
QCD. It provides an implementation of the Dirac operator for Wilson type
fermions and few efficient linear solvers. The library is optimized for
multi-core machines using a hybrid parallelization with OpenMP+MPI. The main
objectives of the library is to provide a scalable implementation of the Dirac
operator for efficient computation of the quark propagator. In this
contribution, a description of the PLQCD library is given together with some
benchmark results.
","['\nA. Abdel-Rehim\n', '\nC. Alexandrou\n', '\nN. Anastopoulos\n', '\nG. Koutsou\n', '\nI. Liabotis\n', '\nN. Papadopoulou\n']","7 pages, presented at the 31st International Symposium on Lattice
  Field Theory (Lattice 2013), 29 July - 3 August 2013, Mainz, Germany",,http://arxiv.org/abs/1405.0700v1,hep-lat,"['hep-lat', 'cs.MS']",,,[]
Computing all Affine Solution Sets of Binomial Systems,http://arxiv.org/abs/1405.0320v1,2014-05-01T23:00:24Z,2014-05-01T23:00:24Z,"  To compute solutions of sparse polynomial systems efficiently we have to
exploit the structure of their Newton polytopes. While the application of
polyhedral methods naturally excludes solutions with zero components, an
irreducible decomposition of a variety is typically understood in affine space,
including also those components with zero coordinates. For the problem of
computing solution sets in the intersection of some coordinate planes, the
direct application of a polyhedral method fails, because the original facial
structure of the Newton polytopes may alter completely when selected variables
become zero. Our new proposed method enumerates all factors contributing to a
generalized permanent and toric solutions as a special case of this
enumeration. For benchmark problems such as the adjacent 2-by-2 minors of a
general matrix, our methods scale much better than the witness set
representations of numerical algebraic geometry.
","['\nDanko Adrovic\n', '\nJan Verschelde\n']","4 page extended abstract accepted by EACA 2014, a conference on
  Computer Algebra and its Applications",,http://arxiv.org/abs/1405.0320v1,cs.SC,"['cs.SC', 'cs.MS', 'math.AG']",,,[]
"Bloscpack: a compressed lightweight serialization format for numerical
  data",http://arxiv.org/abs/1404.6383v2,2014-04-25T10:53:23Z,2014-04-29T14:16:55Z,"  This paper introduces the Bloscpack file format and the accompanying Python
reference implementation. Bloscpack is a lightweight, compressed binary
file-format based on the Blosc codec and is designed for lightweight, fast
serialization of numerical data. This article presents the features of the
file-format and some some API aspects of the reference implementation, in
particular the ability to handle Numpy ndarrays. Furthermore, in order to
demonstrate its utility, the format is compared both feature- and
performance-wise to a few alternative lightweight serialization solutions for
Numpy ndarrays. The performance comparisons take the form of some comprehensive
benchmarks over a range of different artificial datasets with varying size and
complexity, the results of which are presented as the last section of this
article.
",['\nValentin Haenel\n'],"Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)",,http://arxiv.org/abs/1404.6383v2,cs.MS,"['cs.MS', 'cs.PL']",,,[]
Performance of Python runtimes on a non-numeric scientific code,http://arxiv.org/abs/1404.6388v2,2014-04-25T10:55:48Z,2014-04-29T14:21:46Z,"  The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational
homology of the moduli space of Riemann surfaces is an example of a non-numeric
scientific code: most of the processing it does is generating graphs
(represented by complex Python objects) and computing their isomorphisms (a
triple of Python lists; again a nested data structure). These operations are
repeated many times over: for example, the spaces and are triangulated by
4'583'322 and 747'664 graphs, respectively. This is an opportunity for every
Python runtime to prove its strength in optimization. The purpose of this
experiment was to assess the maturity of alternative Python runtimes, in terms
of: compatibility with the language as implemented in CPython 2.7, and
performance speedup. This paper compares the results and experiences from
running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython
0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.
",['\nRiccardo Murri\n'],"Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)",,http://arxiv.org/abs/1404.6388v2,cs.MS,"['cs.MS', 'cs.PL']",,,[]
"Knowledge-Based Automatic Generation of Linear Algebra Algorithms and
  Code",http://arxiv.org/abs/1404.3406v1,2014-04-13T18:13:32Z,2014-04-13T18:13:32Z,"  This dissertation focuses on the design and the implementation of
domain-specific compilers for linear algebra matrix equations. The development
of efficient libraries for such equations, which lie at the heart of most
software for scientific computing, is a complex process that requires expertise
in a variety of areas, including the application domain, algorithms, numerical
analysis and high-performance computing. Moreover, the process involves the
collaboration of several people for a considerable amount of time. With our
compilers, we aim to relieve the developers from both designing algorithms and
writing code, and to generate routines that match or even surpass the
performance of those written by human experts.
",['\nDiego Fabregat-Traver\n'],Dissertation,,http://arxiv.org/abs/1404.3406v1,cs.MS,['cs.MS'],,,[]
A heuristic prover for real inequalities,http://arxiv.org/abs/1404.4410v2,2014-04-17T01:31:39Z,2016-01-04T19:09:17Z,"  We describe a general method for verifying inequalities between real-valued
expressions, especially the kinds of straightforward inferences that arise in
interactive theorem proving. In contrast to approaches that aim to be complete
with respect to a particular language or class of formulas, our method
establishes claims that require heterogeneous forms of reasoning, relying on a
Nelson-Oppen-style architecture in which special-purpose modules collaborate
and share information. The framework is thus modular and extensible. A
prototype implementation shows that the method works well on a variety of
examples, and complements techniques that are used by contemporary interactive
provers.
","['\nJeremy Avigad\n', '\nRobert Y. Lewis\n', '\nCody Roux\n']",,,http://arxiv.org/abs/1404.4410v2,cs.MS,"['cs.MS', 'cs.LO', 'I.1.2; G.4; F.2.1']",,,[]
A New Highly Parallel Non-Hermitian Eigensolver,http://arxiv.org/abs/1404.2891v1,2014-04-10T17:59:44Z,2014-04-10T17:59:44Z,"  Calculating portions of eigenvalues and eigenvectors of matrices or matrix
pencils has many applications. An approach to this calculation for Hermitian
problems based on a density matrix has been proposed in 2009 and a software
package called FEAST has been developed. The density-matrix approach allows
FEAST's implementation to exploit a key strength of modern computer
architectures, namely, multiple levels of parallelism. Consequently, the
software package has been well received and subsequently commercialized. A
detailed theoretical analysis of Hermitian FEAST has also been established very
recently. This paper generalizes the FEAST algorithm and theory, for the first
time, to tackle non-Hermitian problems. Fundamentally, the new algorithm is
basic subspace iteration or Bauer bi-iteration, except applied with a novel
accelerator based on Cauchy integrals. The resulting algorithm retains the
multi-level parallelism of Hermitian FEAST, making it a valuable new tool for
large-scale computational science and engineering problems on leading-edge
computing platforms.
","['\nPing Tak Peter Tang\n', '\nJames Kestyn\n', '\nEric Polizzi\n']",,,http://arxiv.org/abs/1404.2891v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
"An Optimized and Scalable Eigensolver for Sequences of Eigenvalue
  Problems",http://arxiv.org/abs/1404.4161v2,2014-04-16T08:09:56Z,2014-07-06T11:59:36Z,"  In many scientific applications the solution of non-linear differential
equations are obtained through the set-up and solution of a number of
successive eigenproblems. These eigenproblems can be regarded as a sequence
whenever the solution of one problem fosters the initialization of the next. In
addition, in some eigenproblem sequences there is a connection between the
solutions of adjacent eigenproblems. Whenever it is possible to unravel the
existence of such a connection, the eigenproblem sequence is said to be
correlated. When facing with a sequence of correlated eigenproblems the current
strategy amounts to solving each eigenproblem in isolation. We propose a
alternative approach which exploits such correlation through the use of an
eigensolver based on subspace iteration and accelerated with Chebyshev
polynomials (ChFSI). The resulting eigensolver is optimized by minimizing the
number of matrix-vector multiplications and parallelized using the Elemental
library framework. Numerical results show that ChFSI achieves excellent
scalability and is competitive with current dense linear algebra parallel
eigensolvers.
","['\nMario Berljafa\nThe University of Manchester\n', '\nDaniel Wortmann\nForschungszentrum Juelich\n', '\nEdoardo Di Napoli\nForschungszentrum Juelich\nAICES, RWTH Aachen\n']","23 Pages, 6 figures. First revision of an invited submission to
  special issue of Concurrency and Computation: Practice and Experience",,http://arxiv.org/abs/1404.4161v2,cs.MS,"['cs.MS', 'cs.DC', 'physics.comp-ph']",,,"['The University of Manchester', 'Forschungszentrum Juelich', 'Forschungszentrum Juelich', 'AICES, RWTH Aachen']"
CTBNCToolkit: Continuous Time Bayesian Network Classifier Toolkit,http://arxiv.org/abs/1404.4893v1,2014-04-18T21:48:34Z,2014-04-18T21:48:34Z,"  Continuous time Bayesian network classifiers are designed for temporal
classification of multivariate streaming data when time duration of events
matters and the class does not change over time. This paper introduces the
CTBNCToolkit: an open source Java toolkit which provides a stand-alone
application for temporal classification and a library for continuous time
Bayesian network classifiers. CTBNCToolkit implements the inference algorithm,
the parameter learning algorithm, and the structural learning algorithm for
continuous time Bayesian network classifiers. The structural learning algorithm
is based on scoring functions: the marginal log-likelihood score and the
conditional log-likelihood score are provided. CTBNCToolkit provides also an
implementation of the expectation maximization algorithm for clustering
purpose. The paper introduces continuous time Bayesian network classifiers. How
to use the CTBNToolkit from the command line is described in a specific
section. Tutorial examples are included to facilitate users to understand how
the toolkit must be used. A section dedicate to the Java library is proposed to
help further code extensions.
","['\nDaniele Codecasa\n', '\nFabio Stella\n']",,,http://arxiv.org/abs/1404.4893v1,cs.AI,"['cs.AI', 'cs.LG', 'cs.MS']",,,[]
Using RngStreams for Parallel Random Number Generation in C++ and R,http://arxiv.org/abs/1403.7645v1,2014-03-29T16:30:21Z,2014-03-29T16:30:21Z,"  The RngStreams software package provides one viable solution to the problem
of creating independent random number streams for simulations in parallel
processing environments. Techniques are presented for effectively using
RngStreams with C++ programs that are parallelized via OpenMP or MPI. Ways to
access the backbone generator from RngStreams in R through the parallel and
rstream packages are also described. The ideas in the paper are illustrated
with both a simple running example and a Monte Carlo integration application.
","['\nAndrew T. Karl\n', '\nRandy Eubank\n', '\nJelena Milovanovic\n', '\nMark Reiser\n', '\nDennis Young\n']","This paper has been accepted by Computational Statistics and is
  currently in press","Computational Statistics, 2014, 29:1301-1320",http://dx.doi.org/10.1007/s00180-014-0492-3,cs.MS,"['cs.MS', 'stat.CO']",10.1007/s00180-014-0492-3,,[]
Further scramblings of Marsaglia's xorshift generators,http://arxiv.org/abs/1404.0390v3,2014-04-01T20:14:51Z,2016-05-23T15:44:18Z,"  xorshift* generators are a variant of Marsaglia's xorshift generators that
eliminate linear artifacts typical of generators based on $\mathbf Z/2\mathbf
Z$-linear operations using multiplication by a suitable constant. Shortly after
high-dimensional xorshift* generators were introduced, Saito and Matsumoto
suggested a different way to eliminate linear artifacts based on addition in
$\mathbf Z/2^{32}\mathbf Z$, leading to the XSadd generator. Starting from the
observation that the lower bits of XSadd are very weak, as its reverse fails
systematically several statistical tests, we explore xorshift+, a variant of
XSadd using 64-bit operations, which leads, in small dimension, to extremely
fast high-quality generators.
",['\nSebastiano Vigna\n'],arXiv admin note: text overlap with arXiv:1402.6246,,http://arxiv.org/abs/1404.0390v3,cs.DS,"['cs.DS', 'cs.CR', 'cs.MS']",,,[]
"A modified ziggurat algorithm for generating exponentially- and
  normally-distributed pseudorandom numbers",http://arxiv.org/abs/1403.6870v2,2014-03-26T21:51:41Z,2014-04-21T17:28:01Z,"  The Ziggurat Algorithm is a very fast rejection sampling method for
generating PseudoRandom Numbers (PRNs) from common statistical distributions.
The algorithm divides a distribution into rectangular layers that stack on top
of each other (resembling a Ziggurat), subsuming the desired distribution.
Random values within these rectangular layers are then sampled by rejection.
This implementation splits layers into two types: those constituting the
majority that fall completely under the distribution and can be sampled
extremely fast without a rejection test, and a few additional layers that
encapsulate the fringe of the distribution and require a rejection test. This
method offers speedups of 65% for exponentially- and 82% for
normally-distributed PRNs when compared to the best available C implementations
of these generators. Even greater speedups are obtained when the algorithm is
extended to the Python and MATLAB/OCTAVE programming environments.
",['\nChristopher D McFarland\n'],,,http://arxiv.org/abs/1403.6870v2,cs.MS,['cs.MS'],,,[]
The MIXMAX random number generator,http://arxiv.org/abs/1403.5355v2,2014-03-21T03:45:08Z,2014-04-01T15:06:14Z,"  In this note, we give a practical solution to the problem of determining the
maximal period of matrix generators of pseudo-random numbers which are based on
an integer-valued unimodular matrix of size NxN known as MIXMAX and arithmetic
defined on a Galois field GF[p] with large prime modulus p. The existing theory
of Galois finite fields is adapted to the present case, and necessary and
sufficient condition to attain the maximum period is formulated. Three
efficient algorithms are presented. First, allowing to compute the
multiplication by the MIXMAX matrix with O(N) operations. Second, to
recursively compute the characteristic polynomial with O(N^2) operations, and
third, to apply skips of large number of steps S to the sequence in O(N^2
log(S)) operations. It is demonstrated that the dynamical properties of this
generator dramatically improve with the size of the matrix N, as compared to
the classes of generators based on sparse matrices and/or sparse characteristic
polynomials. Finally, we present the implementation details of the generator
and the results of rigorous statistical testing.
",['\nKonstantin G. Savvidy\n'],"15 pages, 3 Figures",,http://dx.doi.org/10.1016/j.cpc.2015.06.003,hep-lat,"['hep-lat', 'cs.MS', 'nlin.CD']",10.1016/j.cpc.2015.06.003,,[]
High Performance Solutions for Big-data GWAS,http://arxiv.org/abs/1403.6426v1,2014-03-25T17:21:55Z,2014-03-25T17:21:55Z,"  In order to associate complex traits with genetic polymorphisms, genome-wide
association studies process huge datasets involving tens of thousands of
individuals genotyped for millions of polymorphisms. When handling these
datasets, which exceed the main memory of contemporary computers, one faces two
distinct challenges: 1) Millions of polymorphisms and thousands of phenotypes
come at the cost of hundreds of gigabytes of data, which can only be kept in
secondary storage; 2) the relatedness of the test population is represented by
a relationship matrix, which, for large populations, can only fit in the
combined main memory of a distributed architecture. In this paper, by using
distributed resources such as Cloud or clusters, we address both challenges:
The genotype and phenotype data is streamed from secondary storage using a
double buffer- ing technique, while the relationship matrix is kept across the
main memory of a distributed memory system. With the help of these solutions,
we develop separate algorithms for studies involving only one or a multitude of
traits. We show that these algorithms sustain high-performance and allow the
analysis of enormous datasets.
","['\nElmar Peise\nAICES, RWTH Aachen\n', '\nDiego Fabregat-Traver\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']","Submitted to Parallel Computing. arXiv admin note: substantial text
  overlap with arXiv:1304.2272",,http://arxiv.org/abs/1403.6426v1,q-bio.GN,"['q-bio.GN', 'cs.CE', 'cs.MS']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
A SageTeX Hypermatrix Algebra Package,http://arxiv.org/abs/1403.2630v1,2014-03-11T16:23:23Z,2014-03-11T16:23:23Z,"  We describe here a rudimentary sage implementation of the Bhattacharya-Mesner
hypermatrix algebra package.
","['\nEdinah K. Gnang\n', '\nOri Parzanchevski\n', '\nYuval Filmus\n']",,,http://arxiv.org/abs/1403.2630v1,cs.MS,"['cs.MS', 'math.CO']",,,[]
Straightforward Bibliography Management in R with the RefManageR Package,http://arxiv.org/abs/1403.2036v1,2014-03-09T08:09:02Z,2014-03-09T08:09:02Z,"  This work introduces the R package RefManageR, which provides tools for
importing and working with bibliographic references. It extends the bibentry
class in R in a number of useful ways, including providing R with previously
unavailable support for BibLaTeX. BibLaTeX provides a superset of the
functionality of BibTeX, including full Unicode support, no memory limitations,
additional fields and entry types, and more sophisticated sorting of
references. RefManageR provides functions for citing and generating a
bibliography with hyperlinks for documents prepared with RMarkdown or RHTML.
Existing .bib files can be read into R and converted from BibTeX to BibLaTeX
and vice versa. References can also be imported via queries to NCBI's Entrez,
Zotero libraries, Google Scholar, and CrossRef. Additionally, references can be
created by reading PDFs stored on the user's machine with the help of Poppler.
Entries stored in the reference manager can be easily searched by any field, by
date ranges, and by various formats for name lists (author by last names,
translator by full names, etc.). Entries can also be updated, combined, sorted,
printed in a number of styles, and exported.
",['\nMathew W. McLean\n'],30 pages,,http://arxiv.org/abs/1403.2036v1,cs.DL,"['cs.DL', 'cs.MS', 'stat.CO']",,,[]
"The jsonlite Package: A Practical and Consistent Mapping Between JSON
  Data and R Objects",http://arxiv.org/abs/1403.2805v1,2014-03-12T04:21:10Z,2014-03-12T04:21:10Z,"  A naive realization of JSON data in R maps JSON arrays to an unnamed list,
and JSON objects to a named list. However, in practice a list is an awkward,
inefficient type to store and manipulate data. Most statistical applications
work with (homogeneous) vectors, matrices or data frames. Therefore JSON
packages in R typically define certain special cases of JSON structures which
map to simpler R types. Currently there exist no formal guidelines, or even
consensus between implementations on how R data should be represented in JSON.
Furthermore, upon closer inspection, even the most basic data structures in R
actually do not perfectly map to their JSON counterparts and leave some
ambiguity for edge cases. These problems have resulted in different behavior
between implementations and can lead to unexpected output. This paper
explicitly describes a mapping between R classes and JSON data, highlights
potential problems, and proposes conventions that generalize the mapping to
cover all common structures. We emphasize the importance of type consistency
when using JSON to exchange dynamic data, and illustrate using examples and
anecdotes. The jsonlite R package is used throughout the paper as a reference
implementation.
",['\nJeroen Ooms\n'],,,http://arxiv.org/abs/1403.2805v1,stat.CO,"['stat.CO', 'cs.MS', 'cs.SE']",,,[]
"Polcovar: Software for Computing the Mean and Variance of Subgraph
  Counts in Random Graphs",http://arxiv.org/abs/1402.5835v2,2014-02-24T14:26:08Z,2016-05-04T20:34:48Z,"  The mean and variance of the number of appearances of a given subgraph $H$ in
an Erd\H{o}s--R\'enyi random graph over $n$ nodes are rational polynomials in
$n$. We present a piece of software named Polcovar (from ""polynomial"" and
""covariance"") that computes the exact rational coefficients of these
polynomials in function of $H$.
",['\nJérôme Kunegis\n'],5 pages; fixed some wording; added link to Github,,http://arxiv.org/abs/1402.5835v2,cs.MS,['cs.MS'],,,[]
Matrix Methods for Solving Algebraic Systems,http://arxiv.org/abs/1403.1140v1,2014-03-05T14:14:12Z,2014-03-05T14:14:12Z,"  We present our public-domain software for the following tasks in sparse (or
toric) elimination theory, given a well-constrained polynomial system. First, C
code for computing the mixed volume of the system. Second, Maple code for
defining an overconstrained system and constructing a Sylvester-type matrix of
its sparse resultant. Third, C code for a Sylvester-type matrix of the sparse
resultant and a superset of all common roots of the initial well-constrained
system by computing the eigen-decomposition of a square matrix obtained from
the resultant matrix. We conclude with experiments in computing molecular
conformations.
",['\nIoannis Z. Emiris\n'],13 pages. arXiv admin note: text overlap with arXiv:1201.5810,,http://arxiv.org/abs/1403.1140v1,cs.MS,"['cs.MS', 'cs.SC']",,,[]
Machine Learning at Scale,http://arxiv.org/abs/1402.6076v1,2014-02-25T07:50:50Z,2014-02-25T07:50:50Z,"  It takes skill to build a meaningful predictive model even with the abundance
of implementations of modern machine learning algorithms and readily available
computing resources. Building a model becomes challenging if hundreds of
terabytes of data need to be processed to produce the training data set. In a
digital advertising technology setting, we are faced with the need to build
thousands of such models that predict user behavior and power advertising
campaigns in a 24/7 chaotic real-time production environment. As data
scientists, we also have to convince other internal departments critical to
implementation success, our management, and our customers that our machine
learning system works. In this paper, we present the details of the design and
implementation of an automated, robust machine learning platform that impacts
billions of advertising impressions monthly. This platform enables us to
continuously optimize thousands of campaigns over hundreds of millions of
users, on multiple continents, against varying performance objectives.
","['\nSergei Izrailev\n', '\nJeremy M. Stanley\n']",Submitted to KDD'14,,http://arxiv.org/abs/1402.6076v1,cs.LG,"['cs.LG', 'cs.MS', 'stat.ML', 'I.5.2']",,,[]
"Recent software developments for special functions in the
  Santander-Amsterdam project",http://arxiv.org/abs/1403.1200v1,2014-03-05T17:36:34Z,2014-03-05T17:36:34Z,"  We give an overview of published algorithms by our group and of current
activities and future plans. In particular, we give details on methods for
computing special functions and discuss in detail two current lines of
research. Firstly, we describe the recent developments for the computation of
central and non-central chi-square cumulative distributions (also called Marcum
Q-functions), and we present a new quadrature method for computing them.
Secondly, we describe the fourth-order methods for computing zeros of special
functions recently developed, and we provide an explicit example for the
computation of complex zeros of Bessel functions. We end with an overview of
published software by our group for computing special functions.
","['\nA. Gil\n', '\nJ. Segura\n', '\nN. M. Temme\n']",To appear in Science of Computer Programming,,http://dx.doi.org/10.1016/j.scico.2013.11.004,math.CA,"['math.CA', 'cs.MS', 'cs.NA', 'math.NA']",10.1016/j.scico.2013.11.004,,[]
Toward Resilient Algorithms and Applications,http://arxiv.org/abs/1402.3809v2,2014-02-16T15:43:05Z,2014-03-13T17:55:31Z,"  Over the past decade, the high performance computing community has become
increasingly concerned that preserving the reliable, digital machine model will
become too costly or infeasible. In this paper we discuss four approaches for
developing new algorithms that are resilient to hard and soft failures.
",['\nMichael A. Heroux\n'],,,http://arxiv.org/abs/1402.3809v2,cs.MS,"['cs.MS', 'cs.DC', 'C.4; D.1.3; D.4.5; G.1.0']",,,[]
Symmetric QR Algorithm with Permutations,http://arxiv.org/abs/1402.5086v1,2014-02-20T17:34:49Z,2014-02-20T17:34:49Z,"  In this paper, we present the QR Algorithm with Permutations that shows an
improved convergence rate compared to the classical QR algorithm. We determine
a bound for performance based on best instantaneous convergence, and develop
low complexity methods for computing the permutation matrices at every
iteration. We use simulations to verify the improvement, and to compare the
performance of proposed algorithms to the classical QR algorithm.
",['\nAravindh Krishnamoorthy\n'],,,http://arxiv.org/abs/1402.5086v1,cs.NA,"['cs.NA', 'cs.MS', 'math.NA']",,,[]
"A Study on the Influence of Caching: Sequences of Dense Linear Algebra
  Kernels",http://arxiv.org/abs/1402.5897v1,2014-02-21T12:23:19Z,2014-02-21T12:23:19Z,"  It is universally known that caching is critical to attain high- performance
implementations: In many situations, data locality (in space and time) plays a
bigger role than optimizing the (number of) arithmetic floating point
operations. In this paper, we show evidence that at least for linear algebra
algorithms, caching is also a crucial factor for accurate performance modeling
and performance prediction.
","['\nElmar Peise\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']","Submitted to the Ninth International Workshop on Automatic
  Performance Tuning (iWAPT2014)",,http://arxiv.org/abs/1402.5897v1,cs.MS,"['cs.MS', 'cs.NA', 'cs.PF']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
Tensor computations in computer algebra systems,http://arxiv.org/abs/1402.6635v1,2014-02-22T15:47:58Z,2014-02-22T15:47:58Z,"  This paper considers three types of tensor computations. On their basis, we
attempt to formulate criteria that must be satisfied by a computer algebra
system dealing with tensors. We briefly overview the current state of tensor
computations in different computer algebra systems. The tensor computations are
illustrated with appropriate examples implemented in specific systems: Cadabra
and Maxima.
","['\nA. V. Korolkova\n', '\nD. S. Kulyabov\n', '\nL. A. Sevastyanov\n']",in Russian; in English,"A. V. Korol'kova, D. S. Kulyabov, and L. A. Sevast'yanov. Tensor
  computations in computer algebra systems. Programming and Computer Software,
  39(3):135--142, 2013",http://dx.doi.org/10.1134/S0361768813030031,cs.SC,"['cs.SC', 'cs.MS', 'gr-qc']",10.1134/S0361768813030031,,[]
Divide-And-Conquer Computation of Cylindrical Algebraic Decomposition,http://arxiv.org/abs/1402.0622v1,2014-02-04T05:52:47Z,2014-02-04T05:52:47Z,"  We present a divide-and-conquer version of the Cylindrical Algebraic
Decomposition (CAD) algorithm. The algorithm represents the input as a Boolean
combination of subformulas, computes cylindrical algebraic decompositions of
solution sets of the subformulas, and combines the results. We propose a
graph-based heuristic to find a suitable partitioning of the input and present
empirical comparison with direct CAD computation.
",['\nAdam Strzebonski\n'],,,http://arxiv.org/abs/1402.0622v1,cs.SC,"['cs.SC', 'cs.MS']",,,[]
"Constructing Performance Models for Dense Linear Algebra Algorithms on
  Cray XE Systems",http://arxiv.org/abs/1402.1285v1,2014-02-06T09:16:38Z,2014-02-06T09:16:38Z,"  Hiding or minimizing the communication cost is key in order to obtain good
performance on large-scale systems. While communication overlapping attempts to
hide communications cost, 2.5D communication avoiding algorithms improve
performance scalability by reducing the volume of data transfers at the cost of
extra memory usage. Both approaches can be used together or separately and the
best choice depends on the machine, the algorithm and the problem size. Thus,
the development of performance models is crucial to determine the best option
for each scenario. In this paper, we present a methodology for constructing
performance models for parallel numerical routines on Cray XE systems. Our
models use portable benchmarks that measure computational cost and network
characteristics, as well as performance degradation caused by simultaneous
accesses to the network. We validate our methodology by constructing the
performance models for the 2D and 2.5D approaches, with and without
overlapping, of two matrix multiplication algorithms (Cannon's and SUMMA),
triangular solve (TRSM) and Cholesky. We compare the estimations provided by
these models with the experimental results using up to 24,576 cores of a Cray
XE6 system and predict the performance of the algorithms on larger systems.
Results prove that the estimations significantly improve when taking into
account network contention.
","['\nJorge González-Domínguez\n', '\nEvangelos Georganas\n', '\nYili Zheng\n', '\nMaría J. Martín\n']",,,http://arxiv.org/abs/1402.1285v1,cs.DC,"['cs.DC', 'cs.MS', 'cs.PF']",,,[]
"GPU acceleration of Newton's method for large systems of polynomial
  equations in double double and quad double arithmetic",http://arxiv.org/abs/1402.2626v2,2014-02-11T20:18:31Z,2014-05-13T13:38:42Z,"  In order to compensate for the higher cost of double double and quad double
arithmetic when solving large polynomial systems, we investigate the
application of NVIDIA Tesla K20C general purpose graphics processing unit. The
focus on this paper is on Newton's method, which requires the evaluation of the
polynomials, their derivatives, and the solution of a linear system to compute
the update to the current approximation for the solution. The reverse mode of
algorithmic differentiation for a product of variables is rewritten in a binary
tree fashion so all threads in a block can collaborate in the computation. For
double arithmetic, the evaluation and differentiation problem is memory bound,
whereas for complex quad double arithmetic the problem is compute bound. With
acceleration we can double the dimension and get results that are twice as
accurate in about the same time.
","['\nJan Verschelde\n', '\nXiangcheng Yu\n']",,,http://arxiv.org/abs/1402.2626v2,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA']",,,[]
Numerical application and Turbo C program using the Gauss-Jordan Method,http://arxiv.org/abs/1401.7962v1,2014-01-29T10:44:45Z,2014-01-29T10:44:45Z,"  The article presents the general notions and algorithm about the Gauss-Jordan
method. An eloquent example is given and the Turbo C program illustrated this
method. We conclude that we can obtain by this method the determinant, by
simple calculations and reducing the rounding errors
","['\nAnghel Drugarin\n', '\nCornelia Victoria\n']",in Romanian,"Algebra liniara. Programare liniara, vol.1, Eftimie Murgu,Press
  Resita (2003). AGIR Press, vol.22, 2012, pp.171-176",http://arxiv.org/abs/1401.7962v1,cs.MS,['cs.MS'],,,[]
"Multivariate sparse interpolation using randomized Kronecker
  substitutions",http://arxiv.org/abs/1401.6694v2,2014-01-26T21:37:51Z,2014-05-02T05:01:05Z,"  We present new techniques for reducing a multivariate sparse polynomial to a
univariate polynomial. The reduction works similarly to the classical and
widely-used Kronecker substitution, except that we choose the degrees randomly
based on the number of nonzero terms in the multivariate polynomial, that is,
its sparsity. The resulting univariate polynomial often has a significantly
lower degree than the Kronecker substitution polynomial, at the expense of a
small number of term collisions. As an application, we give a new algorithm for
multivariate interpolation which uses these new techniques along with any
existing univariate interpolation algorithm.
","['\nAndrew Arnold\n', '\nDaniel S. Roche\n']","21 pages, 2 tables, 1 procedure. Accepted to ISSAC 2014",,http://arxiv.org/abs/1401.6694v2,cs.SC,"['cs.SC', 'cs.DS', 'cs.MS', '68W30', 'F.2.1; G.4; I.1.2']",,,[]
RProtoBuf: Efficient Cross-Language Data Serialization in R,http://arxiv.org/abs/1401.7372v1,2014-01-28T23:57:02Z,2014-01-28T23:57:02Z,"  Modern data collection and analysis pipelines often involve a sophisticated
mix of applications written in general purpose and specialized programming
languages. Many formats commonly used to import and export data between
different programs or systems, such as CSV or JSON, are verbose, inefficient,
not type-safe, or tied to a specific programming language. Protocol Buffers are
a popular method of serializing structured data between applications - while
remaining independent of programming languages or operating systems. They offer
a unique combination of features, performance, and maturity that seems
particularly well suited for data-driven applications and numerical computing.
The RProtoBuf package provides a complete interface to Protocol Buffers from
the R environment for statistical computing. This paper outlines the general
class of data serialization requirements for statistical computing, describes
the implementation of the RProtoBuf package, and illustrates its use with
example applications in large-scale data collection pipelines and web services.
","['\nDirk Eddelbuettel\n', '\nMurray Stokely\n', '\nJeroen Ooms\n']",,,http://dx.doi.org/10.18637/jss.v071.i02,stat.CO,"['stat.CO', 'cs.MS', 'cs.SE']",10.18637/jss.v071.i02,,[]
Increasing precision of uniform pseudorandom number generators,http://arxiv.org/abs/1401.8230v2,2014-01-29T20:20:18Z,2014-05-12T12:45:45Z,"  A general method to produce uniformly distributed pseudorandom numbers with
extended precision by combining two pseudorandom numbers with lower precision
is proposed. In particular, this method can be used for pseudorandom number
generation with extended precision on graphics processing units (GPU), where
the performance of single and double precision operations can vary
significantly.
","['\nVadim Demchik\n', '\nAlexey Gulov\n']","5 pages, 1 figure; additional description of algorithm is applied",,http://arxiv.org/abs/1401.8230v2,cs.MS,"['cs.MS', 'cs.CR', 'cs.DS']",,,[]
"An experimental exploration of Marsaglia's xorshift generators,
  scrambled",http://arxiv.org/abs/1402.6246v5,2014-01-22T19:18:20Z,2016-10-13T06:56:03Z,"  Marsaglia proposed recently xorshift generators as a class of very fast,
good-quality pseudorandom number generators. Subsequent analysis by Panneton
and L'Ecuyer has lowered the expectations raised by Marsaglia's paper, showing
several weaknesses of such generators, verified experimentally using the
TestU01 suite. Nonetheless, many of the weaknesses of xorshift generators fade
away if their result is scrambled by a non-linear operation (as originally
suggested by Marsaglia). In this paper we explore the space of possible
generators obtained by multiplying the result of a xorshift generator by a
suitable constant. We sample generators at 100 equispaced points of their state
space and obtain detailed statistics that lead us to choices of parameters that
improve on the current ones. We then explore for the first time the space of
high-dimensional xorshift generators, following another suggestion in
Marsaglia's paper, finding choices of parameters providing periods of length
$2^{1024} - 1$ and $2^{4096} - 1$. The resulting generators are of extremely
high quality, faster than current similar alternatives, and generate
long-period sequences passing strong statistical tests using only eight logical
operations, one addition and one multiplication by a constant.
",['\nSebastiano Vigna\n'],,,http://arxiv.org/abs/1402.6246v5,cs.DS,"['cs.DS', 'cs.CR', 'cs.MS', 'G.3']",,,[]
"A hierarchically blocked Jacobi SVD algorithm for single and multiple
  graphics processing units",http://arxiv.org/abs/1401.2720v3,2014-01-13T06:12:17Z,2014-09-27T22:51:33Z,"  We present a hierarchically blocked one-sided Jacobi algorithm for the
singular value decomposition (SVD), targeting both single and multiple graphics
processing units (GPUs). The blocking structure reflects the levels of GPU's
memory hierarchy. The algorithm may outperform MAGMA's dgesvd, while retaining
high relative accuracy. To this end, we developed a family of parallel pivot
strategies on GPU's shared address space, but applicable also to inter-GPU
communication. Unlike common hybrid approaches, our algorithm in a single GPU
setting needs a CPU for the controlling purposes only, while utilizing GPU's
resources to the fullest extent permitted by the hardware. When required by the
problem size, the algorithm, in principle, scales to an arbitrary number of GPU
nodes. The scalability is demonstrated by more than twofold speedup for
sufficiently large matrices on a Tesla S2050 system with four GPUs vs. a single
Fermi card.
",['\nVedran Novaković\n'],Accepted for publication in SIAM Journal on Scientific Computing,"SIAM J. Sci. Comput. 37 (2015), C1-C30",http://dx.doi.org/10.1137/140952429,cs.NA,"['cs.NA', 'cs.DC', 'cs.MS', '65Y05 (Primary) 65Y10, 65F15 (Secondary)', 'G.1.0; G.1.3; G.4']",10.1137/140952429,,[]
"Resilience in Numerical Methods: A Position on Fault Models and
  Methodologies",http://arxiv.org/abs/1401.3013v1,2014-01-13T21:18:48Z,2014-01-13T21:18:48Z,"  Future extreme-scale computer systems may expose silent data corruption (SDC)
to applications, in order to save energy or increase performance. However,
resilience research struggles to come up with useful abstract programming
models for reasoning about SDC. Existing work randomly flips bits in running
applications, but this only shows average-case behavior for a low-level,
artificial hardware model. Algorithm developers need to understand worst-case
behavior with the higher-level data types they actually use, in order to make
their algorithms more resilient. Also, we know so little about how SDC may
manifest in future hardware, that it seems premature to draw conclusions about
the average case. We argue instead that numerical algorithms can benefit from a
numerical unreliability fault model, where faults manifest as unbounded
perturbations to floating-point data. Algorithms can use inexpensive ""sanity""
checks that bound or exclude error in the results of computations. Given a
selective reliability programming model that requires reliability only when and
where needed, such checks can make algorithms reliable despite unbounded
faults. Sanity checks, and in general a healthy skepticism about the
correctness of subroutines, are wise even if hardware is perfectly reliable.
","['\nJames Elliott\n', '\nMark Hoemmen\n', '\nFrank Mueller\n']",Position Paper,,http://arxiv.org/abs/1401.3013v1,cs.MS,"['cs.MS', 'cs.ET', 'math.NA']",,,[]
An efficient way to assemble finite element matrices in vector languages,http://arxiv.org/abs/1401.3301v2,2014-01-14T19:36:39Z,2015-06-19T09:17:43Z,"  Efficient Matlab codes in 2D and 3D have been proposed recently to assemble
finite element matrices. In this paper we present simple, compact and efficient
vectorized algorithms, which are variants of these codes, in arbitrary
dimension, without the use of any lower level language. They can be easily
implemented in many vector languages (e.g. Matlab, Octave, Python, Scilab, R,
Julia, C++ with STL,...). The principle of these techniques is general, we
present it for the assembly of several finite element matrices in arbitrary
dimension, in the P1 finite element case. We also provide an extension of the
algorithms to the case of a system of PDE's. Then we give an extension to
piecewise polynomials of higher order. We compare numerically the performance
of these algorithms in Matlab, Octave and Python, with that in FreeFEM++ and in
a compiled language such as C. Examples show that, unlike what is commonly
believed, the performance is not radically worse than that of C : in the
best/worst cases, selected vector languages are respectively 2.3/3.5 and
2.9/4.1 times slower than C in the scalar and vector cases. We also present
numerical results which illustrate the computational costs of these algorithms
compared to standard algorithms and to other recent ones.
","['\nFrançois Cuvelier\n', '\nCaroline Japhet\n', '\nGilles Scarella\n']",,,http://arxiv.org/abs/1401.3301v2,cs.MS,"['cs.MS', 'cs.NA', 'math.NA']",,,[]
MRRR-based Eigensolvers for Multi-core Processors and Supercomputers,http://arxiv.org/abs/1401.4950v1,2014-01-20T15:52:03Z,2014-01-20T15:52:03Z,"  The real symmetric tridiagonal eigenproblem is of outstanding importance in
numerical computations; it arises frequently as part of eigensolvers for
standard and generalized dense Hermitian eigenproblems that are based on a
reduction to tridiagonal form. For its solution, the algorithm of Multiple
Relatively Robust Representations (MRRR or MR3 in short) - introduced in the
late 1990s - is among the fastest methods. To compute k eigenpairs of a real
n-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in
contrast, all the other practical methods require O(k^2 n) or O(n^3) operations
in the worst case. This thesis centers around the performance and accuracy of
MRRR.
","['\nMatthias Petschow\nAICES, RWTH Aachen\n']",PhD thesis,,http://arxiv.org/abs/1401.4950v1,cs.MS,"['cs.MS', 'cs.NA', 'cs.PF', 'math.NA']",,,"['AICES, RWTH Aachen']"
Test Problem Construction for Single-Objective Bilevel Optimization,http://arxiv.org/abs/1401.1942v3,2014-01-09T10:22:26Z,2016-08-16T16:28:15Z,"  In this paper, we propose a procedure for designing controlled test problems
for single-objective bilevel optimization. The construction procedure is
flexible and allows its user to control the different complexities that are to
be included in the test problems independently of each other. In addition to
properties that control the difficulty in convergence, the procedure also
allows the user to introduce difficulties caused by interaction of the two
levels. As a companion to the test problem construction framework, the paper
presents a standard test suite of twelve problems, which includes eight
unconstrained and four constrained problems. Most of the problems are scalable
in terms of variables and constraints. To provide baseline results, we have
solved the proposed test problems using a nested bilevel evolutionary
algorithm. The results can be used for comparison, while evaluating the
performance of any other bilevel optimization algorithm. The codes related to
the paper may be accessed from the website \url{http://bilevel.org}.
","['\nAnkur Sinha\n', '\nPekka Malo\n', '\nKalyanmoy Deb\n']",arXiv admin note: text overlap with arXiv:1303.3901,,http://arxiv.org/abs/1401.1942v3,cs.MS,['cs.MS'],,,[]
"A Study of Successive Over-relaxation Method Parallelization Over Modern
  HPC Languages",http://arxiv.org/abs/1401.0763v1,2014-01-04T01:31:48Z,2014-01-04T01:31:48Z,"  Successive over-relaxation (SOR) is a computationally intensive, yet
extremely important iterative solver for solving linear systems. Due to recent
trends of exponential growth in amount of data generated and increasing problem
sizes, serial platforms have proved to be insufficient in providing the
required computational power. In this paper, we present parallel
implementations of red-black SOR method using three modern programming
languages namely Chapel, D and Go. We employ SOR method for solving 2D
steady-state heat conduction problem. We discuss the optimizations incorporated
and the features of these languages which are crucial for improving the program
performance. Experiments have been performed using 2, 4, and 8 threads and
performance results are compared with serial execution. The analysis of results
provides important insights into working of SOR method.
",['\nSparsh Mittal\n'],,,http://arxiv.org/abs/1401.0763v1,cs.DC,"['cs.DC', 'cs.MS']",,,[]
Program Verification of Numerical Computation,http://arxiv.org/abs/1401.1290v1,2014-01-07T07:07:49Z,2014-01-07T07:07:49Z,"  These notes outline a formal method for program verification of numerical
computation. It forms the basis of the software package VPC in its initial
phase of development. Much of the style of presentation is in the form of notes
that outline the definitions and rules upon which VPC is based. The initial
motivation of this project was to address some practical issues of computation,
especially of numerically intensive programs that are commonplace in computer
models. The project evolved into a wider area for program construction as
proofs leading to a model of inference in a more general sense. Some basic
results of machine arithmetic are derived as a demonstration of VPC.
",['\nGarry Pantelis\n'],,,http://arxiv.org/abs/1401.1290v1,cs.MS,"['cs.MS', 'cs.SE', '03Fxx', 'F.4.1; F.3.1']",,,[]
"Interaction entre mathématique et informatique Libre/Open Source par
  le logiciel mathématique",http://arxiv.org/abs/1401.0827v1,2014-01-04T16:42:05Z,2014-01-04T16:42:05Z,"  This article focuses on the application of model development and opening the
source code available and implemented by the Free Software and Open Source
FLOSS to the instructional and teaching has both mathematics and computer by
the read-write(R/W) of mathematical software, including the most famous cases
are numerical and symbolic computation. The article analysis the development of
the mathematical model of Free/Open Source(math FLOSS) software has proven its
importance in the area of research in mathematics and computer science .
However, although their actual use, is very readable in higher education
courses. We discuss the feasibility of this model to the characteristics of the
domain, actors, interaction they have and the communities they form during the
development of the software. Finally, we propose a mathematical example of
Free/Open Source(Math FlOSS) software as analysis device .
",['\nK. I. A. Derouiche\n'],"11 pages, written in French, In Proceedings of the S\'eminaire
  National sur la didactique des Math\'ematiques, 25-26 Novembre Tebessa,
  Alg\'erie (SNDM'13). 2013",,http://arxiv.org/abs/1401.0827v1,cs.MS,"['cs.MS', 'cs.CY', 'math.HO']",,,[]
DDscat.C++ User and programmer guide,http://arxiv.org/abs/1405.3630v1,2013-12-20T10:29:47Z,2013-12-20T10:29:47Z,"  DDscat.C++ 7.3.0 is a freely available open-source C++ software package
applying the ""discrete dipole approximation"" (DDA) to calculate scattering and
absorption of electromagnetic waves by targets with arbitrary geometries and a
complex refractive index. DDscat.C++ is a clone of well known DDscat Fortran-90
software. We refer to DDscat as to the parent code in this document. Versions
7.3.0 of both codes have the identical functionality but the quite different
implementation. Started as a teaching project, the DDscat.C++ code differs from
the parent code DDscat in programming techniques and features, essential for
C++ but quite seldom in Fortran.
  As DDscat.C++ in its current version is just a clone, usage of DDscat.C++ for
electromagnetic calculations is the same as of DDscat. Please, refer to ""User
Guide for the Discrete Dipole Approximation Code DDSCAT 7.3"" to start using the
code(s).
  This document consists of two parts. In the first part we present Quick start
guide for users who want to begin to use the code. Only differencies between
DDscat.C++ and DDscat are explained. The second part of the document explains
programming tips for the persons who want to change the code, to add the
functionality or help the author with code refactoring and debugging.
",['\nVasyl Choliy\n'],"26 pages, 7 figures",,http://arxiv.org/abs/1405.3630v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",,,[]
Large-Scale Paralleled Sparse Principal Component Analysis,http://arxiv.org/abs/1312.6182v1,2013-12-21T00:38:02Z,2013-12-21T00:38:02Z,"  Principal component analysis (PCA) is a statistical technique commonly used
in multivariate data analysis. However, PCA can be difficult to interpret and
explain since the principal components (PCs) are linear combinations of the
original variables. Sparse PCA (SPCA) aims to balance statistical fidelity and
interpretability by approximating sparse PCs whose projections capture the
maximal variance of original data. In this paper we present an efficient and
paralleled method of SPCA using graphics processing units (GPUs), which can
process large blocks of data in parallel. Specifically, we construct parallel
implementations of the four optimization formulations of the generalized power
method of SPCA (GP-SPCA), one of the most efficient and effective SPCA
approaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS)
is up to eleven times faster than the corresponding CPU implementation (using
CBLAS), and up to 107 times faster than a MatLab implementation. Extensive
comparative experiments in several real-world datasets confirm that SPCA offers
a practical advantage.
","['\nW. Liu\n', '\nH. Zhang\n', '\nD. Tao\n', '\nY. Wang\n', '\nK. Lu\n']",submitted to Multimedia Tools and Applications,,http://arxiv.org/abs/1312.6182v1,cs.MS,"['cs.MS', 'cs.LG', 'cs.NA', 'stat.ML']",,,[]
"Early Observations on Performance of Google Compute Engine for
  Scientific Computing",http://arxiv.org/abs/1312.6488v1,2013-12-23T09:12:09Z,2013-12-23T09:12:09Z,"  Although Cloud computing emerged for business applications in industry,
public Cloud services have been widely accepted and encouraged for scientific
computing in academia. The recently available Google Compute Engine (GCE) is
claimed to support high-performance and computationally intensive tasks, while
little evaluation studies can be found to reveal GCE's scientific capabilities.
Considering that fundamental performance benchmarking is the strategy of
early-stage evaluation of new Cloud services, we followed the Cloud Evaluation
Experiment Methodology (CEEM) to benchmark GCE and also compare it with Amazon
EC2, to help understand the elementary capability of GCE for dealing with
scientific problems. The experimental results and analyses show both potential
advantages of, and possible threats to applying GCE to scientific computing.
For example, compared to Amazon's EC2 service, GCE may better suit applications
that require frequent disk operations, while it may not be ready yet for single
VM-based parallel computing. Following the same evaluation methodology,
different evaluators can replicate and/or supplement this fundamental
evaluation of GCE. Based on the fundamental evaluation results, suitable GCE
environments can be further established for case studies of solving real
science problems.
","['\nZheng Li\n', ""\nLiam O'Brien\n"", '\nRajiv Ranjan\n', '\nMiranda Zhang\n']","Proceedings of the 5th International Conference on Cloud Computing
  Technologies and Science (CloudCom 2013), pp. 1-8, Bristol, UK, December 2-5,
  2013",,http://dx.doi.org/10.1109/CloudCom.2013.7,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA']",10.1109/CloudCom.2013.7,,[]
Efficient Random-Walk Methods for Approximating Polytope Volume,http://arxiv.org/abs/1312.2873v2,2013-12-10T16:58:04Z,2014-03-29T11:37:07Z,"  We experimentally study the fundamental problem of computing the volume of a
convex polytope given as an intersection of linear inequalities. We implement
and evaluate practical randomized algorithms for accurately approximating the
polytope's volume in high dimensions (e.g. one hundred). To carry out this
efficiently we experimentally correlate the effect of parameters, such as
random walk length and number of sample points, on accuracy and runtime.
Moreover, we exploit the problem's geometry by implementing an iterative
rounding procedure, computing partial generations of random points and
designing fast polytope boundary oracles. Our publicly available code is
significantly faster than exact computation and more accurate than existing
approximation methods. We provide volume approximations for the Birkhoff
polytopes B_11,...,B_15, whereas exact methods have only computed that of B_10.
","['\nIoannis Z. Emiris\n', '\nVissarion Fisikopoulos\n']","15 pages, 2 figures, 8 tables, in Proc. of SoCG'14",ACM Transactions on Mathematical Software 2018,http://dx.doi.org/10.1145/3194656,cs.CG,"['cs.CG', 'cs.MS']",10.1145/3194656,,[]
"Misfortunes of a mathematicians' trio using Computer Algebra Systems:
  Can we trust?",http://arxiv.org/abs/1312.3270v2,2013-12-11T18:25:46Z,2013-12-16T00:02:00Z,"  Computer algebra systems are a great help for mathematical research but
sometimes unexpected errors in the software can also badly affect it. As an
example, we show how we have detected an error of Mathematica computing
determinants of matrices of integer numbers: not only it computes the
determinants wrongly, but also it produces different results if one evaluates
the same determinant twice.
","['\nAntonio J. Durán\n', '\nMario Pérez\n', '\nJuan L. Varona\n']",4 pages,"Notices Amer. Math. Soc. 61 (2014), 1249-1252",http://arxiv.org/abs/1312.3270v2,cs.SC,"['cs.SC', 'cs.MS', '68W30']",,,[]
Silent error detection in numerical time-stepping schemes,http://arxiv.org/abs/1312.2674v1,2013-12-10T05:31:23Z,2013-12-10T05:31:23Z,"  Errors due to hardware or low level software problems, if detected, can be
fixed by various schemes, such as recomputation from a checkpoint. Silent
errors are errors in application state that have escaped low-level error
detection. At extreme scale, where machines can perform astronomically many
operations per second, silent errors threaten the validity of computed results.
  We propose a new paradigm for detecting silent errors at the application
level. Our central idea is to frequently compare computed values to those
provided by a cheap checking computation, and to build error detectors based on
the difference between the two output sequences. Numerical analysis provides us
with usable checking computations for the solution of initial-value problems in
ODEs and PDEs, arguably the most common problems in computational science.
Here, we provide, optimize, and test methods based on Runge-Kutta and linear
multistep methods for ODEs, and on implicit and explicit finite difference
schemes for PDEs. We take the heat equation and Navier-Stokes equations as
examples. In tests with artificially injected errors, this approach effectively
detects almost all meaningful errors, without significant slowdown.
","['\nAustin R. Benson\n', '\nSven Schmit\n', '\nRobert Schreiber\n']",,"The International Journal of High Performance Computing
  Applications, 29(4), 2015",http://dx.doi.org/10.1177/1094342014532297,cs.NA,"['cs.NA', 'cs.MS', 'math.NA']",10.1177/1094342014532297,,[]
Sparse Allreduce: Efficient Scalable Communication for Power-Law Data,http://arxiv.org/abs/1312.3020v1,2013-12-11T02:33:45Z,2013-12-11T02:33:45Z,"  Many large datasets exhibit power-law statistics: The web graph, social
networks, text data, click through data etc. Their adjacency graphs are termed
natural graphs, and are known to be difficult to partition. As a consequence
most distributed algorithms on these graphs are communication intensive. Many
algorithms on natural graphs involve an Allreduce: a sum or average of
partitioned data which is then shared back to the cluster nodes. Examples
include PageRank, spectral partitioning, and many machine learning algorithms
including regression, factor (topic) models, and clustering. In this paper we
describe an efficient and scalable Allreduce primitive for power-law data. We
point out scaling problems with existing butterfly and round-robin networks for
Sparse Allreduce, and show that a hybrid approach improves on both.
Furthermore, we show that Sparse Allreduce stages should be nested instead of
cascaded (as in the dense case). And that the optimum throughput Allreduce
network should be a butterfly of heterogeneous degree where degree decreases
with depth into the network. Finally, a simple replication scheme is introduced
to deal with node failures. We present experiments showing significant
improvements over existing systems such as PowerGraph and Hadoop.
","['\nHuasha Zhao\n', '\nJohn Canny\n']",,,http://arxiv.org/abs/1312.3020v1,cs.DC,"['cs.DC', 'cs.AI', 'cs.MS']",,,[]
Radix Conversion for IEEE754-2008 Mixed Radix Floating-Point Arithmetic,http://arxiv.org/abs/1312.0455v1,2013-12-02T13:47:14Z,2013-12-02T13:47:14Z,"  Conversion between binary and decimal floating-point representations is
ubiquitous. Floating-point radix conversion means converting both the exponent
and the mantissa. We develop an atomic operation for FP radix conversion with
simple straight-line algorithm, suitable for hardware design. Exponent
conversion is performed with a small multiplication and a lookup table. It
yields the correct result without error. Mantissa conversion uses a few
multiplications and a small lookup table that is shared amongst all types of
conversions. The accuracy changes by adjusting the computing precision.
","['\nO. Kupriianova\n', '\nCh. Lauter\n', '\nJ. -M. Muller\n']",,,http://dx.doi.org/10.1109/ACSSC.2013.6810471,cs.MS,['cs.MS'],10.1109/ACSSC.2013.6810471,,[]
"MEIGO: an open-source software suite based on metaheuristics for global
  optimization in systems biology and bioinformatics",http://arxiv.org/abs/1311.5735v1,2013-11-22T12:39:29Z,2013-11-22T12:39:29Z,"  Optimization is key to solve many problems in computational biology. Global
optimization methods provide a robust methodology, and metaheuristics in
particular have proven to be the most efficient methods for many applications.
Despite their utility, there is limited availability of metaheuristic tools. We
present MEIGO, an R and Matlab optimization toolbox (also available in Python
via a wrapper of the R version), that implements metaheuristics capable of
solving diverse problems arising in systems biology and bioinformatics:
enhanced scatter search method (eSS) for continuous nonlinear programming
(cNLP) and mixed-integer programming (MINLP) problems, and variable
neighborhood search (VNS) for Integer Programming (IP) problems. Both methods
can be run on a single-thread or in parallel using a cooperative strategy. The
code is supplied under GPLv3 and is available at
\url{http://www.iim.csic.es/~gingproc/meigo.html}. Documentation and examples
are included. The R package has been submitted to Bioconductor. We evaluate
MEIGO against optimization benchmarks, and illustrate its applicability to a
series of case studies in bioinformatics and systems biology, outperforming
other state-of-the-art methods. MEIGO provides a free, open-source platform for
optimization, that can be applied to multiple domains of systems biology and
bioinformatics. It includes efficient state of the art metaheuristics, and its
open and modular structure allows the addition of further methods.
","['\nJose A Egea\n', '\nDavid Henriques\n', '\nThomas Cokelaer\n', '\nAlejandro F Villaverde\n', '\nJulio R Banga\n', '\nJulio Saez-Rodriguez\n']","12 pages, 7 figures, 1 table",,http://arxiv.org/abs/1311.5735v1,math.OC,"['math.OC', 'cs.CE', 'cs.MS', 'q-bio.QM']",,,[]
"A Study of Speed of the Boundary Element Method as applied to the
  Realtime Computational Simulation of Biological Organs",http://arxiv.org/abs/1311.4533v3,2013-11-18T20:54:26Z,2014-01-14T18:28:10Z,"  In this work, possibility of simulating biological organs in realtime using
the Boundary Element Method (BEM) is investigated. Biological organs are
assumed to follow linear elastostatic material behavior, and constant boundary
element is the element type used. First, a Graphics Processing Unit (GPU) is
used to speed up the BEM computations to achieve the realtime performance.
Next, instead of the GPU, a computer cluster is used. Results indicate that BEM
is fast enough to provide for realtime graphics if biological organs are
assumed to follow linear elastostatic material behavior. Although the present
work does not conduct any simulation using nonlinear material models, results
from using the linear elastostatic material model imply that it would be
difficult to obtain realtime performance if highly nonlinear material models
that properly characterize biological organs are used. Although the use of BEM
for the simulation of biological organs is not new, the results presented in
the present study are not found elsewhere in the literature.
",['\nKirana Kumara P\n'],"preprint, draft, 2 tables, 47 references, 7 files, Codes that can
  solve three dimensional linear elastostatic problems using constant boundary
  elements (of triangular shape) while ignoring body forces are provided as
  supplementary files; codes are distributed under the MIT License in three
  versions: i) MATLAB version ii) Fortran 90 version (sequential code) iii)
  Fortran 90 version (parallel code)","Electronic Journal of Boundary Elements, Vol. 12, No. 2, pp. 1-25
  (2014)",http://arxiv.org/abs/1311.4533v3,cs.CE,"['cs.CE', 'cs.DC', 'cs.MS', 'physics.comp-ph', 'physics.med-ph']",,,[]
GooFit: A library for massively parallelising maximum-likelihood fits,http://arxiv.org/abs/1311.1753v1,2013-11-07T17:18:42Z,2013-11-07T17:18:42Z,"  Fitting complicated models to large datasets is a bottleneck of many
analyses. We present GooFit, a library and tool for constructing
arbitrarily-complex probability density functions (PDFs) to be evaluated on
nVidia GPUs or on multicore CPUs using OpenMP. The massive parallelisation of
dividing up event calculations between hundreds of processors can achieve
speedups of factors 200-300 in real-world problems.
","['\nR. Andreassen\n', '\nB. T. Meadows\n', '\nM. de Silva\n', '\nM. D. Sokoloff\n', '\nK. Tomko\n']",Presented at the CHEP 2013 conference,,http://dx.doi.org/10.1088/1742-6596/513/5/052003,cs.DC,"['cs.DC', 'cs.MS']",10.1088/1742-6596/513/5/052003,,[]
Lattice Simulations using OpenACC compilers,http://arxiv.org/abs/1311.2719v1,2013-11-12T09:12:54Z,2013-11-12T09:12:54Z,"  OpenACC compilers allow one to use Graphics Processing Units without having
to write explicit CUDA codes. Programs can be modified incrementally using
OpenMP like directives which causes the compiler to generate CUDA kernels to be
run on the GPUs. In this article we look at the performance gain in lattice
simulations with dynamical fermions using OpenACC compilers.
",['\nPushan Majumdar\n'],"7 pages, 1 figure, presented at the 31st International Symposium on
  Lattice Field Theory (Lattice 2013), 29 July - 3 August 2013, Mainz, Germany",,http://arxiv.org/abs/1311.2719v1,hep-lat,"['hep-lat', 'cs.MS', 'physics.comp-ph']",,,[]
Computation of the Marcum Q-function,http://arxiv.org/abs/1311.0681v1,2013-11-04T12:50:09Z,2013-11-04T12:50:09Z,"  Methods and an algorithm for computing the generalized Marcum $Q-$function
($Q_{\mu}(x,y)$) and the complementary function ($P_{\mu}(x,y)$) are described.
These functions appear in problems of different technical and scientific areas
such as, for example, radar detection and communications, statistics and
probability theory, where they are called the non-central chi-square or the non
central gamma cumulative distribution functions.
  The algorithm for computing the Marcum functions combines different methods
of evaluation in different regions: series expansions, integral
representations, asymptotic expansions, and use of three-term homogeneous
recurrence relations. A relative accuracy close to $10^{-12}$ can be obtained
in the parameter region $(x,y,\mu) \in [0,\,A]\times [0,\,A]\times [1,\,A]$,
$A=200$, while for larger parameters the accuracy decreases (close to
$10^{-11}$ for $A=1000$ and close to $5\times 10^{-11}$ for $A=10000$).
","['\nA. Gil\n', '\nJ. Segura\n', '\nN. M. Temme\n']",Accepted for publication in ACM Trans. Math. Softw,,http://arxiv.org/abs/1311.0681v1,cs.MS,"['cs.MS', 'math.CA']",,,[]
"Composing and Factoring Generalized Green's Operators and Ordinary
  Boundary Problems",http://arxiv.org/abs/1310.8455v1,2013-10-31T10:56:22Z,2013-10-31T10:56:22Z,"  We consider solution operators of linear ordinary boundary problems with ""too
many"" boundary conditions, which are not always solvable. These generalized
Green's operators are a certain kind of generalized inverses of differential
operators. We answer the question when the product of two generalized Green's
operators is again a generalized Green's operator for the product of the
corresponding differential operators and which boundary problem it solves.
Moreover, we show that---provided a factorization of the underlying
differential operator---a generalized boundary problem can be factored into
lower order problems corresponding to a factorization of the respective Green's
operators. We illustrate our results by examples using the Maple package
IntDiffOp, where the presented algorithms are implemented.
","['\nAnja Korporal\n', '\nGeorg Regensburger\n']",19 pages,"AADIOS 2012, LNCS 8372, pp. 116-134, 2014",http://dx.doi.org/10.1007/978-3-642-54479-8_5,cs.SC,"['cs.SC', 'cs.MS', 'cs.NA', 'math.CA', '68W30 (Primary), 34B05, 15A09 (Secondary)']",10.1007/978-3-642-54479-8_5,,[]
SOSTOOLS Version 4.00 Sum of Squares Optimization Toolbox for MATLAB,http://arxiv.org/abs/1310.4716v2,2013-10-17T14:30:42Z,2021-12-27T23:37:26Z,"  The release of SOSTOOLS v4.00 comes as we approach the 20th anniversary of
the original release of SOSTOOLS v1.00 back in April, 2002. SOSTOOLS was
originally envisioned as a flexible tool for parsing and solving polynomial
optimization problems, using the SOS tightening of polynomial positivity
constraints, and capable of adapting to the ever-evolving fauna of applications
of SOS. There are now a variety of SOS programming parsers beyond SOSTOOLS,
including YALMIP, Gloptipoly, SumOfSquares, and others. We hope SOSTOOLS
remains the most intuitive, robust and adaptable toolbox for SOS programming.
Recent progress in Semidefinite programming has opened up new possibilities for
solving large Sum of Squares programming problems, and we hope the next decade
will be one where SOS methods will find wide application in different areas.
  In SOSTOOLS v4.00, we implement a parsing approach that reduces the
computational and memory requirements of the parser below that of the SDP
solver itself. We have re-developed the internal structure of our polynomial
decision variables. Specifically, polynomial and SOS variable declarations made
using sossosvar, sospolyvar, sosmatrixvar, etc now return a new polynomial
structure, dpvar. This new polynomial structure, is documented in the enclosed
dpvar guide, and isolates the scalar SDP decision variables in the SOS program
from the independent variables used to construct the SOS program. As a result,
the complexity of the parser scales almost linearly in the number of decision
variables. As a result of these changes, almost all users will notice a
significant increase in speed, with large-scaleproblems experiencing the most
dramatic speedups. Parsing time is now always less than 10% of time spent in
the SDP solver. Finally, SOSTOOLS now provides support for the MOSEK solver
interface as well as the SeDuMi, SDPT3, CSDP, SDPNAL, SDPNAL+, and SDPA
solvers.
","['\nAntonis Papachristodoulou\n', '\nJames Anderson\n', '\nGiorgio Valmorbida\n', '\nStephen Prajna\n', '\nPete Seiler\n', '\nPablo Parrilo\n', '\nMatthew M. Peet\n', '\nDeclan Jagt\n']","64 pages, 3 figures, ""software available from
  http://sysos.eng.ox.ac.uk/sostools/ """,,http://arxiv.org/abs/1310.4716v2,math.OC,"['math.OC', 'cs.MS', 'cs.SY']",,,[]
SymbolicData:SDEval - Benchmarking for Everyone,http://arxiv.org/abs/1310.5551v1,2013-10-18T19:58:03Z,2013-10-18T19:58:03Z,"  In this paper we will present SDeval, a software project that contains tools
for creating and running benchmarks with a focus on problems in computer
algebra. It is built on top of the Symbolic Data project, able to translate
problems in the database into executable code for various computer algebra
systems. The included tools are designed to be very flexible to use and to
extend, such that they can be utilized even in contexts of other communities.
With the presentation of SDEval, we will also address particularities of
benchmarking in the field of computer algebra. Furthermore, with SDEval, we
provide a feasible and automatizable way of reproducing benchmarks published in
current research works, which appears to be a difficult task in general due to
the customizability of the available programs. We will simultaneously present
the current developments in the Symbolic Data project.
","['\nAlbert Heinle\n', '\nViktor Levandovskyy\n', '\nAndreas Nareike\n']",,,http://arxiv.org/abs/1310.5551v1,cs.SC,"['cs.SC', 'cs.MS', 'cs.SE']",,,[]
Numerical integration on GPUs for higher order finite elements,http://arxiv.org/abs/1310.1191v1,2013-10-04T07:50:02Z,2013-10-04T07:50:02Z,"  The paper considers the problem of implementation on graphics processors of
numerical integration routines for higher order finite element approximations.
The design of suitable GPU kernels is investigated in the context of general
purpose integration procedures, as well as particular example applications. The
most important characteristic of the problem investigated is the large
variation of required processor and memory resources associated with different
degrees of approximating polynomials. The questions that we try to answer are
whether it is possible to design a single integration kernel for different GPUs
and different orders of approximation and what performance can be expected in
such a case.
","['\nKrzysztof Banaś\n', '\nPrzemysław Płaszewski\n', '\nPaweł Macioł\n']",,"Computers and Mathematics with Applications, Volume 67, Issue 6,
  April 2014, Pages 1319-1344",http://dx.doi.org/10.1016/j.camwa.2014.01.021,cs.MS,['cs.MS'],10.1016/j.camwa.2014.01.021,,[]
"Vectorized OpenCL implementation of numerical integration for higher
  order finite elements",http://arxiv.org/abs/1310.1194v1,2013-10-04T08:08:04Z,2013-10-04T08:08:04Z,"  In our work we analyze computational aspects of the problem of numerical
integration in finite element calculations and consider an OpenCL
implementation of related algorithms for processors with wide vector registers.
  As a platform for testing the implementation we choose the PowerXCell
processor, being an example of the Cell Broadband Engine (CellBE) architecture.
Although the processor is considered old for today's standards (its design
dates back to year 2001), we investigate its performance due to two features
that it shares with recent Xeon Phi family of coprocessors: wide vector units
and relatively slow connection of computing cores with main global memory. The
performed analysis of parallelization options can also be used for designing
numerical integration algorithms for other processors with vector registers,
such as contemporary x86 microprocessors.
","['\nFilip Krużel\n', '\nKrzysztof Banaś\n']","published online in Computers and Mathematics with Applications:
  http://www.sciencedirect.com/science/article/pii/S089812211300521X","Computers & Mathematics with Applications, Volume 66, Issue 10,
  December 2013, Pages 2030-2044",http://dx.doi.org/10.1016/j.camwa.2013.08.026,cs.MS,['cs.MS'],10.1016/j.camwa.2013.08.026,,[]
Bertini for Macaulay2,http://arxiv.org/abs/1310.3297v1,2013-10-11T21:17:59Z,2013-10-11T21:17:59Z,"  Numerical algebraic geometry is the field of computational mathematics
concerning the numerical solution of polynomial systems of equations. Bertini,
a popular software package for computational applications of this field,
includes implementations of a variety of algorithms based on polynomial
homotopy continuation. The Macaulay2 package Bertini.m2 provides an interface
to Bertini, making it possible to access the core run modes of Bertini in
Macaulay2. With these run modes, users can find approximate solutions to
zero-dimensional systems and positive-dimensional systems, test numerically
whether a point lies on a variety, sample numerically from a variety, and
perform parameter homotopy runs.
","['\nDaniel J. Bates\n', '\nElizabeth Gross\n', '\nAnton Leykin\n', '\nJose Israel Rodriguez\n']",,,http://arxiv.org/abs/1310.3297v1,math.AG,"['math.AG', 'cs.MS', '65H10']",,,[]
MizAR 40 for Mizar 40,http://arxiv.org/abs/1310.2805v1,2013-10-10T13:24:07Z,2013-10-10T13:24:07Z,"  As a present to Mizar on its 40th anniversary, we develop an AI/ATP system
that in 30 seconds of real time on a 14-CPU machine automatically proves 40% of
the theorems in the latest official version of the Mizar Mathematical Library
(MML). This is a considerable improvement over previous performance of large-
theory AI/ATP methods measured on the whole MML. To achieve that, a large suite
of AI/ATP methods is employed and further developed. We implement the most
useful methods efficiently, to scale them to the 150000 formulas in MML. This
reduces the training times over the corpus to 1-3 seconds, allowing a simple
practical deployment of the methods in the online automated reasoning service
for the Mizar users (MizAR).
","['\nCezary Kaliszyk\n', '\nJosef Urban\n']",,J. Automated Reasoning 55(3): 245-256 (2015),http://dx.doi.org/10.1007/s10817-015-9330-8,cs.AI,"['cs.AI', 'cs.DL', 'cs.LG', 'cs.LO', 'cs.MS']",10.1007/s10817-015-9330-8,,[]
Modernizing PHCpack through phcpy,http://arxiv.org/abs/1310.0056v2,2013-09-30T21:05:03Z,2014-04-29T15:00:39Z,"  PHCpack is a large software package for solving systems of polynomial
equations. The executable phc is menu driven and file oriented. This paper
describes the development of phcpy, a Python interface to PHCpack. Instead of
navigating through menus, users of phcpy solve systems in the Python shell or
via scripts. Persistent objects replace intermediate files.
",['\nJan Verschelde\n'],"Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)",,http://arxiv.org/abs/1310.0056v2,cs.MS,"['cs.MS', 'cs.SC', 'math.AG', 'math.NA']",,,[]
High Precision Arithmetic for Scientific Applications,http://arxiv.org/abs/1309.5498v1,2013-09-21T16:45:13Z,2013-09-21T16:45:13Z,"  All but a few digital computers used for scientific computations have
supported floating-point and digital arithmetic of rather limited numerical
precision. The underlying assumptions were that the systems being studied were
basically deterministic and of limited complexity. The ideal scientific
paradigm was the orbits of the major planets, which could be observed with high
precision, predicted for thousands of years into the future, and extrapolated
for thousands of years into the past. Much the same technology that has made
computers possible has also provided instrumentation that has vastly expanded
the scope and precision of scientific analysis. Complex nonlinear systems
exhibiting so-called chaotic dynamics are now fair game for scientists and
engineers in every discipline. Today it seems that computers need to enhance
the precision of their numerical computations to support the needs of science.
However, there is no need to wait for the necessary updates in both hardware
and software; it is easy enough to monitor numerical precision with a few minor
modifications to existing software.
",['\nFoster Morrison\n'],"8 pages, 1 figure",,http://arxiv.org/abs/1309.5498v1,cs.MS,['cs.MS'],,,[]
"Higher-order Reverse Automatic Differentiation with emphasis on the
  third-order",http://arxiv.org/abs/1309.5479v1,2013-09-21T14:00:40Z,2013-09-21T14:00:40Z,"  It is commonly assumed that calculating third order information is too
expensive for most applications. But we show that the directional derivative of
the Hessian ($D^3f(x)\cdot d$) can be calculated at a cost proportional to that
of a state-of-the-art method for calculating the Hessian matrix. We do this by
first presenting a simple procedure for designing high order reverse methods
and applying it to deduce several methods including a reverse method that
calculates $D^3f(x)\cdot d$. We have implemented this method taking into
account symmetry and sparsity, and successfully calculated this derivative for
functions with a million variables. These results indicate that the use of
third order information in a general nonlinear solver, such as Halley-Chebyshev
methods, could be a practical alternative to Newton's method.
","['\nRobert M. Gower\n', '\nArtur L. Gower\n']",,,http://dx.doi.org/10.1007/s10107-014-0827-4,cs.MS,"['cs.MS', 'cs.SC', 'math.OC']",10.1007/s10107-014-0827-4,,[]
HOL(y)Hammer: Online ATP Service for HOL Light,http://arxiv.org/abs/1309.4962v1,2013-09-19T13:22:31Z,2013-09-19T13:22:31Z,"  HOL(y)Hammer is an online AI/ATP service for formal (computer-understandable)
mathematics encoded in the HOL Light system. The service allows its users to
upload and automatically process an arbitrary formal development (project)
based on HOL Light, and to attack arbitrary conjectures that use the concepts
defined in some of the uploaded projects. For that, the service uses several
automated reasoning systems combined with several premise selection methods
trained on all the project proofs. The projects that are readily available on
the server for such query answering include the recent versions of the
Flyspeck, Multivariate Analysis and Complex Analysis libraries. The service
runs on a 48-CPU server, currently employing in parallel for each task 7 AI/ATP
combinations and 4 decision procedures that contribute to its overall
performance. The system is also available for local installation by interested
users, who can customize it for their own proof development. An Emacs interface
allowing parallel asynchronous queries to the service is also provided. The
overall structure of the service is outlined, problems that arise and their
solutions are discussed, and an initial account of using the system is given.
","['\nCezary Kaliszyk\n', '\nJosef Urban\n']",,,http://arxiv.org/abs/1309.4962v1,cs.AI,"['cs.AI', 'cs.DL', 'cs.LG', 'cs.LO', 'cs.MS']",,,[]
"API design for machine learning software: experiences from the
  scikit-learn project",http://arxiv.org/abs/1309.0238v1,2013-09-01T16:22:48Z,2013-09-01T16:22:48Z,"  Scikit-learn is an increasingly popular machine learning li- brary. Written
in Python, it is designed to be simple and efficient, accessible to
non-experts, and reusable in various contexts. In this paper, we present and
discuss our design choices for the application programming interface (API) of
the project. In particular, we describe the simple and elegant interface shared
by all learning and processing units in the library and then discuss its
advantages in terms of composition and reusability. The paper also comments on
implementation details specific to the Python ecosystem and analyzes obstacles
faced by users and developers of the library.
","['\nLars Buitinck\nILPS\n', '\nGilles Louppe\nINRIA Saclay - Ile de France\n', '\nMathieu Blondel\nINRIA Saclay - Ile de France\n', '\nFabian Pedregosa\nINRIA Saclay - Ile de France\n', '\nAndreas Mueller\nINRIA Saclay - Ile de France, LTCI\n', '\nOlivier Grisel\nINRIA Saclay - Ile de France, LTCI\n', '\nVlad Niculae\nINRIA Saclay - Ile de France, LTCI\n', '\nPeter Prettenhofer\nINRIA Saclay - Ile de France, LTCI\n', '\nAlexandre Gramfort\nINRIA Saclay - Ile de France, LTCI\n', '\nJaques Grobler\nINRIA Saclay - Ile de France\n', '\nRobert Layton\nINRIA Saclay - Ile de France\n', '\nJake Vanderplas\nINRIA Saclay - Ile de France\n', '\nArnaud Joly\nINRIA Saclay - Ile de France\n', '\nBrian Holt\nINRIA Saclay - Ile de France\n', '\nGaël Varoquaux\nINRIA Saclay - Ile de France\n']",,"European Conference on Machine Learning and Principles and
  Practices of Knowledge Discovery in Databases (2013)",http://arxiv.org/abs/1309.0238v1,cs.LG,"['cs.LG', 'cs.MS']",,,"['ILPS', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France, LTCI', 'INRIA Saclay - Ile de France, LTCI', 'INRIA Saclay - Ile de France, LTCI', 'INRIA Saclay - Ile de France, LTCI', 'INRIA Saclay - Ile de France, LTCI', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France', 'INRIA Saclay - Ile de France']"
"Experiences with Automated Build and Test for Geodynamics Simulation
  Codes",http://arxiv.org/abs/1309.1199v1,2013-09-04T22:22:52Z,2013-09-04T22:22:52Z,"  The Computational Infrastructure for Geodynamics (CIG) is an NSF funded
project that develops, supports, and disseminates community-accessible software
for the geodynamics research community. CIG software supports a variety of
computational geodynamic research from mantle and core dynamics, to crustal and
earthquake dynamics, to magma migration and seismology. To support this type of
project a backend computational infrastructure is necessary.
  Part of this backend infrastructure is an automated build and testing system
to ensure codes and changes to them are compatible with multiple platforms and
that the changes do not significantly affect the scientific results. In this
paper we describe the build and test infrastructure for CIG based on the BaTLab
system, how it is organized, and how it assists in operations. We demonstrate
the use of this type of testing for a suite of geophysics codes, show why codes
may compile on one platform but not on another, and demonstrate how minor
changes may alter the computed results in unexpected ways that can influence
the scientific interpretation. Finally, we examine result comparison between
platforms and show how the compiler or operating system may affect results.
","['\nEric M. Heien\n', '\nTodd L. Miller\n', '\nBecky Gietzel\n', '\nLouise H. Kellogg\n']",,,http://arxiv.org/abs/1309.1199v1,cs.CE,"['cs.CE', 'cs.MS']",,,[]
Achieving High Performance with Unified Residual Evaluation,http://arxiv.org/abs/1309.1204v2,2013-09-04T23:03:33Z,2013-09-06T19:35:43Z,"  We examine residual evaluation, perhaps the most basic operation in numerical
simulation. By raising the level of abstraction in this operation, we can
eliminate specialized code, enable optimization, and greatly increase the
extensibility of existing code.
","['\nMatthew G. Knepley\n', '\nJed Brown\n', '\nKarl Rupp\n', '\nBarry F. Smith\n']","4 pages, 1 figure",,http://arxiv.org/abs/1309.1204v2,cs.MS,"['cs.MS', 'cs.CE']",,,[]
"DUNE as an Example of Sustainable Open Source Scientific Software
  Development",http://arxiv.org/abs/1309.1783v2,2013-09-06T21:55:23Z,2013-09-15T19:56:50Z,"  In this paper we describe how DUNE, an open source scientific software
framework, is developed. Having a sustainable software framework for the
solution of partial differential equations is the main driver of DUNE's
development. We take a look how DUNE strives to stay sustainable software.
",['\nMakus Blatt\n'],,,http://arxiv.org/abs/1309.1783v2,cs.MS,"['cs.MS', 'cs.SE', 'D.2.9; K.6.1; K.6.3']",,,[]
"Advanced Techniques for Scientific Programming and Collaborative
  Development of Open Source Software Packages at the International Centre for
  Theoretical Physics (ICTP)",http://arxiv.org/abs/1309.5377v1,2013-09-06T15:07:47Z,2013-09-06T15:07:47Z,"  A large number of computational scientific research projects make use of open
source software packages. However, the development process of such tools
frequently differs from conventional software development; partly because of
the nature of research, where the problems being addressed are not always fully
understood; partly because the majority of the development is often carried out
by scientists with limited experience and exposure to best practices of
software engineering. Often the software development suffers from the pressure
to publish scientific results and that credit for software development is
limited in comparison. Fundamental components of software engineering like
modular and reusable design, validation, documentation, and software
integration as well as effective maintenance and user support tend to be
disregarded due to lack of resources and qualified specialists. Thus innovative
developments are often hindered by steep learning curves required to master
development for legacy software packages full of ad hoc solutions. The growing
complexity of research, however, requires suitable and maintainable
computational tools, resulting in a widening gap between the potential users
(often growing in number) and contributors to the development of such a
package. In this paper we share our experiences aiming to improve the situation
by training particularly young scientists, through disseminating our own
experiences at contributing to open source software packages and practicing key
components of software engineering adapted for scientists and scientific
software development. Specifically we summarize the outcome of the Workshop in
Advanced Techniques for Scientific Programming and Collaborative Development of
Open Source Software Packages run at the Abdus Salam International Centre for
Theoretical Physics in March 2013, and discuss our conclusions for future
efforts.
","['\nIvan Girotto\n', '\nAxel Kohlmeyer\n', '\nDavid Grellscheid\n', '\nShawn T. Brown\n']",,,http://arxiv.org/abs/1309.5377v1,cs.SE,"['cs.SE', 'cs.MS']",,,[]
BayesOpt: A Library for Bayesian optimization with Robotics Applications,http://arxiv.org/abs/1309.0671v1,2013-09-03T13:38:05Z,2013-09-03T13:38:05Z,"  The purpose of this paper is twofold. On one side, we present a general
framework for Bayesian optimization and we compare it with some related fields
in active learning and Bayesian numerical analysis. On the other hand, Bayesian
optimization and related problems (bandits, sequential experimental design) are
highly dependent on the surrogate model that is selected. However, there is no
clear standard in the literature. Thus, we present a fast and flexible toolbox
that allows to test and combine different models and criteria with little
effort. It includes most of the state-of-the-art contributions, algorithms and
models. Its speed also removes part of the stigma that Bayesian optimization
methods are only good for ""expensive functions"". The software is free and it
can be used in many operating systems and computer languages.
",['\nRuben Martinez-Cantin\n'],"Robotics: Science and Systems, Workshop on Active Learning in
  Robotics: Exploration, Curiosity, and Interaction","Journal of Machine Learning Research, 15(Nov), 3915-3919, 2014",http://arxiv.org/abs/1309.0671v1,cs.RO,"['cs.RO', 'cs.AI', 'cs.LG', 'cs.MS']",,,[]
"Software Abstractions and Methodologies for HPC Simulation Codes on
  Future Architectures",http://arxiv.org/abs/1309.1780v1,2013-09-06T21:41:20Z,2013-09-06T21:41:20Z,"  Large, complex, multi-scale, multi-physics simulation codes, running on high
performance com-puting (HPC) platforms, have become essential to advancing
science and engineering. These codes simulate multi-scale, multi-physics
phenomena with unprecedented fidelity on petascale platforms, and are used by
large communities. Continued ability of these codes to run on future platforms
is as crucial to their communities as continued improvements in instruments and
facilities are to experimental scientists. However, the ability of code
developers to do these things faces a serious challenge with the paradigm shift
underway in platform architecture. The complexity and uncertainty of the future
platforms makes it essential to approach this challenge cooperatively as a
community. We need to develop common abstractions, frameworks, programming
models and software development methodologies that can be applied across a
broad range of complex simulation codes, and common software infrastructure to
support them. In this position paper we express and discuss our belief that
such an infrastructure is critical to the deployment of existing and new large,
multi-scale, multi-physics codes on future HPC platforms.
","['\nA. Dubey\n', '\nS. Brandt\n', '\nR. Brower\n', '\nM. Giles\n', '\nP. Hovland\n', '\nD. Q. Lamb\n', '\nF. Loffler\n', '\nB. Norris\n', '\nB. OShea\n', '\nC. Rebbi\n', '\nM. Snir\n', '\nR. Thakur\n']",Position Paper,,http://dx.doi.org/10.5334/jors.aw,cs.CE,"['cs.CE', 'cs.MS', 'cs.SE']",10.5334/jors.aw,,[]
"Experiences from Software Engineering of Large Scale AMR Multiphysics
  Code Frameworks",http://arxiv.org/abs/1309.1781v1,2013-09-06T21:48:39Z,2013-09-06T21:48:39Z,"  Among the present generation of multiphysics HPC simulation codes there are
many that are built upon general infrastructural frameworks. This is especially
true of the codes that make use of structured adaptive mesh refinement (SAMR)
because of unique demands placed on the housekeeping aspects of the code. They
have varying degrees of abstractions between the infrastructure such as mesh
management and IO and the numerics of the physics solvers. In this experience
report we summarize the experiences and lessons learned from two of such major
software efforts, FLASH and Chombo.
","['\nA. Dubey\n', '\nB. Van Straalen\n']",Experience Report,,http://dx.doi.org/10.5334/jors.am,cs.CE,"['cs.CE', 'cs.MS', 'cs.SE']",10.5334/jors.am,,[]
Cactus: Issues for Sustainable Simulation Software,http://arxiv.org/abs/1309.1812v2,2013-09-07T03:18:51Z,2013-09-16T01:33:06Z,"  The Cactus Framework is an open-source, modular, portable programming
environment for the collaborative development and deployment of scientific
applications using high-performance computing. Its roots reach back to 1996 at
the National Center for Supercomputer Applications and the Albert Einstein
Institute in Germany, where its development jumpstarted. Since then, the Cactus
framework has witnessed major changes in hardware infrastructure as well as its
own community. This paper describes its endurance through these past changes
and, drawing upon lessons from its past, also discusses future
","['\nFrank Löffler\n', '\nSteven R. Brandt\n', '\nGabrielle Allen\n', '\nErik Schnetter\n']","submitted to the Workshop on Sustainable Software for Science:
  Practice and Experiences 2013",,http://arxiv.org/abs/1309.1812v2,cs.CE,"['cs.CE', 'cs.MS', 'cs.SE']",,,[]
Branch Cuts in Maple 17,http://arxiv.org/abs/1308.6523v1,2013-08-29T17:06:18Z,2013-08-29T17:06:18Z,"  Accurate and comprehensible knowledge about the position of branch cuts is
essential for correctly working with multi-valued functions, such as the square
root and logarithm. We discuss the new tools in Maple 17 for calculating and
visualising the branch cuts of such functions, and others built up from them.
The cuts are described in an intuitive and accurate form, offering substantial
improvement on the descriptions previously available.
","['\nM. England\n', '\nE. Cheb-Terrab\n', '\nR. Bradford\n', '\nJ. H. Davenport\n', '\nD. Wilson\n']",,"ACM Communications in Computer Algebra 48:1 pp. 24-27, ACM, 2014",http://dx.doi.org/10.1145/2644288.2644293,cs.SC,"['cs.SC', 'cs.MS', 'I.1.1, G.4', 'I.1.1; I.1.2; G.4']",10.1145/2644288.2644293,,[]
"Manopt, a Matlab toolbox for optimization on manifolds",http://arxiv.org/abs/1308.5200v1,2013-08-23T18:35:59Z,2013-08-23T18:35:59Z,"  Optimization on manifolds is a rapidly developing branch of nonlinear
optimization. Its focus is on problems where the smooth geometry of the search
space can be leveraged to design efficient numerical algorithms. In particular,
optimization on manifolds is well-suited to deal with rank and orthogonality
constraints. Such structured constraints appear pervasively in machine learning
applications, including low-rank matrix completion, sensor network
localization, camera network registration, independent component analysis,
metric learning, dimensionality reduction and so on. The Manopt toolbox,
available at www.manopt.org, is a user-friendly, documented piece of software
dedicated to simplify experimenting with state of the art Riemannian
optimization algorithms. We aim particularly at reaching practitioners outside
our field.
","['\nNicolas Boumal\n', '\nBamdev Mishra\n', '\nP. -A. Absil\n', '\nRodolphe Sepulchre\n']",,"The Journal of Machine Learning Research, 15(1), 1455-1459 (2014)",http://arxiv.org/abs/1308.5200v1,cs.MS,"['cs.MS', 'cs.LG', 'math.OC', 'stat.ML']",,,[]
"A Domain Decomposition Approach to Implementing Fault Slip in
  Finite-Element Models of Quasi-static and Dynamic Crustal Deformation",http://arxiv.org/abs/1308.5846v1,2013-08-27T12:46:37Z,2013-08-27T12:46:37Z,"  We employ a domain decomposition approach with Lagrange multipliers to
implement fault slip in a finite-element code, PyLith, for use in both
quasi-static and dynamic crustal deformation applications. This integrated
approach to solving both quasi-static and dynamic simulations leverages common
finite-element data structures and implementations of various boundary
conditions, discretization schemes, and bulk and fault rheologies. We have
developed a custom preconditioner for the Lagrange multiplier portion of the
system of equations that provides excellent scalability with problem size
compared to conventional additive Schwarz methods. We demonstrate application
of this approach using benchmarks for both quasi-static viscoelastic
deformation and dynamic spontaneous rupture propagation that verify the
numerical implementation in PyLith.
","['\nBrad T. Aagaard\n', '\nMatthew G. Knepley\n', '\nCharles A. Williams\n']","14 pages, 15 figures","Journal of Geophysical Research, 118(6), pp.3059-3079, 2013",http://dx.doi.org/10.1002/jgrb.50217,physics.geo-ph,"['physics.geo-ph', 'cs.CE', 'cs.MS']",10.1002/jgrb.50217,,[]
"Algorithm 950: Ncpol2sdpa---Sparse Semidefinite Programming Relaxations
  for Polynomial Optimization Problems of Noncommuting Variables",http://arxiv.org/abs/1308.6029v3,2013-08-28T02:14:20Z,2015-06-12T08:35:08Z,"  A hierarchy of semidefinite programming (SDP) relaxations approximates the
global optimum of polynomial optimization problems of noncommuting variables.
Generating the relaxation, however, is a computationally demanding task, and
only problems of commuting variables have efficient generators. We develop an
implementation for problems of noncommuting problems that creates the
relaxation to be solved by SDPA -- a high-performance solver that runs in a
distributed environment. We further exploit the inherent sparsity of
optimization problems in quantum physics to reduce the complexity of the
resulting relaxations. Constrained problems with a relaxation of order two may
contain up to a hundred variables. The implementation is available in Python.
The tool helps solve problems such as finding the ground state energy or
testing quantum correlations.
",['\nPeter Wittek\n'],"17 pages, 3 figures, 1 table, 2 algorithms, the algorithm is
  available at http://peterwittek.github.io/ncpol2sdpa/","ACM Transactions on Mathematical Software, 2015, 41(3), 21",http://dx.doi.org/10.1145/2699464,cs.MS,"['cs.MS', 'math.OC', 'physics.comp-ph', 'quant-ph', 'G.4']",10.1145/2699464,,[]
xTras: a field-theory inspired xAct package for Mathematica,http://arxiv.org/abs/1308.3493v1,2013-08-15T20:00:02Z,2013-08-15T20:00:02Z,"  We present the tensor computer algebra package xTras, which provides
functions and methods frequently needed when doing (classical) field theory.
Amongst others, it can compute contractions, make Ans\""atze, and solve
tensorial equations. It is built upon the tensor computer algebra system xAct,
a collection of packages for Mathematica.
",['\nTeake Nutma\n'],"29 pages. The package can be downloaded from
  http://www.xact.es/xtras/",Comput. Phys. Commun. 185 (2014) 1719-1738,http://dx.doi.org/10.1016/j.cpc.2014.02.006,cs.SC,"['cs.SC', 'cs.MS', 'gr-qc', 'hep-th']",10.1016/j.cpc.2014.02.006,,[]
"ForestClaw: Hybrid forest-of-octrees AMR for hyperbolic conservation
  laws",http://arxiv.org/abs/1308.1472v1,2013-08-07T04:15:42Z,2013-08-07T04:15:42Z,"  We present a new hybrid paradigm for parallel adaptive mesh refinement (AMR)
that combines the scalability and lightweight architecture of tree-based AMR
with the computational efficiency of patch-based solvers for hyperbolic
conservation laws. The key idea is to interpret each leaf of the AMR hierarchy
as one uniform compute patch in $\sR^d$ with $m^d$ degrees of freedom, where
$m$ is customarily between 8 and 32. Thus, computation on each patch can be
optimized for speed, while we inherit the flexibility of adaptive meshes. In
our work we choose to integrate with the p4est AMR library since it allows us
to compose the mesh from multiple mapped octrees and enables the cubed sphere
and other nontrivial multiblock geometries. We describe aspects of the parallel
implementation and close with scalings for both MPI-only and OpenMP/MPI hybrid
runs, where the largest MPI run executes on 16,384 CPU cores.
","['\nCarsten Burstedde\n', '\nDonna Calhoun\n', '\nKyle Mandli\n', '\nAndy R. Terrel\n']","submitted to International Conference on Parallel Computing -
  ParCo2013",Adv. Par. Comp. 25 (2014) 253-262,http://dx.doi.org/10.3233/978-1-61499-381-0-253,cs.MS,"['cs.MS', 'G.4; G.1.8; D.1.3']",10.3233/978-1-61499-381-0-253,,[]
"ManyClaw: Slicing and dicing Riemann solvers for next generation highly
  parallel architectures",http://arxiv.org/abs/1308.1464v1,2013-08-07T02:24:20Z,2013-08-07T02:24:20Z,"  Next generation computer architectures will include order of magnitude more
intra-node parallelism; however, many application programmers have a difficult
time keeping their codes current with the state-of-the-art machines. In this
context, we analyze Hyperbolic PDE solvers, which are used in the solution of
many important applications in science and engineering. We present ManyClaw, a
project intended to explore the exploitation of intra-node parallelism in
hyperbolic PDE solvers via the Clawpack software package for solving hyperbolic
PDEs. Our goal is to separate the low level parallelism and the physical
equations thus providing users the capability to leverage intra-node
parallelism without explicitly writing code to take advantage of newer
architectures.
","['\nAndy R. Terrel\n', '\nKyle T. Mandli\n']",TACC-Intel Symposium on Highly Parallel Architectures. 2012,,http://arxiv.org/abs/1308.1464v1,cs.CE,"['cs.CE', 'cs.MS', 'C.1.4; D.1.3; G.1.8']",,,[]
"A Parallel Algorithm for Calculation of Large Determinants with High
  Accuracy for GPUs and MPI clusters",http://arxiv.org/abs/1308.1536v2,2013-08-07T11:24:07Z,2013-08-08T11:06:59Z,"  We present a parallel algorithm for calculating very large determinants with
arbitrary precision on computer clusters. This algorithm minimises data
movements between the nodes and computes not only the determinant but also all
minors corresponding to a particular row or column at a little extra cost, and
also the determinants and minors of all submatrices in the top left corner at
no extra cost. We implemented the algorithm in arbitrary precision arithmetic,
suitable for very ill conditioned matrices, and empirically estimated the loss
of precision. The algorithm was applied to studies of Riemann's zeta function.
","['\nGleb Beliakov\n', '\nYuri Matiyasevich\n']",,,http://dx.doi.org/10.1007/s10543-015-0547-z,cs.DC,"['cs.DC', 'cs.MS', 'cs.NA', 'math.NA', 'math.NT', '65F40, 68W10, 11M26', 'D.1.3; G.1.0; G.1.3']",10.1007/s10543-015-0547-z,,[]
"RNGSSELIB: Program library for random number generation. More
  generators, parallel streams of random numbers and Fortran compatibility",http://arxiv.org/abs/1307.5866v1,2013-07-22T20:15:34Z,2013-07-22T20:15:34Z,"  In this update, we present the new version of the random number generator
(RNG) library RNGSSELIB, which, in particular, contains fast SSE realizations
of a number of modern and most reliable generators \cite{RNGSSELIB1}. The new
features are: i) Fortran compatibility and examples of using the library in
Fortran; ii) new modern and reliable generators; iii) the abilities to jump
ahead inside RNG sequence and to initialize up to $10^{19}$ independent random
number streams with block splitting method.
","['\nL. Yu. Barash\n', '\nL. N. Shchur\n']","6 pages, 1 table",Computer Physics Communications 184 (2013) pp. 2367-2369,http://dx.doi.org/10.1016/j.cpc.2013.04.007,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1016/j.cpc.2013.04.007,,[]
"PRAND: GPU accelerated parallel random number generation library: Using
  most reliable algorithms and applying parallelism of modern GPUs and CPUs",http://arxiv.org/abs/1307.5869v2,2013-07-22T20:21:20Z,2014-02-17T16:01:53Z,"  The library PRAND for pseudorandom number generation for modern CPUs and GPUs
is presented. It contains both single-threaded and multi-threaded realizations
of a number of modern and most reliable generators recently proposed and
studied in [1,2,3,4,5] and the efficient SIMD realizations proposed in [6]. One
of the useful features for using PRAND in parallel simulations is the ability
to initialize up to $10^{19}$ independent streams. Using massive parallelism of
modern GPUs and SIMD parallelism of modern CPUs substantially improves
performance of the generators.
","['\nL. Yu. Barash\n', '\nL. N. Shchur\n']","29 pages, 1 figure, 7 tables",Computer Physics Communications 185 (2014) 1343-1353,http://dx.doi.org/10.1016/j.cpc.2014.01.007,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1016/j.cpc.2014.01.007,,[]
"A unified sparse matrix data format for efficient general sparse
  matrix-vector multiply on modern processors with wide SIMD units",http://arxiv.org/abs/1307.6209v2,2013-07-23T12:50:28Z,2014-03-05T14:54:58Z,"  Sparse matrix-vector multiplication (spMVM) is the most time-consuming kernel
in many numerical algorithms and has been studied extensively on all modern
processor and accelerator architectures. However, the optimal sparse matrix
data storage format is highly hardware-specific, which could become an obstacle
when using heterogeneous systems. Also, it is as yet unclear how the wide
single instruction multiple data (SIMD) units in current multi- and many-core
processors should be used most efficiently if there is no structure in the
sparsity pattern of the matrix. We suggest SELL-C-sigma, a variant of Sliced
ELLPACK, as a SIMD-friendly data format which combines long-standing ideas from
General Purpose Graphics Processing Units (GPGPUs) and vector computer
programming. We discuss the advantages of SELL-C-sigma compared to established
formats like Compressed Row Storage (CRS) and ELLPACK and show its suitability
on a variety of hardware platforms (Intel Sandy Bridge, Intel Xeon Phi and
Nvidia Tesla K20) for a wide range of test matrices from different application
areas. Using appropriate performance models we develop deep insight into the
data transfer properties of the SELL-C-sigma spMVM kernel. SELL-C-sigma comes
with two tuning parameters whose performance impact across the range of test
matrices is studied and for which reasonable choices are proposed. This leads
to a hardware-independent (""catch-all"") sparse matrix format, which achieves
very high efficiency for all test matrices across all hardware platforms.
","['\nMoritz Kreutzer\n', '\nGeorg Hager\n', '\nGerhard Wellein\n', '\nHolger Fehske\n', '\nAlan R. Bishop\n']","23 pages, 7 figures, 6 listings","SIAM Journal on Scientific Computing 2014 36:5, C401-C423",http://dx.doi.org/10.1137/130930352,cs.MS,"['cs.MS', 'cs.DC']",10.1137/130930352,,[]
Python for education: permutations,http://arxiv.org/abs/1307.7042v1,2013-07-26T14:18:21Z,2013-07-26T14:18:21Z,"  Python implementation of permutations is presented. Three classes are
introduced: Perm for permutations, Group for permutation groups, and PermError
to report any errors for both classes. The class Perm is based on Python
dictionaries and utilize cycle notation. The methods of calculation for the
perm order, parity, ranking and unranking are given. A random permutation
generation is also shown. The class Group is very simple and it is also based
on dictionaries. It is mainly the presentation of the permutation groups
interface with methods for the group order, subgroups (normalizer, centralizer,
center, stabilizer), orbits, and several tests. The corresponding Python code
is contained in the modules perms and groups.
",['\nAndrzej Kapanowski\n'],"26 pages, 1 figure, 2 tables","The Python Papers 9, 3 (2014)",http://arxiv.org/abs/1307.7042v1,cs.MS,"['cs.MS', 'math.HO']",,,[]
"From Physics Model to Results: An Optimizing Framework for
  Cross-Architecture Code Generation",http://arxiv.org/abs/1307.6488v1,2013-07-24T16:52:44Z,2013-07-24T16:52:44Z,"  Starting from a high-level problem description in terms of partial
differential equations using abstract tensor notation, the Chemora framework
discretizes, optimizes, and generates complete high performance codes for a
wide range of compute architectures. Chemora extends the capabilities of
Cactus, facilitating the usage of large-scale CPU/GPU systems in an efficient
manner for complex applications, without low-level code tuning. Chemora
achieves parallelism through MPI and multi-threading, combining OpenMP and
CUDA. Optimizations include high-level code transformations, efficient loop
traversal strategies, dynamically selected data and instruction cache usage
strategies, and JIT compilation of GPU code tailored to the problem
characteristics. The discretization is based on higher-order finite differences
on multi-block domains. Chemora's capabilities are demonstrated by simulations
of black hole collisions. This problem provides an acid test of the framework,
as the Einstein equations contain hundreds of variables and thousands of terms.
","['\nMarek Blazewicz\nPoznań Supercomputing and Networking Center\nPoznań University of Technology\n', '\nIan Hinder\nAlbert Einstein Institute\n', '\nDavid M. Koppelman\nCenter for Computation and Technology, LSU\nDivision of Electrical Computer Engineering, LSU\n', '\nSteven R. Brandt\nCenter for Computation and Technology, LSU\nDivision of Computer Science, LSU\n', '\nMilosz Ciznicki\nPoznań Supercomputing and Networking Center\n', '\nMichal Kierzynka\nPoznań Supercomputing and Networking Center\nPoznań University of Technology\n', '\nFrank Löffler\nCenter for Computation and Technology, LSU\n', '\nErik Schnetter\nPerimeter Institute for Theoretical Physics\nDepartment of Physics, University of Guelph\nCenter for Computation and Technology, LSU\n', '\nJian Tao\nCenter for Computation and Technology, LSU\n']","18 pages, 4 figures, accepted for publication in Scientific
  Programming",,http://dx.doi.org/10.3233/SPR-130360,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'gr-qc']",10.3233/SPR-130360,,"['Poznań Supercomputing and Networking Center', 'Poznań University of Technology', 'Albert Einstein Institute', 'Center for Computation and Technology, LSU', 'Division of Electrical Computer Engineering, LSU', 'Center for Computation and Technology, LSU', 'Division of Computer Science, LSU', 'Poznań Supercomputing and Networking Center', 'Poznań Supercomputing and Networking Center', 'Poznań University of Technology', 'Center for Computation and Technology, LSU', 'Perimeter Institute for Theoretical Physics', 'Department of Physics, University of Guelph', 'Center for Computation and Technology, LSU', 'Center for Computation and Technology, LSU']"
"Supporting 64-bit global indices in Epetra and other Trilinos packages
  -- Techniques used and lessons learned",http://arxiv.org/abs/1307.6638v1,2013-07-25T06:52:00Z,2013-07-25T06:52:00Z,"  The Trilinos Project is an effort to facilitate the design, development,
integration and ongoing support of mathematical software libraries within an
object-oriented framework. It is intended for large-scale, complex multiphysics
engineering and scientific applications. Epetra is one of its basic packages.
It provides serial and parallel linear algebra capabilities. Before Trilinos
version 11.0, released in 2012, Epetra used the C++ int data-type for storing
global and local indices for degrees of freedom (DOFs). Since int is typically
32-bit, this limited the largest problem size to be smaller than approximately
two billion DOFs. This was true even if a distributed memory machine could
handle larger problems. We have added optional support for C++ long long
data-type, which is at least 64-bit wide, for global indices. To save memory,
maintain the speed of memory-bound operations, and reduce further changes to
the code, the local indices are still 32-bit. We document the changes required
to achieve this feature and how the new functionality can be used. We also
report on the lessons learned in modifying a mature and popular package from
various perspectives -- design goals, backward compatibility, engineering
decisions, C++ language features, effects on existing users and other packages,
and build integration.
","['\nChetan Jhurani\n', '\nTravis M. Austin\n', '\nMichael A. Heroux\n', '\nJames M. Willenbring\n']",,,http://arxiv.org/abs/1307.6638v1,cs.MS,"['cs.MS', 'cs.DC', 'cs.SE']",,,[]
"The Declaratron, semantic specification for scientific computation using
  MathML",http://arxiv.org/abs/1307.3088v1,2013-07-11T12:35:11Z,2013-07-11T12:35:11Z,"  We introduce the Declaratron, a system which takes a declarative approach to
specifying mathematically based scientific computation. This uses displayable
mathematical notation (Content MathML) and is both executable and semantically
well defined. We combine domain specific representations of physical science
(e.g. CML, Chemical Markup Language), MathML formulae and computational
specifications (DeXML) to create executable documents which include scientific
data and mathematical formulae. These documents preserve the provenance of the
data used, and build tight semantic links between components of mathematical
formulae and domain objects---in effect grounding the mathematical semantics in
the scientific domain. The Declaratron takes these specifications and i)
carries out entity resolution and decoration to prepare for computation ii)
uses a MathML execution engine to run calculations over the revised tree iii)
outputs domain objects and the complete document to give both results and an
encapsulated history of the computation. A short description of a case study is
given to illustrate how the system can be used. Many scientific problems
require frequent change of the mathematical functional form and the Declaratron
provides this without requiring changes to code. Additionally, it supports
reproducible science, machine indexing and semantic search of computations,
makes implicit assumptions visible, and separates domain knowledge from
computational techniques. We believe that the Declaratron could replace much
conventional procedural code in science.
","['\nDave Murray-Rust\n', '\nPeter Murray-Rust\n']",Conference on Intelligent Computer Mathematics WiP,,http://arxiv.org/abs/1307.3088v1,cs.MS,['cs.MS'],,,[]
"Towards an Efficient Use of the BLAS Library for Multilinear Tensor
  Contractions",http://arxiv.org/abs/1307.2100v1,2013-07-08T14:12:46Z,2013-07-08T14:12:46Z,"  Mathematical operators whose transformation rules constitute the building
blocks of a multi-linear algebra are widely used in physics and engineering
applications where they are very often represented as tensors. In the last
century, thanks to the advances in tensor calculus, it was possible to uncover
new research fields and make remarkable progress in the existing ones, from
electromagnetism to the dynamics of fluids and from the mechanics of rigid
bodies to quantum mechanics of many atoms. By now, the formal mathematical and
geometrical properties of tensors are well defined and understood; conversely,
in the context of scientific and high-performance computing, many tensor-
related problems are still open. In this paper, we address the problem of
efficiently computing contractions among two tensors of arbitrary dimension by
using kernels from the highly optimized BLAS library. In particular, we
establish precise conditions to determine if and when GEMM, the kernel for
matrix products, can be used. Such conditions take into consideration both the
nature of the operation and the storage scheme of the tensors, and induce a
classification of the contractions into three groups. For each group, we
provide a recipe to guide the users towards the most effective use of BLAS.
","['\nEdoardo Di Napoli\nJülich Supercomputing Centre, Forschungszentrum Jülich\nAICES, RWTH-Aachen University\n', '\nDiego Fabregat-Traver\nAICES, RWTH-Aachen University\n', '\nGregorio Quintana-Ortì\nDepto. de Ingenierìa y Ciencia de Computadores, Universidad Jaume I\n', '\nPaolo Bientinesi\nAICES, RWTH-Aachen University\n']","27 Pages, 7 figures and additional tikz generated diagrams. Submitted
  to Applied Mathematics and Computation",,http://arxiv.org/abs/1307.2100v1,cs.MS,"['cs.MS', 'cs.DM']",,,"['Jülich Supercomputing Centre, Forschungszentrum Jülich', 'AICES, RWTH-Aachen University', 'AICES, RWTH-Aachen University', 'Depto. de Ingenierìa y Ciencia de Computadores, Universidad Jaume I', 'AICES, RWTH-Aachen University']"
PROOFTOOL: a GUI for the GAPT Framework,http://arxiv.org/abs/1307.1942v1,2013-07-08T04:41:18Z,2013-07-08T04:41:18Z,"  This paper introduces PROOFTOOL, the graphical user interface for the General
Architecture for Proof Theory (GAPT) framework. Its features are described with
a focus not only on the visualization but also on the analysis and
transformation of proofs and related tree-like structures, and its
implementation is explained. Finally, PROOFTOOL is compared with three other
graphical interfaces for proofs.
","['\nCvetan Dunchev\nInstitute of Computer Languages\n', '\nAlexander Leitsch\nInstitute of Computer Languages\n', '\nTomer Libal\nInstitute of Computer Languages\n', '\nMartin Riener\nInstitute of Computer Languages\n', '\nMikheil Rukhaia\nInstitute of Computer Languages\n', '\nDaniel Weller\nInstitute of Discrete Mathematics and Geometry\n', '\nBruno Woltzenlogel-Paleo\nInstitute of Computer Languages\n']","In Proceedings UITP 2012, arXiv:1307.1528","EPTCS 118, 2013, pp. 1-14",http://dx.doi.org/10.4204/EPTCS.118.1,cs.LO,"['cs.LO', 'cs.HC', 'cs.MS', 'F.4.1; I.2.3']",10.4204/EPTCS.118.1,,"['Institute of Computer Languages', 'Institute of Computer Languages', 'Institute of Computer Languages', 'Institute of Computer Languages', 'Institute of Computer Languages', 'Institute of Discrete Mathematics and Geometry', 'Institute of Computer Languages']"
"Theorema 2.0: A Graphical User Interface for a Mathematical Assistant
  System",http://arxiv.org/abs/1307.1945v1,2013-07-08T04:42:02Z,2013-07-08T04:42:02Z,"  Theorema 2.0 stands for a re-design including a complete re-implementation of
the Theorema system, which was originally designed, developed, and implemented
by Bruno Buchberger and his Theorema group at RISC. In this paper, we present
the first prototype of a graphical user interface (GUI) for the new system. It
heavily relies on powerful interactive capabilities introduced in recent
releases of the underlying Mathematica system, most importantly the possibility
of having dynamic objects connected to interface elements like sliders, menus,
check-boxes, radio-buttons and the like. All these features are fully
integrated into the Mathematica programming environment and allow the
implementation of a modern user interface.
","['\nWolfgang Windsteiger\nRISC, JKU Linz, Austria\n']","In Proceedings UITP 2012, arXiv:1307.1528","EPTCS 118, 2013, pp. 72-82",http://dx.doi.org/10.4204/EPTCS.118.5,cs.MS,"['cs.MS', 'cs.HC', 'cs.SC']",10.4204/EPTCS.118.5,,"['RISC, JKU Linz, Austria']"
"Acceleration of univariate global optimization algorithms working with
  Lipschitz functions and Lipschitz first derivatives",http://arxiv.org/abs/1307.3522v1,2013-07-12T17:31:45Z,2013-07-12T17:31:45Z,"  This paper deals with two kinds of the one-dimensional global optimization
problems over a closed finite interval: (i) the objective function $f(x)$
satisfies the Lipschitz condition with a constant $L$; (ii) the first
derivative of $f(x)$ satisfies the Lipschitz condition with a constant $M$. In
the paper, six algorithms are presented for the case (i) and six algorithms for
the case (ii). In both cases, auxiliary functions are constructed and
adaptively improved during the search. In the case (i), piece-wise linear
functions are constructed and in the case (ii) smooth piece-wise quadratic
functions are used. The constants $L$ and $M$ either are taken as values known
a priori or are dynamically estimated during the search. A recent technique
that adaptively estimates the local Lipschitz constants over different zones of
the search region is used to accelerate the search. A new technique called the
\emph{local improvement} is introduced in order to accelerate the search in
both cases (i) and (ii). The algorithms are described in a unique framework,
their properties are studied from a general viewpoint, and convergence
conditions of the proposed algorithms are given. Numerical experiments executed
on 120 test problems taken from the literature show quite a promising
performance of the new accelerating techniques.
","['\nDaniela Lera\n', '\nYaroslav D. Sergeyev\n']","21 pages,5 figures, 6 tables","SIAM Journal on Optimization, (2013), 23(1), 508-529",http://dx.doi.org/10.1137/110859129,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'math.NA', '90C26, 65K05']",10.1137/110859129,,[]
"Solving ordinary differential equations on the Infinity Computer by
  working with infinitesimals numerically",http://arxiv.org/abs/1307.3529v1,2013-07-12T17:56:23Z,2013-07-12T17:56:23Z,"  There exists a huge number of numerical methods that iteratively construct
approximations to the solution $y(x)$ of an ordinary differential equation
(ODE) $y'(x)=f(x,y)$ starting from an initial value $y_0=y(x_0)$ and using a
finite approximation step $h$ that influences the accuracy of the obtained
approximation. In this paper, a new framework for solving ODEs is presented for
a new kind of a computer -- the Infinity Computer (it has been patented and its
working prototype exists). The new computer is able to work numerically with
finite, infinite, and infinitesimal numbers giving so the possibility to use
different infinitesimals numerically and, in particular, to take advantage of
infinitesimal values of $h$. To show the potential of the new framework a
number of results is established. It is proved that the Infinity Computer is
able to calculate derivatives of the solution $y(x)$ and to reconstruct its
Taylor expansion of a desired order numerically without finding the respective
derivatives analytically (or symbolically) by the successive derivation of the
ODE as it is usually done when the Taylor method is applied. Methods using
approximations of derivatives obtained thanks to infinitesimals are discussed
and a technique for an automatic control of rounding errors is introduced.
Numerical examples are given.
",['\nYaroslav D. Sergeyev\n'],"25 pages, 1 figure, 3 tables","Applied Mathematics and Computation, (2013), 219(22), 10668-10681",http://arxiv.org/abs/1307.3529v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65L05, 65D25, 65G50']",,,[]
"Lipschitz gradients for global optimization in a one-point-based
  partitioning scheme",http://arxiv.org/abs/1307.4302v1,2013-07-15T13:59:30Z,2013-07-15T13:59:30Z,"  A global optimization problem is studied where the objective function $f(x)$
is a multidimensional black-box function and its gradient $f'(x)$ satisfies the
Lipschitz condition over a hyperinterval with an unknown Lipschitz constant
$K$. Different methods for solving this problem by using an a priori given
estimate of $K$, its adaptive estimates, and adaptive estimates of local
Lipschitz constants are known in the literature. Recently, the authors have
proposed a one-dimensional algorithm working with multiple estimates of the
Lipschitz constant for $f'(x)$ (the existence of such an algorithm was a
challenge for 15 years). In this paper, a new multidimensional geometric method
evolving the ideas of this one-dimensional scheme and using an efficient
one-point-based partitioning strategy is proposed. Numerical experiments
executed on 800 multidimensional test functions demonstrate quite a promising
performance in comparison with popular DIRECT-based methods.
","['\nDmitri E. Kvasov\n', '\nYaroslav D. Sergeyev\n']","25 pages, 4 figures, 5 tables. arXiv admin note: text overlap with
  arXiv:1103.2056","Journal of Computational and Applied Mathematics Volume 236, Issue
  16, October 2012, Pages 4042-4054",http://dx.doi.org/10.1016/j.cam.2012.02.020,math.OC,"['math.OC', 'cs.MS', 'cs.NA', 'math.NA', '65K05, 90C26, 90C56']",10.1016/j.cam.2012.02.020,,[]
"Building Bricks with Bricks, with Mathematica",http://arxiv.org/abs/1307.1343v1,2013-07-04T14:21:49Z,2013-07-04T14:21:49Z,"  In this work we solve a special case of the problem of building an
n-dimensional parallelepiped using a given set of n-dimensional
parallelepipeds. Consider the identity x^3 = x(x-1)(x-2)+3x(x-1+x). For
sufficiently large x, we associate with x^3 a cube with edges of size x, with
x(x-1)(x-2) a parallelepiped with edges x, x-1, x-2, with 3x(x-1+x) three
parallelepipeds of edges x, x-1, 1, and with x a parallelepiped of edges x, 1,
1. The problem we takle is the actual construction of the cube using the given
parallelepipeds. In [DDNP90] it was shown how to solve this specific problem
and all similar instances in which a (monic) polynomial is expressed as a
linear combination of a persistent basis. That is to say a sequence of
polynomials q_0 = 1, and q_k(x) = q_{k-1}(x)(x-r_k) for k > 0. Here, after
[Fil10], we deal with a multivariate version of the problem with respect to a
basis of polynomials of the same degree (binomial basis). We show that it is
possible to build the parallelepiped associated with a multivariate polynomial
P(x_1, ..., x_n)=(x_1- s_1)...(x_n-s_n) with integer roots, using the
parallelepipeds described by the elements of the basis. We provide an algorithm
in Mathematica to solve the problem for each n. Moreover, for n = 2, 3, 4 (in
the latter case, only when a projection is possible) we use Mathematica to
display a step by step construction of the parallelepiped P(x1,...,x_n).
","['\nPietro Codara\n', ""\nOttavio M. D'Antona\n"", '\nDaniele Filaretti\n']",,"Mathematica Italia User Group Meeting (UGM) 2011, ISBN
  9788896810026. (2011)",http://arxiv.org/abs/1307.1343v1,cs.MS,"['cs.MS', 'cs.DM']",,,[]
Making simple proofs simpler,http://arxiv.org/abs/1307.1348v1,2013-07-04T14:29:01Z,2013-07-04T14:29:01Z,"  An open partition \pi{} [Cod09a, Cod09b] of a tree T is a partition of the
vertices of T with the property that, for each block B of \pi, the upset of B
is a union of blocks of \pi. This paper deals with the number, NP(n), of open
partitions of the tree, V_n, made of two chains with n points each, that share
the root.
","['\nPietro Codara\n', ""\nOttavio M. D'Antona\n"", '\nFrancesco Marigo\n', '\nCorrado Monti\n']",,"Mathematica Italia User Group Meeting (UGM) 2013, ISBN
  9788896810033. (2013)",http://arxiv.org/abs/1307.1348v1,cs.MS,"['cs.MS', 'cs.DM']",,,[]
A Mathematica package to cope with partially ordered sets,http://arxiv.org/abs/1307.1352v1,2013-07-04T14:33:31Z,2013-07-04T14:33:31Z,"  Mathematica offers, by way of the package Combinatorics, many useful
functions to work on graphs and ordered structures, but none of these functions
was specific enough to meet the needs of our research group. Moreover, the
existing functions are not always helpful when one has to work on new concepts.
  In this paper we present a package of features developed in Mathematica which
we consider particularly useful for the study of certain categories of
partially ordered sets. Among the features offered, the package includes: (1)
some basic features to treat partially ordered sets; (2) the ability to
enumerate, create, and display monotone and regular partitions of partially
ordered sets; (3) the capability of constructing the lattices of partitions of
a poset, and of doing some useful computations on these structures; (4) the
possibility of computing products and coproducts in the category of partially
ordered sets and monotone maps; (5) the possibility of computing products and
coproducts in the category of forests (disjoint union of trees) and open maps
(cf. [DM06] for the product between forests).
",['\nPietro Codara\n'],,"Mathematica Italia User Group Meeting (UGM) 2010, ISBN
  9788896810002. (2010)",http://arxiv.org/abs/1307.1352v1,cs.MS,"['cs.MS', 'cs.DM']",,,[]
"Next generation input-output data format for HEP using Google's protocol
  buffers",http://arxiv.org/abs/1306.6675v1,2013-06-27T22:30:55Z,2013-06-27T22:30:55Z,"  We propose a data format for Monte Carlo (MC) events, or any structural data,
including experimental data, in a compact binary form using variable-size
integer encoding as implemented in the Google's Protocol Buffers package. This
approach is implemented in the so-called ProMC library which produces smaller
file sizes for MC records compared to the existing input-output libraries used
in high-energy physics (HEP). Other important features are a separation of
abstract data layouts from concrete programming implementations,
self-description and random access. Data stored in ProMC files can be written,
read and manipulated in a number of programming languages, such C++, Java and
Python.
",['\nS. V. Chekanov\n'],"7 pages, 1 figure, 2 tables. Contributed to the Snowmass 2013 Study",,http://arxiv.org/abs/1306.6675v1,cs.CE,"['cs.CE', 'cs.MS', 'hep-ph']",,,[]
"Investigating independent subsets of graphs, with Mathematica",http://arxiv.org/abs/1307.1335v1,2013-07-04T14:06:46Z,2013-07-04T14:06:46Z,"  With this work we aim to show how Mathematica can be a useful tool to
investigate properties of combinatorial structures. Specifically, we will face
enumeration problems on independent subsets of powers of paths and cycles,
trying to highlight the correspondence with other combinatorial objects with
the same cardinality. Then we will study the structures obtained by ordering
properly independent subsets of paths and cycles. We will approach some
enumeration problems on the resulting partially ordered sets, putting in
evidence the correspondences with structures known as Fibonacci and Lucas
Cubes.
","['\nPietro Codara\n', ""\nOttavio M. D'Antona\n""]",,"Mathematica Italia User Group Meeting (UGM) 2013, ISBN
  9788896810033. (2013)",http://arxiv.org/abs/1307.1335v1,cs.MS,"['cs.MS', 'cs.DM', 'math.CO']",,,[]
"Proceedings 10th International Workshop On User Interfaces for Theorem
  Provers",http://arxiv.org/abs/1307.1528v1,2013-07-05T06:21:33Z,2013-07-05T06:21:33Z,"  This EPTCS volume collects the post-proceedings of the 10th International
Workshop On User Interfaces for Theorem Provers (UITP 2012), held as part of
the Conferences on Intelligent Computer Mathematics (CICM 2012) in Bremen on
July 11th 2012. The UITP workshop series aims at bringing together reasearchers
interested in designing, developing and evaluating interfaces for interactive
proof systems, such as theorem provers, formal method tools, and other tools
manipulating and presenting mathematical formulae. Started in 1995, it can look
back on seventeen years of history by now.
  The papers in the present volume give a good indication of the range of
questions currently addressed in the UITP community; this ranges from interface
design (Windsteiger; Dunchev et al) to using technologies such as machine
learning to assist the user (Komendantskaya et al). The web features
prominently (Tankink), and new technology necessitates changes right down to
the very basic modes of interaction (Wenzel) - the old REPL (read, evaluate,
print, loop) mode of interaction can not take advantage of modern technology,
such as the web and multi-core machines.
","['\nCezary Kaliszyk\nUniversity of Innsbruck, Austria\n', '\nChristoph Lüth\nDFKI and University of Bremen, Germany\n']",,"EPTCS 118, 2013",http://dx.doi.org/10.4204/EPTCS.118,cs.LO,"['cs.LO', 'cs.HC', 'cs.MS']",10.4204/EPTCS.118,,"['University of Innsbruck, Austria', 'DFKI and University of Bremen, Germany']"
Programs in C++ for matrix computations in min plus algebra,http://arxiv.org/abs/1306.5526v1,2013-06-24T07:33:16Z,2013-06-24T07:33:16Z,"  The main purpose of this paper is to propose six programs in C++ for matrix
computations and solving recurrent equations systems with entries in min plus
algebra.
","['\nMihai Ivan\n', '\nGheorghe Ivan\n']","73 pages, no figures",,http://arxiv.org/abs/1306.5526v1,math.RA,"['math.RA', 'cs.MS', '15A80, 68-04']",,,[]
vSMC: Parallel Sequential Monte Carlo in C++,http://arxiv.org/abs/1306.5583v1,2013-06-24T11:44:30Z,2013-06-24T11:44:30Z,"  Sequential Monte Carlo is a family of algorithms for sampling from a sequence
of distributions. Some of these algorithms, such as particle filters, are
widely used in the physics and signal processing researches. More recent
developments have established their application in more general inference
problems such as Bayesian modeling.
  These algorithms have attracted considerable attentions in recent years as
they admit natural and scalable parallelizations. However, these algorithms are
perceived to be difficult to implement. In addition, parallel programming is
often unfamiliar to many researchers though conceptually appealing, especially
for sequential Monte Carlo related fields.
  A C++ template library is presented for the purpose of implementing general
sequential Monte Carlo algorithms on parallel hardware. Two examples are
presented: a simple particle filter and a classic Bayesian modeling problem.
",['\nYan Zhou\n'],"44 pages, 3 figures",,http://arxiv.org/abs/1306.5583v1,stat.CO,"['stat.CO', 'cs.MS']",,,[]
Panphasia: a user guide,http://arxiv.org/abs/1306.5771v1,2013-06-24T20:22:29Z,2013-06-24T20:22:29Z,"  We make a very large realisation of a Gaussian white noise field, called
PANPHASIA, public by releasing software that computes this field. Panphasia is
designed specifically for setting up Gaussian initial conditions for
cosmological simulations and resimulations of structure formation. We make
available both software to compute the field itself and codes to illustrate
applications including a modified version of a public serial initial conditions
generator. We document the software and present the results of a few basic
tests of the field. The properties and method of construction of Panphasia are
described in full in a companion paper Jenkins 2013.
","['\nAdrian Jenkins\nICC, Durham\n', '\nStephen Booth\nEPCC, Edinburgh\n']","11 pages, 2 figures. Software to calculate Panphasia is available
  from: http://icc.dur.ac.uk/Panphasia.php",,http://arxiv.org/abs/1306.5771v1,astro-ph.IM,"['astro-ph.IM', 'astro-ph.CO', 'cs.MS']",,,"['ICC, Durham', 'EPCC, Edinburgh']"
swMATH - a new information service for mathematical software,http://arxiv.org/abs/1306.1036v1,2013-06-05T09:53:29Z,2013-06-05T09:53:29Z,"  An information service for mathematical software is presented. Publications
and software are two closely connected facets of mathematical knowledge. This
relation can be used to identify mathematical software and find relevant
information about it. The approach and the state of the art of the information
service are described here.
","['\nSebastian Bönisch\n', '\nMichael Brickenstein\n', '\nHagen Chrapary\n', '\nGert-Martin Greuel\n', '\nWolfram Sperber\n']",see also: http://www.swmath.org,,http://arxiv.org/abs/1306.1036v1,cs.DL,"['cs.DL', 'cs.MS']",,,[]
A Universal Machine for Biform Theory Graphs,http://arxiv.org/abs/1306.3198v1,2013-06-13T19:06:45Z,2013-06-13T19:06:45Z,"  Broadly speaking, there are two kinds of semantics-aware assistant systems
for mathematics: proof assistants express the semantic in logic and emphasize
deduction, and computer algebra systems express the semantics in programming
languages and emphasize computation. Combining the complementary strengths of
both approaches while mending their complementary weaknesses has been an
important goal of the mechanized mathematics community for some time. We pick
up on the idea of biform theories and interpret it in the MMTt/OMDoc framework
which introduced the foundations-as-theories approach, and can thus represent
both logics and programming languages as theories. This yields a formal,
modular framework of biform theory graphs which mixes specifications and
implementations sharing the module system and typing information. We present
automated knowledge management work flows that interface to existing
specification/programming tools and enable an OpenMath Machine, that
operationalizes biform theories, evaluating expressions by exhaustively
applying the implementations of the respective operators. We evaluate the new
biform framework by adding implementations to the OpenMath standard content
dictionaries.
","['\nMichael Kohlhase\n', '\nFelix Mance\n', '\nFlorian Rabe\n']","Conferences on Intelligent Computer Mathematics, CICM 2013 The final
  publication is available at http://link.springer.com/",,http://arxiv.org/abs/1306.3198v1,cs.LO,"['cs.LO', 'cs.MS']",,,[]
Arithmetic Algorithms for Hereditarily Binary Natural Numbers,http://arxiv.org/abs/1306.1128v1,2013-06-05T14:56:04Z,2013-06-05T14:56:04Z,"  We study some essential arithmetic properties of a new tree-based number
representation, {\em hereditarily binary numbers}, defined by applying
recursively run-length encoding of bijective base-2 digits.
  Our representation expresses giant numbers like the largest known prime
number and its related perfect number as well as the largest known Woodall,
Cullen, Proth, Sophie Germain and twin primes as trees of small sizes.
  More importantly, our number representation supports novel algorithms that,
in the best case, collapse the complexity of various computations by
super-exponential factors and in the worse case are within a constant factor of
their traditional counterparts.
  As a result, it opens the door to a new world, where arithmetic operations
are limited by the structural complexity of their operands, rather than their
bitsizes.
",['\nPaul Tarau\n'],unpublished draft,,http://arxiv.org/abs/1306.1128v1,cs.DS,"['cs.DS', 'cs.DM', 'cs.MS']",,,[]
MathGR: a tensor and GR computation package to keep it simple,http://arxiv.org/abs/1306.1295v3,2013-06-06T05:08:44Z,2016-12-07T00:50:35Z,"  We introduce the MathGR package, written in Mathematica. The package can
manipulate tensor and GR calculations with either abstract or explicit indices,
simplify tensors with permutational symmetries, decompose tensors from abstract
indices to partially or completely explicit indices and convert partial
derivatives into total derivatives. Frequently used GR tensors and a model of
FRW universe with ADM type perturbations are predefined. The package is built
around the philosophy to ""keep it simple"", and makes use of latest tensor
technologies of Mathematica.
",['\nYi Wang\n'],"12 pages, 2 figures; v2: version to match updated software; v3: Ibp
  part updated to match behavior of code",,http://arxiv.org/abs/1306.1295v3,cs.MS,"['cs.MS', 'astro-ph.CO', 'gr-qc', 'hep-th', 'physics.comp-ph']",,,[]
A computer algebra user interface manifesto,http://arxiv.org/abs/1305.3215v1,2013-05-14T17:21:29Z,2013-05-14T17:21:29Z,"  Many computer algebra systems have more than 1000 built-in functions, making
expertise difficult. Using mock dialog boxes, this article describes a proposed
interactive general-purpose wizard for organizing optional transformations and
allowing easy fine grain control over the form of the result even by amateurs.
This wizard integrates ideas including:
  * flexible subexpression selection;
  * complete control over the ordering of variables and commutative operands,
with well-chosen defaults;
  * interleaving the choice of successively less main variables with applicable
function choices to provide detailed control without incurring a combinatorial
number of applicable alternatives at any one level;
  * quick applicability tests to reduce the listing of inapplicable
transformations;
  * using an organizing principle to order the alternatives in a helpful
manner;
  * labeling quickly-computed alternatives in dialog boxes with a preview of
their results,
  * using ellipsis elisions if necessary or helpful;
  * allowing the user to retreat from a sequence of choices to explore other
branches of the tree of alternatives or to return quickly to branches already
visited;
  * allowing the user to accumulate more than one of the alternative forms;
  * integrating direct manipulation into the wizard; and
  * supporting not only the usual input-result pair mode, but also the useful
alternative derivational and in situ replacement modes in a unified window.
",['\nDavid R. Stoutemyer\n'],"38 pages, 12 figures, to be published in Communications in Computer
  Algebra",,http://arxiv.org/abs/1305.3215v1,cs.SC,"['cs.SC', 'cs.MS']",,,[]
PetIGA: A Framework for High-Performance Isogeometric Analysis,http://arxiv.org/abs/1305.4452v3,2013-05-20T07:26:33Z,2015-07-28T12:52:07Z,"  We present PetIGA, a code framework to approximate the solution of partial
differential equations using isogeometric analysis. PetIGA can be used to
assemble matrices and vectors which come from a Galerkin weak form, discretized
with Non-Uniform Rational B-spline basis functions. We base our framework on
PETSc, a high-performance library for the scalable solution of partial
differential equations, which simplifies the development of large-scale
scientific codes, provides a rich environment for prototyping, and separates
parallelism from algorithm choice. We describe the implementation of PetIGA,
and exemplify its use by solving a model nonlinear problem. To illustrate the
robustness and flexibility of PetIGA, we solve some challenging nonlinear
partial differential equations that include problems in both solid and fluid
mechanics. We show strong scaling results on up to 4096 cores, which confirm
the suitability of PetIGA for large scale simulations.
","['\nLisandro Dalcin\n', '\nNathan Collier\n', '\nPhilippe Vignal\n', '\nAdriano M. A. Cortes\n', '\nV. M. Calo\n']",,,http://arxiv.org/abs/1305.4452v3,cs.MS,"['cs.MS', 'math.NA']",,,[]
Parallelizing Gaussian Process Calculations in R,http://arxiv.org/abs/1305.4886v1,2013-05-21T17:08:54Z,2013-05-21T17:08:54Z,"  We consider parallel computation for Gaussian process calculations to
overcome computational and memory constraints on the size of datasets that can
be analyzed. Using a hybrid parallelization approach that uses both threading
(shared memory) and message-passing (distributed memory), we implement the core
linear algebra operations used in spatial statistics and Gaussian process
regression in an R package called bigGP that relies on C and MPI. The approach
divides the matrix into blocks such that the computational load is balanced
across processes while communication between processes is limited. The package
provides an API enabling R programmers to implement Gaussian process-based
methods by using the distributed linear algebra operations without any C or MPI
coding. We illustrate the approach and software by analyzing an astrophysics
dataset with n=67,275 observations.
","['\nChristopher J. Paciorek\n', '\nBenjamin Lipshitz\n', '\nWei Zhuo\n', '\n Prabhat\n', '\nCari G. Kaufman\n', '\nRollin C. Thomas\n']","21 pages, 8 figures","Journal of Statistical Software 2015, Vol. 63, Number 10, 1-23",http://dx.doi.org/10.18637/jss.v063.i10,stat.CO,"['stat.CO', 'cs.MS']",10.18637/jss.v063.i10,,[]
"An efficient way to perform the assembly of finite element matrices in
  Matlab and Octave",http://arxiv.org/abs/1305.3122v1,2013-05-14T11:52:17Z,2013-05-14T11:52:17Z,"  We describe different optimization techniques to perform the assembly of
finite element matrices in Matlab and Octave, from the standard approach to
recent vectorized ones, without any low level language used. We finally obtain
a simple and efficient vectorized algorithm able to compete in performance with
dedicated software such as FreeFEM++. The principle of this assembly algorithm
is general, we present it for different matrices in the P1 finite elements case
and in linear elasticity. We present numerical results which illustrate the
computational costs of the different approaches
","['\nFrançois Cuvelier\nLAGA\n', '\nCaroline Japhet\nLAGA, Inria Paris-Rocquencourt\n', '\nGilles Scarella\nLAGA\n']",Inria: No: RR-8305 (2013),,http://arxiv.org/abs/1305.3122v1,cs.NA,"['cs.NA', 'cs.MS', 'math.NA']",,,"['LAGA', 'LAGA, Inria Paris-Rocquencourt', 'LAGA']"
Making the case of GPUs in courses on computational physics,http://arxiv.org/abs/1305.3625v1,2013-05-15T20:16:42Z,2013-05-15T20:16:42Z,"  Most relatively modern desktop or even laptop computers contain a graphics
card useful for more than showing colors on a screen. In this paper, we make a
case for why you should learn enough about GPU (graphics processing unit)
computing to use as an accelerator or even replacement to your CPU code. We
include an example of our own as a case study to show what can be realistically
expected.
",['\nKnut Skogstrand Gjerden\n'],"11 pages, 2 figures",,http://arxiv.org/abs/1305.3625v1,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'physics.ed-ph', '82-01, 82-08, 65Z05, 97Q99']",,,[]
"A Parallel and Scalable Iterative Solver for Sequences of Dense
  Eigenproblems Arising in FLAPW",http://arxiv.org/abs/1305.5120v1,2013-05-21T10:08:01Z,2013-05-21T10:08:01Z,"  In one of the most important methods in Density Functional Theory - the
Full-Potential Linearized Augmented Plane Wave (FLAPW) method - dense
generalized eigenproblems are organized in long sequences. Moreover each
eigenproblem is strongly correlated to the next one in the sequence. We propose
a novel approach which exploits such correlation through the use of an
eigensolver based on subspace iteration and accelerated with Chebyshev
polynomials. The resulting solver, parallelized using the Elemental library
framework, achieves excellent scalability and is competitive with current dense
parallel eigensolvers.
","['\nMario Berljafa\nDepartment of Mathematics, University of Zagreb\n', '\nEdoardo Di Napoli\nJuelich Supercomputing Centre, Forschungszentrum Juelich\nAICES, RWTH Aachen\n']","Submitted to 10th International Conference on Parallel Processing and
  Applied Mathematics(PPAM 2013)",,http://arxiv.org/abs/1305.5120v1,cs.DC,"['cs.DC', 'cs.MS', 'physics.comp-ph']",,,"['Department of Mathematics, University of Zagreb', 'Juelich Supercomputing Centre, Forschungszentrum Juelich', 'AICES, RWTH Aachen']"
Somoclu: An Efficient Parallel Library for Self-Organizing Maps,http://arxiv.org/abs/1305.1422v4,2013-05-07T06:43:26Z,2017-06-09T14:03:01Z,"  Somoclu is a massively parallel tool for training self-organizing maps on
large data sets written in C++. It builds on OpenMP for multicore execution,
and on MPI for distributing the workload across the nodes in a cluster. It is
also able to boost training by using CUDA if graphics processing units are
available. A sparse kernel is included, which is useful for high-dimensional
but sparse data, such as the vector spaces common in text mining workflows.
Python, R and MATLAB interfaces facilitate interactive use. Apart from fast
execution, memory use is highly optimized, enabling training large emergent
maps even on a single computer.
","['\nPeter Wittek\n', '\nShi Chao Gao\n', '\nIk Soo Lim\n', '\nLi Zhao\n']","26 pages, 9 figures. The code is available at
  https://peterwittek.github.io/somoclu/","Journal of Statistical Software, 78(9), 1-21 (2017)",http://dx.doi.org/10.18637/jss.v078.i09,cs.DC,"['cs.DC', 'cs.MS', 'cs.NE']",10.18637/jss.v078.i09,,[]
"HERMES: towards an integrated toolbox to characterize functional and
  effective brain connectivity",http://arxiv.org/abs/1305.2550v2,2013-05-12T01:04:55Z,2013-05-27T03:53:02Z,"  The analysis of the interdependence between time series has become an
important field of research in the last years, mainly as a result of advances
in the characterization of dynamical systems from the signals they produce, the
introduction of concepts such as generalized and phase synchronization and the
application of information theory to time series analysis. In neurophysiology,
different analytical tools stemming from these concepts have added to the
'traditional' set of linear methods, which includes the cross-correlation and
the coherency function in the time and frequency domain, respectively, or more
elaborated tools such as Granger Causality. This increase in the number of
approaches to tackle the existence of functional (FC) or effective connectivity
(EC) between two (or among many) neural networks, along with the mathematical
complexity of the corresponding time series analysis tools, makes it desirable
to arrange them into a unified-easy-to-use software package. The goal is to
allow neuroscientists, neurophysiologists and researchers from related fields
to easily access and make use of these analysis methods from a single
integrated toolbox. Here we present HERMES (http://hermes.ctb.upm.es), a
toolbox for the Matlab environment (The Mathworks, Inc), which is designed for
the analysis functional and effective brain connectivity from
neurophysiological data such as multivariate EEG and/or MEG records. It
includes also visualization tools and statistical methods to address the
problem of multiple comparisons. We believe that this toolbox will be very
helpful to all the researchers working in the emerging field of brain
connectivity analysis.
","['\nGuiomar Niso\n', '\nRicardo Bruña\n', '\nErnesto Pereda\n', '\nRicardo Gutiérrez\n', '\nRicardo Bajo\n', '\nFernando Maestú\n', '\nFrancisco del-Pozo\n']","58 pages, 10 figures, 3 tables, Neuroinformatics 2013",,http://dx.doi.org/10.1007/s12021-013-9186-1,q-bio.NC,"['q-bio.NC', 'cs.CE', 'cs.MS', 'physics.bio-ph', 'physics.data-an']",10.1007/s12021-013-9186-1,,[]
"Minimal Residual Methods for Complex Symmetric, Skew Symmetric, and Skew
  Hermitian Systems",http://arxiv.org/abs/1304.6782v2,2013-04-25T01:21:48Z,2014-01-13T19:45:12Z,"  While there is no lack of efficient Krylov subspace solvers for Hermitian
systems, there are few for complex symmetric, skew symmetric, or skew Hermitian
systems, which are increasingly important in modern applications including
quantum dynamics, electromagnetics, and power systems. For a large consistent
complex symmetric system, one may apply a non-Hermitian Krylov subspace method
disregarding the symmetry of $A$, or a Hermitian Krylov solver on the
equivalent normal equation or an augmented system twice the original dimension.
These have the disadvantages of increasing either memory, conditioning, or
computational costs. An exception is a special version of QMR by Freund (1992),
but that may be affected by non-benign breakdowns unless look-ahead is
implemented; furthermore, it is designed for only consistent and nonsingular
problems. For skew symmetric systems, Greif and Varah (2009) adapted CG for
nonsingular skew symmetric linear systems that are necessarily and
restrictively of even order.
  We extend the symmetric and Hermitian algorithms MINRES and MINRES-QLP by
Choi, Paige and Saunders (2011) to complex symmetric, skew symmetric, and skew
Hermitian systems. In particular, MINRES-QLP uses a rank-revealing QLP
decomposition of the tridiagonal matrix from a three-term recurrent
complex-symmetric Lanczos process. Whether the systems are real or complex,
singular or invertible, compatible or inconsistent, MINRES-QLP computes the
unique minimum-length, i.e., pseudoinverse, solutions. It is a significant
extension of MINRES by Paige and Saunders (1975) with enhanced stability and
capability.
","['\n Sou-Cheng\nTerrya\n', '\n Choi\n']",arXiv admin note: substantial text overlap with arXiv:1003.4042,,http://arxiv.org/abs/1304.6782v2,cs.MS,"['cs.MS', 'math.NA']",,,['Terrya']
"Subspace-preserving sparsification of matrices with minimal perturbation
  to the near null-space. Part I: Basics",http://arxiv.org/abs/1304.7049v1,2013-04-26T01:43:09Z,2013-04-26T01:43:09Z,"  This is the first of two papers to describe a matrix sparsification algorithm
that takes a general real or complex matrix as input and produces a sparse
output matrix of the same size. The non-zero entries in the output are chosen
to minimize changes to the singular values and singular vectors corresponding
to the near null-space of the input. The output matrix is constrained to
preserve left and right null-spaces exactly. The sparsity pattern of the output
matrix is automatically determined or can be given as input.
  If the input matrix belongs to a common matrix subspace, we prove that the
computed sparse matrix belongs to the same subspace. This works without
imposing explicit constraints pertaining to the subspace. This property holds
for the subspaces of Hermitian, complex-symmetric, Hamiltonian, circulant,
centrosymmetric, and persymmetric matrices, and for each of the skew
counterparts.
  Applications of our method include computation of reusable sparse
preconditioning matrices for reliable and efficient solution of high-order
finite element systems. The second paper in this series describes our
open-source implementation, and presents further technical details.
",['\nChetan Jhurani\n'],,,http://arxiv.org/abs/1304.7049v1,math.NA,"['math.NA', 'cs.MS']",,,[]
"Subspace-preserving sparsification of matrices with minimal perturbation
  to the near null-space. Part II: Approximation and Implementation",http://arxiv.org/abs/1304.7050v1,2013-04-26T01:44:09Z,2013-04-26T01:44:09Z,"  This is the second of two papers to describe a matrix sparsification
algorithm that takes a general real or complex matrix as input and produces a
sparse output matrix of the same size. The first paper presented the original
algorithm, its features, and theoretical results.
  Since the output of this sparsification algorithm is a matrix rather than a
vector, it can be costly in memory and run-time if an implementation does not
exploit the structural properties of the algorithm and the matrix. Here we show
how to modify the original algorithm to increase its efficiency. This is
possible by computing an approximation to the exact result. We introduce extra
constraints that are automatically determined based on the input matrix. This
addition reduces the number of unknown degrees of freedom but still preserves
many matrix subspaces. We also describe our open-source library that implements
this sparsification algorithm and has interfaces in C++, C, and MATLAB.
",['\nChetan Jhurani\n'],,,http://arxiv.org/abs/1304.7050v1,math.NA,"['math.NA', 'cs.MS']",,,[]
"Proceedings International Workshop on the ACL2 Theorem Prover and its
  Applications",http://arxiv.org/abs/1304.7123v1,2013-04-26T10:59:21Z,2013-04-26T10:59:21Z,"  This volume contains the proceedings of the Eleventh International Workshop
on the ACL2 Theorem Prover and its Applications, held on May 30 and 31, 2013,
in Laramie, Wyoming, USA.
  ACL2 is an industrial-strength automated reasoning system, the latest in the
Boyer-Moore family of theorem provers. The ACL2 workshop is the major technical
forum for users of the ACL2 theorem proving system to present research on the
prover and its applications.
  This year's workshop received 15 submissions covering a wide range of
applications, libraries, prover enhancements, interfaces, and experience
reports. 11 papers were selected by the program committee for presentation at
the workshop.
","['\nRuben Gamboa\nUniversity of Wyoming, USA\n', '\nJared Davis\nCentaur Technology, USA\n']",,"EPTCS 114, 2013",http://dx.doi.org/10.4204/EPTCS.114,cs.LO,"['cs.LO', 'cs.MS']",10.4204/EPTCS.114,,"['University of Wyoming, USA', 'Centaur Technology, USA']"
Understanding Branch Cuts of Expressions,http://arxiv.org/abs/1304.7223v3,2013-04-26T16:46:48Z,2013-05-24T09:08:09Z,"  We assume some standard choices for the branch cuts of a group of functions
and consider the problem of then calculating the branch cuts of expressions
involving those functions. Typical examples include the addition formulae for
inverse trigonometric functions. Understanding these cuts is essential for
working with the single-valued counterparts, the common approach to encoding
multi-valued functions in computer algebra systems. While the defining choices
are usually simple (typically portions of either the real or imaginary axes)
the cuts induced by the expression may be surprisingly complicated. We have
made explicit and implemented techniques for calculating the cuts in the
computer algebra programme Maple. We discuss the issues raised, classifying the
different cuts produced. The techniques have been gathered in the BranchCuts
package, along with tools for visualising the cuts. The package is included in
Maple 17 as part of the FunctionAdvisor tool.
","['\nMatthew England\n', '\nRussell Bradford\n', '\nJames H. Davenport\n', '\nDavid Wilson\n']","To appear in: Proceedings of Conferences on Intelligent Computer
  Mathematics (CICM '13) - Mathematical Knowledge Management (MKM) strand","Intelligent Computer Mathematics. Berlin: Springer, pp. 136-151.
  (Lecture Notes in Computer Science; 7961), 2013",http://dx.doi.org/10.1007/978-3-642-39320-4_9,cs.MS,"['cs.MS', 'cs.SC', '68W30, 33F10', 'I.1.1; G.4']",10.1007/978-3-642-39320-4_9,,[]
Verified AIG Algorithms in ACL2,http://arxiv.org/abs/1304.7861v1,2013-04-30T04:14:44Z,2013-04-30T04:14:44Z,"  And-Inverter Graphs (AIGs) are a popular way to represent Boolean functions
(like circuits). AIG simplification algorithms can dramatically reduce an AIG,
and play an important role in modern hardware verification tools like
equivalence checkers. In practice, these tricky algorithms are implemented with
optimized C or C++ routines with no guarantee of correctness. Meanwhile, many
interactive theorem provers can now employ SAT or SMT solvers to automatically
solve finite goals, but no theorem prover makes use of these advanced,
AIG-based approaches.
  We have developed two ways to represent AIGs within the ACL2 theorem prover.
One representation, Hons-AIGs, is especially convenient to use and reason
about. The other, Aignet, is the opposite; it is styled after modern AIG
packages and allows for efficient algorithms. We have implemented functions for
converting between these representations, random vector simulation, conversion
to CNF, etc., and developed reasoning strategies for verifying these
algorithms.
  Aside from these contributions towards verifying AIG algorithms, this work
has an immediate, practical benefit for ACL2 users who are using GL to
bit-blast finite ACL2 theorems: they can now optionally trust an off-the-shelf
SAT solver to carry out the proof, instead of using the built-in BDD package.
Looking to the future, it is a first step toward implementing verified AIG
simplification algorithms that might further improve GL performance.
","['\nJared Davis\nCentaur Technology\n', '\nSol Swords\nCentaur Technology\n']","In Proceedings ACL2 2013, arXiv:1304.7123","EPTCS 114, 2013, pp. 95-110",http://dx.doi.org/10.4204/EPTCS.114.8,cs.LO,"['cs.LO', 'cs.MS']",10.4204/EPTCS.114.8,,"['Centaur Technology', 'Centaur Technology']"
An implementation of the relational k-means algorithm,http://arxiv.org/abs/1304.6899v1,2013-04-25T12:59:31Z,2013-04-25T12:59:31Z,"  A C# implementation of a generalized k-means variant called relational
k-means is described here. Relational k-means is a generalization of the
well-known k-means clustering method which works for non-Euclidean scenarios as
well. The input is an arbitrary distance matrix, as opposed to the traditional
k-means method, where the clustered objects need to be identified with vectors.
",['\nBalázs Szalkai\n'],8 pages,,http://arxiv.org/abs/1304.6899v1,cs.LG,"['cs.LG', 'cs.CV', 'cs.MS']",,,[]
"A GEMM interface and implementation on NVIDIA GPUs for multiple small
  matrices",http://arxiv.org/abs/1304.7053v1,2013-04-26T02:22:14Z,2013-04-26T02:22:14Z,"  We present an interface and an implementation of the General Matrix Multiply
(GEMM) routine for multiple small matrices processed simultaneously on NVIDIA
graphics processing units (GPUs). We focus on matrix sizes under 16. The
implementation can be easily extended to larger sizes. For single precision
matrices, our implementation is 30% to 600% faster than the batched cuBLAS
implementation distributed in the CUDA Toolkit 5.0 on NVIDIA Tesla K20c. For
example, we obtain 104 GFlop/s and 216 GFlop/s when multiplying 100,000
independent matrix pairs of size 10 and 16, respectively. Similar improvement
in performance is obtained for other sizes, in single and double precision for
real and complex types, and when the number of matrices is smaller. Apart from
our implementation, our different function interface also plays an important
role in the improved performance. Applications of this software include Finite
Element computation on GPUs.
","['\nChetan Jhurani\n', '\nPaul Mullowney\n']",,,http://arxiv.org/abs/1304.7053v1,cs.MS,"['cs.MS', 'cs.DC', 'math.NA']",,,[]
Batched Kronecker product for 2-D matrices and 3-D arrays on NVIDIA GPUs,http://arxiv.org/abs/1304.7054v1,2013-04-26T02:22:25Z,2013-04-26T02:22:25Z,"  We describe an interface and an implementation for performing Kronecker
product actions on NVIDIA GPUs for multiple small 2-D matrices and 3-D arrays
processed in parallel as a batch. This method is suited to cases where the
Kronecker product component matrices are identical but the operands in a
matrix-free application vary in the batch. Any batched GEMM (General Matrix
Multiply) implementation, for example ours [1] or the one in cuBLAS, can also
be used for performing batched Kronecker products on GPUs. However, the
specialized implementation presented here is faster and uses less memory.
Partly this is because a simple GEMM based approach would require extra copies
to and from main memory. We focus on matrix sizes less than or equal to 16,
since these are the typical polynomial degrees in Finite Elements, but the
implementation can be easily extended for other sizes. We obtain 143 and 285
GFlop/s for single precision real when processing matrices of size 10 and 16,
respectively on NVIDIA Tesla K20c using CUDA 5.0. The corresponding speeds for
3-D array Kronecker products are 126 and 268 GFlop/s, respectively. Double
precision is easily supported using the C++ template mechanism.
",['\nChetan Jhurani\n'],,,http://arxiv.org/abs/1304.7054v1,cs.MS,"['cs.MS', 'cs.DC', 'math.NA']",,,[]
"Enhancements to ACL2 in Versions 5.0, 6.0, and 6.1",http://arxiv.org/abs/1304.7855v1,2013-04-30T04:13:58Z,2013-04-30T04:13:58Z,"  We report on highlights of the ACL2 enhancements introduced in ACL2 releases
since the 2011 ACL2 Workshop. Although many enhancements are critical for
soundness or robustness, we focus in this paper on those improvements that
could benefit users who are aware of them, but that might not be discovered in
everyday practice.
","['\nMatt Kaufmann\nUniversity of Texas at Austin\n', '\nJ Strother Moore\nUniversity of Texas at Austin\n']","In Proceedings ACL2 2013, arXiv:1304.7123","EPTCS 114, 2013, pp. 5-12",http://dx.doi.org/10.4204/EPTCS.114.1,cs.MS,"['cs.MS', 'cs.AI', 'cs.LO', 'F.4.1; I.2.3; G.4']",10.4204/EPTCS.114.1,,"['University of Texas at Austin', 'University of Texas at Austin']"
Solving Wave Equations on Unstructured Geometries,http://arxiv.org/abs/1304.5546v1,2013-04-19T21:07:10Z,2013-04-19T21:07:10Z,"  Waves are all around us--be it in the form of sound, electromagnetic
radiation, water waves, or earthquakes. Their study is an important basic tool
across engineering and science disciplines. Every wave solver serving the
computational study of waves meets a trade-off of two figures of merit--its
computational speed and its accuracy. Discontinuous Galerkin (DG) methods fall
on the high-accuracy end of this spectrum. Fortuitously, their computational
structure is so ideally suited to GPUs that they also achieve very high
computational speeds. In other words, the use of DG methods on GPUs
significantly lowers the cost of obtaining accurate solutions. This article
aims to give the reader an easy on-ramp to the use of this technology, based on
a sample implementation which demonstrates a highly accurate, GPU-capable,
real-time visualizing finite element solver in about 1500 lines of code.
","['\nAndreas Klöckner\n', '\nTimothy Warburton\n', '\nJan S. Hesthaven\n']","GPU Computing Gems, edited by Wen-mei Hwu, Elsevier (2011), ISBN
  9780123859631, Chapter 18",,http://arxiv.org/abs/1304.5546v1,cs.MS,"['cs.MS', 'cs.NA']",,,[]
"Improved Accuracy and Parallelism for MRRR-based Eigensolvers -- A Mixed
  Precision Approach",http://arxiv.org/abs/1304.1864v3,2013-04-06T08:14:25Z,2013-06-22T10:08:46Z,"  The real symmetric tridiagonal eigenproblem is of outstanding importance in
numerical computations; it arises frequently as part of eigensolvers for
standard and generalized dense Hermitian eigenproblems that are based on a
reduction to tridiagonal form. For its solution, the algorithm of Multiple
Relatively Robust Representations (MRRR) is among the fastest methods. Although
fast, the solvers based on MRRR do not deliver the same accuracy as competing
methods like Divide & Conquer or the QR algorithm. In this paper, we
demonstrate that the use of mixed precisions leads to improved accuracy of
MRRR-based eigensolvers with limited or no performance penalty. As a result, we
obtain eigensolvers that are not only equally or more accurate than the best
available methods, but also -in most circumstances- faster and more scalable
than the competition.
","['\nMatthias Petschow\nAICES, RWTH Aachen\n', '\nEnrique Quintana-Orti\nUniversidad Jaume I\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",,,http://arxiv.org/abs/1304.1864v3,cs.NA,"['cs.NA', 'cs.MS']",,,"['AICES, RWTH Aachen', 'Universidad Jaume I', 'AICES, RWTH Aachen']"
"Efficient Generation of Correctness Certificates for the Abstract Domain
  of Polyhedra",http://arxiv.org/abs/1304.0864v1,2013-04-03T08:01:42Z,2013-04-03T08:01:42Z,"  Polyhedra form an established abstract domain for inferring runtime
properties of programs using abstract interpretation. Computations on them need
to be certified for the whole static analysis results to be trusted. In this
work, we look at how far we can get down the road of a posteriori verification
to lower the overhead of certification of the abstract domain of polyhedra. We
demonstrate methods for making the cost of inclusion certificate generation
negligible. From a performance point of view, our single-representation,
constraints-based implementation compares with state-of-the-art
implementations.
","['\nAlexis Fouilhé\nVERIMAG - IMAG\n', '\nDavid Monniaux\nVERIMAG - IMAG\n', '\nMichaël Périn\nVERIMAG - IMAG\n']",,,http://arxiv.org/abs/1304.0864v1,cs.PL,"['cs.PL', 'cs.LO', 'cs.MS']",,,"['VERIMAG - IMAG', 'VERIMAG - IMAG', 'VERIMAG - IMAG']"
C Language Extensions for Hybrid CPU/GPU Programming with StarPU,http://arxiv.org/abs/1304.0878v2,2013-04-03T09:11:25Z,2013-04-10T13:29:43Z,"  Modern platforms used for high-performance computing (HPC) include machines
with both general-purpose CPUs, and ""accelerators"", often in the form of
graphical processing units (GPUs). StarPU is a C library to exploit such
platforms. It provides users with ways to define ""tasks"" to be executed on CPUs
or GPUs, along with the dependencies among them, and by automatically
scheduling them over all the available processing units. In doing so, it also
relieves programmers from the need to know the underlying architecture details:
it adapts to the available CPUs and GPUs, and automatically transfers data
between main memory and GPUs as needed. While StarPU's approach is successful
at addressing run-time scheduling issues, being a C library makes for a poor
and error-prone programming interface. This paper presents an effort started in
2011 to promote some of the concepts exported by the library as C language
constructs, by means of an extension of the GCC compiler suite. Our main
contribution is the design and implementation of language extensions that map
to StarPU's task programming paradigm. We argue that the proposed extensions
make it easier to get started with StarPU,eliminate errors that can occur when
using the C library, and help diagnose possible mistakes. We conclude on future
work.
",['\nLudovic Courtès\nINRIA Bordeaux - Sud-Ouest\n'],,N&deg; RR-8278 (2013),http://arxiv.org/abs/1304.0878v2,cs.MS,"['cs.MS', 'cs.CE', 'cs.DC']",,,['INRIA Bordeaux - Sud-Ouest']
"The Graph Grammar Library - a generic framework for chemical graph
  rewrite systems",http://arxiv.org/abs/1304.1356v1,2013-04-04T13:06:34Z,2013-04-04T13:06:34Z,"  Graph rewrite systems are powerful tools to model and study complex problems
in various fields of research. Their successful application to chemical
reaction modelling on a molecular level was shown but no appropriate and simple
system is available at the moment.
  The presented Graph Grammar Library (GGL) implements a generic Double Push
Out approach for general graph rewrite systems. The framework focuses on a high
level of modularity as well as high performance, using state-of-the-art
algorithms and data structures, and comes with extensive documentation. The
large GGL chemistry module enables extensive and detailed studies of chemical
systems. It well meets the requirements and abilities envisioned by Yadav et
al. (2004) for such chemical rewrite systems. Here, molecules are represented
as undirected labeled graphs while chemical reactions are described by
according graph grammar rules. Beside the graph transformation, the GGL offers
advanced cheminformatics algorithms for instance to estimate energies
ofmolecules or aromaticity perception. These features are illustrated using a
set of reactions from polyketide chemistry a huge class of natural compounds of
medical relevance.
  The graph grammar based simulation of chemical reactions offered by the GGL
is a powerful tool for extensive cheminformatics studies on a molecular level.
The GGL already provides rewrite rules for all enzymes listed in the KEGG
LIGAND database is freely available at
http://www.tbi.univie.ac.at/software/GGL/.
","['\nMartin Mann\n', '\nHeinz Ekker\n', '\nChristoph Flamm\n']","Extended version of an abstract published in proceedings of the
  International Conference on Model Transformation (ICMT) 2013",,http://arxiv.org/abs/1304.1356v1,cs.MS,"['cs.MS', 'cs.CE', 'q-bio.BM', 'q-bio.MN']",,,[]
Algorithms for Large-scale Whole Genome Association Analysis,http://arxiv.org/abs/1304.2272v1,2013-04-08T17:13:39Z,2013-04-08T17:13:39Z,"  In order to associate complex traits with genetic polymorphisms, genome-wide
association studies process huge datasets involving tens of thousands of
individuals genotyped for millions of polymorphisms. When handling these
datasets, which exceed the main memory of contemporary computers, one faces two
distinct challenges: 1) Millions of polymorphisms come at the cost of hundreds
of Gigabytes of genotype data, which can only be kept in secondary storage; 2)
the relatedness of the test population is represented by a covariance matrix,
which, for large populations, can only fit in the combined main memory of a
distributed architecture. In this paper, we present solutions for both
challenges: The genotype data is streamed from and to secondary storage using a
double buffering technique, while the covariance matrix is kept across the main
memory of a distributed memory system. We show that these methods sustain
high-performance and allow the analysis of enormous dataset
","['\nElmar Peise\nAICES, RWTH Aachen\n', '\nDiego Fabregat\nAICES, RWTH Aachen\n', '\nYurii Aulchenko\nInstitute of Cytology and Genetics, Novosibirsk\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",,,http://arxiv.org/abs/1304.2272v1,cs.CE,"['cs.CE', 'cs.MS', 'q-bio.GN']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen', 'Institute of Cytology and Genetics, Novosibirsk', 'AICES, RWTH Aachen']"
"The RAppArmor Package: Enforcing Security Policies in R Using Dynamic
  Sandboxing on Linux",http://arxiv.org/abs/1303.4808v3,2013-03-20T01:57:36Z,2013-11-01T17:53:22Z,"  The increasing availability of cloud computing and scientific super computers
brings great potential for making R accessible through public or shared
resources. This allows us to efficiently run code requiring lots of cycles and
memory, or embed R functionality into, e.g., systems and web services. However
some important security concerns need to be addressed before this can be put in
production. The prime use case in the design of R has always been a single
statistician running R on the local machine through the interactive console.
Therefore the execution environment of R is entirely unrestricted, which could
result in malicious behavior or excessive use of hardware resources in a shared
environment. Properly securing an R process turns out to be a complex problem.
We describe various approaches and illustrate potential issues using some of
our personal experiences in hosting public web services. Finally we introduce
the RAppArmor package: a Linux based reference implementation for dynamic
sandboxing in R on the level of the operating system.
",['\nJeroen Ooms\n'],,"Journal of Statistical Software, Vol. 55, Issue 7, Nov 2013",http://arxiv.org/abs/1303.4808v3,cs.CR,"['cs.CR', 'cs.MS', 'stat.CO']",,,[]
Parameter identification in large kinetic networks with BioPARKIN,http://arxiv.org/abs/1303.4928v2,2013-03-20T13:05:33Z,2013-04-09T08:08:31Z,"  Modelling, parameter identification, and simulation play an important role in
systems biology. Usually, the goal is to determine parameter values that
minimise the difference between experimental measurement values and model
predictions in a least-squares sense. Large-scale biological networks, however,
often suffer from missing data for parameter identification. Thus, the
least-squares problems are rank-deficient and solutions are not unique. Many
common optimisation methods ignore this detail because they do not take into
account the structure of the underlying inverse problem. These algorithms
simply return a ""solution"" without additional information on identifiability or
uniqueness. This can yield misleading results, especially if parameters are
co-regulated and data are noisy.
","['\nThomas Dierkes\n', '\nSusanna Röblitz\n', '\nMoritz Wade\n', '\nPeter Deuflhard\n']","20 pages, 7 figures, 4 tables; added 1 figure, and revised section 4",,http://arxiv.org/abs/1303.4928v2,cs.MS,"['cs.MS', 'cs.CE', 'q-bio.QM', '65L09 (Primary) 49M15, 65C20, 65L04, 65L80, 92C42 (Secondary)', 'G.1.6; G.1.7; J.3']",,,[]
"ZKCM: a C++ library for multiprecision matrix computation with
  applications in quantum information",http://arxiv.org/abs/1303.6034v2,2013-03-25T06:18:35Z,2013-04-15T10:46:46Z,"  ZKCM is a C++ library developed for the purpose of multiprecision matrix
computation, on the basis of the GNU MP and MPFR libraries. It provides an
easy-to-use syntax and convenient functions for matrix manipulations including
those often used in numerical simulations in quantum physics. Its extension
library, ZKCM_QC, is developed for simulating quantum computing using the
time-dependent matrix-product-state simulation method. This paper gives an
introduction about the libraries with practical sample programs.
",['\nAkira SaiToh\n'],"19 pages, 5 figures, to appear in Comput. Phys. Comm.; this is an
  extended version of arXiv:1111.3124, v2: typographical corrections only","Comput. Phys. Comm. 184, 2005-2020 (2013)",http://dx.doi.org/10.1016/j.cpc.2013.03.022,cs.MS,"['cs.MS', 'physics.comp-ph', 'quant-ph', '97N80, 81-01', 'G.4']",10.1016/j.cpc.2013.03.022,,[]
Sampling exactly from the normal distribution,http://arxiv.org/abs/1303.6257v2,2013-03-25T19:19:47Z,2014-06-10T09:46:45Z,"  An algorithm for sampling exactly from the normal distribution is given. The
algorithm reads some number of uniformly distributed random digits in a given
base and generates an initial portion of the representation of a normal deviate
in the same base. Thereafter, uniform random digits are copied directly into
the representation of the normal deviate. Thus, in contrast to existing
methods, it is possible to generate normal deviates exactly rounded to any
precision with a mean cost that scales linearly in the precision. The method
performs no extended precision arithmetic, calls no transcendental functions,
and, indeed, uses no floating point arithmetic whatsoever; it uses only simple
integer operations. It can easily be adapted to sample exactly from the
discrete normal distribution whose parameters are rational numbers.
",['\nCharles F. F. Karney\n'],"LaTeX, 8 pages, 1 figure. Revision includes algorithm for sampling
  discrete normal distribution. An implementation of the algorithms is
  available at http://exrandom.sf.net","ACM Trans. Mathematical Software 42(1), 3:1-14 (Jan. 2016)",http://dx.doi.org/10.1145/2710016,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'math.PR', 'G.3']",10.1145/2710016,,[]
"Highly Scalable Multiplication for Distributed Sparse Multivariate
  Polynomials on Many-core Systems",http://arxiv.org/abs/1303.7425v1,2013-03-29T15:47:45Z,2013-03-29T15:47:45Z,"  We present a highly scalable algorithm for multiplying sparse multivariate
polynomials represented in a distributed format. This algo- rithm targets not
only the shared memory multicore computers, but also computers clusters or
specialized hardware attached to a host computer, such as graphics processing
units or many-core coprocessors. The scal- ability on the large number of cores
is ensured by the lacks of synchro- nizations, locks and false-sharing during
the main parallel step.
","['\nMicka\x7fel Gastineau\n', '\nJacques Laskar\n']","15 pages, 5 figures",,http://arxiv.org/abs/1303.7425v1,cs.SC,"['cs.SC', 'astro-ph.IM', 'cs.DC', 'cs.MS']",,,[]
Tiled Algorithms for Matrix Computations on Multicore Architectures,http://arxiv.org/abs/1303.3182v1,2013-03-13T15:04:05Z,2013-03-13T15:04:05Z,"  The current computer architecture has moved towards the multi/many-core
structure. However, the algorithms in the current sequential dense numerical
linear algebra libraries (e.g. LAPACK) do not parallelize well on
multi/many-core architectures. A new family of algorithms, the tile algorithms,
has recently been introduced to circumvent this problem. Previous research has
shown that it is possible to write efficient and scalable tile algorithms for
performing a Cholesky factorization, a (pseudo) LU factorization, and a QR
factorization. The goal of this thesis is to study tiled algorithms in a
multi/many-core setting and to provide new algorithms which exploit the current
architecture to improve performance relative to current state-of-the-art
libraries while maintaining the stability and robustness of these libraries.
",['\nHenricus Bouwmeester\n'],"PhD Thesis, 2012 http://math.ucdenver.edu",,http://arxiv.org/abs/1303.3182v1,cs.NA,"['cs.NA', 'cs.MS', 'math.NA']",,,[]
Update report: LEO-II version 1.5,http://arxiv.org/abs/1303.3761v2,2013-03-15T13:03:40Z,2013-05-14T07:51:31Z,"  Recent improvements of the LEO-II theorem prover are presented. These
improvements include a revised ATP interface, new translations into first-order
logic, rule support for the axiom of choice, detection of defined equality, and
more flexible strategy scheduling.
","['\nChristoph Benzmüller\n', '\nNik Sultana\n']",7 pages,,http://arxiv.org/abs/1303.3761v2,cs.LO,"['cs.LO', 'cs.AI', 'cs.MS', '03B35, 68T15', 'I.2.3; F.4.1']",,,[]
"A Qualitative Comparison of the Suitability of Four Theorem Provers for
  Basic Auction Theory",http://arxiv.org/abs/1303.4193v3,2013-03-18T09:20:41Z,2013-05-23T18:16:52Z,"  Novel auction schemes are constantly being designed. Their design has
significant consequences for the allocation of goods and the revenues
generated. But how to tell whether a new design has the desired properties,
such as efficiency, i.e. allocating goods to those bidders who value them most?
We say: by formal, machine-checked proofs. We investigated the suitability of
the Isabelle, Theorema, Mizar, and Hets/CASL/TPTP theorem provers for
reproducing a key result of auction theory: Vickrey's 1961 theorem on the
properties of second-price auctions. Based on our formalisation experience,
taking an auction designer's perspective, we give recommendations on what
system to use for formalising auctions, and outline further steps towards a
complete auction theory toolbox.
","['\nChristoph Lange\n', '\nMarco B. Caminati\n', '\nManfred Kerber\n', '\nTill Mossakowski\n', '\nColin Rowat\n', '\nMakarius Wenzel\n', '\nWolfgang Windsteiger\n']","Conference on Intelligent Computer Mathematics, 8-12 July, Bath, UK.
  Published as number 7961 in Lecture Notes in Artificial Intelligence,
  Springer",,http://arxiv.org/abs/1303.4193v3,cs.LO,"['cs.LO', 'cs.GT', 'cs.MS', '68T15, 03B35, 68T35, 91B26, 03B70, 03B10, 03B15', 'I.2.3; I.2.4; F.4.1; H.1.2; J.4']",,,[]
"Model-guided Performance Analysis of the Sparse Matrix-Matrix
  Multiplication",http://arxiv.org/abs/1303.1651v2,2013-03-07T11:40:27Z,2013-05-06T07:43:45Z,"  Achieving high efficiency with numerical kernels for sparse matrices is of
utmost importance, since they are part of many simulation codes and tend to use
most of the available compute time and resources. In addition, especially in
large scale simulation frameworks the readability and ease of use of
mathematical expressions are essential components for the continuous
maintenance, modification, and extension of software. In this context, the
sparse matrix-matrix multiplication is of special interest. In this paper we
thoroughly analyze the single-core performance of sparse matrix-matrix
multiplication kernels in the Blaze Smart Expression Template (SET) framework.
We develop simple models for estimating the achievable maximum performance, and
use them to assess the efficiency of our implementations. Additionally, we
compare these kernels with several commonly used SET-based C++ libraries,
which, just as Blaze, aim at combining the requirements of high performance
with an elegant user interface. For the different sparse matrix structures
considered here, we show that our implementations are competitive or faster
than those of the other SET libraries for most problem sizes on a current Intel
multicore processor.
","['\nTobias Scharpff\n', '\nKlaus Iglberger\n', '\nGeorg Hager\n', '\nUlrich Ruede\n']","8 pages, 12 figures. Small corrections w.r.t. previous version",,http://arxiv.org/abs/1303.1651v2,cs.PF,"['cs.PF', 'cs.MS']",,,[]
GURLS: a Least Squares Library for Supervised Learning,http://arxiv.org/abs/1303.0934v1,2013-03-05T05:55:59Z,2013-03-05T05:55:59Z,"  We present GURLS, a least squares, modular, easy-to-extend software library
for efficient supervised learning. GURLS is targeted to machine learning
practitioners, as well as non-specialists. It offers a number state-of-the-art
training strategies for medium and large-scale learning, and routines for
efficient model selection. The library is particularly well suited for
multi-output problems (multi-category/multi-label). GURLS is currently
available in two independent implementations: Matlab and C++. It takes
advantage of the favorable properties of regularized least squares algorithm to
exploit advanced tools in linear algebra. Routines to handle computations with
very large matrices by means of memory-mapped storage and distributed task
execution are available. The package is distributed under the BSD licence and
is available for download at https://github.com/CBCL/GURLS.
","['\nAndrea Tacchetti\n', '\nPavan K Mallapragada\n', '\nMatteo Santoro\n', '\nLorenzo Rosasco\n']",,,http://arxiv.org/abs/1303.0934v1,cs.LG,"['cs.LG', 'cs.AI', 'cs.MS']",,,[]
A framework for automated PDE-constrained optimisation,http://arxiv.org/abs/1302.3894v1,2013-02-15T21:30:51Z,2013-02-15T21:30:51Z,"  A generic framework for the solution of PDE-constrained optimisation problems
based on the FEniCS system is presented. Its main features are an intuitive
mathematical interface, a high degree of automation, and an efficient
implementation of the generated adjoint model. The framework is based upon the
extension of a domain-specific language for variational problems to cleanly
express complex optimisation problems in a compact, high-level syntax. For
example, optimisation problems constrained by the time-dependent Navier-Stokes
equations can be written in tens of lines of code. Based on this high-level
representation, the framework derives the associated adjoint equations in the
same domain-specific language, and uses the FEniCS code generation technology
to emit parallel optimised low-level C++ code for the solution of the forward
and adjoint systems. The functional and gradient information so computed is
then passed to the optimisation algorithm to update the parameter values. This
approach works both for steady-state as well as transient, and for linear as
well as nonlinear governing PDEs and a wide range of functionals and control
parameters. We demonstrate the applicability and efficiency of this approach on
classical textbook optimisation problems and advanced examples.
","['\nS. W. Funke\n', '\nP. E. Farrell\n']",,,http://arxiv.org/abs/1302.3894v1,cs.MS,"['cs.MS', 'G.4; G.1.8; G.1.6; I.6.5; J.2; J.6; D.2']",,,[]
Streaming Data from HDD to GPUs for Sustained Peak Performance,http://arxiv.org/abs/1302.4332v1,2013-02-18T16:03:08Z,2013-02-18T16:03:08Z,"  In the context of the genome-wide association studies (GWAS), one has to
solve long sequences of generalized least-squares problems; such a task has two
limiting factors: execution time --often in the range of days or weeks-- and
data management --data sets in the order of Terabytes. We present an algorithm
that obviates both issues. By pipelining the computation, and thanks to a
sophisticated transfer strategy, we stream data from hard disk to main memory
to GPUs and achieve sustained peak performance; with respect to a
highly-optimized CPU implementation, our algorithm shows a speedup of 2.6x.
Moreover, the approach lends itself to multiple GPUs and attains almost perfect
scalability. When using 4 GPUs, we observe speedups of 9x over the
aforementioned implementation, and 488x over a widespread biology library.
","['\nLucas Beyer\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",,,http://arxiv.org/abs/1302.4332v1,cs.DC,"['cs.DC', 'cs.CE', 'cs.MS', 'q-bio.GN']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
"Q#, a quantum computation package for the .NET platform",http://arxiv.org/abs/1302.5133v1,2013-02-20T21:37:43Z,2013-02-20T21:37:43Z,"  Quantum computing is a promising approach of computation that is based on
equations from Quantum Mechanics. A simulator for quantum algorithms must be
capable of performing heavy mathematical matrix transforms. The design of the
simulator itself takes one of three forms: Quantum Turing Machine, Network
Model or circuit model of connected gates or, Quantum Programming Language,
yet, some simulators are hybrid. We studied previous simulators and then we
adopt features from three simulators of different implementation languages,
different paradigms, and for different platforms. They are Quantum Computing
Language (QCL), QUASI, and Quantum Optics Toolbox for Matlab 5. Our simulator
for quantum algorithms takes the form of a package or a programming library for
Quantum computing, with a case study showing the ability of using it in the
circuit model. The .NET is a promising platform for computing. VB.NET is an
easy, high productive programming language with the full power and
functionality provided by the .NET framework. It is highly readable, writeable,
and flexible language, compared to another language such as C#.NET in many
aspects. We adopted VB.NET although its shortage in built-in mathematical
complex and matrix operations, compared to Matlab. For implementation, we first
built a mathematical core of matrix operations. Then, we built a quantum core
which contains: basic qubits and register operations, basic 1D, 2D, and 3D
quantum gates, and multi-view visualization of the quantum state, then a window
for demos to show you how to use and get the most of the package.
","['\nA. S. Tolba\n', '\nM. Z. Rashad\n', '\nM. A. El-Dosuky\n']",,,http://arxiv.org/abs/1302.5133v1,cs.ET,"['cs.ET', 'cs.MS', 'cs.PL', 'quant-ph']",,,[]
Kleene Algebra with Tests and Coq Tools for While Programs,http://arxiv.org/abs/1302.1737v1,2013-02-07T13:15:45Z,2013-02-07T13:15:45Z,"  We present a Coq library about Kleene algebra with tests, including a proof
of their completeness over the appropriate notion of languages, a decision
procedure for their equational theory, and tools for exploiting hypotheses of a
particular shape in such a theory. Kleene algebra with tests make it possible
to represent if-then-else statements and while loops in most imperative
programming languages. They were actually introduced by Kozen as an alternative
to propositional Hoare logic. We show how to exploit the corresponding Coq
tools in the context of program verification by proving equivalences of while
programs, correctness of some standard compiler optimisations, Hoare rules for
partial correctness, and a particularly challenging equivalence of flowchart
schemes.
",['\nDamien Pous\nLIP\n'],16+3 pages,,http://arxiv.org/abs/1302.1737v1,cs.LO,"['cs.LO', 'cs.MS', 'cs.PL']",,,['LIP']
"RandFile package for Mathematica for accessing file-based sources of
  randomness",http://arxiv.org/abs/1302.2738v2,2013-02-12T09:38:46Z,2015-03-15T10:03:45Z,"  We present a package for Mathematica computer algebra system which allows the
exploitation of local files as sources of random data. We provide the
description of the package and illustrate its usage by showing some examples.
We also compare the provided functionality with alternative sources of
randomness, namely a built-in pseudo-random generator and the package for
accessing hardware true random number generators.
","['\nJ. A. Miszczak\n', '\nM. Wahl\n']","16 pages, 4 figures, 3 tables, improved version of the software
  available from http://www.iitis.pl/~miszczak/rand_file/",,http://arxiv.org/abs/1302.2738v2,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'physics.data-an', 'quant-ph', 'G.3; G.4']",,,[]
"Exploiting Symmetry in Tensors for High Performance: Multiplication with
  Symmetric Tensors",http://arxiv.org/abs/1301.7744v3,2013-01-31T20:39:44Z,2014-04-09T21:40:55Z,"  Symmetric tensor operations arise in a wide variety of computations. However,
the benefits of exploiting symmetry in order to reduce storage and computation
is in conflict with a desire to simplify memory access patterns. In this paper,
we propose a blocked data structure (Blocked Compact Symmetric Storage) wherein
we consider the tensor by blocks and store only the unique blocks of a
symmetric tensor. We propose an algorithm-by-blocks, already shown of benefit
for matrix computations, that exploits this storage format by utilizing a
series of temporary tensors to avoid redundant computation. Further, partial
symmetry within temporaries is exploited to further avoid redundant storage and
redundant computation. A detailed analysis shows that, relative to storing and
computing with tensors without taking advantage of symmetry and partial
symmetry, storage requirements are reduced by a factor of $ O\left( m! \right)$
and computational requirements by a factor of $O\left( (m+1)!/2^m \right)$,
where $ m $ is the order of the tensor. However, as the analysis shows, care
must be taken in choosing the correct block size to ensure these storage and
computational benefits are achieved (particularly for low-order tensors). An
implementation demonstrates that storage is greatly reduced and the complexity
introduced by storing and computing with tensors by blocks is manageable.
Preliminary results demonstrate that computational time is also reduced. The
paper concludes with a discussion of how insights in this paper point to
opportunities for generalizing recent advances in the domain of linear algebra
libraries to the field of multi-linear computation.
","['\nMartin D. Schatz\n', '\nTze Meng Low\n', '\nRobert A. van de Geijn\n', '\nTamara G. Kolda\n']",,"SIAM Journal on Scientific Computing, Vol. 36, No. 5, pp.
  C453-C479, September 2014",http://dx.doi.org/10.1137/130907215,math.NA,"['math.NA', 'cs.MS', '15-02 (Primary)']",10.1137/130907215,,[]
A Unified Software Framework for Empirical Gramians,http://arxiv.org/abs/1301.6879v5,2013-01-29T10:05:37Z,2013-07-15T15:12:32Z,"  A common approach in model reduction is balanced truncation, which is based
on gramian matrices classifiying certain attributes of states or parameters of
a given dynamic system. Initially restricted to linear systems, the empirical
gramians not only extended this concept to nonlinear systems, but also provide
a uniform computational method. This work introduces a unified software
framework supplying routines for six types of empirical gramians. The gramian
types will be discussed and applied in a model reduction framework for
multiple-input-multiple-output (MIMO) systems.
","['\nChristian Himpe\n', '\nMario Ohlberger\n']",Preprint,,http://dx.doi.org/10.1155/2013/365909,math.OC,"['math.OC', 'cs.MS', 'cs.SY', 'math.DS', '93c99', 'G.1.3']",10.1155/2013/365909,,[]
On the effects of scaling on the performance of Ipopt,http://arxiv.org/abs/1301.7283v1,2013-01-30T16:52:05Z,2013-01-30T16:52:05Z,"  The open-source nonlinear solver Ipopt (https://projects.coin-or.org/Ipopt)
is a widely-used software package for the solution of large-scale non-linear
optimization problems. At its heart, it employs a third-party linear solver to
solve a series of sparse symmetric indefinite systems. The speed, accuracy and
robustness of the chosen linear solver is critical to the overall performance
of Ipopt. In some instances, it can be beneficial to scale the linear system
before it is solved.
  In this paper, different scaling algorithms are employed within Ipopt with a
new linear solver HSL_MA97 from the HSL mathematical software library
(http://www.hsl.rl.ac.uk). An extensive collection of problems from the CUTEr
test set (http://www.cuter.rl.ac.uk) is used to illustrate the effects of
scaling.
","['\nJ. D. Hogg\n', '\nJ. A. Scott\n']",,,http://arxiv.org/abs/1301.7283v1,math.OC,"['math.OC', 'cs.MS', 'math.NA']",,,[]
"FEAST as a Subspace Iteration Eigensolver Accelerated by Approximate
  Spectral Projection",http://arxiv.org/abs/1302.0432v4,2013-02-02T22:30:20Z,2014-01-20T02:18:26Z,"  The calculation of a segment of eigenvalues and their corresponding
eigenvectors of a Hermitian matrix or matrix pencil has many applications. A
new density-matrix-based algorithm has been proposed recently and a software
package FEAST has been developed. The density-matrix approach allows FEAST's
implementation to exploit a key strength of modern computer architectures,
namely, multiple levels of parallelism. Consequently, the software package has
been well received, especially in the electronic structure community.
Nevertheless, theoretical analysis of FEAST has lagged. For instance, the FEAST
algorithm has not been proven to converge. This paper offers a detailed
numerical analysis of FEAST. In particular, we show that the FEAST algorithm
can be understood as an accelerated subspace iteration algorithm in conjunction
with the Rayleigh-Ritz procedure. The novelty of FEAST lies in its accelerator
which is a rational matrix function that approximates the spectral projector
onto the eigenspace in question. Analysis of the numerical nature of this
approximate spectral projector and the resulting subspaces generated in the
FEAST algorithm establishes the algorithm's convergence. This paper shows that
FEAST is resilient against rounding errors and establishes properties that can
be leveraged to enhance the algorithm's robustness. Finally, we propose an
extension of FEAST to handle non-Hermitian problems and suggest some future
research directions.
","['\nPing Tak Peter Tang\n', '\nEric Polizzi\n']",,,http://arxiv.org/abs/1302.0432v4,math.NA,"['math.NA', 'cs.MS', 'cs.NA']",,,[]
Simultaneous computation of the row and column rank profiles,http://arxiv.org/abs/1301.4438v1,2013-01-18T17:23:01Z,2013-01-18T17:23:01Z,"  Gaussian elimination with full pivoting generates a PLUQ matrix
decomposition. Depending on the strategy used in the search for pivots, the
permutation matrices can reveal some information about the row or the column
rank profiles of the matrix. We propose a new pivoting strategy that makes it
possible to recover at the same time both row and column rank profiles of the
input matrix and of any of its leading sub-matrices. We propose a
rank-sensitive and quad-recursive algorithm that computes the latter PLUQ
triangular decomposition of an m \times n matrix of rank r in O(mnr^{\omega-2})
field operations, with \omega the exponent of matrix multiplication. Compared
to the LEU decomposition by Malashonock, sharing a similar recursive structure,
its time complexity is rank sensitive and has a lower leading constant. Over a
word size finite field, this algorithm also improveLs the practical efficiency
of previously known implementations.
","['\nJean-Guillaume Dumas\nLJK\n', ""\nClément Pernet\nINRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble\n"", ""\nZiad Sultan\nLJK, INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble\n""]",,"ISSAC 2013, Boston, MA : \'Etats-Unis (2013)",http://arxiv.org/abs/1301.4438v1,cs.NA,"['cs.NA', 'cs.MS']",,,"['LJK', ""INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble"", ""LJK, INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble""]"
Factorization of Z-homogeneous polynomials in the First (q)-Weyl Algebra,http://arxiv.org/abs/1302.5674v3,2013-01-20T18:37:47Z,2016-02-18T16:04:15Z,"  We present algorithms to factorize weighted homogeneous elements in the first
polynomial Weyl algebra and $q$-Weyl algebra, which are both viewed as a
$\mathbb{Z}$-graded rings. We show, that factorization of homogeneous
polynomials can be almost completely reduced to commutative univariate
factorization over the same base field with some additional uncomplicated
combinatorial steps. This allows to deduce the complexity of our algorithms in
detail. Furthermore, we will show for homogeneous polynomials that
irreducibility in the polynomial first Weyl algebra also implies irreducibility
in the rational one, which is of interest for practical reasons. We report on
our implementation in the computer algebra system \textsc{Singular}. It
outperforms for homogeneous polynomials currently available implementations
dealing with factorization in the first Weyl algebra both in speed and elegancy
of the results.
","['\nAlbert Heinle\n', '\nViktor Levandovskyy\n']","26 pages, Singular implementation, 2 algorithms, 1 figure, 2 tables",,http://arxiv.org/abs/1302.5674v3,cs.SC,"['cs.SC', 'cs.MS']",,,[]
YGGDRASIL - A Statistical Package for Learning Split Models,http://arxiv.org/abs/1301.3863v1,2013-01-16T15:50:42Z,2013-01-16T15:50:42Z,"  There are two main objectives of this paper. The first is to present a
statistical framework for models with context specific independence structures,
i.e., conditional independences holding only for sepcific values of the
conditioning variables. This framework is constituted by the class of split
models. Split models are extension of graphical models for contigency tables
and allow for a more sophisticiated modelling than graphical models. The
treatment of split models include estimation, representation and a Markov
property for reading off those independencies holding in a specific context.
The second objective is to present a software package named YGGDRASIL which is
designed for statistical inference in split models, i.e., for learning such
models on the basis of data.
",['\nSoren Hojsgaard\n'],"Appears in Proceedings of the Sixteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2000)",,http://arxiv.org/abs/1301.3863v1,cs.AI,"['cs.AI', 'cs.MS', 'stat.ME']",,,[]
"NIFTY - Numerical Information Field Theory - a versatile Python library
  for signal inference",http://arxiv.org/abs/1301.4499v2,2013-01-18T21:00:01Z,2013-06-05T17:24:59Z,"  NIFTY, ""Numerical Information Field Theory"", is a software package designed
to enable the development of signal inference algorithms that operate
regardless of the underlying spatial grid and its resolution. Its
object-oriented framework is written in Python, although it accesses libraries
written in Cython, C++, and C for efficiency. NIFTY offers a toolkit that
abstracts discretized representations of continuous spaces, fields in these
spaces, and operators acting on fields into classes. Thereby, the correct
normalization of operations on fields is taken care of automatically without
concerning the user. This allows for an abstract formulation and programming of
inference algorithms, including those derived within information field theory.
Thus, NIFTY permits its user to rapidly prototype algorithms in 1D, and then
apply the developed code in higher-dimensional settings of real world problems.
The set of spaces on which NIFTY operates comprises point sets, n-dimensional
regular grids, spherical spaces, their harmonic counterparts, and product
spaces constructed as combinations of those. The functionality and diversity of
the package is demonstrated by a Wiener filter code example that successfully
runs without modification regardless of the space on which the inference
problem is defined.
","['\nMarco Selig\n', '\nMichael R. Bell\n', '\nHenrik Junklewitz\n', '\nNiels Oppermann\n', '\nMartin Reinecke\n', '\nMaksim Greiner\n', '\nCarlos Pachajoa\n', '\nTorsten A. Enßlin\n']","9 pages, 3 tables, 4 figures, accepted by Astronomy & Astrophysics;
  refereed version, 1 figure added, results unchanged",,http://dx.doi.org/10.1051/0004-6361/201321236,astro-ph.IM,"['astro-ph.IM', 'cs.IT', 'cs.MS', 'math-ph', 'math.IT', 'math.MP', 'physics.data-an', 'stat.CO']",10.1051/0004-6361/201321236,,[]
Improved QFT algorithm for power-of-two FFT,http://arxiv.org/abs/1301.0763v1,2013-01-04T16:25:56Z,2013-01-04T16:25:56Z,"  This paper shows that it is possible to improve the computational cost, the
memory requirements and the accuracy of Quick Fourier Transform (QFT) algorithm
for power-of-two FFT (Fast Fourier Transform) just introducing a slight
modification in this algorithm. The new algorithm requires the same number of
additions and multiplications of split-radix 3add/3mul, one of the most
appreciated FFT algorithms appeared in the literature, but employing only half
of the trigonometric constants. These results can elevate the QFT approach to
the level of most used FFT procedures. A new quite general way to describe FFT
algorithms, based on signal types and on a particular notation, is also
proposed and used, highligting its advantages.
",['\nLorenzo Pasquini\n'],,,http://arxiv.org/abs/1301.0763v1,cs.DS,"['cs.DS', 'cs.MS', 'F.2.1, G.4']",,,[]
"Parallel Algorithms for Constructing Data Structures for Fast Multipole
  Methods",http://arxiv.org/abs/1301.1704v1,2013-01-08T21:57:20Z,2013-01-08T21:57:20Z,"  We present efficient algorithms to build data structures and the lists needed
for fast multipole methods. The algorithms are capable of being efficiently
implemented on both serial, data parallel GPU and on distributed architectures.
With these algorithms it is possible to map the FMM efficiently on to the GPU
or distributed heterogeneous CPU-GPU systems. Further, in dynamic problems, as
the distribution of the particles change, the reduced cost of building the data
structures improves performance. Using these algorithms, we demonstrate example
high fidelity simulations with large problem sizes by using FMM on both single
and multiple heterogeneous computing facilities equipped with multi-core CPU
and many-core GPUs.
","['\nQi Hu\n', '\nNail A. Gumerov\n', '\nRamani Duraiswami\n']",,,http://arxiv.org/abs/1301.1704v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
"Object-oriented implementations of the MPDATA advection equation solver
  in C++, Python and Fortran",http://arxiv.org/abs/1301.1334v2,2013-01-07T20:59:13Z,2013-03-19T12:59:17Z,"  Three object-oriented implementations of a prototype solver of the advection
equation are introduced. The presented programs are based on Blitz++ (C++),
NumPy (Python), and Fortran's built-in array containers. The solvers include an
implementation of the Multidimensional Positive-Definite Advective Transport
Algorithm (MPDATA). The introduced codes exemplify how the application of
object-oriented programming (OOP) techniques allows to reproduce the
mathematical notation used in the literature within the program code. A
discussion on the tradeoffs of the programming language choice is presented.
The main angles of comparison are code brevity and syntax clarity (and hence
maintainability and auditability) as well as performance. In the case of
Python, a significant performance gain is observed when switching from the
standard interpreter (CPython) to the PyPy implementation of Python. Entire
source code of all three implementations is embedded in the text and is
licensed under the terms of the GNU GPL license.
","['\nSylwester Arabas\n', '\nDorota Jarecka\n', '\nAnna Jaruga\n', '\nMaciej Fijałkowski\n']",,"Scientific Programming 22, 201-222 (2014)",http://dx.doi.org/10.3233/SPR-140379,physics.comp-ph,"['physics.comp-ph', 'cs.MS', 'physics.ao-ph']",10.3233/SPR-140379,,[]
A block MINRES algorithm based on the banded Lanczos method,http://arxiv.org/abs/1301.2102v3,2013-01-10T12:22:23Z,2014-05-13T13:29:05Z,"  We develop a block minimum residual (MINRES) algorithm for symmetric
indefinite matrices. This version is built upon the band Lanczos method that
generates one basis vector of the block Krylov subspace per iteration rather
than a whole block as in the block Lanczos process. However, we modify the
method such that the most expensive operations are still performed in a block
fashion. The benefit of using the band Lanczos method is that one can detect
breakdowns from scalar values arising in the computation, allowing for a
handling of breakdown which is straightforward to implement.
  We derive a progressive formulation of the MINRES method based on the band
Lanczos process and give some implementation details. Specifically, a simple
reordering of the steps allows us to perform many of the operations at the
block level in order to take advantage of communication efficiencies offered by
the block Lanczos process. This is an important concern in the context of
next-generation super computing applications.
  We also present a technique allowing us to maintain the block size by
replacing dependent Lanczos vectors with pregenerated random vectors whose
orthogonality against all Lanczos vectors is maintained. Numerical results
illustrate the performance on some sample problems. We present experiments that
show how the relationship between right-hand sides can effect the performance
of the method.
",['\nKirk M. Soodhalter\n'],"20 Pages, 8 figures, 1 Algorithm, Revision based on reviewer comments",,http://dx.doi.org/10.1007/s11075-014-9907-z,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F10']",10.1007/s11075-014-9907-z,,[]
Programming CUDA and OpenCL: A Case Study Using Modern C++ Libraries,http://arxiv.org/abs/1212.6326v2,2012-12-27T08:56:00Z,2013-04-26T07:50:28Z,"  We present a comparison of several modern C++ libraries providing high-level
interfaces for programming multi- and many-core architectures on top of CUDA or
OpenCL. The comparison focuses on the solution of ordinary differential
equations and is based on odeint, a framework for the solution of systems of
ordinary differential equations. Odeint is designed in a very flexible way and
may be easily adapted for effective use of libraries such as Thrust, MTL4,
VexCL, or ViennaCL, using CUDA or OpenCL technologies. We found that CUDA and
OpenCL work equally well for problems of large sizes, while OpenCL has higher
overhead for smaller problems. Furthermore, we show that modern high-level
libraries allow to effectively use the computational resources of many-core
GPUs or multi-core CPUs without much knowledge of the underlying technologies.
","['\nDenis Demidov\n', '\nKarsten Ahnert\n', '\nKarl Rupp\n', '\nPeter Gottschling\n']","21 pages, 4 figures, submitted to SIAM Journal of Scientific
  Computing and accepted",,http://dx.doi.org/10.1137/120903683,cs.MS,"['cs.MS', 'cs.DC', 'physics.comp-ph']",10.1137/120903683,,[]
Automated verification of termination certificates,http://arxiv.org/abs/1212.2350v1,2012-12-11T09:24:46Z,2012-12-11T09:24:46Z,"  In order to increase user confidence, many automated theorem provers provide
certificates that can be independently verified. In this paper, we report on
our progress in developing a standalone tool for checking the correctness of
certificates for the termination of term rewrite systems, and formally proving
its correctness in the proof assistant Coq. To this end, we use the extraction
mechanism of Coq and the library on rewriting theory and termination called
CoLoR.
","['\nFrédéric Blanqui\nLIAMA, LCS\n', '\nKim Quyen Ly\nLIAMA, LCS\n']",,15th National Symposium of Selected ICT Problems (2012),http://arxiv.org/abs/1212.2350v1,cs.LO,"['cs.LO', 'cs.MS', 'cs.SE']",,,"['LIAMA, LCS', 'LIAMA, LCS']"
"A modular framework for randomness extraction based on Trevisan's
  construction",http://arxiv.org/abs/1212.0520v1,2012-12-03T20:20:02Z,2012-12-03T20:20:02Z,"  Informally, an extractor delivers perfect randomness from a source that may
be far away from the uniform distribution, yet contains some randomness. This
task is a crucial ingredient of any attempt to produce perfectly random
numbers---required, for instance, by cryptographic protocols, numerical
simulations, or randomised computations. Trevisan's extractor raised
considerable theoretical interest not only because of its data parsimony
compared to other constructions, but particularly because it is secure against
quantum adversaries, making it applicable to quantum key distribution.
  We discuss a modular, extensible and high-performance implementation of the
construction based on various building blocks that can be flexibly combined to
satisfy the requirements of a wide range of scenarios. Besides quantitatively
analysing the properties of many combinations in practical settings, we improve
previous theoretical proofs, and give explicit results for non-asymptotic
cases. The self-contained description does not assume familiarity with
extractors.
","['\nWolfgang Mauerer\n', '\nChristopher Portmann\n', '\nVolkher B. Scholz\n']","21 pages, 15 figures. Source code is available under GPLv2+. Comments
  welcome",,http://arxiv.org/abs/1212.0520v1,cs.IT,"['cs.IT', 'cs.MS', 'math.IT', 'quant-ph']",,,[]
"Confusion of Tagged Perturbations in Forward Automatic Differentiation
  of Higher-Order Functions",http://arxiv.org/abs/1211.4892v4,2012-11-20T22:08:31Z,2019-06-29T20:44:41Z,"  Forward Automatic Differentiation (AD) is a technique for augmenting programs
to compute derivatives. The essence of Forward AD is to attach perturbations to
each number, and propagate these through the computation. When derivatives are
nested, the distinct derivative calculations, and their associated
perturbations, must be distinguished. This is typically accomplished by
creating a unique tag for each derivative calculation, tagging the
perturbations, and overloading the arithmetic operators. We exhibit a subtle
bug, present in fielded implementations, in which perturbations are confused
despite the tagging machinery. The essence of the bug is this: each invocation
of a derivative creates a unique tag but a unique tag is needed for each
derivative calculation. When taking derivatives of higher-order functions,
these need not correspond! The derivative of a higher-order function $f$ that
returns a function $g$ will be a function $f'$ that returns a function
$\bar{g}$ that performs a derivative calculation. A single invocation of $f'$
will create a single fresh tag but that same tag will be used for each
derivative calculation resulting from an invocation of $\bar{g}$. This
situation arises when taking derivatives of curried functions. Two potential
solutions are presented, and their serious deficiencies discussed. One requires
eta expansion to delay the creation of fresh tags from the invocation of $f'$
to the invocation of $\bar{g}$, which can be difficult or even impossible in
some circumstances. The other requires $f'$ to wrap $\bar{g}$ with tag
renaming, which is difficult to implement without violating the desirable
complexity properties of forward AD.
","['\nOleksandr Manzyuk\n', '\nBarak A. Pearlmutter\n', '\nAlexey Andreyevich Radul\n', '\nDavid R. Rush\n', '\nJeffrey Mark Siskind\n']",,,http://dx.doi.org/10.1017/S095679681900008X,cs.SC,"['cs.SC', 'cs.MS', 'math.DG']",10.1017/S095679681900008X,,[]
Application-tailored Linear Algebra Algorithms: A search-based Approach,http://arxiv.org/abs/1211.5904v1,2012-11-26T10:15:29Z,2012-11-26T10:15:29Z,"  In this paper, we tackle the problem of automatically generating algorithms
for linear algebra operations by taking advantage of problem-specific
knowledge. In most situations, users possess much more information about the
problem at hand than what current libraries and computing environments accept;
evidence shows that if properly exploited, such information leads to
uncommon/unexpected speedups. We introduce a knowledge-aware linear algebra
compiler that allows users to input matrix equations together with properties
about the operands and the problem itself; for instance, they can specify that
the equation is part of a sequence, and how successive instances are related to
one another. The compiler exploits all this information to guide the generation
of algorithms, to limit the size of the search space, and to avoid redundant
computations. We applied the compiler to equations arising as part of
sensitivity and genome studies; the algorithms produced exhibit, respectively,
100- and 1000-fold speedups.
","['\nDiego Fabregat-Traver\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",,,http://arxiv.org/abs/1211.5904v1,cs.MS,"['cs.MS', 'cs.NA', 'cs.PL']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
A multi-scale code for flexible hybrid simulations,http://arxiv.org/abs/1211.2075v1,2012-11-09T08:55:53Z,2012-11-09T08:55:53Z,"  Multi-scale computer simulations combine the computationally efficient
classical algorithms with more expensive but also more accurate ab-initio
quantum mechanical algorithms. This work describes one implementation of
multi-scale computations using the Atomistic Simulation Environment (ASE). This
implementation can mix classical codes like LAMMPS and the Density Functional
Theory-based GPAW. Any combination of codes linked via the ASE interface
however can be mixed. We also introduce a framework to easily add classical
force fields calculators for ASE using LAMMPS, which also allows harnessing the
full performance of classical-only molecular dynamics. Our work makes it
possible to combine different simulation codes, quantum mechanical or
classical, with great ease and minimal coding effort.
","['\nL. Leukkunen\n', '\nT. Verho\n', '\nO. Lopez-Acevedo\n']",,,http://dx.doi.org/10.1109/MCSE.2013.51,physics.comp-ph,"['physics.comp-ph', 'cs.MS']",10.1109/MCSE.2013.51,,[]
GPU-accelerated generation of correctly-rounded elementary functions,http://arxiv.org/abs/1211.3056v2,2012-11-13T17:28:03Z,2013-06-05T11:51:55Z,"  The IEEE 754-2008 standard recommends the correct rounding of some elementary
functions. This requires to solve the Table Maker's Dilemma which implies a
huge amount of CPU computation time. We consider in this paper accelerating
such computations, namely Lefe'vre algorithm on Graphics Processing Units
(GPUs) which are massively parallel architectures with a partial SIMD execution
(Single Instruction Multiple Data). We first propose an analysis of the
Lef\`evre hard-to-round argument search using the concept of continued
fractions. We then propose a new parallel search algorithm much more efficient
on GPU thanks to its more regular control flow. We also present an efficient
hybrid CPU-GPU deployment of the generation of the polynomial approximations
required in Lef\`evre algorithm. In the end, we manage to obtain overall
speedups up to 53.4x on one GPU over a sequential CPU execution, and up to 7.1x
over a multi-core CPU, which enable a much faster solving of the Table Maker's
Dilemma for the double precision format.
","['\nPierre Fortin\nLIP6\n', '\nMourad Gouicem\nLIP6\n', '\nStef Graillat\nLIP6\n']",,,http://arxiv.org/abs/1211.3056v2,cs.MS,"['cs.MS', 'cs.DC', 'cs.NA']",,,"['LIP6', 'LIP6', 'LIP6']"
"A Bernstein Polynomial Collocation Method for the Solution of Elliptic
  Boundary Value Problems",http://arxiv.org/abs/1211.3567v1,2012-11-15T10:38:46Z,2012-11-15T10:38:46Z,"  In this article, a formulation of a point-collocation method in which the
unknown function is approximated using global expansion in tensor product
Bernstein polynomial basis is presented. Bernstein polynomials used in this
study are defined over general interval [a,b]. Method incorporates several
ideas that enable higher numerical efficiency compared to Bernstein polynomial
methods that have been previously presented. The approach is illustrated by a
solution of Poisson, Helmholtz and Biharmonic equations with Dirichlet and
Neumann type boundary conditions. Comparisons with analytical solutions are
given to demonstrate the accuracy and convergence properties of the current
procedure. The method is implemented in an open-source code, and a library for
manipulation of Bernstein polynomials bernstein-poly, developed by the authors.
","['\nNikola Mirkov\n', '\nBosko Rasuo\n']","21 page, 12 figures, 5tables, Python code listings in the Appendix",,http://arxiv.org/abs/1211.3567v1,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'physics.comp-ph']",,,[]
"Unified Form Language: A domain-specific language for weak formulations
  of partial differential equations",http://arxiv.org/abs/1211.4047v2,2012-11-16T21:56:02Z,2013-04-25T20:18:09Z,"  We present the Unified Form Language (UFL), which is a domain-specific
language for representing weak formulations of partial differential equations
with a view to numerical approximation. Features of UFL include support for
variational forms and functionals, automatic differentiation of forms and
expressions, arbitrary function space hierarchies for multi-field problems,
general differential operators and flexible tensor algebra. With these
features, UFL has been used to effortlessly express finite element methods for
complex systems of partial differential equations in near-mathematical
notation, resulting in compact, intuitive and readable programs. We present in
this work the language and its construction. An implementation of UFL is freely
available as an open-source software library. The library generates abstract
syntax tree representations of variational problems, which are used by other
software libraries to generate concrete low-level implementations. Some
application examples are presented and libraries that support UFL are
highlighted.
","['\nMartin S. Alnaes\n', '\nAnders Logg\n', '\nKristian B. Oelgaard\n', '\nMarie E. Rognes\n', '\nGarth N. Wells\n']",To appear in ACM Transactions on Mathematical Software,,http://arxiv.org/abs/1211.4047v2,cs.MS,"['cs.MS', 'cs.NA', 'cs.SC', '97N80', 'G.4; G.1.8; G.1.4']",,,[]
High-Order Discontinuous Galerkin Methods by GPU Metaprogramming,http://arxiv.org/abs/1211.0582v1,2012-11-02T23:55:22Z,2012-11-02T23:55:22Z,"  Discontinuous Galerkin (DG) methods for the numerical solution of partial
differential equations have enjoyed considerable success because they are both
flexible and robust: They allow arbitrary unstructured geometries and easy
control of accuracy without compromising simulation stability. In a recent
publication, we have shown that DG methods also adapt readily to execution on
modern, massively parallel graphics processors (GPUs). A number of qualities of
the method contribute to this suitability, reaching from locality of reference,
through regularity of access patterns, to high arithmetic intensity. In this
article, we illuminate a few of the more practical aspects of bringing DG onto
a GPU, including the use of a Python-based metaprogramming infrastructure that
was created specifically to support DG, but has found many uses across all
disciplines of computational science.
","['\nAndreas Klöckner\n', '\nTimothy Warburton\n', '\nJan S. Hesthaven\n']","To appear as part of ""GPU Solutions to Multi-scale Problems in
  Science and Engineering"", http://books.google.com/books?vid=9783642164040","ISBN 9783642164040, Springer, 2012",http://arxiv.org/abs/1211.0582v1,cs.MS,"['cs.MS', 'math.NA']",,,[]
"Computing Petaflops over Terabytes of Data: The Case of Genome-Wide
  Association Studies",http://arxiv.org/abs/1210.7683v1,2012-10-29T14:58:03Z,2012-10-29T14:58:03Z,"  In many scientific and engineering applications, one has to solve not one but
a sequence of instances of the same problem. Often times, the problems in the
sequence are linked in a way that allows intermediate results to be reused. A
characteristic example for this class of applications is given by the
Genome-Wide Association Studies (GWAS), a widely spread tool in computational
biology. GWAS entails the solution of up to trillions ($10^{12}$) of correlated
generalized least-squares problems, posing a daunting challenge: the
performance of petaflops ($10^{15}$ floating-point operations) over terabytes
of data.
  In this paper, we design an algorithm for performing GWAS on multi-core
architectures. This is accomplished in three steps. First, we show how to
exploit the relation among successive problems, thus reducing the overall
computational complexity. Then, through an analysis of the required data
transfers, we identify how to eliminate any overhead due to input/output
operations. Finally, we study how to decompose computation into tasks to be
distributed among the available cores, to attain high performance and
scalability. With our algorithm, a GWAS that currently requires the use of a
supercomputer may now be performed in matter of hours on a single multi-core
node.
  The discussion centers around the methodology to develop the algorithm rather
than the specific application. We believe the paper contributes valuable
guidelines of general applicability for computational scientists on how to
develop and optimize numerical algorithms.
","['\nDiego Fabregat-Traver\nAICES, RWTH Aachen\n', '\nPaolo Bientinesi\nAICES, RWTH Aachen\n']",,,http://arxiv.org/abs/1210.7683v1,cs.MS,"['cs.MS', 'cs.CE', 'cs.PF', 'q-bio.GN', 'q-bio.QM']",,,"['AICES, RWTH Aachen', 'AICES, RWTH Aachen']"
A New Recursive Algorithm For Inverting A General Comrade Matrix,http://arxiv.org/abs/1210.4662v1,2012-10-17T08:09:08Z,2012-10-17T08:09:08Z,"  In this paper, the author present a reliable symbolic computational algorithm
for inverting a general comrade matrix by using parallel computing along with
recursion. The computational cost of our algorithm is O(n^2). The algorithm is
implementable to the Computer Algebra System (CAS) such as MAPLE, MATLAB and
MATHEMATICA. Three examples are presented for the sake of illustration.
",['\nA. A. Karawia\n'],,,http://arxiv.org/abs/1210.4662v1,cs.SC,"['cs.SC', 'cs.MS', '15A15, 15A23, 68W30, 11Y05, 33F10, F.2.1, G.1.0']",,,[]
MLPACK: A Scalable C++ Machine Learning Library,http://arxiv.org/abs/1210.6293v1,2012-10-23T17:15:03Z,2012-10-23T17:15:03Z,"  MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning
library released in late 2011 offering both a simple, consistent API accessible
to novice users and high performance and flexibility to expert users by
leveraging modern features of C++. MLPACK provides cutting-edge algorithms
whose benchmarks exhibit far better performance than other leading machine
learning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available
at http://www.mlpack.org.
","['\nRyan R. Curtin\n', '\nJames R. Cline\n', '\nN. P. Slagle\n', '\nWilliam B. March\n', '\nParikshit Ram\n', '\nNishant A. Mehta\n', '\nAlexander G. Gray\n']",Submitted to JMLR MLOSS (http://jmlr.csail.mit.edu/mloss/),Journal of Machine Learning Research 14 (2013) 801-805,http://arxiv.org/abs/1210.6293v1,cs.MS,"['cs.MS', 'cs.CV', 'cs.LG']",,,[]
"Demonstrating the Usefulness of CAELinux for Computer Aided Engineering
  using an Example of the Three Dimensional Reconstruction of a Pig Liver",http://arxiv.org/abs/1210.8418v1,2012-10-26T03:14:03Z,2012-10-26T03:14:03Z,"  CAELinux is a Linux distribution which is bundled with free software packages
related to Computer Aided Engineering (CAE). The free software packages include
software that can build a three dimensional solid model, programs that can mesh
a geometry, software for carrying out Finite Element Analysis (FEA), programs
that can carry out image processing etc. Present work has two goals: 1) To give
a brief description of CAELinux 2) To demonstrate that CAELinux could be useful
for Computer Aided Engineering, using an example of the three dimensional
reconstruction of a pig liver from a stack of CT-scan images. One can note that
instead of using CAELinux, using commercial software for reconstructing the
liver would cost a lot of money. One can also note that CAELinux is a free and
open source operating system and all software packages that are included in the
operating system are also free. Hence one can conclude that CAELinux could be a
very useful tool in application areas like surgical simulation which require
three dimensional reconstructions of biological organs. Also, one can see that
CAELinux could be a very useful tool for Computer Aided Engineering, in
general.
","['\nKirana Kumara P.\nIndian Institute of Science, Bangalore, India\n']","10 pages, six *.JPG figures, uses html.sty, to be published in
  International Journal of Advancements in Technology (ISSN : 0976-4860)","International Journal of Advancements in Technology Vol. 3 No. 4
  (December 2012) pp. 301-309",http://arxiv.org/abs/1210.8418v1,cs.MS,"['cs.MS', 'physics.bio-ph', 'physics.comp-ph', 'physics.med-ph']",,,"['Indian Institute of Science, Bangalore, India']"
SMAT: An Input Adaptive Sparse Matrix-Vector Multiplication Auto-Tuner,http://arxiv.org/abs/1210.2536v1,2012-10-09T09:19:43Z,2012-10-09T09:19:43Z,"  Sparse matrix vector multiplication (SpMV) is an important kernel in
scientific and engineering applications. The previous optimizations are sparse
matrix format specific and expose the choice of the best format to application
programmers. In this work we develop an auto-tuning framework to bridge gap
between the specific optimized kernels and their general-purpose use. We
propose an SpMV auto-tuner (SMAT) that provides an unified interface based on
compressed sparse row (CSR) to programmers by implicitly choosing the best
format and the fastest implementation of any input sparse matrix in runtime.
SMAT leverage a data mining model, which is formulated based on a set of
performance parameters extracted from 2373 matrices in UF sparse matrix
collection, to fast search the best combination. The experiments show that SMAT
achieves the maximum performance of 75 GFLOP/s in single-precision and 33
GFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34
GFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL
library, SMAT runs faster by more than 3 times.
","['\nJiajia Li\n', '\nXiuxia Zhang\n', '\nGuangming Tan\n', '\nMingyu Chen\n']",,,http://arxiv.org/abs/1210.2536v1,cs.MS,"['cs.MS', 'cs.DC']",,,[]
Regular and Singular Boundary Problems in Maple,http://arxiv.org/abs/1210.2951v1,2012-10-10T15:13:55Z,2012-10-10T15:13:55Z,"  We describe a new Maple package for treating boundary problems for linear
ordinary differential equations, allowing two-/multipoint as well as Stieltjes
boundary conditions. For expressing differential operators, boundary
conditions, and Green's operators, we employ the algebra of
integro-differential operators. The operations implemented for regular boundary
problems include computing Green's operators as well as composing and factoring
boundary problems. Our symbolic approach to singular boundary problems is new;
it provides algorithms for computing compatibility conditions and generalized
Green's operators.
","['\nAnja Korporal\n', '\nGeorg Regensburger\n', '\nMarkus Rosenkranz\n']","14 pages; Berlin/Heidelberg, Springer","Computer Algebra in Scientific Computing (CASC 2011), LNCS 6885,
  pp. 280-293, 2011",http://dx.doi.org/10.1007/978-3-642-23568-9_22,cs.SC,"['cs.SC', 'cs.MS', '68W30']",10.1007/978-3-642-23568-9_22,,[]
"Symbolic Analysis for Boundary Problems: From Rewriting to Parametrized
  Gröbner Bases",http://arxiv.org/abs/1210.2950v1,2012-10-10T15:11:49Z,2012-10-10T15:11:49Z,"  We review our algebraic framework for linear boundary problems (concentrating
on ordinary differential equations). Its starting point is an appropriate
algebraization of the domain of functions, which we have named
integro-differential algebras. The algebraic treatment of boundary problems
brings up two new algebraic structures whose symbolic representation and
computational realization is based on canonical forms in certain commutative
and noncommutative polynomial domains. The first of these, the ring of
integro-differential operators, is used for both stating and solving linear
boundary problems. The other structure, called integro-differential
polynomials, is the key tool for describing extensions of integro-differential
algebras. We use the canonical simplifier for integro-differential polynomials
for generating an automated proof establishing a canonical simplifier for
integro-differential operators. Our approach is fully implemented in the
Theorema system; some code fragments and sample computations are included.
","['\nMarkus Rosenkranz\n', '\nGeorg Regensburger\n', '\nLoredana Tec\n', '\nBruno Buchberger\n']",54 pages,"Numerical and Symbolic Scientific Computing, Vol. 1, pp. 273-331,
  2012",http://dx.doi.org/10.1007/978-3-7091-0794-2_13,cs.SC,"['cs.SC', 'cs.MS', 'math.CA', '65L10, 34B05, 13P10, 54J05, 45P05, 68W30']",10.1007/978-3-7091-0794-2_13,,[]
"On Newton-Raphson iteration for multiplicative inverses modulo prime
  powers",http://arxiv.org/abs/1209.6626v5,2012-09-28T19:52:06Z,2018-05-15T10:10:49Z,"  We study algorithms for the fast computation of modular inverses.
Newton-Raphson iteration over $p$-adic numbers gives a recurrence relation
computing modular inverse modulo $p^m$, that is logarithmic in $m$. We solve
the recurrence to obtain an explicit formula for the inverse. Then we study
different implementation variants of this iteration and show that our explicit
formula is interesting for small exponent values but slower or large exponent,
say of more than $700$ bits. Overall we thus propose a hybrid combination of
our explicit formula and the best asymptotic variants. This hybrid combination
yields then a constant factor improvement, also for large exponents.
",['\nJean-Guillaume Dumas\nCASYS\n'],,"IEEE Transactions on Computers, Institute of Electrical and
  Electronics Engineers, 2014, 63 (8), pp.2106-2109",http://dx.doi.org/10.1109/TC.2013.94,cs.SC,"['cs.SC', 'cs.MS']",10.1109/TC.2013.94,,['CASYS']
Best Practices for Scientific Computing,http://arxiv.org/abs/1210.0530v4,2012-10-01T01:04:04Z,2013-09-26T12:09:42Z,"  Scientists spend an increasing amount of time building and using software.
However, most scientists are never taught how to do this efficiently. As a
result, many are unaware of tools and practices that would allow them to write
more reliable and maintainable code with less effort. We describe a set of best
practices for scientific software development that have solid foundations in
research and experience, and that improve scientists' productivity and the
reliability of their software.
","['\nGreg Wilson\n', '\nD. A. Aruliah\n', '\nC. Titus Brown\n', '\nNeil P. Chue Hong\n', '\nMatt Davis\n', '\nRichard T. Guy\n', '\nSteven H. D. Haddock\n', '\nKaty Huff\n', '\nIan M. Mitchell\n', '\nMark Plumbley\n', '\nBen Waugh\n', '\nEthan P. White\n', '\nPaul Wilson\n']",18 pages,"PLOS Biology 12(1): e1001745, Jan 2014",http://dx.doi.org/10.1371/journal.pbio.1001745,cs.MS,"['cs.MS', 'cs.SE']",10.1371/journal.pbio.1001745,,[]
"Orthogononalization on a general purpose graphics processing unit with
  double double and quad double arithmetic",http://arxiv.org/abs/1210.0800v2,2012-10-02T15:08:27Z,2013-01-13T21:42:07Z,"  Our problem is to accurately solve linear systems on a general purpose
graphics processing unit with double double and quad double arithmetic. The
linear systems originate from the application of Newton's method on polynomial
systems. Newton's method is applied as a corrector in a path following method,
so the linear systems are solved in sequence and not simultaneously. One
solution path may require the solution of thousands of linear systems. In
previous work we reported good speedups with our implementation to evaluate and
differentiate polynomial systems on the NVIDIA Tesla C2050. Although the cost
of evaluation and differentiation often dominates the cost of linear system
solving in Newton's method, because of the limited bandwidth of the
communication between CPU and GPU, we cannot afford to send the linear system
to the CPU for solving during path tracking.
  Because of large degrees, the Jacobian matrix may contain extreme values,
requiring extended precision, leading to a significant overhead. This overhead
of multiprecision arithmetic is our main motivation to develop a massively
parallel algorithm. To allow overdetermined linear systems we solve linear
systems in the least squares sense, computing the QR decomposition of the
matrix by the modified Gram-Schmidt algorithm. We describe our implementation
of the modified Gram-Schmidt orthogonalization method for the NVIDIA Tesla
C2050, using double double and quad double arithmetic. Our experimental results
show that the achieved speedups are sufficiently high to compensate for the
overhead of one extra level of precision.
","['\nJan Verschelde\n', '\nGenady Yoffe\n']",replaced with revised version,,http://arxiv.org/abs/1210.0800v2,cs.MS,"['cs.MS', 'cs.DC', 'math.NA']",,,[]
"Writing Reusable Digital Geometry Algorithms in a Generic Image
  Processing Framework",http://arxiv.org/abs/1209.4233v1,2012-09-18T15:17:10Z,2012-09-18T15:17:10Z,"  Digital Geometry software should reflect the generality of the underlying
mathe- matics: mapping the latter to the former requires genericity. By
designing generic solutions, one can effectively reuse digital geometry data
structures and algorithms. We propose an image processing framework focused on
the Generic Programming paradigm in which an algorithm on the paper can be
turned into a single code, written once and usable with various input types.
This approach enables users to design and implement new methods at a lower
cost, try cross-domain experiments and help generalize results
","['\nRoland Levillain\nLIGM, LRDE\n', '\nThierry Géraud\nLRDE\n', '\nLaurent Najman\nLIGM\n']","Workshop on Applications of Discrete Geometry and Mathematical
  Morphology, Istanb : France (2010)",,http://dx.doi.org/10.1007/978-3-642-32313-3_10,cs.MS,"['cs.MS', 'cs.CV']",10.1007/978-3-642-32313-3_10,,"['LIGM, LRDE', 'LRDE', 'LIGM']"
